Using device: cuda:0
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    8209 filtered patches indexed
    8209 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7150 filtered patches indexed
    7150 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    4263 filtered patches indexed
    4263 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7180 filtered patches indexed
    7180 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    3248 filtered patches indexed
    3248 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 10372 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    5941 filtered patches indexed
    5941 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 10372 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    1871 filtered patches indexed
    1871 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 1939 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    1323 filtered patches indexed
    1323 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 1939 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    32 filtered patches indexed
    32 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 8775 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    4206 filtered patches indexed
    4206 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 8775 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    2151 filtered patches indexed
    2151 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 16438 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    8037 filtered patches indexed
    8037 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 16438 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    4220 filtered patches indexed
    4220 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 4874 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    1692 filtered patches indexed
    1692 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 4874 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    2039 filtered patches indexed
    2039 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    15720 filtered patches indexed
    15720 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    29135 filtered patches indexed
    29135 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Loading BEN data for train...
    237871 patches indexed
    237871 filtered patches indexed
    237871 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
==================================================
ROUND 1/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 1.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 40183 | mAP: 0.3860
macro     precision: 0.0526 | recall: 0.0000 | f1-score: 0.0000 | support: 40183 | mAP: 0.2669

==================================================
ROUND 2/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.4143 | recall: 0.2254 | f1-score: 0.2919 | support: 40183 | mAP: 0.4430
macro     precision: 0.1388 | recall: 0.0971 | f1-score: 0.0753 | support: 40183 | mAP: 0.3217

==================================================
ROUND 3/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.5113 | recall: 0.3958 | f1-score: 0.4462 | support: 40183 | mAP: 0.4977
macro     precision: 0.2280 | recall: 0.1750 | f1-score: 0.1556 | support: 40183 | mAP: 0.3474

==================================================
ROUND 4/25
==================================================
Finale Anzahl der Pruning-Patches: 17
Anzahl eindeutiger Klassen: 18
Klassenverteilung in den Pruning-Patches (Häufigkeiten): {'Marine waters': 9, 'Transitional woodland, shrub': 7, 'Mixed forest': 7, 'Coniferous forest': 6, 'Land principally occupied by agriculture, with significant areas of natural vegetation': 2, 'Inland waters': 1, 'Broad-leaved forest': 2, 'Arable land': 4, 'Urban fabric': 1, 'Industrial or commercial units': 1, 'Coastal wetlands': 2, 'Inland wetlands': 2, 'Pastures': 4, 'Complex cultivation patterns': 1, 'Moors, heathland and sclerophyllous vegetation': 1, 'Natural grassland and sparsely vegetated areas': 1, 'Beaches, dunes, sands': 1, 'Permanent crops': 1}
[INFO] Erstelle Prune Loader...
[INFO] 12 Patches nach Filterung übrig.
[SUCCESS] Prune Loader erfolgreich erstellt.
Starting relevance computation and pruning mask generation.
Type of components_relevances: <class 'collections.OrderedDict'>
Layer: conv1
Total layer relevance: 3.1377006445854846e+22
--------------------------------------------------
Layer: encoder.4.0.conv1
Total layer relevance: 1.8674457329868472e+22
--------------------------------------------------
Layer: encoder.4.0.conv2
Total layer relevance: 1.498569736077784e+22
--------------------------------------------------
Layer: encoder.4.0.conv3
Total layer relevance: 2.1939167365245153e+21
--------------------------------------------------
Layer: encoder.4.0.downsample.0
Total layer relevance: 2.202621631654269e+21
--------------------------------------------------
Layer: encoder.4.1.conv1
Total layer relevance: 4.304851025924404e+19
--------------------------------------------------
Layer: encoder.4.1.conv2
Total layer relevance: 3.172496985826735e+19
--------------------------------------------------
Layer: encoder.4.1.conv3
Total layer relevance: 7.916805876894138e+18
--------------------------------------------------
Layer: encoder.4.2.conv1
Total layer relevance: 7.293243420846326e+17
--------------------------------------------------
Layer: encoder.4.2.conv2
Total layer relevance: 5.1959284268374426e+17
--------------------------------------------------
Layer: encoder.4.2.conv3
Total layer relevance: 1.494788119545774e+17
--------------------------------------------------
Layer: encoder.5.0.conv1
Total layer relevance: 3.1199980320456704e+16
--------------------------------------------------
Layer: encoder.5.0.conv2
Total layer relevance: 2.631505846416179e+16
--------------------------------------------------
Layer: encoder.5.0.conv3
Total layer relevance: 4873193911222272.0
--------------------------------------------------
Layer: encoder.5.0.downsample.0
Total layer relevance: 4900786928615424.0
--------------------------------------------------
Layer: encoder.5.1.conv1
Total layer relevance: 211831679352832.0
--------------------------------------------------
Layer: encoder.5.1.conv2
Total layer relevance: 205825285029888.0
--------------------------------------------------
Layer: encoder.5.1.conv3
Total layer relevance: 35246338736128.0
--------------------------------------------------
Layer: encoder.5.2.conv1
Total layer relevance: 5592528715776.0
--------------------------------------------------
Layer: encoder.5.2.conv2
Total layer relevance: 5436921610240.0
--------------------------------------------------
Layer: encoder.5.2.conv3
Total layer relevance: 590946893824.0
--------------------------------------------------
Layer: encoder.5.3.conv1
Total layer relevance: 67542659072.0
--------------------------------------------------
Layer: encoder.5.3.conv2
Total layer relevance: 75543298048.0
--------------------------------------------------
Layer: encoder.5.3.conv3
Total layer relevance: 11988402176.0
--------------------------------------------------
Layer: encoder.6.0.conv1
Total layer relevance: 1260199552.0
--------------------------------------------------
Layer: encoder.6.0.conv2
Total layer relevance: 1528732416.0
--------------------------------------------------
Layer: encoder.6.0.conv3
Total layer relevance: 345726784.0
--------------------------------------------------
Layer: encoder.6.0.downsample.0
Total layer relevance: 345135968.0
--------------------------------------------------
Layer: encoder.6.1.conv1
Total layer relevance: 31950396.0
--------------------------------------------------
Layer: encoder.6.1.conv2
Total layer relevance: 46286096.0
--------------------------------------------------
Layer: encoder.6.1.conv3
Total layer relevance: 13110689.0
--------------------------------------------------
Layer: encoder.6.2.conv1
Total layer relevance: 3461647.5
--------------------------------------------------
Layer: encoder.6.2.conv2
Total layer relevance: 5856456.0
--------------------------------------------------
Layer: encoder.6.2.conv3
Total layer relevance: 2108046.5
--------------------------------------------------
Layer: encoder.6.3.conv1
Total layer relevance: 770993.0
--------------------------------------------------
Layer: encoder.6.3.conv2
Total layer relevance: 2035710.75
--------------------------------------------------
Layer: encoder.6.3.conv3
Total layer relevance: 410016.75
--------------------------------------------------
Layer: encoder.6.4.conv1
Total layer relevance: 169686.1875
--------------------------------------------------
Layer: encoder.6.4.conv2
Total layer relevance: 338302.71875
--------------------------------------------------
Layer: encoder.6.4.conv3
Total layer relevance: 85980.234375
--------------------------------------------------
Layer: encoder.6.5.conv1
Total layer relevance: 45913.87109375
--------------------------------------------------
Layer: encoder.6.5.conv2
Total layer relevance: 115488.1953125
--------------------------------------------------
Layer: encoder.6.5.conv3
Total layer relevance: 14740.92578125
--------------------------------------------------
Layer: encoder.7.0.conv1
Total layer relevance: 1915.536865234375
--------------------------------------------------
Layer: encoder.7.0.conv2
Total layer relevance: 6783.2939453125
--------------------------------------------------
Layer: encoder.7.0.conv3
Total layer relevance: 3281.32177734375
--------------------------------------------------
Layer: encoder.7.0.downsample.0
Total layer relevance: 5383.65234375
--------------------------------------------------
Layer: encoder.7.1.conv1
Total layer relevance: 1716.4114990234375
--------------------------------------------------
Layer: encoder.7.1.conv2
Total layer relevance: 5487.18408203125
--------------------------------------------------
Layer: encoder.7.1.conv3
Total layer relevance: 3201.57568359375
--------------------------------------------------
Layer: encoder.7.2.conv1
Total layer relevance: 2995.706298828125
--------------------------------------------------
Layer: encoder.7.2.conv2
Total layer relevance: 3603.45361328125
--------------------------------------------------
Layer: encoder.7.2.conv3
Total layer relevance: 2133.101318359375
--------------------------------------------------
--------------------------------------------------
Global Pruning Mask
Pruning-rate: 0.3
Layer: conv1		% of pruned neurons: 0.00%
Layer: encoder.4.0.conv1		% of pruned neurons: 0.00%
Layer: encoder.4.0.conv2		% of pruned neurons: 0.00%
Layer: encoder.4.0.conv3		% of pruned neurons: 0.00%
Layer: encoder.4.0.downsample.0		% of pruned neurons: 0.00%
Layer: encoder.4.1.conv1		% of pruned neurons: 0.00%
Layer: encoder.4.1.conv2		% of pruned neurons: 0.00%
Layer: encoder.4.1.conv3		% of pruned neurons: 0.00%
Layer: encoder.4.2.conv1		% of pruned neurons: 0.00%
Layer: encoder.4.2.conv2		% of pruned neurons: 0.00%
Layer: encoder.4.2.conv3		% of pruned neurons: 0.00%
Layer: encoder.5.0.conv1		% of pruned neurons: 0.00%
Layer: encoder.5.0.conv2		% of pruned neurons: 0.00%
Layer: encoder.5.0.conv3		% of pruned neurons: 0.00%
Layer: encoder.5.0.downsample.0		% of pruned neurons: 0.00%
Layer: encoder.5.1.conv1		% of pruned neurons: 0.00%
Layer: encoder.5.1.conv2		% of pruned neurons: 0.00%
Layer: encoder.5.1.conv3		% of pruned neurons: 0.00%
Layer: encoder.5.2.conv1		% of pruned neurons: 0.00%
Layer: encoder.5.2.conv2		% of pruned neurons: 0.00%
Layer: encoder.5.2.conv3		% of pruned neurons: 0.00%
Layer: encoder.5.3.conv1		% of pruned neurons: 0.00%
Layer: encoder.5.3.conv2		% of pruned neurons: 0.00%
Layer: encoder.5.3.conv3		% of pruned neurons: 0.00%
Layer: encoder.6.0.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.0.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.0.conv3		% of pruned neurons: 0.00%
Layer: encoder.6.0.downsample.0		% of pruned neurons: 0.00%
Layer: encoder.6.1.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.1.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.1.conv3		% of pruned neurons: 0.00%
Layer: encoder.6.2.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.2.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.2.conv3		% of pruned neurons: 0.00%
Layer: encoder.6.3.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.3.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.3.conv3		% of pruned neurons: 0.68%
Layer: encoder.6.4.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.4.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.4.conv3		% of pruned neurons: 13.18%
Layer: encoder.6.5.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.5.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.5.conv3		% of pruned neurons: 72.95%
Layer: encoder.7.0.conv1		% of pruned neurons: 19.73%
Layer: encoder.7.0.conv2		% of pruned neurons: 0.00%
Layer: encoder.7.0.conv3		% of pruned neurons: 87.11%
Layer: encoder.7.0.downsample.0		% of pruned neurons: 70.46%
Layer: encoder.7.1.conv1		% of pruned neurons: 17.19%
Layer: encoder.7.1.conv2		% of pruned neurons: 0.39%
Layer: encoder.7.1.conv3		% of pruned neurons: 84.81%
Layer: encoder.7.2.conv1		% of pruned neurons: 2.15%
Layer: encoder.7.2.conv2		% of pruned neurons: 2.15%
Layer: encoder.7.2.conv3		% of pruned neurons: 92.87%
Sendeing pruning mask to clients...
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.6363 | recall: 0.4078 | f1-score: 0.4970 | support: 40183 | mAP: 0.5682
macro     precision: 0.2931 | recall: 0.1847 | f1-score: 0.1741 | support: 40183 | mAP: 0.3962

==================================================
ROUND 5/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.5906 | recall: 0.5577 | f1-score: 0.5737 | support: 40183 | mAP: 0.5937
macro     precision: 0.3654 | recall: 0.2549 | f1-score: 0.2267 | support: 40183 | mAP: 0.3847

==================================================
ROUND 6/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.6754 | recall: 0.6421 | f1-score: 0.6583 | support: 40183 | mAP: 0.7034
macro     precision: 0.4695 | recall: 0.3330 | f1-score: 0.3304 | support: 40183 | mAP: 0.4408

==================================================
ROUND 7/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.5662 | recall: 0.5943 | f1-score: 0.5799 | support: 40183 | mAP: 0.6304
macro     precision: 0.4052 | recall: 0.2927 | f1-score: 0.2714 | support: 40183 | mAP: 0.4017

==================================================
ROUND 8/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.6868 | recall: 0.6368 | f1-score: 0.6608 | support: 40183 | mAP: 0.7122
macro     precision: 0.4101 | recall: 0.3222 | f1-score: 0.3169 | support: 40183 | mAP: 0.4191

==================================================
ROUND 9/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.6003 | recall: 0.5611 | f1-score: 0.5800 | support: 40183 | mAP: 0.6062
macro     precision: 0.3625 | recall: 0.2856 | f1-score: 0.2853 | support: 40183 | mAP: 0.3884

==================================================
ROUND 10/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7494 | recall: 0.5849 | f1-score: 0.6570 | support: 40183 | mAP: 0.7056
macro     precision: 0.4251 | recall: 0.2926 | f1-score: 0.3096 | support: 40183 | mAP: 0.4415

==================================================
ROUND 11/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.6956 | recall: 0.5802 | f1-score: 0.6327 | support: 40183 | mAP: 0.6608
macro     precision: 0.3760 | recall: 0.2967 | f1-score: 0.3089 | support: 40183 | mAP: 0.4248

==================================================
ROUND 12/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7750 | recall: 0.5969 | f1-score: 0.6744 | support: 40183 | mAP: 0.7419
macro     precision: 0.4737 | recall: 0.3059 | f1-score: 0.3331 | support: 40183 | mAP: 0.4564

==================================================
ROUND 13/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7417 | recall: 0.5729 | f1-score: 0.6465 | support: 40183 | mAP: 0.7175
macro     precision: 0.4490 | recall: 0.2950 | f1-score: 0.3209 | support: 40183 | mAP: 0.4371

==================================================
ROUND 14/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7946 | recall: 0.5814 | f1-score: 0.6715 | support: 40183 | mAP: 0.7622
macro     precision: 0.6109 | recall: 0.3186 | f1-score: 0.3642 | support: 40183 | mAP: 0.4813

==================================================
ROUND 15/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.6951 | recall: 0.5709 | f1-score: 0.6270 | support: 40183 | mAP: 0.6763
macro     precision: 0.3968 | recall: 0.2970 | f1-score: 0.3155 | support: 40183 | mAP: 0.4283

==================================================
ROUND 16/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7789 | recall: 0.5616 | f1-score: 0.6527 | support: 40183 | mAP: 0.7432
macro     precision: 0.6197 | recall: 0.3000 | f1-score: 0.3451 | support: 40183 | mAP: 0.4705

==================================================
ROUND 17/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7311 | recall: 0.5684 | f1-score: 0.6395 | support: 40183 | mAP: 0.6998
macro     precision: 0.4058 | recall: 0.3058 | f1-score: 0.3289 | support: 40183 | mAP: 0.4339

==================================================
ROUND 18/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7769 | recall: 0.5829 | f1-score: 0.6661 | support: 40183 | mAP: 0.7520
macro     precision: 0.6097 | recall: 0.3165 | f1-score: 0.3570 | support: 40183 | mAP: 0.4587

==================================================
ROUND 19/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7746 | recall: 0.5484 | f1-score: 0.6421 | support: 40183 | mAP: 0.7283
macro     precision: 0.5224 | recall: 0.2979 | f1-score: 0.3394 | support: 40183 | mAP: 0.4518

==================================================
ROUND 20/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7792 | recall: 0.5743 | f1-score: 0.6613 | support: 40183 | mAP: 0.7369
macro     precision: 0.5847 | recall: 0.3129 | f1-score: 0.3581 | support: 40183 | mAP: 0.4564

==================================================
ROUND 21/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7403 | recall: 0.5539 | f1-score: 0.6337 | support: 40183 | mAP: 0.7093
macro     precision: 0.5116 | recall: 0.3017 | f1-score: 0.3287 | support: 40183 | mAP: 0.4435

==================================================
ROUND 22/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7630 | recall: 0.5479 | f1-score: 0.6378 | support: 40183 | mAP: 0.7073
macro     precision: 0.5261 | recall: 0.2965 | f1-score: 0.3283 | support: 40183 | mAP: 0.4390

==================================================
ROUND 23/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7378 | recall: 0.5119 | f1-score: 0.6044 | support: 40183 | mAP: 0.6909
macro     precision: 0.5181 | recall: 0.2725 | f1-score: 0.3077 | support: 40183 | mAP: 0.4319

==================================================
ROUND 24/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7622 | recall: 0.5551 | f1-score: 0.6424 | support: 40183 | mAP: 0.7182
macro     precision: 0.5390 | recall: 0.2957 | f1-score: 0.3296 | support: 40183 | mAP: 0.4420

==================================================
ROUND 25/25
==================================================
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
Epoch 1/3
----------
Epoch 2/3
----------
Epoch 3/3
----------
micro     precision: 0.7015 | recall: 0.5564 | f1-score: 0.6206 | support: 40183 | mAP: 0.6554
macro     precision: 0.5045 | recall: 0.3160 | f1-score: 0.3277 | support: 40183 | mAP: 0.4270

[{'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}]

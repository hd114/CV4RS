Using device: cuda:0
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    8209 filtered patches indexed
    8209 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    15720 filtered patches indexed
    15720 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
=== Round 1/5 ===
----------
Training and communication for Round 1...
Epoch 1/1
----------
Communication and training completed successfully.
Running validation...
Bug fix for empty classification report.
Validation completed successfully.
Updating results...
micro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.3981
macro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.2658

Results updated successfully.
Debug: Results successfully updated for Round 1. Proceeding to pruning...
Applying pruning after round 1...
Layer: conv1.weight | Mask shape: torch.Size([64, 10, 7, 7]) | Pruned: 9408/31360 (0.30)
Layer: encoder.0.weight | Mask shape: torch.Size([64, 10, 7, 7]) | Pruned: 9408/31360 (0.30)
Layer: encoder.1.weight | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.1.bias | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.1.running_mean | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.1.running_var | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.conv1.weight | Mask shape: torch.Size([64, 64, 1, 1]) | Pruned: 1228/4096 (0.30)
Layer: encoder.4.0.bn1.weight | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.bn1.bias | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.bn1.running_mean | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.bn1.running_var | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.conv2.weight | Mask shape: torch.Size([64, 64, 3, 3]) | Pruned: 11059/36864 (0.30)
Layer: encoder.4.0.bn2.weight | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.bn2.bias | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.bn2.running_mean | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.bn2.running_var | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.0.conv3.weight | Mask shape: torch.Size([256, 64, 1, 1]) | Pruned: 4915/16384 (0.30)
Layer: encoder.4.0.bn3.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.0.bn3.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.0.bn3.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.0.bn3.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.0.downsample.0.weight | Mask shape: torch.Size([256, 64, 1, 1]) | Pruned: 4915/16384 (0.30)
Layer: encoder.4.0.downsample.1.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.0.downsample.1.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.0.downsample.1.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.0.downsample.1.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.1.conv1.weight | Mask shape: torch.Size([64, 256, 1, 1]) | Pruned: 4915/16384 (0.30)
Layer: encoder.4.1.bn1.weight | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.1.bn1.bias | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.1.bn1.running_mean | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.1.bn1.running_var | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.1.conv2.weight | Mask shape: torch.Size([64, 64, 3, 3]) | Pruned: 11059/36864 (0.30)
Layer: encoder.4.1.bn2.weight | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.1.bn2.bias | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.1.bn2.running_mean | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.1.bn2.running_var | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.1.conv3.weight | Mask shape: torch.Size([256, 64, 1, 1]) | Pruned: 4915/16384 (0.30)
Layer: encoder.4.1.bn3.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.1.bn3.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.1.bn3.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.1.bn3.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.2.conv1.weight | Mask shape: torch.Size([64, 256, 1, 1]) | Pruned: 4915/16384 (0.30)
Layer: encoder.4.2.bn1.weight | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.2.bn1.bias | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.2.bn1.running_mean | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.2.bn1.running_var | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.2.conv2.weight | Mask shape: torch.Size([64, 64, 3, 3]) | Pruned: 11059/36864 (0.30)
Layer: encoder.4.2.bn2.weight | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.2.bn2.bias | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.2.bn2.running_mean | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.2.bn2.running_var | Mask shape: torch.Size([64]) | Pruned: 19/64 (0.30)
Layer: encoder.4.2.conv3.weight | Mask shape: torch.Size([256, 64, 1, 1]) | Pruned: 4915/16384 (0.30)
Layer: encoder.4.2.bn3.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.2.bn3.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.2.bn3.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.4.2.bn3.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.5.0.conv1.weight | Mask shape: torch.Size([128, 256, 1, 1]) | Pruned: 9830/32768 (0.30)
Layer: encoder.5.0.bn1.weight | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.0.bn1.bias | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.0.bn1.running_mean | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.0.bn1.running_var | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.0.conv2.weight | Mask shape: torch.Size([128, 128, 3, 3]) | Pruned: 44236/147456 (0.30)
Layer: encoder.5.0.bn2.weight | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.0.bn2.bias | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.0.bn2.running_mean | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.0.bn2.running_var | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.0.conv3.weight | Mask shape: torch.Size([512, 128, 1, 1]) | Pruned: 19660/65536 (0.30)
Layer: encoder.5.0.bn3.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.0.bn3.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.0.bn3.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.0.bn3.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.0.downsample.0.weight | Mask shape: torch.Size([512, 256, 1, 1]) | Pruned: 39321/131072 (0.30)
Layer: encoder.5.0.downsample.1.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.0.downsample.1.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.0.downsample.1.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.0.downsample.1.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.1.conv1.weight | Mask shape: torch.Size([128, 512, 1, 1]) | Pruned: 19660/65536 (0.30)
Layer: encoder.5.1.bn1.weight | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.1.bn1.bias | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.1.bn1.running_mean | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.1.bn1.running_var | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.1.conv2.weight | Mask shape: torch.Size([128, 128, 3, 3]) | Pruned: 44236/147456 (0.30)
Layer: encoder.5.1.bn2.weight | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.1.bn2.bias | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.1.bn2.running_mean | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.1.bn2.running_var | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.1.conv3.weight | Mask shape: torch.Size([512, 128, 1, 1]) | Pruned: 19660/65536 (0.30)
Layer: encoder.5.1.bn3.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.1.bn3.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.1.bn3.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.1.bn3.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.2.conv1.weight | Mask shape: torch.Size([128, 512, 1, 1]) | Pruned: 19660/65536 (0.30)
Layer: encoder.5.2.bn1.weight | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.2.bn1.bias | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.2.bn1.running_mean | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.2.bn1.running_var | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.2.conv2.weight | Mask shape: torch.Size([128, 128, 3, 3]) | Pruned: 44236/147456 (0.30)
Layer: encoder.5.2.bn2.weight | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.2.bn2.bias | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.2.bn2.running_mean | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.2.bn2.running_var | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.2.conv3.weight | Mask shape: torch.Size([512, 128, 1, 1]) | Pruned: 19660/65536 (0.30)
Layer: encoder.5.2.bn3.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.2.bn3.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.2.bn3.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.2.bn3.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.3.conv1.weight | Mask shape: torch.Size([128, 512, 1, 1]) | Pruned: 19660/65536 (0.30)
Layer: encoder.5.3.bn1.weight | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.3.bn1.bias | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.3.bn1.running_mean | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.3.bn1.running_var | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.3.conv2.weight | Mask shape: torch.Size([128, 128, 3, 3]) | Pruned: 44236/147456 (0.30)
Layer: encoder.5.3.bn2.weight | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.3.bn2.bias | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.3.bn2.running_mean | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.3.bn2.running_var | Mask shape: torch.Size([128]) | Pruned: 38/128 (0.30)
Layer: encoder.5.3.conv3.weight | Mask shape: torch.Size([512, 128, 1, 1]) | Pruned: 19660/65536 (0.30)
Layer: encoder.5.3.bn3.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.3.bn3.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.3.bn3.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.5.3.bn3.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.6.0.conv1.weight | Mask shape: torch.Size([256, 512, 1, 1]) | Pruned: 39321/131072 (0.30)
Layer: encoder.6.0.bn1.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.0.bn1.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.0.bn1.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.0.bn1.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.0.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Pruned: 176947/589824 (0.30)
Layer: encoder.6.0.bn2.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.0.bn2.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.0.bn2.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.0.bn2.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.0.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.0.bn3.weight | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.0.bn3.bias | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.0.bn3.running_mean | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.0.bn3.running_var | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.0.downsample.0.weight | Mask shape: torch.Size([1024, 512, 1, 1]) | Pruned: 157286/524288 (0.30)
Layer: encoder.6.0.downsample.1.weight | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.0.downsample.1.bias | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.0.downsample.1.running_mean | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.0.downsample.1.running_var | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.1.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.1.bn1.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.1.bn1.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.1.bn1.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.1.bn1.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.1.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Pruned: 176947/589824 (0.30)
Layer: encoder.6.1.bn2.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.1.bn2.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.1.bn2.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.1.bn2.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.1.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.1.bn3.weight | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.1.bn3.bias | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.1.bn3.running_mean | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.1.bn3.running_var | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.2.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.2.bn1.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.2.bn1.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.2.bn1.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.2.bn1.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.2.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Pruned: 176947/589824 (0.30)
Layer: encoder.6.2.bn2.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.2.bn2.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.2.bn2.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.2.bn2.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.2.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.2.bn3.weight | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.2.bn3.bias | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.2.bn3.running_mean | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.2.bn3.running_var | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.3.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.3.bn1.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.3.bn1.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.3.bn1.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.3.bn1.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.3.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Pruned: 176947/589824 (0.30)
Layer: encoder.6.3.bn2.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.3.bn2.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.3.bn2.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.3.bn2.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.3.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.3.bn3.weight | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.3.bn3.bias | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.3.bn3.running_mean | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.3.bn3.running_var | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.4.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.4.bn1.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.4.bn1.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.4.bn1.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.4.bn1.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.4.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Pruned: 176947/589824 (0.30)
Layer: encoder.6.4.bn2.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.4.bn2.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.4.bn2.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.4.bn2.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.4.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.4.bn3.weight | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.4.bn3.bias | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.4.bn3.running_mean | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.4.bn3.running_var | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.5.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.5.bn1.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.5.bn1.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.5.bn1.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.5.bn1.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.5.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Pruned: 176947/589824 (0.30)
Layer: encoder.6.5.bn2.weight | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.5.bn2.bias | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.5.bn2.running_mean | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.5.bn2.running_var | Mask shape: torch.Size([256]) | Pruned: 76/256 (0.30)
Layer: encoder.6.5.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Pruned: 78643/262144 (0.30)
Layer: encoder.6.5.bn3.weight | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.5.bn3.bias | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.5.bn3.running_mean | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.6.5.bn3.running_var | Mask shape: torch.Size([1024]) | Pruned: 307/1024 (0.30)
Layer: encoder.7.0.conv1.weight | Mask shape: torch.Size([512, 1024, 1, 1]) | Pruned: 157286/524288 (0.30)
Layer: encoder.7.0.bn1.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.0.bn1.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.0.bn1.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.0.bn1.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.0.conv2.weight | Mask shape: torch.Size([512, 512, 3, 3]) | Pruned: 707788/2359296 (0.30)
Layer: encoder.7.0.bn2.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.0.bn2.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.0.bn2.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.0.bn2.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.0.conv3.weight | Mask shape: torch.Size([2048, 512, 1, 1]) | Pruned: 314572/1048576 (0.30)
Layer: encoder.7.0.bn3.weight | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.0.bn3.bias | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.0.bn3.running_mean | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.0.bn3.running_var | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.0.downsample.0.weight | Mask shape: torch.Size([2048, 1024, 1, 1]) | Pruned: 629145/2097152 (0.30)
Layer: encoder.7.0.downsample.1.weight | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.0.downsample.1.bias | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.0.downsample.1.running_mean | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.0.downsample.1.running_var | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.1.conv1.weight | Mask shape: torch.Size([512, 2048, 1, 1]) | Pruned: 314572/1048576 (0.30)
Layer: encoder.7.1.bn1.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.1.bn1.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.1.bn1.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.1.bn1.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.1.conv2.weight | Mask shape: torch.Size([512, 512, 3, 3]) | Pruned: 707788/2359296 (0.30)
Layer: encoder.7.1.bn2.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.1.bn2.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.1.bn2.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.1.bn2.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.1.conv3.weight | Mask shape: torch.Size([2048, 512, 1, 1]) | Pruned: 314572/1048576 (0.30)
Layer: encoder.7.1.bn3.weight | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.1.bn3.bias | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.1.bn3.running_mean | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.1.bn3.running_var | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.2.conv1.weight | Mask shape: torch.Size([512, 2048, 1, 1]) | Pruned: 314572/1048576 (0.30)
Layer: encoder.7.2.bn1.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.2.bn1.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.2.bn1.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.2.bn1.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.2.conv2.weight | Mask shape: torch.Size([512, 512, 3, 3]) | Pruned: 707788/2359296 (0.30)
Layer: encoder.7.2.bn2.weight | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.2.bn2.bias | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.2.bn2.running_mean | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.2.bn2.running_var | Mask shape: torch.Size([512]) | Pruned: 153/512 (0.30)
Layer: encoder.7.2.conv3.weight | Mask shape: torch.Size([2048, 512, 1, 1]) | Pruned: 314572/1048576 (0.30)
Layer: encoder.7.2.bn3.weight | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.2.bn3.bias | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.2.bn3.running_mean | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: encoder.7.2.bn3.running_var | Mask shape: torch.Size([2048]) | Pruned: 614/2048 (0.30)
Layer: FC.weight | Mask shape: torch.Size([19, 2048]) | Pruned: 11673/38912 (0.30)
Layer: FC.bias | Mask shape: torch.Size([19]) | Pruned: 5/19 (0.30)
Pruning completed successfully.
Generated pruning mask and pruned state_dict:
Layer: conv1.weight | Mask shape: torch.Size([64, 10, 7, 7]) | Non-zero elements: 21952.0/31360
Layer: encoder.0.weight | Mask shape: torch.Size([64, 10, 7, 7]) | Non-zero elements: 21952.0/31360
Layer: encoder.1.weight | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.1.bias | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.1.running_mean | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.1.running_var | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.conv1.weight | Mask shape: torch.Size([64, 64, 1, 1]) | Non-zero elements: 2868.0/4096
Layer: encoder.4.0.bn1.weight | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.bn1.bias | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.bn1.running_mean | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.bn1.running_var | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.conv2.weight | Mask shape: torch.Size([64, 64, 3, 3]) | Non-zero elements: 25805.0/36864
Layer: encoder.4.0.bn2.weight | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.bn2.bias | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.bn2.running_mean | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.bn2.running_var | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.0.conv3.weight | Mask shape: torch.Size([256, 64, 1, 1]) | Non-zero elements: 11469.0/16384
Layer: encoder.4.0.bn3.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.0.bn3.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.0.bn3.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.0.bn3.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.0.downsample.0.weight | Mask shape: torch.Size([256, 64, 1, 1]) | Non-zero elements: 11469.0/16384
Layer: encoder.4.0.downsample.1.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.0.downsample.1.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.0.downsample.1.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.0.downsample.1.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.1.conv1.weight | Mask shape: torch.Size([64, 256, 1, 1]) | Non-zero elements: 11469.0/16384
Layer: encoder.4.1.bn1.weight | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.1.bn1.bias | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.1.bn1.running_mean | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.1.bn1.running_var | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.1.conv2.weight | Mask shape: torch.Size([64, 64, 3, 3]) | Non-zero elements: 25805.0/36864
Layer: encoder.4.1.bn2.weight | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.1.bn2.bias | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.1.bn2.running_mean | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.1.bn2.running_var | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.1.conv3.weight | Mask shape: torch.Size([256, 64, 1, 1]) | Non-zero elements: 11469.0/16384
Layer: encoder.4.1.bn3.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.1.bn3.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.1.bn3.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.1.bn3.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.2.conv1.weight | Mask shape: torch.Size([64, 256, 1, 1]) | Non-zero elements: 11469.0/16384
Layer: encoder.4.2.bn1.weight | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.2.bn1.bias | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.2.bn1.running_mean | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.2.bn1.running_var | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.2.conv2.weight | Mask shape: torch.Size([64, 64, 3, 3]) | Non-zero elements: 25805.0/36864
Layer: encoder.4.2.bn2.weight | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.2.bn2.bias | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.2.bn2.running_mean | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.2.bn2.running_var | Mask shape: torch.Size([64]) | Non-zero elements: 45.0/64
Layer: encoder.4.2.conv3.weight | Mask shape: torch.Size([256, 64, 1, 1]) | Non-zero elements: 11469.0/16384
Layer: encoder.4.2.bn3.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.2.bn3.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.2.bn3.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.4.2.bn3.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.5.0.conv1.weight | Mask shape: torch.Size([128, 256, 1, 1]) | Non-zero elements: 22938.0/32768
Layer: encoder.5.0.bn1.weight | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.0.bn1.bias | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.0.bn1.running_mean | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.0.bn1.running_var | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.0.conv2.weight | Mask shape: torch.Size([128, 128, 3, 3]) | Non-zero elements: 103220.0/147456
Layer: encoder.5.0.bn2.weight | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.0.bn2.bias | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.0.bn2.running_mean | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.0.bn2.running_var | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.0.conv3.weight | Mask shape: torch.Size([512, 128, 1, 1]) | Non-zero elements: 45876.0/65536
Layer: encoder.5.0.bn3.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.0.bn3.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.0.bn3.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.0.bn3.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.0.downsample.0.weight | Mask shape: torch.Size([512, 256, 1, 1]) | Non-zero elements: 91751.0/131072
Layer: encoder.5.0.downsample.1.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.0.downsample.1.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.0.downsample.1.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.0.downsample.1.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.1.conv1.weight | Mask shape: torch.Size([128, 512, 1, 1]) | Non-zero elements: 45876.0/65536
Layer: encoder.5.1.bn1.weight | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.1.bn1.bias | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.1.bn1.running_mean | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.1.bn1.running_var | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.1.conv2.weight | Mask shape: torch.Size([128, 128, 3, 3]) | Non-zero elements: 103220.0/147456
Layer: encoder.5.1.bn2.weight | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.1.bn2.bias | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.1.bn2.running_mean | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.1.bn2.running_var | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.1.conv3.weight | Mask shape: torch.Size([512, 128, 1, 1]) | Non-zero elements: 45876.0/65536
Layer: encoder.5.1.bn3.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.1.bn3.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.1.bn3.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.1.bn3.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.2.conv1.weight | Mask shape: torch.Size([128, 512, 1, 1]) | Non-zero elements: 45876.0/65536
Layer: encoder.5.2.bn1.weight | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.2.bn1.bias | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.2.bn1.running_mean | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.2.bn1.running_var | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.2.conv2.weight | Mask shape: torch.Size([128, 128, 3, 3]) | Non-zero elements: 103220.0/147456
Layer: encoder.5.2.bn2.weight | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.2.bn2.bias | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.2.bn2.running_mean | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.2.bn2.running_var | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.2.conv3.weight | Mask shape: torch.Size([512, 128, 1, 1]) | Non-zero elements: 45876.0/65536
Layer: encoder.5.2.bn3.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.2.bn3.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.2.bn3.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.2.bn3.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.3.conv1.weight | Mask shape: torch.Size([128, 512, 1, 1]) | Non-zero elements: 45876.0/65536
Layer: encoder.5.3.bn1.weight | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.3.bn1.bias | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.3.bn1.running_mean | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.3.bn1.running_var | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.3.conv2.weight | Mask shape: torch.Size([128, 128, 3, 3]) | Non-zero elements: 103220.0/147456
Layer: encoder.5.3.bn2.weight | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.3.bn2.bias | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.3.bn2.running_mean | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.3.bn2.running_var | Mask shape: torch.Size([128]) | Non-zero elements: 90.0/128
Layer: encoder.5.3.conv3.weight | Mask shape: torch.Size([512, 128, 1, 1]) | Non-zero elements: 45876.0/65536
Layer: encoder.5.3.bn3.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.3.bn3.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.3.bn3.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.5.3.bn3.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.6.0.conv1.weight | Mask shape: torch.Size([256, 512, 1, 1]) | Non-zero elements: 91751.0/131072
Layer: encoder.6.0.bn1.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.0.bn1.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.0.bn1.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.0.bn1.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.0.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Non-zero elements: 412877.0/589824
Layer: encoder.6.0.bn2.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.0.bn2.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.0.bn2.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.0.bn2.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.0.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.0.bn3.weight | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.0.bn3.bias | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.0.bn3.running_mean | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.0.bn3.running_var | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.0.downsample.0.weight | Mask shape: torch.Size([1024, 512, 1, 1]) | Non-zero elements: 367002.0/524288
Layer: encoder.6.0.downsample.1.weight | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.0.downsample.1.bias | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.0.downsample.1.running_mean | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.0.downsample.1.running_var | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.1.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.1.bn1.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.1.bn1.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.1.bn1.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.1.bn1.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.1.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Non-zero elements: 412877.0/589824
Layer: encoder.6.1.bn2.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.1.bn2.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.1.bn2.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.1.bn2.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.1.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.1.bn3.weight | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.1.bn3.bias | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.1.bn3.running_mean | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.1.bn3.running_var | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.2.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.2.bn1.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.2.bn1.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.2.bn1.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.2.bn1.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.2.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Non-zero elements: 412877.0/589824
Layer: encoder.6.2.bn2.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.2.bn2.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.2.bn2.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.2.bn2.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.2.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.2.bn3.weight | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.2.bn3.bias | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.2.bn3.running_mean | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.2.bn3.running_var | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.3.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.3.bn1.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.3.bn1.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.3.bn1.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.3.bn1.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.3.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Non-zero elements: 412877.0/589824
Layer: encoder.6.3.bn2.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.3.bn2.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.3.bn2.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.3.bn2.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.3.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.3.bn3.weight | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.3.bn3.bias | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.3.bn3.running_mean | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.3.bn3.running_var | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.4.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.4.bn1.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.4.bn1.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.4.bn1.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.4.bn1.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.4.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Non-zero elements: 412877.0/589824
Layer: encoder.6.4.bn2.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.4.bn2.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.4.bn2.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.4.bn2.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.4.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.4.bn3.weight | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.4.bn3.bias | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.4.bn3.running_mean | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.4.bn3.running_var | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.5.conv1.weight | Mask shape: torch.Size([256, 1024, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.5.bn1.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.5.bn1.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.5.bn1.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.5.bn1.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.5.conv2.weight | Mask shape: torch.Size([256, 256, 3, 3]) | Non-zero elements: 412877.0/589824
Layer: encoder.6.5.bn2.weight | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.5.bn2.bias | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.5.bn2.running_mean | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.5.bn2.running_var | Mask shape: torch.Size([256]) | Non-zero elements: 180.0/256
Layer: encoder.6.5.conv3.weight | Mask shape: torch.Size([1024, 256, 1, 1]) | Non-zero elements: 183501.0/262144
Layer: encoder.6.5.bn3.weight | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.5.bn3.bias | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.5.bn3.running_mean | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.6.5.bn3.running_var | Mask shape: torch.Size([1024]) | Non-zero elements: 717.0/1024
Layer: encoder.7.0.conv1.weight | Mask shape: torch.Size([512, 1024, 1, 1]) | Non-zero elements: 367002.0/524288
Layer: encoder.7.0.bn1.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.0.bn1.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.0.bn1.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.0.bn1.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.0.conv2.weight | Mask shape: torch.Size([512, 512, 3, 3]) | Non-zero elements: 1651508.0/2359296
Layer: encoder.7.0.bn2.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.0.bn2.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.0.bn2.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.0.bn2.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.0.conv3.weight | Mask shape: torch.Size([2048, 512, 1, 1]) | Non-zero elements: 734004.0/1048576
Layer: encoder.7.0.bn3.weight | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.0.bn3.bias | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.0.bn3.running_mean | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.0.bn3.running_var | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.0.downsample.0.weight | Mask shape: torch.Size([2048, 1024, 1, 1]) | Non-zero elements: 1468007.0/2097152
Layer: encoder.7.0.downsample.1.weight | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.0.downsample.1.bias | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.0.downsample.1.running_mean | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.0.downsample.1.running_var | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.1.conv1.weight | Mask shape: torch.Size([512, 2048, 1, 1]) | Non-zero elements: 734004.0/1048576
Layer: encoder.7.1.bn1.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.1.bn1.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.1.bn1.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.1.bn1.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.1.conv2.weight | Mask shape: torch.Size([512, 512, 3, 3]) | Non-zero elements: 1651508.0/2359296
Layer: encoder.7.1.bn2.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.1.bn2.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.1.bn2.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.1.bn2.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.1.conv3.weight | Mask shape: torch.Size([2048, 512, 1, 1]) | Non-zero elements: 734004.0/1048576
Layer: encoder.7.1.bn3.weight | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.1.bn3.bias | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.1.bn3.running_mean | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.1.bn3.running_var | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.2.conv1.weight | Mask shape: torch.Size([512, 2048, 1, 1]) | Non-zero elements: 734004.0/1048576
Layer: encoder.7.2.bn1.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.2.bn1.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.2.bn1.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.2.bn1.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.2.conv2.weight | Mask shape: torch.Size([512, 512, 3, 3]) | Non-zero elements: 1651508.0/2359296
Layer: encoder.7.2.bn2.weight | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.2.bn2.bias | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.2.bn2.running_mean | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.2.bn2.running_var | Mask shape: torch.Size([512]) | Non-zero elements: 359.0/512
Layer: encoder.7.2.conv3.weight | Mask shape: torch.Size([2048, 512, 1, 1]) | Non-zero elements: 734004.0/1048576
Layer: encoder.7.2.bn3.weight | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.2.bn3.bias | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.2.bn3.running_mean | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: encoder.7.2.bn3.running_var | Mask shape: torch.Size([2048]) | Non-zero elements: 1434.0/2048
Layer: FC.weight | Mask shape: torch.Size([19, 2048]) | Non-zero elements: 27239.0/38912
Layer: FC.bias | Mask shape: torch.Size([19]) | Non-zero elements: 14.0/19
Pruned state_dict successfully loaded.
Reapplying pruning mask directly...
Pruning mask reapplied successfully.
Distributing pruning mask to all clients...
Pruning mask distributed to all clients.
=== End of Round 1/5 ===

=== Round 2/5 ===
----------
Applying global pruning mask...
Applied mask to layer conv1.weight | Shape: torch.Size([64, 10, 7, 7])
Applied mask to layer encoder.0.weight | Shape: torch.Size([64, 10, 7, 7])
Applied mask to layer encoder.1.weight | Shape: torch.Size([64])
Applied mask to layer encoder.1.bias | Shape: torch.Size([64])
Applied mask to layer encoder.1.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.1.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.conv1.weight | Shape: torch.Size([64, 64, 1, 1])
Applied mask to layer encoder.4.0.bn1.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn1.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn1.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn1.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.conv2.weight | Shape: torch.Size([64, 64, 3, 3])
Applied mask to layer encoder.4.0.bn2.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn2.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn2.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn2.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.conv3.weight | Shape: torch.Size([256, 64, 1, 1])
Applied mask to layer encoder.4.0.bn3.weight | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.bn3.bias | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.bn3.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.bn3.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.downsample.0.weight | Shape: torch.Size([256, 64, 1, 1])
Applied mask to layer encoder.4.0.downsample.1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.downsample.1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.downsample.1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.downsample.1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.4.1.conv1.weight | Shape: torch.Size([64, 256, 1, 1])
Applied mask to layer encoder.4.1.bn1.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn1.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn1.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn1.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.conv2.weight | Shape: torch.Size([64, 64, 3, 3])
Applied mask to layer encoder.4.1.bn2.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn2.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn2.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn2.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.conv3.weight | Shape: torch.Size([256, 64, 1, 1])
Applied mask to layer encoder.4.1.bn3.weight | Shape: torch.Size([256])
Applied mask to layer encoder.4.1.bn3.bias | Shape: torch.Size([256])
Applied mask to layer encoder.4.1.bn3.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.4.1.bn3.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.4.2.conv1.weight | Shape: torch.Size([64, 256, 1, 1])
Applied mask to layer encoder.4.2.bn1.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn1.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn1.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn1.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.conv2.weight | Shape: torch.Size([64, 64, 3, 3])
Applied mask to layer encoder.4.2.bn2.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn2.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn2.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn2.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.conv3.weight | Shape: torch.Size([256, 64, 1, 1])
Applied mask to layer encoder.4.2.bn3.weight | Shape: torch.Size([256])
Applied mask to layer encoder.4.2.bn3.bias | Shape: torch.Size([256])
Applied mask to layer encoder.4.2.bn3.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.4.2.bn3.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.5.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1])
Applied mask to layer encoder.5.0.bn1.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn1.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn1.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn1.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.conv2.weight | Shape: torch.Size([128, 128, 3, 3])
Applied mask to layer encoder.5.0.bn2.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn2.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn2.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn2.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.conv3.weight | Shape: torch.Size([512, 128, 1, 1])
Applied mask to layer encoder.5.0.bn3.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.bn3.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.bn3.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.bn3.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.downsample.0.weight | Shape: torch.Size([512, 256, 1, 1])
Applied mask to layer encoder.5.0.downsample.1.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.downsample.1.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.downsample.1.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.downsample.1.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.5.1.conv1.weight | Shape: torch.Size([128, 512, 1, 1])
Applied mask to layer encoder.5.1.bn1.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn1.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn1.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn1.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.conv2.weight | Shape: torch.Size([128, 128, 3, 3])
Applied mask to layer encoder.5.1.bn2.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn2.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn2.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn2.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.conv3.weight | Shape: torch.Size([512, 128, 1, 1])
Applied mask to layer encoder.5.1.bn3.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.1.bn3.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.1.bn3.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.1.bn3.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.5.2.conv1.weight | Shape: torch.Size([128, 512, 1, 1])
Applied mask to layer encoder.5.2.bn1.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn1.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn1.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn1.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.conv2.weight | Shape: torch.Size([128, 128, 3, 3])
Applied mask to layer encoder.5.2.bn2.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn2.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn2.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn2.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.conv3.weight | Shape: torch.Size([512, 128, 1, 1])
Applied mask to layer encoder.5.2.bn3.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.2.bn3.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.2.bn3.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.2.bn3.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.5.3.conv1.weight | Shape: torch.Size([128, 512, 1, 1])
Applied mask to layer encoder.5.3.bn1.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn1.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn1.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn1.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.conv2.weight | Shape: torch.Size([128, 128, 3, 3])
Applied mask to layer encoder.5.3.bn2.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn2.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn2.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn2.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.conv3.weight | Shape: torch.Size([512, 128, 1, 1])
Applied mask to layer encoder.5.3.bn3.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.3.bn3.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.3.bn3.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.3.bn3.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.6.0.conv1.weight | Shape: torch.Size([256, 512, 1, 1])
Applied mask to layer encoder.6.0.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.0.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.0.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.downsample.0.weight | Shape: torch.Size([1024, 512, 1, 1])
Applied mask to layer encoder.6.0.downsample.1.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.downsample.1.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.downsample.1.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.downsample.1.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.1.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.1.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.1.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.1.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.1.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.1.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.1.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.2.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.2.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.2.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.2.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.2.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.2.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.2.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.3.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.3.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.3.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.3.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.3.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.3.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.3.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.4.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.4.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.4.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.4.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.4.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.4.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.4.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.5.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.5.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.5.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.5.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.5.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.5.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.5.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.7.0.conv1.weight | Shape: torch.Size([512, 1024, 1, 1])
Applied mask to layer encoder.7.0.bn1.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn1.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn1.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn1.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.conv2.weight | Shape: torch.Size([512, 512, 3, 3])
Applied mask to layer encoder.7.0.bn2.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn2.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn2.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn2.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.conv3.weight | Shape: torch.Size([2048, 512, 1, 1])
Applied mask to layer encoder.7.0.bn3.weight | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.bn3.bias | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.bn3.running_mean | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.bn3.running_var | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.downsample.0.weight | Shape: torch.Size([2048, 1024, 1, 1])
Applied mask to layer encoder.7.0.downsample.1.weight | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.downsample.1.bias | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.downsample.1.running_mean | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.downsample.1.running_var | Shape: torch.Size([2048])
Applied mask to layer encoder.7.1.conv1.weight | Shape: torch.Size([512, 2048, 1, 1])
Applied mask to layer encoder.7.1.bn1.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn1.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn1.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn1.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.conv2.weight | Shape: torch.Size([512, 512, 3, 3])
Applied mask to layer encoder.7.1.bn2.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn2.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn2.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn2.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.conv3.weight | Shape: torch.Size([2048, 512, 1, 1])
Applied mask to layer encoder.7.1.bn3.weight | Shape: torch.Size([2048])
Applied mask to layer encoder.7.1.bn3.bias | Shape: torch.Size([2048])
Applied mask to layer encoder.7.1.bn3.running_mean | Shape: torch.Size([2048])
Applied mask to layer encoder.7.1.bn3.running_var | Shape: torch.Size([2048])
Applied mask to layer encoder.7.2.conv1.weight | Shape: torch.Size([512, 2048, 1, 1])
Applied mask to layer encoder.7.2.bn1.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn1.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn1.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn1.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.conv2.weight | Shape: torch.Size([512, 512, 3, 3])
Applied mask to layer encoder.7.2.bn2.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn2.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn2.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn2.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.conv3.weight | Shape: torch.Size([2048, 512, 1, 1])
Applied mask to layer encoder.7.2.bn3.weight | Shape: torch.Size([2048])
Applied mask to layer encoder.7.2.bn3.bias | Shape: torch.Size([2048])
Applied mask to layer encoder.7.2.bn3.running_mean | Shape: torch.Size([2048])
Applied mask to layer encoder.7.2.bn3.running_var | Shape: torch.Size([2048])
Applied mask to layer FC.weight | Shape: torch.Size([19, 2048])
Applied mask to layer FC.bias | Shape: torch.Size([19])
Pruning mask successfully applied.
Training and communication for Round 2...
Epoch 1/1
----------
Communication and training completed successfully.
Running validation...
Bug fix for empty classification report.
Validation completed successfully.
Updating results...
micro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.3620
macro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.2599

Results updated successfully.
Debug: Results successfully updated for Round 2. Proceeding to pruning...
=== End of Round 2/5 ===

=== Round 3/5 ===
----------
Applying global pruning mask...
Applied mask to layer conv1.weight | Shape: torch.Size([64, 10, 7, 7])
Applied mask to layer encoder.0.weight | Shape: torch.Size([64, 10, 7, 7])
Applied mask to layer encoder.1.weight | Shape: torch.Size([64])
Applied mask to layer encoder.1.bias | Shape: torch.Size([64])
Applied mask to layer encoder.1.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.1.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.conv1.weight | Shape: torch.Size([64, 64, 1, 1])
Applied mask to layer encoder.4.0.bn1.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn1.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn1.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn1.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.conv2.weight | Shape: torch.Size([64, 64, 3, 3])
Applied mask to layer encoder.4.0.bn2.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn2.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn2.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.bn2.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.0.conv3.weight | Shape: torch.Size([256, 64, 1, 1])
Applied mask to layer encoder.4.0.bn3.weight | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.bn3.bias | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.bn3.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.bn3.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.downsample.0.weight | Shape: torch.Size([256, 64, 1, 1])
Applied mask to layer encoder.4.0.downsample.1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.downsample.1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.downsample.1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.4.0.downsample.1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.4.1.conv1.weight | Shape: torch.Size([64, 256, 1, 1])
Applied mask to layer encoder.4.1.bn1.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn1.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn1.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn1.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.conv2.weight | Shape: torch.Size([64, 64, 3, 3])
Applied mask to layer encoder.4.1.bn2.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn2.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn2.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.bn2.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.1.conv3.weight | Shape: torch.Size([256, 64, 1, 1])
Applied mask to layer encoder.4.1.bn3.weight | Shape: torch.Size([256])
Applied mask to layer encoder.4.1.bn3.bias | Shape: torch.Size([256])
Applied mask to layer encoder.4.1.bn3.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.4.1.bn3.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.4.2.conv1.weight | Shape: torch.Size([64, 256, 1, 1])
Applied mask to layer encoder.4.2.bn1.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn1.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn1.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn1.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.conv2.weight | Shape: torch.Size([64, 64, 3, 3])
Applied mask to layer encoder.4.2.bn2.weight | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn2.bias | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn2.running_mean | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.bn2.running_var | Shape: torch.Size([64])
Applied mask to layer encoder.4.2.conv3.weight | Shape: torch.Size([256, 64, 1, 1])
Applied mask to layer encoder.4.2.bn3.weight | Shape: torch.Size([256])
Applied mask to layer encoder.4.2.bn3.bias | Shape: torch.Size([256])
Applied mask to layer encoder.4.2.bn3.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.4.2.bn3.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.5.0.conv1.weight | Shape: torch.Size([128, 256, 1, 1])
Applied mask to layer encoder.5.0.bn1.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn1.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn1.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn1.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.conv2.weight | Shape: torch.Size([128, 128, 3, 3])
Applied mask to layer encoder.5.0.bn2.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn2.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn2.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.bn2.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.0.conv3.weight | Shape: torch.Size([512, 128, 1, 1])
Applied mask to layer encoder.5.0.bn3.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.bn3.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.bn3.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.bn3.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.downsample.0.weight | Shape: torch.Size([512, 256, 1, 1])
Applied mask to layer encoder.5.0.downsample.1.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.downsample.1.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.downsample.1.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.0.downsample.1.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.5.1.conv1.weight | Shape: torch.Size([128, 512, 1, 1])
Applied mask to layer encoder.5.1.bn1.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn1.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn1.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn1.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.conv2.weight | Shape: torch.Size([128, 128, 3, 3])
Applied mask to layer encoder.5.1.bn2.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn2.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn2.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.bn2.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.1.conv3.weight | Shape: torch.Size([512, 128, 1, 1])
Applied mask to layer encoder.5.1.bn3.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.1.bn3.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.1.bn3.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.1.bn3.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.5.2.conv1.weight | Shape: torch.Size([128, 512, 1, 1])
Applied mask to layer encoder.5.2.bn1.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn1.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn1.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn1.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.conv2.weight | Shape: torch.Size([128, 128, 3, 3])
Applied mask to layer encoder.5.2.bn2.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn2.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn2.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.bn2.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.2.conv3.weight | Shape: torch.Size([512, 128, 1, 1])
Applied mask to layer encoder.5.2.bn3.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.2.bn3.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.2.bn3.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.2.bn3.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.5.3.conv1.weight | Shape: torch.Size([128, 512, 1, 1])
Applied mask to layer encoder.5.3.bn1.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn1.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn1.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn1.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.conv2.weight | Shape: torch.Size([128, 128, 3, 3])
Applied mask to layer encoder.5.3.bn2.weight | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn2.bias | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn2.running_mean | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.bn2.running_var | Shape: torch.Size([128])
Applied mask to layer encoder.5.3.conv3.weight | Shape: torch.Size([512, 128, 1, 1])
Applied mask to layer encoder.5.3.bn3.weight | Shape: torch.Size([512])
Applied mask to layer encoder.5.3.bn3.bias | Shape: torch.Size([512])
Applied mask to layer encoder.5.3.bn3.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.5.3.bn3.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.6.0.conv1.weight | Shape: torch.Size([256, 512, 1, 1])
Applied mask to layer encoder.6.0.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.0.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.0.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.0.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.downsample.0.weight | Shape: torch.Size([1024, 512, 1, 1])
Applied mask to layer encoder.6.0.downsample.1.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.downsample.1.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.downsample.1.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.0.downsample.1.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.1.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.1.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.1.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.1.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.1.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.1.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.1.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.1.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.2.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.2.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.2.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.2.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.2.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.2.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.2.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.2.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.3.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.3.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.3.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.3.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.3.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.3.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.3.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.3.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.4.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.4.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.4.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.4.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.4.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.4.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.4.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.4.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.6.5.conv1.weight | Shape: torch.Size([256, 1024, 1, 1])
Applied mask to layer encoder.6.5.bn1.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn1.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn1.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn1.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.conv2.weight | Shape: torch.Size([256, 256, 3, 3])
Applied mask to layer encoder.6.5.bn2.weight | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn2.bias | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn2.running_mean | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.bn2.running_var | Shape: torch.Size([256])
Applied mask to layer encoder.6.5.conv3.weight | Shape: torch.Size([1024, 256, 1, 1])
Applied mask to layer encoder.6.5.bn3.weight | Shape: torch.Size([1024])
Applied mask to layer encoder.6.5.bn3.bias | Shape: torch.Size([1024])
Applied mask to layer encoder.6.5.bn3.running_mean | Shape: torch.Size([1024])
Applied mask to layer encoder.6.5.bn3.running_var | Shape: torch.Size([1024])
Applied mask to layer encoder.7.0.conv1.weight | Shape: torch.Size([512, 1024, 1, 1])
Applied mask to layer encoder.7.0.bn1.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn1.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn1.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn1.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.conv2.weight | Shape: torch.Size([512, 512, 3, 3])
Applied mask to layer encoder.7.0.bn2.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn2.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn2.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.bn2.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.0.conv3.weight | Shape: torch.Size([2048, 512, 1, 1])
Applied mask to layer encoder.7.0.bn3.weight | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.bn3.bias | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.bn3.running_mean | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.bn3.running_var | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.downsample.0.weight | Shape: torch.Size([2048, 1024, 1, 1])
Applied mask to layer encoder.7.0.downsample.1.weight | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.downsample.1.bias | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.downsample.1.running_mean | Shape: torch.Size([2048])
Applied mask to layer encoder.7.0.downsample.1.running_var | Shape: torch.Size([2048])
Applied mask to layer encoder.7.1.conv1.weight | Shape: torch.Size([512, 2048, 1, 1])
Applied mask to layer encoder.7.1.bn1.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn1.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn1.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn1.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.conv2.weight | Shape: torch.Size([512, 512, 3, 3])
Applied mask to layer encoder.7.1.bn2.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn2.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn2.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.bn2.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.1.conv3.weight | Shape: torch.Size([2048, 512, 1, 1])
Applied mask to layer encoder.7.1.bn3.weight | Shape: torch.Size([2048])
Applied mask to layer encoder.7.1.bn3.bias | Shape: torch.Size([2048])
Applied mask to layer encoder.7.1.bn3.running_mean | Shape: torch.Size([2048])
Applied mask to layer encoder.7.1.bn3.running_var | Shape: torch.Size([2048])
Applied mask to layer encoder.7.2.conv1.weight | Shape: torch.Size([512, 2048, 1, 1])
Applied mask to layer encoder.7.2.bn1.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn1.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn1.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn1.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.conv2.weight | Shape: torch.Size([512, 512, 3, 3])
Applied mask to layer encoder.7.2.bn2.weight | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn2.bias | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn2.running_mean | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.bn2.running_var | Shape: torch.Size([512])
Applied mask to layer encoder.7.2.conv3.weight | Shape: torch.Size([2048, 512, 1, 1])
Applied mask to layer encoder.7.2.bn3.weight | Shape: torch.Size([2048])
Applied mask to layer encoder.7.2.bn3.bias | Shape: torch.Size([2048])
Applied mask to layer encoder.7.2.bn3.running_mean | Shape: torch.Size([2048])
Applied mask to layer encoder.7.2.bn3.running_var | Shape: torch.Size([2048])
Applied mask to layer FC.weight | Shape: torch.Size([19, 2048])
Applied mask to layer FC.bias | Shape: torch.Size([19])
Pruning mask successfully applied.
Training and communication for Round 3...
Epoch 1/1
----------
Communication and training completed successfully.
Running validation...
NaN detected in logits during validation.
Error during validation: Logits contain NaN values during validation.

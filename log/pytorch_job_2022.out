Lines that potentially need to be canonized 309
Using device: cuda:0
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    8209 filtered patches indexed
    8209 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    15720 filtered patches indexed
    15720 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Initializing LRP Pruning...
LRP initialized successfully.
=== Round 1/3 ===
Training and communication for Round 1...
Epoch 1/1
----------
[INFO] Performing LRP Pruning in Round 1...
[INFO] Computing LRP pruning mask...
Erstelle DataLoader f√ºr Land: Finland
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([5])
Input shape before relevance computation: torch.Size([5, 10, 1, 5])
Model output shape: torch.Size([5, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([5, 19]) to 5 for one-hot encoding.
Targets shape: torch.Size([5])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([5, 19])
Relevance computation successful. Relevance shape: torch.Size([5, 10, 1, 5])
[INFO] Relevance maps computed for 53 layers.
[DEBUG] Layer: conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.0.downsample.0
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.1.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.1.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.1.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.2.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.2.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.2.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.5.0.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.0.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.0.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.0.downsample.0
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.1.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.1.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.1.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.2.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.2.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.2.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.3.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.3.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.3.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.6.0.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.0.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.0.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.0.downsample.0
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.1.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.1.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.1.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.2.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.2.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.2.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.3.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.3.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.3.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.4.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.4.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.4.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.5.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.5.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.5.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.7.0.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.0.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.0.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.0.downsample.0
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.1.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.1.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.1.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.2.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.2.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.2.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 1939
Layer: conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([8.4764e+18, 9.2369e+18, 8.2235e+18, 6.9870e+18, 7.8580e+18, 2.6565e+18,
        2.6888e+18, 5.6267e+18, 3.5170e+18, 4.9706e+18, 9.6892e+18, 4.4010e+18,
        3.5530e+18, 7.5134e+18, 4.8731e+18, 1.0240e+19, 6.7953e+18, 8.2446e+18,
        3.5069e+18, 1.2201e+19, 1.1152e+19, 1.4011e+19, 3.0002e+18, 4.1362e+18,
        8.2718e+18, 5.2660e+18, 6.9985e+18, 5.1748e+18, 1.0564e+19, 3.0602e+18,
        5.0393e+18, 9.0492e+18, 3.8013e+18, 6.2708e+18, 4.4776e+18, 4.4175e+18,
        8.2400e+18, 4.9201e+18, 9.5407e+18, 5.3625e+18, 7.3708e+18, 6.1560e+18,
        1.3856e+19, 7.3282e+18, 2.4946e+18, 1.6891e+19, 3.7779e+18, 9.2566e+18,
        3.9891e+18, 4.7259e+18, 5.7683e+18, 9.1379e+18, 7.7901e+18, 6.2218e+18,
        8.7787e+18, 7.3933e+18, 1.7527e+18, 6.6298e+18, 2.3036e+18, 1.3364e+18,
        3.5687e+18, 5.7305e+18, 4.4109e+18, 6.6324e+18])
Layer: encoder.4.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.4506e+18, 2.5554e+18, 1.3808e+18, 6.5084e+18, 1.4035e+18, 6.7342e+18,
        2.4894e+18, 2.1511e+18, 1.5997e+18, 3.8447e+18, 1.7114e+18, 3.2510e+18,
        7.3367e+18, 1.5828e+18, 1.8802e+18, 2.5998e+18, 3.2608e+18, 2.1175e+18,
        9.0292e+17, 2.6843e+18, 1.5194e+18, 1.8484e+18, 2.2395e+18, 9.3958e+17,
        4.9794e+18, 4.7308e+18, 2.2592e+18, 2.3330e+18, 2.3512e+18, 3.7664e+18,
        4.5445e+18, 1.6419e+18, 8.7603e+17, 8.9373e+17, 2.1042e+18, 2.6786e+18,
        7.3262e+18, 1.2874e+18, 1.5732e+18, 3.8252e+18, 1.1622e+18, 5.9606e+18,
        4.7272e+18, 5.9249e+18, 2.8995e+18, 2.0081e+18, 4.0616e+18, 1.4142e+18,
        3.9889e+18, 3.4447e+18, 1.5833e+18, 3.6155e+18, 3.9940e+18, 1.7776e+18,
        6.7565e+17, 4.5546e+18, 8.6429e+17, 5.8350e+17, 5.1947e+18, 2.0763e+18,
        5.2369e+18, 2.7631e+18, 3.6937e+18, 1.2930e+18])
Layer: encoder.4.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.0032e+18, 6.0348e+18, 2.1313e+18, 2.3491e+18, 1.6944e+18, 7.2938e+18,
        2.1033e+18, 7.7068e+18, 3.3933e+18, 2.7048e+18, 4.5715e+18, 1.2308e+18,
        2.9044e+18, 1.9467e+18, 2.0076e+18, 5.2043e+18, 2.1233e+18, 3.1831e+18,
        6.2573e+18, 3.2557e+18, 4.2114e+18, 2.8072e+18, 1.2914e+18, 3.2218e+18,
        6.2254e+18, 1.6225e+18, 1.4762e+18, 1.7229e+18, 5.1534e+18, 2.2729e+18,
        5.7700e+17, 2.5201e+18, 3.0021e+18, 3.2651e+18, 9.4006e+17, 1.8059e+18,
        6.1143e+18, 8.3629e+18, 8.4233e+17, 1.5316e+18, 3.7756e+18, 1.0607e+18,
        3.3888e+18, 2.6328e+18, 3.5298e+18, 2.4531e+18, 5.1032e+18, 3.6902e+18,
        1.5552e+18, 2.6134e+18, 3.4658e+18, 1.7867e+18, 2.1894e+18, 5.8175e+18,
        2.6283e+18, 1.6734e+18, 6.8533e+18, 1.8981e+18, 3.1365e+18, 3.9027e+18,
        1.2636e+18, 3.9543e+18, 7.7502e+18, 3.1627e+18])
Layer: encoder.4.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.6237e+17, 4.5827e+16, 1.9639e+17, 4.8343e+15, 1.1309e+17, 7.3003e+15,
        8.3004e+16, 1.4227e+17, 1.3845e+17, 2.6806e+17, 5.2655e+16, 6.0346e+16,
        3.5374e+16, 5.3261e+16, 1.8610e+17, 9.7792e+15, 8.6610e+16, 1.0280e+16,
        9.5647e+16, 1.4032e+18, 3.5603e+15, 1.0401e+17, 7.1413e+16, 6.6623e+16,
        8.9814e+15, 3.3275e+18, 1.5724e+17, 3.9636e+16, 3.1530e+16, 4.8117e+17,
        8.9427e+16, 1.2241e+16, 3.4247e+16, 2.9411e+17, 6.5534e+17, 3.3467e+16,
        2.6398e+16, 1.4248e+17, 4.6994e+16, 6.8103e+16, 2.7560e+17, 1.1719e+16,
        3.5707e+16, 7.1274e+15, 5.6194e+16, 5.5813e+15, 5.4214e+16, 1.2474e+16,
        5.2218e+15, 5.6124e+17, 4.6803e+16, 8.3527e+15, 5.8716e+16, 8.4404e+15,
        3.7022e+16, 2.0253e+17, 1.1079e+17, 3.2408e+16, 8.5712e+16, 7.6327e+17,
        9.4893e+15, 5.9076e+16, 3.5475e+16, 1.5734e+17, 1.1776e+17, 1.0584e+16,
        5.5014e+16, 6.0876e+15, 2.4412e+16, 3.1401e+16, 4.9099e+17, 1.9720e+17,
        2.2729e+16, 6.3762e+15, 9.2188e+16, 7.2649e+16, 1.3954e+17, 4.8840e+16,
        3.9900e+16, 2.8984e+16, 4.4637e+16, 1.9374e+16, 8.2095e+16, 1.3155e+18,
        2.2072e+16, 2.8352e+16, 1.4484e+16, 1.0994e+17, 7.7147e+17, 1.5276e+17,
        5.1322e+16, 6.5259e+16, 6.7355e+17, 8.9929e+16, 3.3709e+16, 5.1908e+16,
        1.8795e+16, 1.5296e+18, 7.6442e+15, 7.6327e+16, 2.0540e+17, 7.0634e+18,
        4.3288e+17, 1.3550e+17, 3.9216e+16, 8.7200e+17, 2.6086e+16, 5.5618e+16,
        2.9459e+17, 1.2646e+17, 1.7132e+16, 1.4895e+17, 2.5678e+16, 1.0024e+16,
        3.0685e+16, 1.3106e+18, 2.0388e+15, 1.1431e+17, 3.5661e+16, 8.0552e+16,
        1.9006e+16, 3.3089e+16, 9.8139e+15, 5.0486e+16, 4.5167e+15, 4.8002e+16,
        8.7242e+16, 3.2712e+16, 6.2462e+17, 1.0883e+16, 4.7784e+17, 3.1099e+16,
        8.2035e+16, 3.6705e+16, 2.0801e+16, 5.7936e+16, 6.1459e+15, 3.6478e+17,
        6.3222e+15, 4.1110e+17, 1.1609e+17, 1.3017e+16, 7.8717e+18, 4.1813e+15,
        8.6829e+15, 1.0377e+17, 7.3746e+16, 3.7240e+16, 4.3529e+16, 1.7968e+17,
        1.4221e+17, 3.3074e+16, 6.7040e+16, 5.2788e+16, 5.1007e+16, 1.4968e+16,
        2.5263e+17, 2.7929e+16, 7.3922e+16, 4.6183e+17, 3.5406e+16, 3.5956e+16,
        1.1707e+16, 1.6259e+17, 7.8934e+16, 7.6228e+16, 5.1418e+16, 1.4905e+16,
        3.4993e+16, 4.3197e+16, 2.0109e+16, 2.2971e+16, 1.3102e+18, 4.9324e+16,
        2.0078e+17, 1.5770e+17, 2.6973e+17, 2.9533e+16, 4.3477e+15, 2.3651e+17,
        1.0663e+17, 3.2713e+16, 2.4310e+16, 2.1713e+15, 3.9012e+16, 9.2492e+15,
        8.9177e+16, 1.0486e+17, 7.0044e+16, 5.3137e+16, 1.0252e+16, 1.6773e+17,
        1.6479e+17, 7.4061e+16, 1.0027e+17, 4.3523e+16, 1.9387e+16, 8.6381e+15,
        7.2774e+15, 1.8904e+16, 2.0516e+17, 5.9419e+17, 7.2143e+15, 1.0139e+17,
        6.1789e+16, 1.9433e+16, 1.7798e+16, 9.8612e+16, 5.3559e+17, 8.7428e+16,
        4.6561e+16, 2.0923e+16, 7.9420e+16, 7.0493e+16, 7.0043e+16, 4.1362e+17,
        2.7257e+16, 4.1115e+17, 6.2755e+16, 3.2281e+15, 2.6271e+16, 4.0613e+16,
        1.0073e+17, 1.7290e+16, 7.5127e+15, 1.1975e+17, 5.1843e+16, 8.0779e+16,
        4.7731e+17, 1.4371e+17, 1.9584e+17, 1.4281e+17, 2.9997e+16, 1.6228e+16,
        1.7612e+15, 8.0790e+16, 1.2449e+16, 1.3773e+17, 2.5705e+16, 1.5675e+16,
        3.4771e+17, 2.3397e+16, 3.5383e+16, 7.1367e+15, 2.9998e+16, 7.0038e+16,
        2.7556e+15, 8.2673e+16, 3.1695e+18, 1.6627e+17, 1.9789e+17, 2.8703e+16,
        1.1517e+17, 4.8458e+16, 3.0551e+17, 2.6406e+17])
Layer: encoder.4.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.2777e+17, 6.2108e+16, 3.2038e+17, 3.7952e+16, 6.4033e+16, 3.2049e+16,
        1.2054e+17, 1.3565e+17, 2.2434e+17, 2.6148e+17, 4.0241e+16, 3.4765e+16,
        1.0117e+16, 4.8546e+16, 8.1904e+16, 5.8959e+16, 2.5986e+15, 4.4232e+16,
        1.5849e+17, 1.4143e+18, 3.5845e+16, 3.3933e+16, 6.9179e+16, 1.4176e+16,
        2.2681e+16, 3.3420e+18, 7.4057e+16, 5.3037e+16, 6.0118e+16, 5.2594e+17,
        6.7171e+16, 7.6543e+16, 1.6677e+16, 3.7277e+17, 5.6703e+17, 4.2996e+16,
        1.1788e+17, 1.5564e+16, 1.1051e+17, 3.4673e+16, 3.2332e+17, 6.1931e+16,
        2.9498e+16, 4.3005e+16, 6.6775e+16, 1.3352e+16, 2.9377e+16, 8.0257e+16,
        3.2956e+16, 6.3368e+17, 6.2577e+16, 9.7191e+15, 1.2268e+16, 3.0390e+16,
        1.4454e+17, 1.5853e+17, 1.3965e+17, 3.5144e+16, 7.2414e+16, 6.5567e+17,
        1.6657e+16, 8.7638e+16, 5.7520e+16, 7.5949e+16, 6.4641e+15, 4.1100e+16,
        2.1754e+16, 5.5061e+16, 6.1858e+16, 2.7490e+16, 4.8314e+17, 7.0828e+16,
        7.6395e+16, 6.5132e+16, 7.1919e+16, 1.0617e+17, 7.8039e+16, 4.0233e+16,
        5.8466e+16, 1.5646e+17, 2.4552e+16, 4.6201e+16, 2.6179e+16, 1.2561e+18,
        3.8997e+16, 7.3403e+16, 3.8462e+16, 1.3430e+17, 8.1408e+17, 1.2580e+17,
        7.8124e+15, 4.4496e+16, 6.4116e+17, 2.7012e+16, 3.1158e+16, 1.5170e+16,
        3.4776e+16, 1.4844e+18, 9.1007e+16, 7.2359e+16, 4.9650e+16, 7.0416e+18,
        3.8598e+17, 8.8928e+16, 3.3357e+16, 9.0851e+17, 9.6293e+15, 3.0483e+16,
        3.0319e+17, 1.2778e+17, 8.2597e+16, 1.8338e+17, 7.7301e+16, 2.1832e+16,
        2.3233e+16, 1.3664e+18, 5.2503e+16, 1.1328e+17, 2.5158e+16, 1.2021e+17,
        1.2554e+17, 4.5112e+16, 2.2041e+16, 2.9357e+16, 4.0839e+16, 2.4892e+16,
        7.4223e+16, 2.3784e+16, 5.4437e+17, 3.2425e+16, 3.9704e+17, 2.2864e+16,
        8.0932e+15, 2.8138e+16, 7.0608e+16, 2.6915e+16, 2.2699e+16, 3.7669e+17,
        6.3004e+16, 5.1031e+17, 1.3589e+17, 2.7975e+16, 7.9382e+18, 1.4066e+16,
        1.7844e+16, 5.8204e+16, 1.2987e+16, 2.9002e+16, 3.2508e+16, 1.5075e+17,
        1.6067e+17, 8.3037e+16, 7.6609e+15, 2.1833e+16, 1.2189e+17, 6.1956e+15,
        1.8817e+17, 2.1766e+16, 1.7411e+16, 4.5992e+17, 9.9186e+16, 3.3001e+16,
        1.4052e+16, 1.0923e+17, 7.3444e+16, 8.2860e+16, 5.4437e+16, 8.4406e+16,
        1.7692e+16, 7.5999e+16, 6.3998e+16, 1.8796e+16, 1.4073e+18, 7.8461e+16,
        2.1067e+17, 1.4839e+17, 2.7279e+17, 1.1475e+16, 5.1078e+16, 1.4347e+17,
        3.2795e+16, 1.3561e+17, 3.0477e+16, 2.4668e+16, 2.2128e+16, 5.6360e+16,
        8.4043e+16, 1.1411e+16, 1.1511e+16, 2.0200e+16, 3.0656e+16, 1.9842e+17,
        1.2727e+17, 3.1664e+16, 2.0342e+17, 2.4562e+16, 5.9706e+16, 2.4062e+16,
        6.2771e+16, 1.0321e+16, 2.5762e+17, 5.1017e+17, 1.7392e+16, 1.6183e+17,
        4.6151e+16, 5.8311e+16, 3.7143e+16, 1.2210e+17, 4.5932e+17, 6.8484e+16,
        5.4825e+16, 7.3852e+16, 1.3563e+17, 1.4134e+17, 5.7961e+15, 3.5141e+17,
        1.1185e+17, 4.5770e+17, 7.3209e+16, 1.7804e+16, 2.0016e+16, 4.5038e+16,
        4.0716e+16, 5.5260e+16, 1.8358e+16, 6.8487e+16, 1.0608e+17, 1.2130e+17,
        4.0182e+17, 1.6360e+17, 1.0260e+17, 1.9825e+17, 4.8730e+16, 7.3218e+16,
        1.7581e+16, 7.1348e+16, 3.1299e+16, 4.8848e+16, 4.5408e+16, 2.9034e+16,
        4.3564e+17, 4.1947e+16, 2.1357e+16, 4.2347e+16, 1.2800e+16, 9.3573e+15,
        4.9581e+16, 2.8638e+16, 3.1770e+18, 1.5213e+17, 1.9064e+17, 3.9430e+16,
        2.1308e+16, 3.7758e+16, 2.3511e+17, 2.3729e+17])
Layer: encoder.4.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([6.8573e+16, 8.4811e+15, 8.8094e+16, 6.1566e+16, 1.1690e+17, 1.3008e+17,
        2.5559e+16, 6.4242e+16, 2.4610e+17, 4.2133e+16, 2.9753e+16, 9.5277e+16,
        1.0061e+17, 7.0448e+16, 1.4502e+17, 7.9291e+16, 1.3156e+17, 2.5281e+16,
        4.9083e+16, 1.6889e+17, 1.1770e+17, 1.3031e+17, 8.0428e+16, 1.3580e+17,
        9.4027e+16, 7.6354e+16, 5.1774e+16, 1.1144e+17, 7.0990e+16, 9.0433e+16,
        7.5500e+16, 7.1477e+16, 1.3115e+17, 8.3838e+16, 6.3326e+16, 2.7861e+16,
        7.9779e+16, 4.2095e+16, 1.9280e+17, 6.7855e+16, 7.9718e+16, 7.0443e+16,
        6.2653e+16, 5.0042e+16, 4.9102e+16, 1.4079e+17, 1.5246e+17, 8.6402e+16,
        6.3964e+16, 1.2390e+17, 1.6185e+17, 4.0040e+16, 1.2742e+17, 1.0536e+17,
        4.0911e+16, 1.1238e+17, 4.7900e+16, 1.5425e+17, 3.3173e+16, 6.4352e+16,
        1.6416e+17, 7.7800e+16, 1.5482e+17, 5.0979e+16])
Layer: encoder.4.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.3009e+17, 2.3720e+17, 7.7757e+16, 2.9029e+16, 1.5449e+17, 4.5799e+16,
        8.6160e+16, 1.1549e+17, 3.5096e+16, 1.0963e+17, 6.8756e+16, 1.0937e+17,
        6.0153e+16, 6.9492e+16, 9.6687e+16, 7.3399e+16, 8.4131e+16, 5.4300e+16,
        2.3548e+17, 1.8348e+17, 7.9118e+16, 7.6369e+16, 1.1976e+17, 4.6950e+16,
        7.5462e+16, 5.9384e+16, 4.6480e+16, 1.4241e+17, 1.6492e+17, 9.4685e+16,
        3.1284e+16, 1.2668e+17, 7.7737e+16, 9.2255e+16, 1.2397e+17, 9.0502e+16,
        9.7470e+16, 6.5776e+16, 1.1450e+17, 8.0899e+16, 6.8119e+16, 1.2959e+17,
        1.7128e+17, 4.0118e+16, 4.2832e+16, 1.9042e+17, 7.0260e+16, 3.3380e+16,
        1.5583e+17, 1.6149e+17, 5.5531e+16, 4.9762e+16, 3.0193e+16, 4.8803e+16,
        1.0812e+17, 5.1686e+16, 9.0830e+16, 2.9403e+16, 6.3383e+16, 1.0099e+17,
        4.5534e+16, 1.6566e+17, 1.1338e+17, 1.0885e+17])
Layer: encoder.4.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.7711e+15, 8.0118e+14, 3.6484e+17, 8.0321e+14, 4.3209e+15, 4.2904e+15,
        1.3848e+15, 1.4572e+15, 6.9949e+14, 1.2946e+15, 1.4577e+15, 1.5336e+15,
        1.3230e+15, 2.0962e+15, 2.0253e+15, 1.7530e+15, 5.6312e+14, 1.3349e+15,
        1.1184e+15, 1.1448e+15, 2.0295e+14, 5.8876e+15, 1.8313e+15, 9.7782e+14,
        3.2245e+15, 1.2925e+15, 1.2159e+15, 1.3051e+15, 2.2232e+15, 1.8346e+15,
        1.2258e+15, 9.1509e+13, 5.9280e+15, 6.3542e+15, 1.3336e+16, 1.5319e+15,
        1.5972e+15, 8.0724e+14, 1.0819e+15, 2.3808e+15, 5.5866e+15, 1.8426e+15,
        9.2096e+14, 1.1221e+15, 1.6861e+15, 1.9388e+15, 2.7988e+15, 2.9492e+15,
        7.0361e+14, 7.7739e+14, 2.2001e+16, 9.0430e+14, 5.0878e+15, 1.5667e+15,
        7.8775e+14, 1.3178e+16, 1.2014e+15, 1.5124e+15, 1.0505e+15, 1.5982e+15,
        1.7972e+15, 5.8413e+14, 1.1589e+15, 1.9955e+15, 1.3038e+15, 1.3350e+15,
        8.7227e+14, 1.2946e+15, 6.6353e+14, 1.5469e+15, 1.5667e+15, 1.4044e+15,
        1.7990e+15, 1.7075e+14, 1.6520e+15, 1.0935e+15, 1.1814e+15, 3.0192e+15,
        5.0109e+15, 2.7072e+15, 2.5452e+15, 8.7411e+14, 3.7690e+16, 2.1469e+15,
        6.8896e+14, 3.7687e+14, 1.5162e+15, 3.2181e+15, 1.2325e+15, 7.4938e+14,
        2.3795e+14, 6.0132e+14, 1.4453e+15, 1.2389e+15, 2.1244e+15, 4.6250e+15,
        3.8203e+14, 1.2577e+16, 1.9224e+15, 4.4716e+14, 2.7235e+14, 8.9818e+15,
        4.7596e+15, 1.6192e+15, 1.2929e+15, 2.6979e+15, 8.1269e+14, 1.7472e+15,
        1.4087e+15, 5.5278e+15, 2.7383e+14, 1.7159e+15, 1.3584e+15, 1.4840e+15,
        3.2712e+15, 3.4452e+15, 1.2847e+15, 2.4557e+15, 1.2905e+15, 1.7930e+15,
        1.1430e+16, 1.7223e+15, 4.6436e+15, 1.8019e+15, 4.3139e+14, 1.5297e+14,
        1.6922e+15, 1.7176e+15, 2.9370e+15, 2.1112e+15, 1.6322e+15, 1.4766e+15,
        2.3678e+15, 1.4822e+15, 1.2639e+15, 6.0792e+15, 1.1178e+15, 2.0763e+15,
        1.0596e+15, 2.0671e+15, 2.1047e+15, 6.3832e+14, 1.6787e+15, 3.5989e+14,
        2.0481e+15, 5.6664e+15, 1.0919e+15, 9.7479e+14, 3.3063e+14, 2.2941e+15,
        1.8322e+15, 9.2642e+14, 1.5719e+15, 2.2150e+15, 5.2323e+15, 2.7720e+14,
        4.4449e+15, 1.9974e+15, 1.0833e+15, 1.9723e+15, 8.3176e+14, 1.4384e+15,
        1.6107e+15, 4.4865e+15, 1.0815e+15, 2.3569e+15, 1.9822e+15, 2.3300e+15,
        1.6070e+15, 6.9418e+15, 2.4271e+14, 1.6364e+15, 2.3678e+15, 4.2786e+15,
        1.5105e+15, 6.7261e+14, 1.8284e+15, 1.9899e+15, 1.8240e+15, 1.5885e+15,
        1.5604e+15, 7.1332e+16, 1.3448e+15, 7.6940e+14, 1.6063e+15, 3.7378e+15,
        3.5798e+15, 1.1963e+15, 3.8277e+15, 4.8483e+14, 2.9062e+14, 1.9312e+15,
        1.6988e+15, 1.4481e+15, 7.6658e+14, 3.3936e+14, 1.1403e+15, 1.1370e+15,
        7.5046e+14, 1.5733e+15, 1.5681e+15, 4.5295e+15, 9.5091e+14, 4.1126e+15,
        3.7017e+15, 6.9097e+14, 1.6678e+15, 6.9822e+15, 1.0250e+15, 1.5071e+15,
        4.4939e+15, 1.0989e+15, 1.6641e+15, 2.0334e+15, 7.8854e+14, 9.6664e+16,
        2.4136e+14, 9.9265e+14, 1.4944e+15, 3.2209e+14, 1.6387e+15, 4.9382e+15,
        3.1991e+15, 2.7763e+14, 5.2282e+14, 1.3345e+15, 1.6990e+15, 7.6452e+14,
        3.9446e+16, 1.0413e+15, 1.5681e+15, 7.4537e+14, 1.8159e+15, 2.7682e+15,
        3.8618e+14, 9.5136e+14, 2.1197e+15, 1.0857e+15, 6.0092e+15, 2.1517e+14,
        2.2870e+15, 1.4339e+15, 6.9650e+13, 2.0993e+15, 3.8990e+15, 1.3326e+15,
        1.2242e+15, 6.5805e+15, 2.6765e+15, 6.2205e+15, 7.4486e+15, 3.0879e+15,
        1.2081e+15, 1.5983e+15, 2.4434e+15, 1.7392e+15])
Layer: encoder.4.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.3364e+15, 2.9540e+15, 4.0758e+15, 4.3474e+15, 2.0770e+15, 3.6031e+15,
        2.3680e+15, 3.1478e+15, 2.4967e+15, 5.0851e+15, 3.8425e+15, 2.9718e+15,
        1.7873e+15, 7.1225e+15, 3.1696e+15, 4.8345e+15, 2.3572e+15, 2.0138e+15,
        2.2072e+15, 3.7200e+15, 5.3039e+15, 4.1650e+15, 3.8999e+15, 1.4212e+15,
        4.5008e+15, 6.3104e+15, 3.7695e+15, 3.9950e+15, 1.3017e+15, 2.0709e+15,
        4.7357e+15, 4.2178e+15, 3.7886e+15, 4.7308e+15, 3.6075e+15, 2.9661e+15,
        2.9725e+15, 2.9770e+15, 3.6742e+15, 2.9165e+15, 4.4110e+15, 4.4246e+15,
        2.4286e+15, 3.0374e+15, 4.2388e+15, 4.0180e+15, 5.5981e+15, 1.0373e+15,
        3.3526e+15, 2.4851e+15, 2.1570e+15, 6.1733e+15, 4.0675e+15, 2.1697e+15,
        4.0940e+15, 4.0276e+15, 2.0297e+15, 7.0712e+15, 2.7453e+15, 1.7865e+15,
        3.1789e+15, 4.0509e+15, 4.9587e+15, 1.3401e+15])
Layer: encoder.4.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.2579e+15, 4.3506e+15, 4.9167e+15, 3.4765e+15, 2.9854e+15, 2.8423e+15,
        5.3121e+15, 2.9230e+15, 4.0751e+15, 4.5889e+15, 5.6281e+15, 3.8982e+15,
        1.5942e+15, 2.5955e+15, 3.3115e+15, 5.0343e+15, 4.2953e+15, 4.4029e+15,
        2.5114e+15, 4.3094e+15, 6.4382e+15, 4.0966e+15, 3.2848e+15, 3.1806e+15,
        3.2436e+15, 3.8555e+15, 3.9942e+15, 4.0956e+15, 2.6264e+15, 4.0391e+15,
        3.7404e+15, 5.9292e+15, 4.6961e+15, 3.4196e+15, 5.4671e+15, 4.8410e+15,
        2.8584e+15, 3.5112e+15, 2.8724e+15, 3.9002e+15, 3.1751e+15, 4.0345e+15,
        2.1467e+15, 3.7027e+15, 2.8808e+15, 5.3398e+15, 2.7812e+15, 4.7149e+15,
        2.9647e+15, 2.3821e+15, 7.3082e+15, 2.6975e+15, 3.0958e+15, 3.7387e+15,
        3.2578e+15, 4.3609e+15, 3.1706e+15, 2.3248e+15, 4.9973e+15, 2.8000e+15,
        2.2253e+15, 7.1566e+15, 4.5120e+15, 4.6779e+15])
Layer: encoder.4.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5.0002e+13, 6.2748e+14, 1.9886e+14, 5.5657e+12, 3.6820e+14, 9.8143e+13,
        3.8748e+13, 1.2901e+14, 2.1744e+13, 3.8243e+14, 4.7545e+14, 4.4672e+13,
        1.5432e+14, 2.6280e+14, 3.0231e+13, 7.4954e+13, 2.2036e+13, 6.9161e+13,
        7.9783e+14, 5.0697e+13, 8.1215e+12, 6.1829e+13, 4.6427e+13, 2.5521e+14,
        1.5785e+13, 6.8783e+13, 2.0779e+14, 3.9362e+13, 1.6902e+13, 1.5558e+14,
        1.1555e+14, 6.9030e+12, 1.6325e+14, 4.8965e+13, 5.2150e+13, 5.1420e+13,
        1.4440e+14, 5.6972e+13, 2.1505e+14, 3.7038e+13, 5.3780e+13, 6.1964e+13,
        3.8609e+13, 5.8738e+13, 1.0936e+13, 2.3325e+13, 6.5605e+13, 9.8284e+13,
        2.8990e+13, 1.8913e+14, 1.8360e+14, 6.3286e+13, 2.9549e+15, 1.3676e+14,
        2.4072e+13, 7.6641e+13, 3.2842e+14, 2.6903e+14, 5.7125e+13, 8.1306e+13,
        7.8000e+13, 1.4935e+13, 4.5750e+13, 7.7662e+13, 2.9697e+14, 6.5159e+13,
        5.4712e+13, 5.7580e+13, 4.2638e+13, 1.9634e+13, 2.0345e+13, 8.6248e+13,
        1.9208e+14, 4.9314e+12, 4.0044e+13, 6.9220e+13, 1.3313e+14, 1.2667e+15,
        4.2544e+13, 4.9586e+13, 4.2031e+13, 2.5498e+13, 2.5178e+14, 9.5503e+13,
        3.5425e+13, 1.3976e+13, 5.4815e+13, 5.2401e+13, 6.5996e+13, 2.2674e+13,
        1.0711e+13, 1.2009e+14, 6.7581e+14, 2.6972e+13, 7.6899e+13, 2.2118e+14,
        8.7165e+12, 3.5978e+13, 1.5811e+14, 9.3131e+13, 9.2631e+13, 3.8580e+13,
        7.9413e+13, 8.8172e+13, 1.0641e+14, 2.5350e+13, 1.3773e+14, 5.6760e+13,
        3.9171e+14, 6.0947e+13, 2.3924e+12, 5.0150e+12, 5.5057e+13, 3.0690e+13,
        6.2206e+13, 7.4515e+13, 6.8674e+13, 4.8096e+13, 5.6381e+13, 5.5557e+13,
        1.6282e+14, 1.8857e+14, 1.5532e+14, 4.9143e+13, 6.9474e+12, 6.9486e+12,
        2.9146e+13, 6.5625e+13, 4.3413e+13, 9.1829e+14, 6.1345e+13, 7.2094e+13,
        1.3276e+14, 4.8827e+14, 8.2456e+13, 4.3524e+13, 2.2009e+13, 4.1512e+13,
        7.7952e+13, 5.6104e+13, 1.1934e+14, 8.5156e+13, 8.5413e+14, 5.9130e+12,
        2.2990e+14, 5.0334e+13, 3.4867e+14, 3.3822e+13, 1.6722e+13, 4.8397e+13,
        2.9386e+14, 1.2928e+13, 3.0359e+13, 5.4673e+13, 5.1276e+15, 3.2610e+13,
        3.3370e+13, 4.1519e+13, 8.3526e+12, 1.9520e+14, 3.0510e+13, 1.7840e+14,
        9.9136e+13, 8.8798e+13, 3.4465e+13, 8.9751e+13, 1.9516e+13, 2.7836e+14,
        4.8961e+13, 9.6591e+13, 4.0740e+12, 2.5059e+14, 2.9979e+14, 7.6181e+13,
        7.0241e+13, 1.9495e+13, 2.2571e+13, 5.5246e+13, 8.4771e+13, 2.0251e+14,
        3.7758e+13, 2.0077e+14, 3.7734e+13, 4.2341e+13, 1.0531e+14, 1.7191e+13,
        8.6719e+13, 8.4896e+13, 2.7735e+15, 1.2578e+13, 8.8588e+13, 4.8996e+13,
        1.7672e+14, 4.7195e+13, 4.2811e+12, 6.8993e+12, 2.3234e+13, 1.1075e+14,
        3.8431e+14, 3.1661e+13, 5.9714e+13, 4.0590e+13, 1.3508e+13, 2.8627e+14,
        4.3663e+14, 6.6852e+13, 1.9419e+14, 8.9877e+14, 3.1497e+13, 5.9930e+13,
        1.5276e+14, 5.3726e+13, 1.2514e+13, 4.5367e+14, 5.7863e+13, 3.4331e+14,
        8.1641e+12, 2.9053e+13, 5.3433e+13, 8.1191e+12, 1.0667e+14, 5.7786e+13,
        3.3381e+13, 1.7501e+13, 1.4555e+13, 9.8346e+13, 5.7606e+13, 2.8669e+14,
        1.5199e+14, 2.5470e+13, 3.8036e+13, 2.3327e+14, 4.8557e+13, 7.7336e+13,
        8.9572e+12, 3.6357e+13, 7.1636e+13, 3.8236e+13, 5.4740e+13, 2.7810e+13,
        6.0409e+13, 2.9572e+13, 1.5194e+13, 1.5974e+13, 7.4072e+15, 7.2127e+13,
        4.3681e+14, 5.7860e+13, 1.2586e+14, 6.8215e+15, 2.3776e+14, 1.0713e+14,
        3.7570e+13, 6.3104e+13, 3.5871e+13, 3.0173e+13])
Layer: encoder.5.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.0890e+14, 9.6175e+13, 7.8722e+13, 8.0220e+13, 5.7409e+13, 5.4517e+13,
        5.8311e+13, 6.7444e+13, 4.5344e+13, 4.4255e+13, 8.2400e+13, 5.9811e+13,
        9.4091e+13, 9.3145e+13, 8.3602e+13, 8.4115e+13, 6.2365e+13, 4.6552e+13,
        9.6150e+13, 7.2047e+13, 8.0765e+13, 1.0403e+14, 1.1238e+14, 6.6296e+13,
        7.9595e+13, 4.6451e+13, 4.4585e+13, 7.2566e+13, 1.0374e+14, 6.6977e+13,
        5.5551e+13, 9.2444e+13, 5.4086e+13, 8.0018e+13, 3.4375e+13, 6.8323e+13,
        8.1751e+13, 9.0256e+13, 4.4090e+13, 8.5803e+13, 5.0951e+13, 5.7885e+13,
        9.6070e+13, 5.4903e+13, 4.5006e+13, 8.4876e+13, 1.0275e+14, 8.1924e+13,
        6.4648e+13, 7.2445e+13, 9.0386e+13, 7.5487e+13, 8.6413e+13, 4.6329e+13,
        5.5756e+13, 9.2478e+13, 6.0840e+13, 5.7610e+13, 5.6082e+13, 5.7998e+13,
        7.6989e+13, 5.7643e+13, 5.7199e+13, 4.5423e+13, 7.9002e+13, 7.5415e+13,
        6.3687e+13, 8.5820e+13, 5.5873e+13, 8.4087e+13, 4.7798e+13, 4.1311e+13,
        5.1453e+13, 3.5290e+13, 8.6616e+13, 4.9934e+13, 9.1693e+13, 7.5422e+13,
        8.4557e+13, 6.2132e+13, 6.2122e+13, 5.6358e+13, 8.9035e+13, 5.4992e+13,
        9.6365e+13, 6.2077e+13, 5.7208e+13, 9.1036e+13, 5.3278e+13, 6.7759e+13,
        7.1964e+13, 4.9154e+13, 1.0565e+14, 4.1659e+13, 4.9301e+13, 8.6536e+13,
        6.5838e+13, 9.3427e+13, 9.0916e+13, 8.6277e+13, 7.3467e+13, 7.3182e+13,
        6.9364e+13, 4.2181e+13, 7.2561e+13, 6.0631e+13, 8.0616e+13, 7.6571e+13,
        8.3063e+13, 7.2081e+13, 1.3629e+14, 9.6891e+13, 6.1992e+13, 4.1921e+13,
        6.8516e+13, 6.7113e+13, 7.3554e+13, 8.1194e+13, 8.9415e+13, 8.1131e+13,
        6.0709e+13, 4.5537e+13, 8.9606e+13, 8.3288e+13, 8.6328e+13, 5.5368e+13,
        5.9495e+13, 5.7665e+13])
Layer: encoder.5.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([9.8726e+13, 1.0906e+14, 9.9224e+13, 1.0721e+14, 5.8383e+13, 9.2250e+13,
        1.3102e+14, 9.0959e+13, 8.5014e+13, 1.4571e+14, 7.5496e+13, 8.9132e+13,
        6.3193e+13, 4.3524e+13, 6.9010e+13, 8.4935e+13, 6.9698e+13, 5.0604e+13,
        9.2394e+13, 1.1828e+14, 1.0244e+14, 5.0351e+13, 8.4638e+13, 1.1425e+14,
        6.2381e+13, 9.4471e+13, 1.0609e+14, 8.8177e+13, 9.4403e+13, 9.0628e+13,
        5.7732e+13, 9.0314e+13, 8.1794e+13, 7.2771e+13, 7.3647e+13, 7.9931e+13,
        9.2598e+13, 8.8970e+13, 8.7109e+13, 7.9867e+13, 6.3280e+13, 1.0443e+14,
        7.5848e+13, 9.2478e+13, 9.3551e+13, 7.6071e+13, 8.0763e+13, 7.7878e+13,
        1.0991e+14, 8.4491e+13, 1.1500e+14, 4.9446e+13, 8.5840e+13, 1.3232e+14,
        8.2307e+13, 9.9328e+13, 1.1670e+14, 1.0845e+14, 9.9795e+13, 8.7486e+13,
        7.9534e+13, 9.8165e+13, 8.0220e+13, 9.0800e+13, 9.7184e+13, 7.4549e+13,
        8.9798e+13, 1.4632e+14, 6.7800e+13, 8.3802e+13, 7.5257e+13, 1.0854e+14,
        9.0838e+13, 1.0032e+14, 9.6861e+13, 9.6566e+13, 8.6909e+13, 7.9917e+13,
        6.5404e+13, 7.9655e+13, 1.2656e+14, 7.0283e+13, 9.6780e+13, 1.1253e+14,
        8.3106e+13, 9.3776e+13, 5.9500e+13, 9.4478e+13, 7.0231e+13, 1.0092e+14,
        1.2528e+14, 9.6841e+13, 7.9212e+13, 1.0761e+14, 1.5678e+14, 1.2528e+14,
        1.0019e+14, 1.2839e+14, 8.7722e+13, 6.6174e+13, 5.8902e+13, 6.0533e+13,
        1.0576e+14, 8.2286e+13, 6.1537e+13, 7.2608e+13, 8.4655e+13, 3.4689e+13,
        8.5630e+13, 1.3196e+14, 8.4866e+13, 1.1109e+14, 1.0777e+14, 8.8295e+13,
        7.5380e+13, 1.1263e+14, 8.5857e+13, 6.9400e+13, 6.9982e+13, 1.0712e+14,
        6.7973e+13, 1.3983e+14, 1.4216e+14, 8.7853e+13, 1.0094e+14, 1.2205e+14,
        1.1061e+14, 7.2585e+13])
Layer: encoder.5.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.6116e+11, 1.3637e+12, 2.4870e+12, 2.1229e+11, 1.4218e+12, 4.6008e+12,
        3.8341e+11, 1.7517e+12, 1.9114e+12, 3.9158e+11, 1.6846e+12, 7.5646e+12,
        8.8298e+12, 4.1637e+12, 2.2639e+12, 8.0210e+13, 1.7948e+12, 1.7727e+12,
        9.0093e+13, 6.7312e+11, 3.7689e+13, 1.2166e+12, 1.5316e+11, 4.5370e+12,
        6.3128e+12, 4.0067e+11, 1.1692e+11, 3.0360e+11, 5.1023e+13, 6.9773e+11,
        9.4782e+12, 2.9691e+12, 5.0050e+12, 1.3648e+13, 7.3588e+11, 2.3301e+11,
        1.2983e+12, 1.3851e+12, 1.7630e+12, 4.8818e+11, 1.4372e+12, 2.1432e+12,
        2.1675e+12, 1.2603e+12, 6.8817e+11, 7.0365e+12, 2.4761e+12, 2.7387e+12,
        5.9709e+12, 5.8448e+11, 3.0277e+13, 1.6459e+12, 2.7173e+12, 1.0134e+13,
        1.6068e+12, 4.8366e+11, 2.3949e+12, 2.3124e+11, 1.7929e+12, 3.3950e+11,
        3.7054e+12, 6.1108e+12, 9.9532e+12, 4.0668e+12, 5.5925e+11, 8.2225e+11,
        4.6729e+11, 3.5706e+12, 1.8044e+12, 1.3160e+11, 1.5222e+12, 9.6833e+11,
        1.2087e+12, 2.6758e+11, 4.3892e+11, 8.4793e+12, 1.2298e+13, 2.4264e+12,
        4.4729e+11, 2.3441e+11, 4.3299e+11, 2.5592e+12, 1.8587e+12, 1.6138e+12,
        2.4833e+12, 6.2224e+11, 5.9430e+12, 4.9331e+11, 1.5454e+12, 8.1677e+11,
        1.9798e+12, 7.0419e+11, 2.2074e+13, 2.0522e+13, 1.9939e+12, 5.6305e+11,
        6.5782e+11, 2.7688e+11, 8.4039e+11, 4.8524e+12, 1.5029e+12, 1.1398e+12,
        6.2658e+11, 6.3737e+11, 9.1326e+11, 2.9596e+12, 2.9804e+11, 4.9795e+11,
        9.9784e+11, 1.6545e+12, 3.0315e+11, 2.2386e+11, 6.6215e+11, 1.1470e+12,
        1.2139e+13, 3.0560e+12, 6.4130e+11, 4.0764e+11, 9.0663e+12, 6.4232e+12,
        2.2996e+12, 1.7871e+12, 5.3016e+11, 1.6817e+12, 9.6355e+13, 1.1586e+12,
        8.7461e+11, 3.4404e+12, 3.4598e+12, 6.2721e+12, 9.5053e+11, 7.3671e+11,
        4.5549e+12, 6.8207e+11, 2.0669e+12, 4.9388e+12, 9.5360e+12, 1.0638e+12,
        1.4863e+12, 6.5980e+12, 5.2017e+11, 1.6385e+12, 7.2425e+11, 3.5621e+11,
        9.8587e+10, 3.7032e+11, 1.0055e+13, 3.8604e+12, 2.7014e+11, 2.3373e+12,
        1.6953e+12, 1.9730e+12, 3.8275e+11, 6.3163e+12, 5.7107e+12, 1.3141e+12,
        2.2605e+11, 7.8089e+12, 5.9639e+12, 1.1129e+12, 1.6647e+12, 6.2012e+12,
        4.4875e+11, 8.8867e+12, 1.0594e+13, 8.4260e+12, 1.5355e+12, 2.9105e+12,
        2.2183e+12, 7.2604e+11, 3.6356e+12, 9.8630e+12, 2.3815e+11, 3.4416e+11,
        1.1176e+12, 8.8706e+11, 3.7690e+11, 1.5405e+12, 1.0417e+12, 1.6181e+12,
        1.0686e+13, 2.7767e+13, 7.1233e+12, 5.2036e+12, 5.5638e+11, 1.2136e+13,
        5.9496e+12, 9.4633e+11, 4.7020e+11, 6.4886e+12, 1.0613e+13, 2.5908e+12,
        3.6134e+11, 4.0687e+12, 6.9461e+11, 2.9046e+11, 2.6390e+12, 2.4080e+12,
        1.7424e+12, 4.4154e+12, 3.4220e+11, 9.4894e+11, 4.1197e+12, 1.0525e+12,
        4.4636e+12, 3.3720e+11, 1.1991e+12, 1.5133e+12, 2.7749e+11, 1.0021e+14,
        1.8439e+12, 2.9723e+11, 1.5969e+13, 1.3820e+11, 8.4050e+12, 4.4332e+11,
        2.7704e+12, 2.1801e+12, 6.2356e+11, 5.2657e+12, 1.3076e+12, 4.7325e+11,
        1.3515e+12, 8.2718e+11, 5.9911e+11, 1.8285e+11, 4.4748e+11, 5.6847e+11,
        1.4773e+12, 6.0971e+11, 4.1800e+11, 1.8582e+12, 8.3215e+12, 5.6337e+11,
        5.7667e+12, 4.9429e+11, 2.2876e+12, 1.1944e+13, 3.3484e+12, 4.3050e+12,
        1.7355e+11, 5.2895e+12, 4.9622e+12, 4.8916e+11, 2.5069e+12, 2.4730e+12,
        1.4684e+12, 4.5239e+11, 1.2534e+12, 1.3366e+12, 3.2845e+11, 2.6015e+11,
        9.0238e+11, 8.9246e+11, 1.9703e+11, 3.3978e+12, 2.0422e+12, 1.2264e+12,
        6.3143e+11, 1.2869e+12, 1.7638e+12, 3.1120e+11, 4.2993e+12, 1.1585e+12,
        3.3155e+11, 3.3826e+12, 1.2898e+13, 1.2356e+12, 1.5312e+12, 2.0436e+12,
        6.5869e+11, 5.8812e+11, 6.9213e+11, 1.0617e+12, 4.1659e+11, 2.6936e+12,
        1.3569e+12, 1.3516e+12, 4.5036e+12, 2.3199e+13, 3.9681e+11, 3.1005e+12,
        6.8185e+11, 1.3192e+12, 6.9392e+12, 1.7985e+12, 7.1960e+12, 3.9574e+11,
        6.0243e+11, 2.3993e+11, 5.3664e+12, 2.2260e+12, 6.0059e+12, 2.9056e+11,
        8.5486e+12, 8.6132e+11, 1.9059e+11, 1.9839e+12, 3.2931e+12, 1.7361e+11,
        6.4755e+11, 1.1692e+12, 2.4610e+11, 2.0565e+11, 5.8114e+11, 1.7534e+12,
        2.1934e+12, 3.6513e+12, 1.2150e+12, 1.8053e+13, 8.9562e+11, 2.8069e+11,
        4.3329e+12, 1.0566e+11, 1.2080e+12, 9.4830e+11, 1.5127e+12, 5.5400e+11,
        1.1859e+12, 5.3071e+11, 5.4589e+11, 3.6070e+12, 3.6250e+11, 5.9304e+12,
        2.1946e+12, 5.5931e+12, 1.0803e+12, 1.7997e+12, 4.6460e+12, 4.8530e+11,
        1.3783e+12, 8.9123e+11, 6.7557e+11, 5.6003e+11, 4.6836e+11, 5.8320e+11,
        8.1415e+11, 1.7098e+12, 1.8380e+12, 2.8902e+12, 3.2928e+12, 9.8244e+12,
        3.2312e+12, 1.0885e+12, 7.4731e+11, 5.4983e+11, 5.0112e+11, 2.5596e+11,
        7.9694e+11, 1.9991e+12, 1.2037e+13, 7.6523e+13, 1.4553e+13, 1.9424e+12,
        6.7382e+11, 4.1065e+12, 9.9171e+11, 2.8834e+12, 2.1628e+12, 3.9214e+11,
        5.7546e+11, 5.1076e+11, 4.7656e+11, 4.8271e+11, 1.7164e+12, 1.1437e+12,
        1.0643e+12, 1.6669e+12, 1.1354e+12, 1.5337e+12, 3.9026e+11, 1.9370e+13,
        9.1353e+12, 3.6820e+13, 5.7020e+11, 7.1893e+11, 3.5156e+11, 5.1893e+11,
        1.0390e+12, 4.9467e+12, 8.8403e+11, 4.8375e+11, 2.0102e+12, 5.0920e+11,
        2.4377e+12, 1.1069e+12, 3.2717e+11, 2.5195e+11, 4.0444e+11, 1.3720e+13,
        7.7459e+11, 1.5991e+12, 1.3731e+12, 3.0027e+12, 1.2460e+11, 1.3413e+12,
        3.3222e+11, 1.3552e+12, 9.1867e+11, 6.3548e+11, 1.2711e+12, 1.9874e+12,
        6.7206e+11, 9.7491e+11, 1.6172e+12, 3.0751e+12, 9.0165e+11, 1.2379e+12,
        1.7845e+12, 3.1450e+11, 1.2446e+12, 5.2897e+11, 1.9956e+11, 4.5343e+12,
        2.7422e+12, 3.6265e+11, 1.9477e+12, 2.1839e+12, 3.8057e+11, 6.8379e+11,
        2.8681e+11, 1.5068e+13, 1.3055e+12, 1.1843e+12, 3.0156e+12, 2.7077e+11,
        3.2338e+12, 2.0135e+11, 5.4266e+11, 4.8767e+11, 1.0514e+12, 4.1572e+11,
        2.6631e+12, 6.4469e+11, 3.3709e+11, 2.7604e+11, 3.1840e+11, 2.0971e+12,
        4.1219e+12, 2.6536e+13, 1.7528e+12, 5.3812e+12, 6.0798e+12, 6.5990e+11,
        6.4729e+11, 1.5737e+12, 1.1589e+12, 1.8320e+12, 2.5133e+12, 1.0514e+12,
        2.4561e+12, 7.2404e+12, 1.4606e+12, 7.3301e+11, 2.7287e+11, 4.2269e+11,
        9.8392e+11, 1.5838e+13, 5.3125e+12, 1.9403e+12, 2.0118e+11, 5.2326e+12,
        1.3160e+12, 1.7475e+12, 2.9136e+11, 7.2741e+12, 1.7017e+12, 2.3524e+12,
        1.0040e+14, 3.5920e+12, 7.6361e+11, 1.7393e+11, 2.0142e+13, 3.4417e+12,
        3.0534e+12, 3.1656e+12, 2.5606e+12, 1.4346e+13, 3.4995e+11, 2.2068e+12,
        9.6742e+11, 9.9528e+11, 1.3541e+12, 7.4819e+11, 1.1842e+12, 6.2801e+11,
        6.9289e+11, 1.6681e+12, 5.7807e+11, 3.6532e+11, 3.6897e+12, 4.2446e+12,
        2.8840e+11, 2.2199e+12, 2.2672e+12, 6.1473e+11, 9.2408e+11, 7.0529e+11,
        1.5038e+11, 6.7705e+11, 1.0455e+12, 1.4381e+12, 3.7434e+11, 4.8623e+11,
        1.1142e+12, 2.7513e+11, 1.1192e+12, 1.9242e+12, 2.8467e+12, 1.2885e+12,
        8.3992e+11, 6.4765e+12])
Layer: encoder.5.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.6239e+12, 1.5155e+12, 2.9573e+12, 1.0800e+12, 2.0251e+12, 5.2692e+12,
        1.7062e+12, 2.7178e+12, 2.6118e+12, 1.5900e+12, 1.6283e+12, 8.0828e+12,
        9.3541e+12, 4.2305e+12, 2.0732e+12, 7.9673e+13, 1.7729e+12, 4.4141e+11,
        8.9921e+13, 1.6576e+12, 3.7927e+13, 4.9474e+11, 8.2258e+11, 4.6296e+12,
        5.8078e+12, 9.8063e+11, 1.4011e+12, 7.2935e+11, 5.1107e+13, 2.4270e+12,
        7.7715e+12, 2.0292e+12, 4.7544e+12, 1.4387e+13, 1.7429e+12, 9.9714e+11,
        1.6754e+12, 3.9652e+11, 2.7479e+12, 1.0807e+12, 6.1893e+11, 2.7620e+12,
        2.3832e+12, 2.3683e+12, 1.0193e+12, 8.1883e+12, 2.9681e+12, 2.2158e+12,
        6.4841e+12, 1.1481e+12, 2.9566e+13, 1.5685e+12, 3.1041e+12, 9.5067e+12,
        2.2394e+12, 5.4137e+11, 1.5311e+12, 1.1570e+12, 1.5076e+12, 1.0854e+12,
        3.3218e+12, 6.2135e+12, 1.0113e+13, 4.3340e+12, 1.4550e+12, 1.1257e+12,
        9.6234e+11, 3.4107e+12, 2.3485e+12, 1.2672e+12, 2.5761e+12, 3.9909e+11,
        2.4178e+12, 1.7273e+12, 1.4671e+12, 8.5556e+12, 1.3245e+13, 2.7296e+12,
        8.9808e+11, 1.0381e+12, 1.6353e+12, 2.6793e+12, 2.1389e+12, 1.2883e+12,
        2.7672e+12, 1.7861e+12, 6.3873e+12, 9.5445e+11, 8.9990e+11, 1.2075e+12,
        2.2190e+12, 1.7681e+12, 2.1476e+13, 1.9589e+13, 2.7218e+12, 5.6830e+11,
        8.7997e+11, 1.1746e+12, 1.4264e+12, 5.4472e+12, 3.2654e+12, 2.7189e+12,
        1.9262e+12, 1.0142e+12, 4.7377e+11, 2.8047e+12, 7.7505e+11, 3.9521e+11,
        1.2531e+12, 2.8780e+12, 1.7380e+12, 8.6427e+11, 1.3765e+12, 1.8337e+12,
        1.1871e+13, 3.3026e+12, 1.4318e+12, 1.0729e+12, 8.3927e+12, 6.1443e+12,
        2.2554e+12, 1.2576e+12, 1.7650e+12, 2.8278e+12, 9.5052e+13, 1.1877e+12,
        9.8261e+11, 3.9754e+12, 2.9932e+12, 5.6285e+12, 1.7130e+12, 5.5196e+11,
        4.3764e+12, 4.6046e+11, 2.0810e+12, 5.4806e+12, 9.3252e+12, 1.8776e+12,
        2.0631e+12, 4.9865e+12, 8.1071e+11, 1.2983e+12, 1.5938e+12, 8.3228e+11,
        1.4505e+12, 5.2322e+11, 9.5406e+12, 4.5776e+12, 1.0598e+12, 2.2025e+12,
        3.3579e+12, 2.4590e+12, 2.4034e+12, 6.7647e+12, 6.0824e+12, 1.6328e+12,
        1.0044e+12, 7.8641e+12, 6.6041e+12, 8.6420e+11, 1.9105e+12, 6.2677e+12,
        6.7862e+11, 8.3436e+12, 1.0078e+13, 8.0685e+12, 2.1149e+12, 4.0697e+12,
        2.6576e+12, 1.1318e+12, 3.7390e+12, 9.1978e+12, 7.7032e+11, 9.7496e+11,
        5.9068e+11, 1.6378e+12, 1.5433e+12, 2.4524e+12, 1.7017e+12, 2.9600e+12,
        1.0965e+13, 2.7761e+13, 6.7414e+12, 5.8674e+12, 5.9925e+11, 1.2833e+13,
        6.7808e+12, 5.2644e+11, 1.6625e+12, 6.0716e+12, 1.0708e+13, 3.1990e+12,
        1.2919e+12, 4.8900e+12, 1.5099e+12, 1.6579e+12, 3.2563e+12, 2.7990e+12,
        2.2287e+12, 4.3621e+12, 1.0926e+12, 1.2707e+12, 4.6527e+12, 4.1056e+11,
        4.1694e+12, 9.1440e+11, 2.4725e+12, 1.6092e+12, 6.3580e+11, 9.9655e+13,
        2.3047e+12, 1.4943e+12, 1.6022e+13, 8.6888e+11, 8.4361e+12, 1.3681e+12,
        1.9984e+12, 2.0381e+12, 5.7387e+11, 6.2227e+12, 1.0630e+12, 6.9190e+11,
        2.1354e+12, 1.4755e+12, 1.3860e+12, 9.7219e+11, 3.8725e+11, 8.0325e+11,
        2.0681e+12, 1.1007e+12, 9.6420e+11, 3.2260e+12, 8.6758e+12, 1.3894e+12,
        5.8044e+12, 1.1498e+12, 2.8019e+12, 1.2265e+13, 4.0751e+12, 4.5500e+12,
        8.7692e+11, 1.5900e+12, 4.9113e+12, 5.8463e+11, 2.5881e+12, 2.7095e+12,
        1.5728e+12, 1.8174e+12, 7.0978e+11, 5.4591e+11, 1.3627e+12, 1.4720e+12,
        9.3384e+11, 4.8231e+11, 1.2950e+12, 4.5428e+12, 1.4345e+12, 7.5733e+11,
        7.2722e+11, 2.6214e+12, 2.7417e+12, 8.7394e+11, 7.3008e+11, 2.5384e+12,
        4.7005e+11, 4.1997e+12, 1.2202e+13, 1.4168e+12, 2.1646e+12, 1.9970e+12,
        2.8279e+11, 7.6274e+11, 8.2604e+11, 1.5183e+12, 9.0614e+11, 2.8551e+12,
        8.2207e+11, 2.2331e+12, 5.4464e+12, 2.3126e+13, 1.3959e+12, 7.8597e+12,
        2.8945e+12, 1.5096e+12, 9.5885e+12, 2.0734e+12, 7.0582e+12, 1.4850e+12,
        9.4754e+11, 8.3576e+11, 4.7357e+12, 2.7725e+12, 6.4109e+12, 6.3240e+11,
        9.0569e+12, 1.2400e+12, 1.0540e+12, 2.5160e+12, 3.2813e+12, 7.0685e+11,
        5.4442e+11, 2.7464e+11, 8.3777e+11, 8.0619e+11, 1.5204e+12, 1.1180e+12,
        2.6043e+12, 4.9462e+12, 2.5312e+12, 1.8126e+13, 8.3550e+11, 8.5349e+11,
        4.2810e+12, 1.6850e+12, 1.4881e+12, 3.8453e+11, 1.5496e+12, 1.0611e+12,
        6.1266e+11, 7.1778e+11, 1.0184e+12, 3.6605e+12, 1.1853e+12, 5.9292e+12,
        2.9272e+12, 6.3060e+12, 1.0618e+12, 2.3588e+12, 3.9085e+12, 7.1579e+11,
        1.1920e+12, 1.0272e+12, 1.7067e+12, 6.8116e+11, 9.6470e+11, 3.9102e+11,
        1.4285e+12, 5.3261e+11, 1.5116e+12, 3.7129e+12, 3.1670e+12, 8.9795e+12,
        3.1691e+12, 1.3551e+12, 1.2302e+12, 1.0893e+12, 1.0754e+12, 1.3058e+12,
        1.4385e+12, 1.9822e+12, 1.2507e+13, 7.6834e+13, 1.4331e+13, 1.3681e+12,
        5.4801e+11, 3.9741e+12, 1.5941e+12, 3.1816e+12, 2.5517e+12, 7.1073e+11,
        1.6666e+12, 9.7067e+11, 1.7185e+12, 5.2423e+11, 2.6497e+12, 2.7172e+11,
        1.2050e+12, 2.7609e+12, 1.8089e+12, 3.0407e+12, 7.9217e+11, 1.9706e+13,
        9.1805e+12, 3.7666e+13, 1.6880e+12, 5.9246e+11, 8.4142e+11, 1.9090e+12,
        1.5745e+12, 4.7877e+12, 8.4566e+11, 9.5856e+11, 1.3658e+12, 6.8267e+11,
        2.3968e+12, 1.4480e+12, 1.5515e+12, 1.0514e+12, 2.0834e+12, 1.4694e+13,
        1.8558e+12, 2.4345e+12, 1.7195e+12, 4.0583e+12, 1.1367e+12, 1.5969e+12,
        7.5506e+11, 2.0174e+12, 9.2538e+11, 7.7576e+11, 9.4886e+11, 1.3819e+12,
        5.7076e+11, 3.3713e+11, 2.3851e+12, 2.3986e+12, 5.4622e+11, 1.6455e+12,
        2.9540e+12, 1.4631e+12, 2.2115e+12, 8.1275e+11, 1.4064e+12, 4.8849e+12,
        3.1424e+12, 1.2431e+12, 2.0793e+12, 1.0917e+12, 1.2488e+12, 4.2889e+11,
        8.8379e+11, 1.5711e+13, 2.6935e+12, 6.8284e+11, 1.8036e+12, 8.4455e+11,
        3.3474e+12, 1.3169e+12, 1.3216e+12, 1.2941e+12, 1.6515e+12, 1.6632e+12,
        4.0246e+12, 1.5944e+12, 1.6257e+12, 5.8667e+11, 7.8475e+11, 2.0317e+12,
        4.5834e+12, 2.7142e+13, 2.1084e+12, 5.1119e+12, 6.0371e+12, 2.1218e+12,
        1.3844e+12, 1.7410e+12, 1.4742e+12, 2.0242e+12, 2.4089e+12, 1.7112e+12,
        1.9191e+12, 7.4432e+12, 1.7789e+12, 1.4591e+12, 1.3363e+12, 1.3316e+12,
        4.9061e+11, 1.5705e+13, 5.1714e+12, 1.1923e+12, 1.0182e+12, 4.0326e+12,
        3.2667e+12, 1.8373e+12, 1.4900e+12, 6.4868e+12, 2.2174e+12, 2.3658e+12,
        1.0091e+14, 4.5851e+12, 9.4325e+11, 1.2507e+12, 1.9774e+13, 2.0994e+12,
        2.8149e+12, 2.6883e+12, 4.5608e+12, 1.3809e+13, 1.4572e+12, 2.2611e+12,
        8.2478e+11, 1.0138e+12, 2.1729e+12, 3.2090e+11, 1.1580e+12, 1.0164e+12,
        9.6210e+11, 1.2141e+12, 8.3009e+11, 1.0440e+12, 3.7900e+12, 4.8113e+12,
        8.6056e+11, 2.0121e+12, 2.0868e+12, 2.6873e+11, 7.6765e+11, 6.9377e+11,
        1.1306e+12, 9.2248e+11, 8.4019e+11, 1.8982e+12, 4.4324e+11, 8.3370e+11,
        2.1436e+12, 1.2429e+12, 9.2558e+11, 6.3672e+11, 3.5293e+12, 1.7280e+12,
        1.0383e+12, 4.8236e+12])
Layer: encoder.5.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.7246e+12, 1.8554e+12, 2.2665e+12, 2.1774e+12, 2.9983e+12, 2.7256e+12,
        1.5707e+12, 2.4408e+12, 2.3550e+12, 2.1790e+12, 1.9737e+12, 2.5763e+12,
        2.5654e+12, 2.0603e+12, 2.5693e+12, 1.9946e+12, 2.4805e+12, 1.1502e+12,
        3.4369e+12, 2.9606e+12, 2.4020e+12, 2.4557e+12, 2.2345e+12, 1.9625e+12,
        2.7940e+12, 2.9424e+12, 1.9868e+12, 2.5036e+12, 2.0996e+12, 2.0626e+12,
        2.6564e+12, 2.3477e+12, 2.2421e+12, 3.0680e+12, 1.8584e+12, 2.1543e+12,
        2.5480e+12, 2.9221e+12, 1.7101e+12, 1.9358e+12, 2.0170e+12, 1.9162e+12,
        2.2928e+12, 1.8812e+12, 2.2025e+12, 2.2713e+12, 1.7623e+12, 2.3101e+12,
        1.7088e+12, 1.8408e+12, 2.4111e+12, 2.8893e+12, 2.0627e+12, 2.0394e+12,
        1.8580e+12, 1.5119e+12, 2.3048e+12, 2.5043e+12, 2.2277e+12, 2.2599e+12,
        2.4095e+12, 2.0773e+12, 2.9087e+12, 2.9536e+12, 2.3990e+12, 2.8974e+12,
        1.9265e+12, 2.9396e+12, 2.6486e+12, 3.3604e+12, 2.1681e+12, 1.6942e+12,
        2.4973e+12, 2.3687e+12, 1.6718e+12, 2.8049e+12, 1.4896e+12, 1.7924e+12,
        1.8512e+12, 2.2535e+12, 2.1262e+12, 2.2343e+12, 2.3470e+12, 1.6764e+12,
        2.4048e+12, 2.2575e+12, 2.0587e+12, 1.7161e+12, 2.8744e+12, 2.9714e+12,
        1.8594e+12, 1.7381e+12, 1.6163e+12, 2.2863e+12, 1.9574e+12, 2.2146e+12,
        2.3636e+12, 2.7409e+12, 2.0400e+12, 2.2341e+12, 3.1412e+12, 2.0746e+12,
        1.5747e+12, 2.0601e+12, 1.6192e+12, 1.9651e+12, 2.0336e+12, 2.4406e+12,
        1.9759e+12, 2.3693e+12, 3.8339e+12, 2.0928e+12, 1.8151e+12, 2.1883e+12,
        2.4867e+12, 2.3319e+12, 2.3222e+12, 1.5287e+12, 2.1848e+12, 2.4280e+12,
        3.0657e+12, 2.9542e+12, 3.0763e+12, 2.3449e+12, 2.2806e+12, 2.2254e+12,
        3.6814e+12, 2.0039e+12])
Layer: encoder.5.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.1546e+12, 3.9804e+12, 3.3980e+12, 3.1968e+12, 3.3687e+12, 4.9423e+12,
        3.7087e+12, 2.5881e+12, 3.9101e+12, 2.6744e+12, 3.8801e+12, 2.1849e+12,
        2.3369e+12, 2.6978e+12, 3.5241e+12, 5.1155e+12, 2.8989e+12, 2.3492e+12,
        4.0189e+12, 4.6846e+12, 2.0802e+12, 3.6075e+12, 5.1296e+12, 3.3815e+12,
        2.3592e+12, 2.5247e+12, 3.4497e+12, 3.1640e+12, 2.6388e+12, 4.0563e+12,
        2.7838e+12, 4.3582e+12, 1.8006e+12, 3.3264e+12, 4.6877e+12, 3.3543e+12,
        4.2604e+12, 4.9628e+12, 4.0866e+12, 4.8712e+12, 5.1266e+12, 3.5389e+12,
        3.0349e+12, 2.4055e+12, 2.3104e+12, 4.0585e+12, 2.7255e+12, 3.3374e+12,
        2.5474e+12, 2.2063e+12, 3.8580e+12, 2.6327e+12, 4.7362e+12, 3.9956e+12,
        2.7331e+12, 3.4100e+12, 4.2557e+12, 2.1873e+12, 3.3778e+12, 2.4882e+12,
        2.2747e+12, 4.3300e+12, 3.3767e+12, 3.0546e+12, 2.9112e+12, 4.1910e+12,
        4.1789e+12, 3.5907e+12, 5.2437e+12, 4.5868e+12, 3.1655e+12, 3.1683e+12,
        4.1321e+12, 4.1867e+12, 5.4975e+12, 3.0097e+12, 2.2566e+12, 2.5052e+12,
        4.6285e+12, 3.9612e+12, 3.9498e+12, 4.7007e+12, 3.3031e+12, 4.4146e+12,
        4.2101e+12, 2.8359e+12, 3.6182e+12, 2.0022e+12, 2.5848e+12, 4.5974e+12,
        2.8877e+12, 2.4002e+12, 2.7525e+12, 3.4881e+12, 4.0893e+12, 3.1690e+12,
        1.9791e+12, 5.5905e+12, 3.7536e+12, 3.5392e+12, 4.4645e+12, 5.7327e+12,
        2.0762e+12, 3.2587e+12, 3.0787e+12, 2.4805e+12, 4.2088e+12, 4.4143e+12,
        3.5842e+12, 4.3961e+12, 2.6063e+12, 3.1931e+12, 3.1177e+12, 2.4128e+12,
        5.8130e+12, 3.1247e+12, 2.5168e+12, 3.0444e+12, 2.4737e+12, 1.8160e+12,
        3.8401e+12, 2.4791e+12, 2.4500e+12, 4.0410e+12, 3.7991e+12, 2.4148e+12,
        3.4993e+12, 2.9638e+12])
Layer: encoder.5.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.6515e+10, 7.9926e+10, 3.8994e+10, 4.1497e+10, 1.3322e+12, 7.6376e+10,
        6.2680e+10, 3.6123e+10, 1.0649e+11, 5.7293e+10, 6.0576e+10, 3.8775e+11,
        7.8263e+10, 4.5238e+10, 4.7625e+10, 5.7045e+10, 3.3566e+10, 5.6083e+11,
        1.9082e+11, 4.7511e+10, 5.5080e+10, 1.2712e+10, 8.6915e+10, 8.1747e+10,
        6.4450e+10, 2.8283e+11, 7.0877e+10, 4.7673e+10, 4.9982e+10, 2.3424e+11,
        2.2675e+11, 1.7089e+11, 8.8748e+10, 6.7059e+10, 7.4628e+10, 7.4315e+10,
        4.4586e+10, 4.6073e+10, 1.0352e+11, 5.1061e+10, 5.3638e+10, 6.1713e+10,
        1.0624e+11, 5.8187e+10, 2.7189e+10, 4.2282e+11, 7.4360e+10, 6.8937e+10,
        3.0225e+11, 4.7951e+10, 9.1871e+10, 6.1196e+10, 4.5554e+10, 7.8332e+10,
        3.4153e+10, 4.7183e+10, 6.6094e+10, 3.5269e+10, 1.0288e+11, 5.7676e+11,
        5.3936e+10, 3.6310e+10, 3.7203e+10, 1.2436e+11, 1.9037e+10, 7.5075e+10,
        5.8186e+10, 8.2527e+10, 6.4853e+10, 9.1476e+10, 8.1527e+10, 9.1168e+10,
        5.2744e+10, 2.2272e+11, 1.6193e+11, 9.1401e+11, 1.5716e+11, 1.5124e+11,
        1.0346e+11, 3.9097e+10, 1.6834e+10, 5.6507e+10, 5.6858e+10, 1.0113e+11,
        4.9921e+10, 5.7670e+10, 3.0243e+10, 7.9247e+10, 2.9128e+10, 5.9977e+10,
        5.4231e+11, 2.4568e+10, 7.6851e+10, 1.6276e+11, 7.9149e+10, 3.0487e+10,
        2.8480e+10, 4.1687e+10, 6.6153e+10, 5.8871e+10, 6.1574e+10, 6.2035e+11,
        1.1339e+11, 8.9289e+10, 1.3139e+11, 2.3018e+10, 8.3868e+10, 3.7603e+11,
        5.9804e+10, 1.1516e+12, 8.7412e+10, 1.0588e+10, 3.3663e+10, 5.9213e+10,
        9.2152e+10, 3.5755e+10, 6.6274e+10, 5.9752e+10, 8.6163e+10, 6.3091e+10,
        3.9105e+10, 4.5546e+10, 1.9867e+11, 1.2695e+10, 6.2872e+10, 3.9597e+10,
        4.5742e+10, 1.3914e+11, 3.4947e+11, 8.4819e+10, 3.0697e+10, 7.2167e+10,
        1.8362e+11, 7.9123e+10, 1.8636e+11, 8.7528e+10, 7.0977e+10, 6.1607e+10,
        9.8692e+09, 5.7883e+10, 2.1226e+11, 1.9423e+11, 3.0126e+11, 5.2195e+10,
        1.3627e+10, 6.4720e+10, 3.9291e+10, 4.4944e+10, 3.3623e+10, 2.1706e+10,
        3.7935e+11, 1.9644e+11, 1.8756e+12, 5.1105e+10, 5.6008e+10, 8.0111e+10,
        2.9144e+10, 1.5267e+11, 4.0206e+10, 1.6031e+11, 8.3974e+10, 1.7171e+11,
        6.9622e+10, 6.6460e+10, 1.0598e+11, 5.2979e+10, 2.4845e+11, 3.9707e+10,
        5.2738e+10, 2.3092e+10, 4.2729e+10, 2.3235e+11, 9.5932e+10, 4.4673e+10,
        2.1754e+10, 9.4722e+10, 9.1914e+10, 5.7074e+10, 9.0577e+10, 1.0399e+12,
        4.2804e+10, 4.2974e+10, 3.1163e+11, 4.6856e+10, 1.3223e+11, 1.0895e+11,
        2.5000e+11, 3.0422e+10, 1.8272e+10, 4.1662e+10, 4.0083e+10, 3.4394e+10,
        9.3033e+10, 3.4743e+11, 1.6981e+11, 8.4715e+10, 5.3548e+10, 5.5325e+10,
        4.7506e+10, 1.6757e+11, 2.3942e+10, 6.6983e+10, 6.9134e+10, 8.1823e+10,
        2.4395e+11, 5.3208e+11, 4.2680e+10, 7.5988e+10, 8.6947e+10, 1.1459e+11,
        2.2120e+11, 3.0907e+10, 4.7294e+10, 5.2973e+09, 1.2704e+11, 2.5927e+11,
        1.0036e+11, 8.9826e+10, 1.1604e+10, 7.9948e+10, 3.6301e+10, 7.2459e+10,
        7.7861e+10, 3.7341e+10, 4.8660e+10, 9.4940e+09, 2.6087e+10, 3.4625e+10,
        8.4704e+10, 1.0936e+10, 1.3366e+10, 9.7083e+10, 4.2896e+10, 6.2866e+10,
        7.3900e+10, 3.4680e+10, 6.6975e+10, 1.9731e+10, 2.6914e+10, 4.8382e+10,
        3.3195e+10, 3.7686e+12, 7.6699e+10, 1.3979e+10, 7.8340e+10, 9.0315e+10,
        7.0156e+10, 1.0528e+11, 2.8600e+11, 3.9154e+10, 2.0707e+10, 8.7467e+10,
        5.4605e+10, 1.6611e+10, 6.8784e+10, 4.7439e+10, 3.4227e+10, 9.3991e+10,
        2.4626e+11, 2.0675e+11, 5.1348e+10, 5.8878e+10, 3.2717e+12, 4.4598e+10,
        7.6993e+10, 3.2654e+11, 2.7019e+10, 3.4657e+10, 4.9778e+10, 8.1618e+10,
        7.0489e+10, 5.2135e+10, 4.6455e+10, 5.8894e+10, 1.1150e+11, 5.4284e+10,
        5.0548e+10, 4.9383e+10, 4.8757e+10, 9.5859e+10, 8.4126e+10, 8.2387e+12,
        1.1019e+12, 3.8681e+10, 2.1313e+12, 2.8700e+11, 1.4100e+11, 4.0837e+10,
        3.5324e+10, 5.2421e+10, 4.8605e+10, 5.5060e+10, 1.2084e+11, 6.0400e+09,
        9.1944e+10, 4.7439e+10, 4.3070e+10, 1.6268e+11, 7.6906e+10, 8.9057e+10,
        8.8877e+10, 1.3725e+10, 5.6475e+10, 8.2166e+10, 9.8966e+10, 2.5793e+11,
        1.1609e+11, 1.5250e+11, 6.8866e+10, 1.3266e+11, 6.7758e+10, 4.6897e+10,
        7.5212e+10, 5.5892e+10, 4.6647e+10, 6.5624e+10, 6.9609e+10, 5.9652e+10,
        1.2100e+11, 1.3466e+10, 6.9357e+10, 6.3591e+10, 6.9425e+10, 6.1448e+10,
        5.8529e+10, 4.0280e+10, 3.8307e+10, 3.0034e+10, 2.2172e+11, 1.4314e+10,
        3.9141e+10, 1.0344e+11, 2.4230e+10, 4.9850e+10, 2.2786e+11, 4.0541e+10,
        6.8521e+11, 8.8527e+10, 1.7211e+10, 5.7154e+10, 8.5462e+10, 8.2074e+10,
        2.3734e+11, 1.1417e+11, 7.3033e+10, 7.7116e+10, 6.2938e+10, 2.8663e+10,
        1.1909e+11, 6.0312e+10, 7.3260e+10, 8.9784e+10, 6.9713e+10, 7.0087e+10,
        5.5204e+10, 3.9592e+10, 6.0888e+10, 3.8015e+11, 6.6151e+10, 1.1146e+11,
        3.5618e+10, 8.6263e+10, 6.6634e+10, 1.1341e+11, 2.0977e+10, 1.9828e+11,
        6.8743e+10, 1.4642e+11, 6.2838e+10, 8.9292e+11, 1.4527e+10, 9.0202e+10,
        9.6173e+10, 9.6393e+10, 3.0644e+11, 1.4338e+11, 6.0098e+10, 4.6966e+10,
        4.3232e+11, 9.0004e+10, 5.8542e+10, 2.8095e+10, 1.0118e+11, 8.5678e+09,
        5.6137e+10, 9.2731e+10, 1.4484e+10, 5.7508e+10, 7.0888e+10, 4.4359e+10,
        1.2093e+11, 6.0668e+10, 6.4784e+10, 5.5809e+10, 1.5260e+10, 4.9532e+10,
        6.9306e+10, 4.3099e+10, 4.1866e+10, 4.1207e+10, 4.5468e+10, 1.6599e+11,
        1.8288e+10, 7.8462e+09, 5.1173e+10, 7.3991e+10, 8.3252e+10, 8.0334e+10,
        1.0835e+11, 3.8691e+10, 1.0656e+11, 5.2943e+10, 6.0083e+10, 4.4946e+10,
        5.8176e+10, 5.9974e+10, 5.4265e+10, 7.9126e+10, 9.2678e+10, 5.6313e+10,
        1.0054e+10, 6.9204e+11, 9.4748e+10, 5.4497e+10, 4.2345e+10, 6.7857e+10,
        6.7338e+10, 1.6835e+11, 2.1181e+11, 5.3988e+10, 7.1453e+10, 3.9113e+10,
        3.2600e+11, 6.3841e+10, 1.7926e+10, 5.5875e+10, 6.7750e+10, 4.5838e+10,
        6.1426e+10, 8.3216e+10, 3.9464e+10, 3.5421e+10, 3.1188e+10, 2.9611e+10,
        5.8331e+10, 1.1956e+11, 4.9193e+10, 5.4138e+10, 7.5370e+10, 3.4747e+10,
        1.3227e+11, 4.4939e+10, 4.7353e+10, 4.8144e+10, 6.2844e+10, 5.3948e+10,
        4.9138e+10, 5.2336e+10, 1.7839e+11, 3.0849e+10, 7.6682e+10, 9.1601e+10,
        4.6956e+10, 5.6356e+10, 4.7345e+09, 1.7666e+11, 1.9515e+11, 7.2500e+10,
        2.3804e+11, 4.9280e+10, 4.0283e+10, 7.5098e+10, 1.2221e+11, 1.4324e+12,
        4.3591e+10, 3.2974e+10, 1.6690e+12, 6.0108e+10, 2.2077e+10, 7.5298e+10,
        1.2300e+11, 8.4318e+10, 9.9211e+10, 4.0550e+10, 6.1739e+10, 1.1918e+10,
        9.7899e+10, 2.7185e+10, 9.5657e+09, 7.5465e+10, 2.6810e+10, 1.1002e+11,
        7.7384e+10, 1.1343e+11, 9.3343e+10, 4.2394e+10, 2.7317e+10, 2.0987e+10,
        3.8292e+10, 1.1767e+11, 5.5714e+10, 9.0206e+10, 2.0018e+10, 3.6384e+11,
        4.9914e+10, 1.8910e+10, 3.5649e+10, 2.6448e+11, 7.3660e+10, 1.7075e+11,
        6.0719e+10, 2.4084e+11])
Layer: encoder.5.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.3319e+11, 1.3190e+11, 1.0731e+11, 1.2578e+11, 9.2882e+10, 3.2712e+11,
        1.3871e+11, 1.4075e+11, 1.4908e+11, 2.0194e+11, 7.0304e+10, 1.7026e+11,
        1.1960e+11, 1.2723e+11, 1.4089e+11, 8.2869e+10, 1.6420e+11, 1.5183e+11,
        1.8590e+11, 1.6263e+11, 1.1864e+11, 1.7808e+11, 8.6899e+10, 2.1637e+11,
        1.7084e+11, 1.4994e+11, 1.8002e+11, 1.1898e+11, 1.7311e+11, 1.3261e+11,
        1.6453e+11, 1.3401e+11, 2.1734e+11, 1.9563e+11, 1.4181e+11, 1.2104e+11,
        2.0658e+11, 1.5974e+11, 1.1823e+11, 2.0635e+11, 1.2418e+11, 1.2870e+11,
        1.2439e+11, 1.2858e+11, 1.1743e+11, 1.6374e+11, 1.1783e+11, 1.3954e+11,
        1.6986e+11, 1.5800e+11, 1.8595e+11, 1.0328e+11, 9.1377e+10, 1.4103e+11,
        2.0955e+11, 1.0817e+11, 1.4528e+11, 1.0547e+11, 1.2919e+11, 1.2849e+11,
        1.3863e+11, 1.5845e+11, 1.9363e+11, 1.3520e+11, 1.2341e+11, 1.2469e+11,
        2.3193e+11, 8.5660e+10, 1.1407e+11, 1.2680e+11, 2.0421e+11, 1.3231e+11,
        2.1382e+11, 1.0699e+11, 1.7372e+11, 2.2604e+11, 1.1278e+11, 1.1456e+11,
        1.0752e+11, 2.0592e+11, 1.3503e+11, 1.2225e+11, 1.2042e+11, 1.3461e+11,
        1.4404e+11, 1.3105e+11, 2.0043e+11, 9.7156e+10, 9.1373e+10, 9.7038e+10,
        1.2629e+11, 1.3171e+11, 2.0326e+11, 1.3112e+11, 2.0305e+11, 1.3848e+11,
        1.2724e+11, 1.2569e+11, 9.4877e+10, 1.1437e+11, 1.1257e+11, 1.5560e+11,
        1.5574e+11, 1.2836e+11, 1.3107e+11, 1.2595e+11, 1.1300e+11, 1.9718e+11,
        1.6203e+11, 1.5145e+11, 1.1623e+11, 1.4661e+11, 1.2904e+11, 1.3949e+11,
        9.0510e+10, 1.5805e+11, 1.6186e+11, 1.6128e+11, 2.2098e+11, 1.6268e+11,
        1.3068e+11, 1.4391e+11, 1.2117e+11, 1.1263e+11, 1.2344e+11, 1.3516e+11,
        1.6924e+11, 1.6015e+11])
Layer: encoder.5.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.1494e+11, 1.1572e+11, 3.2104e+11, 2.1286e+11, 3.3722e+11, 1.2133e+11,
        1.3871e+11, 3.0866e+11, 2.2501e+11, 1.5994e+11, 1.4670e+11, 2.4045e+11,
        1.4077e+11, 2.0711e+11, 2.2183e+11, 2.4073e+11, 1.8555e+11, 3.1621e+11,
        2.7205e+11, 2.1840e+11, 3.1657e+11, 1.3561e+11, 1.8741e+11, 1.5276e+11,
        1.3251e+11, 3.2708e+11, 1.8675e+11, 2.6119e+11, 2.1024e+11, 1.6156e+11,
        2.8160e+11, 1.3050e+11, 2.3620e+11, 2.1745e+11, 1.5429e+11, 2.1511e+11,
        1.4820e+11, 2.0458e+11, 1.1601e+11, 3.1322e+11, 2.7901e+11, 1.5821e+11,
        2.4871e+11, 2.5457e+11, 1.9677e+11, 3.1408e+11, 2.3777e+11, 2.0294e+11,
        1.9466e+11, 1.1708e+11, 1.6555e+11, 3.4247e+11, 1.6795e+11, 2.8920e+11,
        3.0526e+11, 1.2453e+11, 2.1905e+11, 2.0913e+11, 1.4671e+11, 2.2199e+11,
        1.5007e+11, 1.6774e+11, 2.1573e+11, 2.0047e+11, 1.6934e+11, 1.9768e+11,
        1.5769e+11, 2.1340e+11, 2.4183e+11, 1.8701e+11, 1.9383e+11, 2.9351e+11,
        1.8754e+11, 1.9819e+11, 2.1846e+11, 1.8858e+11, 1.1940e+11, 1.6696e+11,
        1.6685e+11, 2.8589e+11, 1.5456e+11, 1.4345e+11, 2.1465e+11, 1.8939e+11,
        1.8054e+11, 1.7910e+11, 2.1908e+11, 1.8074e+11, 2.0814e+11, 1.2710e+11,
        1.6880e+11, 2.3399e+11, 2.7798e+11, 2.5279e+11, 2.0001e+11, 2.2839e+11,
        2.9824e+11, 1.8307e+11, 2.0359e+11, 2.0462e+11, 1.7609e+11, 2.0177e+11,
        1.3871e+11, 1.6285e+11, 2.5613e+11, 2.3870e+11, 2.5215e+11, 2.8107e+11,
        2.0902e+11, 1.9521e+11, 1.8802e+11, 2.1125e+11, 2.0310e+11, 2.0143e+11,
        1.9077e+11, 1.4753e+11, 2.4666e+11, 2.2094e+11, 2.5398e+11, 2.0075e+11,
        1.4602e+11, 2.3326e+11, 1.3686e+11, 2.2561e+11, 2.4630e+11, 1.7417e+11,
        2.9196e+11, 2.2637e+11])
Layer: encoder.5.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.2707e+09, 2.3679e+09, 6.5961e+09, 1.3776e+10, 5.4493e+09, 6.1970e+09,
        9.1435e+08, 5.5710e+08, 6.1666e+09, 3.2522e+09, 8.4311e+09, 3.9726e+09,
        2.8168e+09, 2.9755e+09, 5.3377e+09, 2.2826e+10, 2.0921e+10, 1.4132e+10,
        1.7554e+11, 6.8101e+09, 8.2316e+09, 4.0461e+08, 3.9012e+09, 2.5077e+09,
        2.0430e+09, 3.4457e+09, 2.4102e+10, 3.5989e+09, 2.3506e+10, 9.9943e+10,
        9.8454e+09, 4.3193e+09, 1.8153e+09, 4.6464e+09, 8.6620e+09, 8.0093e+09,
        3.9070e+09, 2.0334e+09, 1.2711e+10, 1.5083e+10, 3.4791e+09, 2.8292e+10,
        6.5431e+09, 5.0731e+09, 1.8996e+09, 1.7889e+11, 8.4949e+09, 7.8312e+09,
        3.7295e+09, 4.7072e+09, 9.3237e+09, 5.2287e+09, 2.4095e+09, 4.0244e+09,
        2.6723e+09, 2.8258e+09, 2.2264e+09, 9.9920e+09, 6.5956e+09, 1.1525e+10,
        1.5521e+09, 1.4062e+10, 2.4225e+09, 6.6024e+09, 1.0929e+09, 2.5056e+09,
        6.1431e+09, 3.9112e+09, 5.7122e+09, 4.2115e+09, 2.8311e+09, 3.3684e+09,
        2.8449e+10, 2.1746e+09, 1.0147e+10, 7.2579e+09, 9.1740e+09, 2.0227e+10,
        6.8843e+10, 3.0988e+09, 8.1797e+08, 5.6307e+09, 1.3909e+10, 2.1438e+10,
        5.5866e+09, 1.8979e+09, 2.2219e+09, 3.5796e+09, 1.4207e+09, 2.5873e+10,
        8.8127e+09, 3.2528e+10, 5.7543e+09, 2.3550e+09, 3.1340e+09, 1.0414e+09,
        1.0719e+09, 2.7786e+09, 7.2660e+09, 6.4517e+09, 2.4004e+10, 4.8980e+09,
        2.6259e+09, 2.0505e+10, 4.1087e+10, 3.8288e+09, 2.8346e+09, 3.3735e+11,
        4.7009e+09, 1.1191e+10, 3.2688e+09, 8.1915e+09, 1.3522e+09, 1.3721e+09,
        6.8875e+09, 4.7895e+09, 4.4668e+09, 2.0038e+09, 8.7585e+09, 9.3469e+09,
        1.0111e+09, 7.2122e+09, 4.6160e+09, 1.3327e+09, 4.8790e+09, 2.7214e+09,
        3.4112e+09, 8.4778e+09, 7.2385e+09, 1.8463e+10, 2.1839e+09, 1.7333e+10,
        6.2403e+09, 1.5280e+09, 9.2979e+09, 8.3296e+09, 4.6703e+09, 6.7709e+09,
        2.6848e+09, 1.9903e+10, 1.4909e+10, 6.2731e+09, 1.6209e+10, 5.3407e+09,
        1.0709e+09, 2.9818e+10, 5.0254e+09, 2.3393e+09, 1.5173e+09, 6.3959e+09,
        2.8668e+09, 8.1005e+09, 5.8821e+09, 3.4040e+09, 2.3927e+10, 7.2885e+08,
        2.7667e+09, 1.0699e+10, 2.5210e+09, 1.9313e+10, 8.6957e+09, 6.2823e+09,
        7.9503e+09, 2.1921e+10, 3.1210e+09, 1.7642e+09, 3.9268e+09, 2.5710e+10,
        4.2813e+09, 5.8541e+09, 5.0694e+09, 6.5110e+09, 8.3493e+09, 1.9779e+09,
        1.9877e+09, 2.8891e+09, 2.4352e+09, 4.5554e+09, 2.6319e+09, 3.2343e+09,
        3.4231e+09, 4.7256e+09, 1.2693e+11, 7.8310e+09, 5.2267e+09, 6.6826e+10,
        3.7528e+09, 2.0628e+09, 1.5852e+09, 3.0096e+09, 4.8621e+10, 2.2409e+09,
        5.0431e+10, 1.2747e+10, 6.3604e+09, 3.8936e+09, 3.6835e+09, 5.3821e+09,
        6.4469e+08, 4.2070e+09, 3.5444e+09, 4.6013e+09, 5.4617e+09, 6.3867e+09,
        3.2804e+09, 2.0503e+09, 4.8482e+09, 1.1375e+10, 5.6188e+09, 4.8803e+09,
        2.5785e+09, 1.6509e+09, 8.2648e+09, 2.7561e+09, 8.5893e+09, 4.9207e+09,
        2.4074e+09, 7.1727e+09, 1.6183e+09, 9.0694e+09, 1.8293e+09, 7.9350e+09,
        1.0008e+10, 1.6298e+09, 1.7900e+09, 6.2071e+08, 6.2484e+08, 9.7046e+08,
        5.1841e+10, 2.2156e+09, 5.4296e+09, 6.3097e+09, 4.7117e+09, 5.9934e+09,
        1.4930e+10, 4.1357e+09, 5.3075e+09, 7.4840e+08, 3.5685e+09, 5.0494e+09,
        2.5885e+10, 3.4176e+10, 5.1466e+09, 5.2988e+08, 4.1093e+09, 3.6332e+09,
        5.6715e+09, 1.6199e+09, 2.9907e+09, 2.3666e+09, 1.5662e+09, 3.1299e+10,
        5.1455e+09, 4.8078e+08, 1.9842e+10, 3.9713e+09, 2.4773e+09, 3.0930e+09,
        4.5288e+10, 2.6535e+10, 8.3294e+08, 5.6387e+09, 2.0776e+09, 7.7872e+09,
        1.9454e+09, 8.7437e+09, 4.2799e+08, 4.2324e+09, 1.0612e+09, 9.3678e+09,
        3.0834e+09, 1.0737e+10, 5.3488e+09, 2.7091e+09, 8.7727e+10, 3.0093e+09,
        1.7451e+09, 1.4966e+09, 2.4583e+10, 4.6529e+09, 1.7206e+09, 4.7248e+09,
        2.0207e+09, 6.3068e+09, 9.7794e+09, 4.0556e+10, 8.0851e+09, 1.0545e+09,
        7.1359e+08, 5.9020e+09, 2.6548e+09, 3.7818e+10, 5.8805e+09, 1.7316e+08,
        6.2386e+09, 1.0204e+09, 9.2140e+09, 8.0827e+09, 7.8935e+09, 4.9468e+09,
        3.2363e+09, 1.0660e+09, 5.3342e+09, 5.9901e+09, 1.4528e+10, 2.3267e+11,
        3.3081e+09, 1.0319e+10, 6.9831e+09, 6.4481e+09, 5.7480e+09, 1.2231e+10,
        1.5025e+10, 5.2564e+09, 8.6878e+09, 5.2602e+09, 3.3104e+09, 7.8220e+09,
        3.7227e+09, 5.5901e+08, 2.3708e+09, 4.3249e+10, 4.1783e+09, 2.8372e+09,
        2.0659e+09, 5.9375e+08, 1.8066e+10, 2.2037e+09, 2.4249e+09, 4.0374e+08,
        2.2143e+09, 1.0270e+09, 1.1175e+09, 5.5606e+09, 3.8544e+09, 2.3014e+09,
        1.6065e+10, 1.4151e+09, 3.5394e+10, 9.2783e+09, 5.8033e+08, 2.5098e+09,
        2.1503e+09, 3.0300e+09, 4.3685e+09, 8.5375e+09, 6.9203e+09, 4.0973e+08,
        6.2243e+10, 2.2676e+09, 3.4830e+09, 4.1648e+09, 4.7119e+09, 1.0756e+10,
        8.0335e+09, 6.8391e+09, 3.9623e+09, 5.3673e+09, 7.3770e+09, 6.8211e+10,
        3.4233e+09, 1.0419e+10, 3.4111e+09, 4.3807e+09, 2.0317e+09, 2.5553e+09,
        4.8164e+09, 3.6218e+10, 2.0369e+09, 9.2523e+09, 5.6117e+09, 5.0202e+09,
        1.1035e+10, 6.1812e+09, 2.2761e+10, 5.9207e+09, 6.2475e+09, 3.8088e+09,
        7.9061e+10, 1.0651e+10, 2.4676e+09, 1.6933e+09, 2.5725e+09, 1.1822e+10,
        4.2228e+09, 5.6071e+09, 2.3141e+09, 7.9646e+09, 3.6477e+09, 1.0400e+10,
        4.3484e+09, 1.5520e+10, 1.4963e+09, 1.2500e+10, 1.8013e+09, 3.6787e+10,
        9.7377e+09, 3.4766e+09, 1.2507e+09, 2.0893e+09, 9.8285e+09, 4.0845e+09,
        5.9252e+08, 3.0492e+08, 2.6869e+10, 4.6936e+09, 7.0797e+09, 4.9352e+09,
        2.8575e+09, 1.6539e+09, 4.9494e+09, 2.9080e+08, 8.4222e+09, 2.7053e+09,
        1.1941e+09, 5.3063e+09, 8.5190e+09, 4.8707e+09, 5.1272e+09, 3.7955e+09,
        1.4936e+09, 5.6882e+09, 3.0352e+09, 1.3460e+09, 2.1366e+10, 4.8696e+09,
        3.0751e+09, 2.2867e+09, 2.6615e+09, 1.7558e+10, 7.7526e+09, 4.6667e+09,
        1.8067e+11, 4.1412e+09, 2.4034e+09, 5.4013e+09, 1.2832e+10, 6.2579e+09,
        3.4320e+09, 4.7491e+09, 3.5583e+09, 9.4056e+08, 2.4663e+09, 3.9925e+08,
        4.9452e+09, 3.7712e+09, 2.9715e+09, 2.2449e+10, 6.5015e+09, 3.0921e+09,
        4.8376e+09, 2.6815e+09, 4.3835e+09, 4.0594e+09, 5.3489e+09, 7.9095e+09,
        1.1130e+10, 2.3177e+09, 3.5319e+09, 1.2303e+10, 7.5438e+09, 5.8628e+09,
        6.0470e+09, 3.4318e+09, 9.9028e+08, 1.5421e+10, 4.1829e+09, 7.5730e+09,
        3.6098e+11, 2.0375e+09, 7.2615e+09, 4.8791e+09, 1.1814e+10, 5.3692e+09,
        5.0067e+09, 3.8993e+09, 4.6459e+09, 6.0903e+09, 1.0927e+09, 5.6520e+09,
        2.2573e+09, 1.3552e+10, 8.0871e+09, 6.3970e+09, 4.7704e+09, 1.5802e+09,
        1.4364e+09, 1.4766e+10, 1.0431e+09, 5.1494e+09, 1.6618e+09, 5.6853e+09,
        7.9215e+09, 7.1120e+09, 2.2718e+09, 6.2530e+09, 5.3721e+09, 2.6576e+09,
        3.7997e+09, 1.4762e+10, 8.9604e+09, 3.4493e+09, 7.3437e+08, 1.0399e+11,
        2.4817e+09, 6.5023e+08, 8.7523e+09, 4.0236e+09, 3.2137e+09, 4.1679e+10,
        8.7509e+09, 4.8076e+09])
Layer: encoder.5.3.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.6396e+10, 1.4365e+10, 2.0371e+10, 1.8774e+10, 9.4114e+09, 2.9820e+10,
        1.2136e+10, 1.0020e+10, 1.0294e+10, 1.7071e+10, 1.1782e+10, 2.6439e+10,
        1.3760e+10, 1.9650e+10, 1.7871e+10, 7.6875e+09, 1.1347e+10, 2.1136e+10,
        1.8864e+10, 9.2297e+09, 1.3926e+10, 8.8884e+09, 2.2755e+10, 9.8997e+09,
        3.5375e+10, 1.1410e+10, 1.2734e+10, 9.9499e+09, 1.5605e+10, 9.6037e+09,
        1.2838e+10, 1.5789e+10, 1.9330e+10, 1.7190e+10, 1.6253e+10, 1.8940e+10,
        1.1361e+10, 1.3517e+10, 2.5819e+10, 2.3137e+10, 2.0895e+10, 2.3274e+10,
        2.1632e+10, 7.8631e+09, 1.1731e+10, 1.2864e+10, 1.9654e+10, 1.3012e+10,
        1.3087e+10, 1.7452e+10, 2.5124e+10, 1.8322e+10, 1.6278e+10, 1.1390e+10,
        1.5308e+10, 1.4031e+10, 6.6300e+09, 8.0828e+09, 1.1844e+10, 1.0360e+10,
        1.0955e+10, 1.5930e+10, 1.2443e+10, 1.0513e+10, 1.0608e+10, 2.7525e+10,
        1.7491e+10, 7.5779e+09, 1.9540e+10, 2.9775e+10, 1.0706e+10, 1.9007e+10,
        1.4773e+10, 2.8470e+10, 2.2653e+10, 3.2328e+10, 1.0900e+10, 1.6609e+10,
        1.2553e+10, 1.4218e+10, 1.4344e+10, 1.3312e+10, 1.2408e+10, 1.0331e+10,
        1.4629e+10, 1.2177e+10, 2.0543e+10, 2.2618e+10, 1.3988e+10, 7.9582e+09,
        1.5470e+10, 2.1351e+10, 1.8067e+10, 2.1204e+10, 1.5284e+10, 2.4057e+10,
        1.0328e+10, 1.3423e+10, 2.1658e+10, 1.2666e+10, 1.1210e+10, 9.1911e+09,
        2.5374e+10, 1.0112e+10, 1.0788e+10, 1.3631e+10, 1.6172e+10, 1.6496e+10,
        2.3853e+10, 1.7843e+10, 1.9843e+10, 1.1080e+10, 1.8709e+10, 1.7933e+10,
        1.0317e+10, 1.1072e+10, 1.8701e+10, 1.0804e+10, 2.0550e+10, 2.4078e+10,
        1.6480e+10, 1.4861e+10, 1.3258e+10, 8.7339e+09, 6.6921e+09, 1.1140e+10,
        1.8047e+10, 1.4307e+10])
Layer: encoder.5.3.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.1390e+10, 1.4560e+10, 1.4936e+10, 1.7374e+10, 1.4052e+10, 2.3025e+10,
        4.4944e+10, 2.4635e+10, 1.9752e+10, 2.3591e+10, 2.3439e+10, 3.0958e+10,
        1.0307e+10, 2.3650e+10, 1.0723e+10, 2.0335e+10, 3.5450e+10, 2.6576e+10,
        2.0103e+10, 1.7122e+10, 3.8773e+10, 2.6496e+10, 1.7368e+10, 2.4941e+10,
        2.3776e+10, 1.2749e+10, 1.2780e+10, 2.4733e+10, 1.8354e+10, 1.6062e+10,
        1.3598e+10, 2.0269e+10, 4.7845e+10, 1.4854e+10, 2.8888e+10, 1.4306e+10,
        3.0573e+10, 3.1064e+10, 4.5892e+10, 1.8278e+10, 2.1062e+10, 1.0181e+10,
        3.2679e+10, 1.8476e+10, 3.1531e+10, 2.7739e+10, 4.7748e+10, 2.7832e+10,
        1.6300e+10, 3.2093e+10, 2.4394e+10, 2.7610e+10, 2.9020e+10, 3.1113e+10,
        3.2737e+10, 3.4230e+10, 1.2817e+10, 1.6278e+10, 2.8776e+10, 4.5993e+10,
        1.7162e+10, 2.4504e+10, 1.7662e+10, 3.8338e+10, 2.3073e+10, 2.2139e+10,
        1.1168e+10, 2.6047e+10, 2.4215e+10, 1.6135e+10, 3.1579e+10, 1.9273e+10,
        2.0601e+10, 1.6913e+10, 2.3434e+10, 1.8267e+10, 1.4055e+10, 3.0500e+10,
        3.0157e+10, 3.5263e+10, 1.2285e+10, 2.2950e+10, 2.4251e+10, 2.4326e+10,
        2.2530e+10, 1.4738e+10, 2.0200e+10, 3.5276e+10, 3.5605e+10, 3.2360e+10,
        2.5588e+10, 3.5457e+10, 1.0730e+10, 2.7496e+10, 2.1592e+10, 3.5099e+10,
        2.0198e+10, 1.2164e+10, 1.5787e+10, 3.0997e+10, 1.1161e+10, 1.7795e+10,
        1.3724e+10, 1.5664e+10, 2.0416e+10, 2.2237e+10, 2.0698e+10, 2.3164e+10,
        3.0714e+10, 1.6651e+10, 1.3652e+10, 2.0491e+10, 3.3198e+10, 4.4872e+10,
        1.1975e+10, 2.1392e+10, 2.8406e+10, 1.5534e+10, 1.5887e+10, 1.5315e+10,
        1.7473e+10, 2.7744e+10, 1.9353e+10, 3.3738e+10, 3.8944e+10, 2.4276e+10,
        1.7849e+10, 2.3580e+10])
Layer: encoder.5.3.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.3727e+09, 7.8784e+08, 4.0768e+08, 6.9939e+08, 1.0342e+09, 7.8060e+07,
        5.2662e+07, 2.7605e+08, 2.1694e+09, 1.0341e+09, 5.4023e+08, 3.2776e+08,
        3.7445e+08, 1.3804e+08, 5.0380e+08, 3.1804e+08, 3.2553e+08, 3.0121e+08,
        2.9533e+08, 1.3668e+08, 3.6444e+08, 5.6399e+07, 3.2776e+08, 1.0081e+08,
        5.6025e+08, 1.1225e+08, 2.4191e+08, 4.8646e+08, 8.9859e+09, 8.2551e+08,
        8.6990e+08, 4.4957e+08, 9.7923e+07, 8.2588e+07, 6.2686e+08, 1.5697e+09,
        2.7234e+08, 5.4660e+07, 3.1527e+08, 2.3260e+08, 4.5045e+08, 9.4845e+08,
        7.7133e+08, 3.0887e+09, 3.4539e+07, 1.2984e+11, 2.5243e+09, 6.2033e+08,
        7.6023e+07, 2.3316e+08, 4.3611e+08, 5.1018e+08, 7.4557e+07, 5.2749e+08,
        1.6363e+08, 1.5204e+08, 2.4839e+08, 1.7023e+09, 1.5042e+08, 4.5999e+08,
        1.2377e+08, 2.4016e+08, 2.6270e+08, 1.3361e+09, 7.3291e+08, 8.5147e+08,
        1.2696e+09, 1.0206e+08, 9.8214e+08, 4.1968e+08, 2.9392e+08, 4.8118e+09,
        6.1114e+09, 2.6384e+08, 2.4754e+08, 2.9434e+08, 7.4900e+08, 1.4766e+09,
        2.5317e+08, 1.9914e+09, 1.3660e+08, 2.4017e+08, 3.6443e+08, 5.6551e+08,
        3.5284e+08, 5.8877e+07, 2.6151e+08, 8.1932e+07, 3.7759e+07, 4.6863e+08,
        6.5676e+08, 1.8639e+08, 3.2038e+08, 4.6500e+08, 6.6396e+07, 2.4089e+08,
        8.1744e+07, 6.0009e+07, 5.3979e+08, 2.6602e+08, 4.6898e+08, 1.6338e+09,
        1.6906e+09, 3.0330e+08, 6.8835e+08, 1.5861e+08, 4.5891e+08, 7.2831e+08,
        2.8381e+08, 2.9173e+08, 4.2307e+08, 9.8595e+07, 9.0176e+07, 5.9470e+07,
        1.3713e+08, 2.6334e+08, 5.0431e+08, 5.8157e+08, 4.9389e+08, 4.9147e+08,
        9.8352e+07, 1.1748e+08, 2.7352e+08, 1.5690e+08, 2.5191e+09, 1.5602e+08,
        5.1586e+08, 9.9164e+08, 3.6117e+08, 2.2762e+08, 1.9192e+07, 4.2435e+08,
        1.3014e+09, 7.1792e+07, 7.9003e+08, 3.4550e+08, 5.7547e+08, 5.7081e+08,
        2.3650e+09, 4.6465e+08, 1.6051e+08, 2.0405e+08, 6.2413e+08, 2.8516e+08,
        4.1782e+07, 1.4778e+09, 6.4853e+08, 4.8601e+07, 7.6342e+07, 2.1777e+08,
        8.0286e+07, 4.7289e+08, 7.8522e+08, 5.2648e+08, 4.8191e+09, 2.6711e+08,
        1.0017e+08, 4.3835e+08, 8.7169e+08, 2.4689e+08, 4.5234e+08, 3.5301e+08,
        6.1844e+08, 9.0669e+08, 1.0747e+09, 3.1745e+07, 3.5602e+09, 1.4842e+09,
        2.7746e+09, 1.8296e+08, 5.0246e+08, 3.6110e+08, 5.3574e+08, 6.5182e+07,
        5.5588e+07, 1.9570e+08, 6.5815e+07, 8.8336e+08, 1.1257e+08, 1.4463e+08,
        1.4079e+08, 3.9997e+08, 4.6112e+09, 1.6998e+09, 3.7813e+08, 3.1054e+08,
        1.8362e+09, 8.7302e+07, 7.4628e+07, 9.2670e+07, 5.4693e+08, 1.0337e+08,
        4.2797e+08, 8.6865e+08, 5.1092e+08, 3.4271e+08, 3.1513e+08, 3.4207e+08,
        3.7496e+07, 5.7961e+07, 3.4270e+08, 3.2053e+08, 5.2889e+08, 3.2531e+08,
        3.5272e+08, 1.7676e+08, 1.3564e+08, 4.3269e+08, 2.6667e+08, 6.2486e+08,
        9.6589e+07, 5.2784e+07, 5.7187e+07, 3.3339e+08, 9.9136e+08, 3.0592e+08,
        8.6966e+07, 3.8094e+09, 8.4070e+07, 3.3366e+08, 1.7809e+08, 4.0681e+08,
        5.0262e+08, 1.0082e+08, 2.2202e+08, 8.1848e+07, 4.1599e+07, 6.2619e+07,
        4.4712e+09, 6.2864e+08, 7.5014e+08, 7.7634e+08, 6.2573e+07, 3.7088e+08,
        1.3273e+10, 7.4344e+08, 4.0871e+08, 9.9999e+08, 4.7205e+08, 8.6753e+07,
        4.4843e+08, 7.4901e+08, 2.8983e+08, 1.8860e+07, 5.5298e+08, 5.2990e+08,
        3.1344e+08, 3.4042e+09, 5.1932e+08, 2.3029e+08, 3.8056e+07, 4.2894e+08,
        4.2709e+08, 7.1858e+07, 3.6622e+08, 1.6796e+08, 1.4243e+09, 4.2513e+08,
        4.6156e+08, 3.4761e+08, 1.5549e+08, 2.7690e+08, 3.0262e+08, 4.7881e+09,
        6.3463e+08, 2.6804e+09, 2.5212e+07, 2.7782e+08, 2.4044e+08, 4.9857e+08,
        3.6778e+08, 4.1113e+09, 2.0485e+08, 1.2318e+09, 2.3278e+08, 1.3411e+08,
        5.1174e+08, 3.6822e+08, 2.8386e+08, 3.8273e+08, 4.6204e+08, 2.4622e+08,
        1.1170e+08, 1.2999e+08, 6.9491e+08, 1.1945e+09, 1.3994e+09, 9.6723e+07,
        9.6041e+07, 1.4188e+08, 6.7055e+08, 1.9375e+08, 1.8817e+09, 3.4679e+07,
        3.6862e+08, 5.2998e+08, 4.0498e+08, 4.5172e+08, 3.2675e+08, 4.9338e+08,
        1.0948e+09, 1.2037e+08, 2.3626e+08, 4.6237e+08, 1.2287e+09, 2.1384e+08,
        9.1398e+08, 1.1655e+09, 1.1168e+08, 1.4853e+08, 3.3765e+08, 3.0400e+09,
        6.4478e+09, 2.0740e+08, 3.8469e+08, 3.4046e+08, 3.9830e+08, 6.4042e+08,
        1.5976e+09, 1.2871e+08, 4.2127e+08, 7.1288e+08, 4.8045e+08, 4.5559e+08,
        1.1638e+08, 1.6719e+08, 2.8956e+08, 9.1865e+07, 8.9809e+07, 3.8021e+07,
        2.3391e+08, 1.3121e+08, 3.7755e+08, 2.1960e+09, 3.2475e+08, 2.0261e+08,
        5.9806e+08, 2.0086e+08, 3.2216e+09, 1.5834e+09, 3.8286e+08, 1.9041e+08,
        1.2619e+09, 3.4027e+08, 5.8088e+08, 7.5426e+08, 1.0220e+08, 2.7341e+07,
        5.4843e+08, 3.5595e+07, 5.7033e+08, 5.2626e+08, 1.6014e+09, 2.8655e+08,
        8.0153e+07, 3.6708e+08, 1.0486e+08, 4.6214e+08, 2.9874e+08, 3.9658e+08,
        7.2119e+08, 8.5725e+08, 7.5930e+07, 2.3085e+08, 9.2180e+07, 9.6723e+08,
        1.1503e+09, 5.7383e+08, 1.0065e+08, 4.7438e+08, 9.8031e+08, 1.4264e+08,
        1.0647e+09, 3.1958e+08, 2.4947e+08, 2.6279e+08, 7.6699e+08, 4.0574e+08,
        2.7133e+08, 3.9452e+08, 2.0191e+08, 1.4825e+07, 1.8547e+08, 9.6289e+07,
        4.9237e+09, 4.0224e+08, 4.7625e+07, 8.0420e+08, 2.1961e+09, 3.0965e+08,
        2.0931e+08, 3.5643e+08, 6.4377e+07, 4.7260e+08, 1.2423e+08, 1.8417e+08,
        4.2129e+08, 4.4949e+07, 2.4736e+08, 1.7628e+08, 7.2813e+08, 5.2969e+08,
        3.7131e+07, 9.4130e+07, 3.6827e+08, 8.2212e+08, 1.2562e+08, 1.2578e+09,
        1.7496e+09, 2.7248e+08, 2.4690e+08, 5.5776e+07, 3.9372e+08, 3.9425e+07,
        1.3408e+08, 8.1533e+08, 2.9775e+08, 3.1530e+08, 1.3918e+08, 4.8193e+08,
        1.3256e+08, 2.3636e+08, 1.3068e+09, 2.1725e+07, 5.3650e+08, 9.7348e+07,
        9.2125e+08, 1.3475e+08, 7.9609e+07, 4.6591e+08, 3.7287e+08, 9.2321e+07,
        1.0823e+09, 1.2118e+08, 7.3419e+08, 4.3960e+08, 3.0985e+08, 5.3437e+08,
        1.5914e+08, 3.5110e+08, 1.8093e+08, 1.4526e+08, 4.3129e+07, 5.4740e+07,
        4.4329e+08, 3.4092e+08, 9.8522e+07, 6.3029e+08, 1.1202e+08, 4.5261e+08,
        5.0635e+08, 8.1542e+07, 3.6054e+08, 2.5428e+08, 3.8448e+08, 8.2901e+09,
        5.0497e+09, 8.0609e+07, 1.8540e+09, 3.7132e+08, 1.9329e+09, 1.8311e+08,
        6.0814e+08, 4.5586e+08, 7.6132e+07, 1.2697e+10, 4.3109e+08, 7.8311e+08,
        2.5934e+09, 1.0450e+08, 8.2777e+08, 1.9722e+09, 4.4230e+08, 1.7315e+09,
        2.7648e+08, 3.7356e+08, 4.2439e+08, 2.7405e+08, 7.0892e+07, 1.2006e+09,
        2.4811e+08, 9.0217e+09, 5.2601e+08, 2.2917e+09, 6.6279e+07, 1.9742e+09,
        1.9461e+08, 3.2671e+08, 1.9155e+08, 4.4244e+09, 8.2142e+08, 3.6055e+08,
        3.1297e+08, 3.4415e+08, 1.5648e+08, 3.1856e+08, 3.3352e+08, 3.9451e+08,
        2.4125e+08, 2.0057e+08, 6.9502e+09, 1.5667e+08, 7.2438e+07, 4.8642e+08,
        3.3118e+08, 8.9278e+07, 4.6728e+08, 2.2594e+09, 6.6209e+07, 8.9206e+08,
        7.2353e+08, 2.1945e+09])
Layer: encoder.6.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.8356e+08, 6.2222e+08, 7.6103e+08, 5.2982e+08, 5.8888e+08, 5.4266e+08,
        4.9542e+08, 7.5554e+08, 4.6374e+08, 7.3951e+08, 4.3349e+08, 6.6668e+08,
        5.9389e+08, 7.4571e+08, 5.3692e+08, 6.9713e+08, 6.5040e+08, 6.9357e+08,
        5.2987e+08, 5.2708e+08, 4.8971e+08, 4.8826e+08, 6.7717e+08, 4.4929e+08,
        6.3865e+08, 4.9073e+08, 7.1033e+08, 4.4374e+08, 6.3667e+08, 6.0877e+08,
        4.9411e+08, 6.4870e+08, 8.0942e+08, 5.3467e+08, 5.2064e+08, 6.6749e+08,
        5.3708e+08, 6.4903e+08, 6.1872e+08, 5.6001e+08, 5.6087e+08, 8.9086e+08,
        7.1023e+08, 6.8354e+08, 5.8940e+08, 6.2821e+08, 8.3053e+08, 5.4783e+08,
        5.9085e+08, 3.8633e+08, 4.8313e+08, 7.0299e+08, 4.6216e+08, 3.9591e+08,
        4.2945e+08, 6.0003e+08, 5.3168e+08, 6.0639e+08, 6.1043e+08, 6.5401e+08,
        6.2327e+08, 6.1897e+08, 7.7504e+08, 7.0291e+08, 5.8668e+08, 7.2661e+08,
        4.8806e+08, 4.9667e+08, 4.9996e+08, 7.8255e+08, 5.7902e+08, 1.0012e+09,
        4.7047e+08, 4.6452e+08, 7.1846e+08, 4.4227e+08, 8.5563e+08, 6.6301e+08,
        7.6940e+08, 4.5587e+08, 6.4115e+08, 6.7532e+08, 4.6671e+08, 5.6628e+08,
        7.0456e+08, 4.9427e+08, 5.2841e+08, 4.6507e+08, 6.0329e+08, 5.5288e+08,
        5.1391e+08, 7.4025e+08, 6.4391e+08, 5.7632e+08, 7.3568e+08, 5.5941e+08,
        4.7709e+08, 6.3893e+08, 7.1009e+08, 7.1153e+08, 4.2804e+08, 5.4313e+08,
        6.0702e+08, 7.2281e+08, 5.3530e+08, 6.2063e+08, 3.4997e+08, 9.6711e+08,
        8.6417e+08, 7.0381e+08, 6.4582e+08, 5.7038e+08, 5.6942e+08, 5.1508e+08,
        4.6229e+08, 6.5719e+08, 6.6368e+08, 6.2144e+08, 5.9270e+08, 6.7876e+08,
        7.2793e+08, 4.9958e+08, 6.7255e+08, 6.6912e+08, 5.4433e+08, 5.3360e+08,
        5.1511e+08, 5.4454e+08, 6.9254e+08, 4.3564e+08, 6.8363e+08, 6.9655e+08,
        5.5130e+08, 3.9511e+08, 7.1615e+08, 5.4713e+08, 5.8949e+08, 4.8619e+08,
        7.1083e+08, 5.6911e+08, 6.2087e+08, 3.4879e+08, 3.4962e+08, 5.3899e+08,
        7.2496e+08, 6.8889e+08, 6.8357e+08, 4.7627e+08, 7.8055e+08, 4.9886e+08,
        6.5800e+08, 8.2764e+08, 7.0675e+08, 4.6601e+08, 5.1488e+08, 4.8779e+08,
        6.9666e+08, 6.1613e+08, 4.8038e+08, 6.9934e+08, 6.2189e+08, 4.8818e+08,
        4.8096e+08, 6.2101e+08, 5.9683e+08, 5.9488e+08, 7.2849e+08, 6.0456e+08,
        4.8329e+08, 6.1557e+08, 5.1754e+08, 4.8906e+08, 6.5692e+08, 6.2299e+08,
        4.8673e+08, 5.5075e+08, 6.5136e+08, 6.3277e+08, 8.3150e+08, 7.6857e+08,
        7.2739e+08, 5.3129e+08, 7.1800e+08, 5.7725e+08, 5.4225e+08, 5.8035e+08,
        6.2663e+08, 5.4649e+08, 6.3512e+08, 6.7779e+08, 6.0887e+08, 5.3118e+08,
        4.7714e+08, 4.9706e+08, 5.7589e+08, 8.2022e+08, 6.2409e+08, 6.5072e+08,
        6.9936e+08, 4.4338e+08, 7.0864e+08, 4.6838e+08, 4.1384e+08, 5.1616e+08,
        6.8642e+08, 5.3024e+08, 4.7396e+08, 4.9030e+08, 4.3998e+08, 9.4086e+08,
        4.9090e+08, 6.3879e+08, 5.1111e+08, 6.7221e+08, 6.3028e+08, 6.3388e+08,
        7.1289e+08, 4.7042e+08, 4.8826e+08, 6.4841e+08, 6.3517e+08, 5.5924e+08,
        5.9290e+08, 7.2559e+08, 8.0371e+08, 5.7994e+08, 5.4542e+08, 5.6197e+08,
        3.9071e+08, 3.8961e+08, 7.1574e+08, 5.5205e+08, 4.0705e+08, 6.7519e+08,
        5.1069e+08, 4.9342e+08, 5.3045e+08, 1.0036e+09, 3.1167e+08, 5.2466e+08,
        6.5159e+08, 6.7942e+08, 5.3736e+08, 4.5106e+08, 5.8618e+08, 5.8569e+08,
        5.2363e+08, 4.7705e+08, 5.8814e+08, 6.2563e+08, 7.0369e+08, 5.6897e+08,
        6.7905e+08, 4.1195e+08, 7.6672e+08, 4.5149e+08])
Layer: encoder.6.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.0499e+09, 1.2097e+09, 8.3656e+08, 1.1954e+09, 1.0718e+09, 1.0814e+09,
        1.1033e+09, 1.1720e+09, 1.2253e+09, 1.2468e+09, 9.3001e+08, 1.1641e+09,
        1.4452e+09, 9.5137e+08, 1.1135e+09, 9.0276e+08, 1.2828e+09, 1.1605e+09,
        7.7228e+08, 9.8115e+08, 1.0573e+09, 1.1037e+09, 9.4841e+08, 9.1025e+08,
        1.0886e+09, 1.1600e+09, 7.3117e+08, 1.1399e+09, 1.4937e+09, 1.2380e+09,
        1.0228e+09, 9.2435e+08, 1.2938e+09, 1.3362e+09, 7.3013e+08, 1.3350e+09,
        9.7742e+08, 1.2861e+09, 1.2046e+09, 9.0958e+08, 1.2607e+09, 1.0821e+09,
        1.0043e+09, 1.2375e+09, 9.1443e+08, 9.5750e+08, 1.0639e+09, 1.1909e+09,
        1.7356e+09, 1.3265e+09, 9.9625e+08, 1.0273e+09, 8.0239e+08, 1.1002e+09,
        8.8974e+08, 8.9767e+08, 1.1403e+09, 7.5121e+08, 1.2355e+09, 7.6839e+08,
        7.4481e+08, 8.5688e+08, 1.0412e+09, 9.5579e+08, 1.2223e+09, 6.2001e+08,
        1.2396e+09, 1.6699e+09, 8.8933e+08, 9.4658e+08, 9.5267e+08, 6.6704e+08,
        1.0205e+09, 9.6597e+08, 1.0050e+09, 6.8511e+08, 9.1828e+08, 8.9072e+08,
        1.1453e+09, 8.9364e+08, 1.4128e+09, 1.1911e+09, 7.9278e+08, 1.4887e+09,
        1.1721e+09, 1.5112e+09, 1.1272e+09, 1.3383e+09, 9.8872e+08, 7.1144e+08,
        1.4117e+09, 1.1705e+09, 1.1230e+09, 8.2080e+08, 8.8929e+08, 9.3889e+08,
        1.1122e+09, 1.1755e+09, 1.0062e+09, 9.3995e+08, 9.4434e+08, 1.0939e+09,
        9.5553e+08, 9.0014e+08, 1.1575e+09, 1.3509e+09, 1.4053e+09, 1.0800e+09,
        6.7223e+08, 1.4085e+09, 1.0423e+09, 1.2613e+09, 9.8379e+08, 8.3018e+08,
        1.2322e+09, 1.0970e+09, 1.2125e+09, 1.1535e+09, 1.2937e+09, 1.1337e+09,
        1.1396e+09, 1.1472e+09, 1.2824e+09, 8.2667e+08, 9.6521e+08, 1.1908e+09,
        1.1317e+09, 1.3398e+09, 1.2035e+09, 1.0657e+09, 1.1020e+09, 1.1948e+09,
        7.8701e+08, 8.7006e+08, 1.1300e+09, 8.8761e+08, 1.0663e+09, 1.5211e+09,
        1.2311e+09, 1.2501e+09, 1.1570e+09, 1.0652e+09, 1.0989e+09, 9.6574e+08,
        1.1713e+09, 8.7917e+08, 1.1754e+09, 1.3263e+09, 1.0838e+09, 1.3695e+09,
        1.0840e+09, 9.8173e+08, 1.1646e+09, 7.0707e+08, 9.4746e+08, 1.2567e+09,
        1.4366e+09, 1.1047e+09, 1.0269e+09, 1.0840e+09, 9.3267e+08, 9.2803e+08,
        1.5372e+09, 1.5112e+09, 1.3102e+09, 1.0559e+09, 1.2339e+09, 8.4548e+08,
        1.3821e+09, 1.3206e+09, 1.2557e+09, 1.1100e+09, 1.3545e+09, 7.1492e+08,
        6.8605e+08, 7.9321e+08, 1.1638e+09, 1.0892e+09, 1.0926e+09, 9.3106e+08,
        1.2186e+09, 1.2227e+09, 1.0990e+09, 1.3887e+09, 1.1980e+09, 1.2103e+09,
        8.9567e+08, 8.8836e+08, 1.2760e+09, 9.8271e+08, 8.2968e+08, 1.0809e+09,
        1.1587e+09, 1.0374e+09, 8.7796e+08, 8.9465e+08, 1.2308e+09, 6.3253e+08,
        1.0983e+09, 8.8825e+08, 1.0626e+09, 1.2302e+09, 1.0335e+09, 1.1163e+09,
        1.3084e+09, 9.3273e+08, 1.1528e+09, 9.9487e+08, 1.0279e+09, 8.5265e+08,
        1.4082e+09, 1.1967e+09, 1.4283e+09, 1.0912e+09, 1.0133e+09, 1.0450e+09,
        1.2744e+09, 1.0943e+09, 9.8378e+08, 1.4080e+09, 9.5516e+08, 1.3689e+09,
        6.9806e+08, 1.2191e+09, 1.1253e+09, 1.2228e+09, 1.1675e+09, 9.7267e+08,
        1.3697e+09, 9.8999e+08, 1.3535e+09, 8.4717e+08, 1.2063e+09, 1.1646e+09,
        1.0228e+09, 1.0128e+09, 1.0299e+09, 9.2445e+08, 1.1691e+09, 8.2482e+08,
        1.1097e+09, 1.1490e+09, 1.0230e+09, 8.2448e+08, 1.2718e+09, 1.0893e+09,
        1.5723e+09, 1.3229e+09, 9.6502e+08, 7.2112e+08, 8.0133e+08, 1.4466e+09,
        1.1738e+09, 1.0292e+09, 9.9918e+08, 1.4225e+09])
Layer: encoder.6.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 5576000.5000, 19845170.0000,   726217.4375,  ...,
         4200184.5000,  3105103.2500, 16761072.0000])
Layer: encoder.6.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 6212194.5000, 12583284.0000, 19359102.0000,  ...,
        13639630.0000, 21024444.0000, 11746246.0000])
Layer: encoder.6.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([53503748., 24402240., 26345070., 22522108., 29821038., 43791932.,
        36831368., 41489808., 35368516., 28457242., 41888100., 33323730.,
        39301308., 34547540., 29805154., 37036832., 26619640., 35710388.,
        32732602., 28137076., 38681716., 42405992., 29239278., 24155456.,
        28280630., 38326932., 35883908., 28309072., 37548936., 40201124.,
        31482738., 31811454., 35085472., 20183790., 33224954., 22470164.,
        28846312., 23990392., 29609472., 30078700., 22385826., 26317358.,
        28255144., 47227868., 19533896., 30062272., 30030916., 28545212.,
        28039736., 29248424., 21116238., 38146972., 38782352., 34346380.,
        33994772., 30548294., 34463924., 29168934., 39733128., 22317580.,
        30460654., 24913550., 30470556., 20581766., 24322162., 35870468.,
        46450568., 43496816., 37611140., 25193074., 31307266., 28744652.,
        30481788., 21949628., 37296024., 54012856., 41318152., 28668812.,
        37895668., 32926344., 29490234., 22251812., 25240882., 41268768.,
        30231140., 22567382., 34418532., 41360736., 39184544., 23060596.,
        34292560., 41491796., 43044512., 41284344., 31196850., 27567302.,
        26237648., 21602744., 32045048., 50132924., 35645644., 28253026.,
        26949968., 36846552., 20674128., 20199336., 32923172., 29679702.,
        43243076., 26845418., 21783154., 42578880., 26811984., 30064652.,
        39789496., 23790042., 30152904., 25619442., 40048236., 30366862.,
        26129480., 33179968., 38759108., 44937012., 45554864., 30563290.,
        36209140., 40985304., 45899264., 29212512., 32943876., 24807060.,
        29238090., 24400308., 30166900., 31952512., 42445628., 28410426.,
        24175480., 27635254., 24720304., 27864564., 36120192., 39808244.,
        36321928., 20355830., 29081152., 35897860., 25827588., 21981324.,
        40095500., 23603902., 30740690., 35993232., 34185396., 25661140.,
        35391176., 39492848., 36623072., 49815924., 23541990., 30758002.,
        25900748., 24884850., 30852370., 29807278., 23630686., 33673056.,
        37135860., 40121368., 31434100., 41587156., 29591148., 33688720.,
        38185100., 26889596., 34010060., 47898948., 32965092., 28209390.,
        32119170., 36897412., 28373878., 21755454., 33087350., 21315718.,
        22740386., 34404828., 31306944., 28077454., 41762268., 35087968.,
        24394524., 24150206., 39318716., 31441442., 31476720., 42568808.,
        28543334., 32738182., 25226116., 33966928., 27590116., 36259884.,
        26946442., 31003194., 27833470., 37782060., 34398844., 32842994.,
        22106018., 26494708., 31477878., 42699188., 25845288., 23910140.,
        47494340., 26690530., 31002132., 40648932., 25015412., 24568250.,
        38553452., 27851652., 29025072., 30716194., 21442788., 26161212.,
        26924166., 28117586., 38129584., 30115106., 31580958., 27893120.,
        34912976., 27645580., 45285660., 40796528., 38317364., 24682950.,
        32526076., 25268012., 36462844., 15572660., 30856104., 28623770.,
        28297220., 49935484., 28080624., 42964632., 43573988., 24139098.,
        41387424., 30609460., 37166180., 46673520.])
Layer: encoder.6.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.0992e+07, 8.8341e+07, 7.4777e+07, 9.5156e+07, 6.6062e+07, 8.5263e+07,
        5.1534e+07, 6.9714e+07, 1.0531e+08, 7.7439e+07, 1.3008e+08, 8.5931e+07,
        9.2449e+07, 6.7515e+07, 7.4666e+07, 4.5351e+07, 5.8649e+07, 5.3443e+07,
        1.0418e+08, 8.2600e+07, 8.2306e+07, 9.0215e+07, 6.4169e+07, 7.6910e+07,
        1.0133e+08, 7.4412e+07, 4.9492e+07, 7.4668e+07, 1.0014e+08, 8.9672e+07,
        7.2963e+07, 8.8356e+07, 8.6721e+07, 7.6322e+07, 8.4828e+07, 1.1392e+08,
        7.5435e+07, 9.5827e+07, 1.1158e+08, 4.7435e+07, 9.2141e+07, 5.6294e+07,
        8.2881e+07, 5.5357e+07, 8.5089e+07, 6.4639e+07, 7.1229e+07, 4.6807e+07,
        4.3704e+07, 6.3470e+07, 7.4974e+07, 7.7127e+07, 9.2722e+07, 1.0013e+08,
        9.6865e+07, 6.7553e+07, 7.1340e+07, 4.1182e+07, 5.6207e+07, 8.5962e+07,
        8.9107e+07, 6.1155e+07, 5.4099e+07, 5.3990e+07, 7.7036e+07, 6.9832e+07,
        9.4756e+07, 5.7473e+07, 6.2811e+07, 8.9953e+07, 9.5007e+07, 9.7781e+07,
        6.6930e+07, 6.5464e+07, 7.9559e+07, 6.1080e+07, 9.5528e+07, 5.1246e+07,
        9.8446e+07, 7.3106e+07, 7.4772e+07, 9.8969e+07, 6.6454e+07, 6.7934e+07,
        9.4909e+07, 6.6564e+07, 9.5879e+07, 9.2333e+07, 6.2553e+07, 1.3105e+08,
        8.9610e+07, 9.4609e+07, 9.1259e+07, 6.9597e+07, 3.9805e+07, 1.0182e+08,
        6.9531e+07, 6.1920e+07, 7.2172e+07, 8.9378e+07, 6.8242e+07, 6.2908e+07,
        9.2940e+07, 9.9155e+07, 5.9166e+07, 7.2969e+07, 9.0563e+07, 6.9965e+07,
        8.7290e+07, 9.9074e+07, 5.2799e+07, 7.4139e+07, 7.5067e+07, 1.1052e+08,
        1.1181e+08, 8.8267e+07, 9.4960e+07, 4.6709e+07, 4.6788e+07, 7.7261e+07,
        8.9756e+07, 9.8741e+07, 6.0815e+07, 1.1830e+08, 7.8084e+07, 8.3244e+07,
        5.3717e+07, 5.8800e+07, 7.3333e+07, 6.2769e+07, 5.8906e+07, 7.2823e+07,
        5.3093e+07, 5.2691e+07, 5.2669e+07, 8.3612e+07, 7.4921e+07, 9.8642e+07,
        7.0225e+07, 5.5306e+07, 5.0904e+07, 9.0780e+07, 6.4707e+07, 9.9319e+07,
        1.1360e+08, 6.3665e+07, 7.6754e+07, 1.2738e+08, 8.8907e+07, 8.0734e+07,
        7.0276e+07, 8.6398e+07, 1.4981e+08, 8.2386e+07, 8.1236e+07, 4.9808e+07,
        6.6581e+07, 1.1787e+08, 8.5142e+07, 6.8204e+07, 9.0542e+07, 8.2516e+07,
        5.3300e+07, 9.4296e+07, 4.8483e+07, 9.0876e+07, 9.3801e+07, 6.8930e+07,
        6.1943e+07, 6.2421e+07, 8.3614e+07, 9.6052e+07, 8.5383e+07, 9.9674e+07,
        7.0370e+07, 9.8983e+07, 5.9767e+07, 6.7790e+07, 7.4641e+07, 5.8404e+07,
        6.3806e+07, 6.8549e+07, 1.0671e+08, 6.9844e+07, 1.1800e+08, 9.1208e+07,
        1.1611e+08, 8.8836e+07, 9.0276e+07, 4.6719e+07, 6.3899e+07, 7.1708e+07,
        5.8942e+07, 9.0543e+07, 6.1817e+07, 7.5666e+07, 9.4225e+07, 7.4996e+07,
        6.9222e+07, 8.1642e+07, 9.2578e+07, 9.4927e+07, 9.5005e+07, 7.7108e+07,
        7.3316e+07, 1.1578e+08, 8.6548e+07, 7.0866e+07, 7.6467e+07, 8.3052e+07,
        7.9821e+07, 6.9542e+07, 8.1593e+07, 6.8616e+07, 9.0817e+07, 7.3172e+07,
        1.0905e+08, 6.4780e+07, 7.1849e+07, 6.9907e+07, 8.0160e+07, 9.2615e+07,
        6.7776e+07, 6.6364e+07, 6.6123e+07, 7.3696e+07, 6.5974e+07, 8.6653e+07,
        6.7223e+07, 9.4105e+07, 6.7806e+07, 8.7796e+07, 1.0952e+08, 8.8061e+07,
        9.4000e+07, 8.2292e+07, 5.9417e+07, 6.9742e+07, 1.0605e+08, 6.8660e+07,
        6.3720e+07, 1.1047e+08, 7.4138e+07, 1.0458e+08, 1.1685e+08, 7.3408e+07,
        8.3003e+07, 1.4010e+08, 7.3997e+07, 7.5626e+07, 6.5862e+07, 1.2538e+08,
        5.1050e+07, 9.8621e+07, 5.9221e+07, 9.3793e+07])
Layer: encoder.6.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 2131866.0000,  1987970.1250, 27749916.0000,  ...,
         5579064.5000,  6746108.5000,  2825001.5000])
Layer: encoder.6.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 8440764.0000,  9684816.0000,  5753037.5000, 18582820.0000,
        12358065.0000, 13048164.0000,  9169227.0000,  8216303.0000,
        16973338.0000, 14795077.0000,  5631875.0000,  5906950.5000,
        10824306.0000, 10741915.0000, 10751074.0000, 11205836.0000,
         9066164.0000,  8779157.0000,  9672060.0000, 16024875.0000,
        10018960.0000,  6356354.5000, 14301901.0000, 13327090.0000,
        10714109.0000,  7220160.0000,  5931255.5000, 12049303.0000,
         9747407.0000, 11356462.0000,  8000651.0000,  5477291.5000,
         6840968.0000, 10121946.0000,  7944275.0000,  9222038.0000,
        16927464.0000,  6083622.5000, 12648080.0000, 10666411.0000,
        11300491.0000, 11845442.0000, 16588223.0000, 13877591.0000,
        18042340.0000, 10615401.0000, 10266206.0000, 11104906.0000,
         7304231.5000, 12727587.0000,  6684942.5000,  8885984.0000,
        13218716.0000, 13630457.0000,  9862145.0000, 15272011.0000,
        10915083.0000, 12702379.0000, 10749742.0000,  9834240.0000,
        10981467.0000, 11689228.0000, 12240763.0000, 13414782.0000,
         8386317.5000,  7921836.0000, 12093432.0000, 18924534.0000,
        14219375.0000,  8217727.0000, 10943900.0000, 10433379.0000,
        12045849.0000, 11491079.0000,  8421490.0000,  7410164.0000,
         8194624.0000,  5487589.5000,  9493561.0000,  6221271.5000,
         9313901.0000,  6113099.5000, 10626204.0000, 16191183.0000,
         8691903.0000, 12820940.0000,  8295209.0000,  8625431.0000,
        15941829.0000, 18568924.0000, 21431784.0000,  8113549.5000,
        10774254.0000, 10851111.0000, 12904633.0000,  7604267.5000,
         7253721.0000,  8336633.0000, 18143668.0000, 15392177.0000,
         9702870.0000, 11649017.0000, 14585248.0000,  5593863.0000,
         9633999.0000, 12822121.0000, 13936914.0000,  9908434.0000,
        11121047.0000, 10191245.0000,  7058884.5000,  7666577.0000,
        14147358.0000, 10747323.0000,  9000097.0000, 12007660.0000,
        18486342.0000, 11585792.0000,  5404773.0000,  9798738.0000,
        15709165.0000,  8833135.0000,  7866302.5000, 14197294.0000,
         8713966.0000, 12573279.0000, 10201084.0000,  6362364.5000,
        13170837.0000, 13232106.0000, 16259132.0000,  8326083.5000,
         8203885.0000, 12548119.0000, 15898637.0000,  5816927.5000,
        15013069.0000, 10598557.0000,  7837796.0000, 16217906.0000,
         9958887.0000, 11759566.0000, 17452078.0000,  6545211.5000,
        12651261.0000, 11157583.0000,  5844641.0000,  6715321.5000,
        10611039.0000,  8430550.0000, 10531681.0000,  8667033.0000,
         8703422.0000, 12747901.0000, 13249719.0000, 10060484.0000,
         9854417.0000, 11468355.0000,  8654324.0000, 16812610.0000,
         9906250.0000, 11121289.0000, 10132394.0000, 15858836.0000,
        12254805.0000, 12763512.0000, 14409047.0000,  7610806.5000,
        14377710.0000,  8228567.5000, 12198659.0000,  8033040.0000,
        17116626.0000,  7930992.0000,  8969011.0000, 11832833.0000,
        14607237.0000,  9035363.0000, 13158554.0000, 13277413.0000,
        11824217.0000, 14167339.0000,  6903283.5000, 13281320.0000,
         9752954.0000,  7405660.0000, 19323896.0000, 12939063.0000,
        12552452.0000, 12995523.0000, 14466684.0000, 15252952.0000,
         6513410.0000, 11690466.0000,  6674814.0000,  8554125.0000,
        10238381.0000, 12763477.0000,  7720531.5000, 10096141.0000,
         8745632.0000,  9732817.0000, 11593683.0000, 10660619.0000,
         7073711.5000, 12652230.0000,  8760165.0000, 16487586.0000,
         8314716.5000,  8411719.0000, 11048137.0000, 12785917.0000,
         9288336.0000, 19656554.0000,  7824688.5000, 12216555.0000,
        18352374.0000,  8101794.5000, 10388223.0000,  9535152.0000,
         9884224.0000,  9937635.0000, 11793166.0000, 12391438.0000,
        11661804.0000, 10692570.0000, 10353995.0000, 10395222.0000,
         9107588.0000, 11353257.0000, 14427681.0000,  7455278.5000,
        11604298.0000, 10648965.0000,  8640649.0000,  8356677.0000,
         7473379.5000,  9329851.0000,  9536285.0000,  8573620.0000,
         9549364.0000, 10682029.0000, 14109579.0000,  8221226.5000,
        11009041.0000,  8716866.0000, 11270905.0000,  6434720.5000,
         8735751.0000,  8432635.0000,  7468435.5000, 13585646.0000,
        13751841.0000,  8609399.0000,  9613222.0000, 12900407.0000])
Layer: encoder.6.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([19412136., 29041914., 21163604., 23491768., 37734704., 30184956.,
        34717844., 22970604., 13906694., 26267982., 28871274., 19348578.,
        17989406., 22052732., 24993910., 27020932., 13912858., 38685808.,
        21729228., 26385848., 16786184., 28453908., 37924768., 25164510.,
        40759696., 21408080., 25602702., 23062738., 44012680., 38307184.,
        27902810., 37390904., 31202508., 35559400., 34305448., 40174276.,
        21019710., 31473602., 23728378., 18590766., 16930674., 22190714.,
        16946682., 40674336., 32461992., 22931872., 28756994., 35835972.,
        25004260., 29606374., 30435804., 35974236., 37700384., 30860224.,
        20667796., 26872538., 41690972., 33005808., 17478834., 17837514.,
        27724666., 37851388., 34097948., 19893766., 27871220., 17687180.,
        44429208., 30708774., 27618704., 27706652., 10809400., 23799414.,
        24064946., 38479076., 43311912., 36390012., 24578220., 45750900.,
        18100768., 31821872., 30732818., 23462104., 28837618., 24542278.,
        63805508., 23563908., 21253332., 31117026., 18067488., 33715592.,
        29748794., 39877836., 30525620., 45445228., 19903374., 32809646.,
        37405036., 25280082., 19766184., 54363752., 30697338., 31607190.,
        35811288., 28007780., 34841228., 14858322., 31642708., 39397728.,
        42693676., 24001184., 38223052., 18018950., 36778820., 34152032.,
        30497348., 44868296., 27873698., 29906042., 29676578., 32586594.,
        33065638., 38452176., 31154646., 25006668., 43124872., 21563400.,
        33480948., 37007640., 40526892., 32907630., 28738416., 25767114.,
        21720774., 35459120., 24007660., 36791348., 27129760., 24640698.,
        32067956., 43345072., 40945992., 25463706., 25047140., 38831732.,
        20282692., 26139112., 36291220., 24978356., 15721468., 29918946.,
        27119266., 33659696., 29167550., 24072446., 30311174., 44084036.,
        18452334., 27834236., 29278938., 26013604., 41169800., 21084612.,
        23838670., 18817858., 23195770., 40339000., 43418600., 43258708.,
        50960388., 30946498., 40307704., 23317898., 27815020., 25836850.,
        24482598., 26107374., 13609955., 52155140., 29559800., 39348056.,
        27160056., 21014096., 32993064., 29048926., 39000108., 26910270.,
        35406904., 27475086., 33825104., 26075254., 21615678., 25882462.,
        20847360., 30099174., 19392282., 27747872., 37808824., 28257602.,
        40646560., 40691096., 31969792., 24524698., 14639415., 34896144.,
        45770848., 36402992., 28869330., 34064068., 51319932., 24424240.,
        21172816., 30524144., 23410872., 38920080., 33391996., 32970140.,
        37584800., 25054708., 36722780., 29803612., 35876416., 24707396.,
        21807406., 22695720., 27781408., 25369586., 26196494., 19560278.,
        35723040., 29314510., 51076980., 30768280., 25884686., 31649038.,
        39052752., 18639586., 50763880., 22884712., 33311578., 38782960.,
        19837300., 28161468., 34315464., 33594164., 22526654., 12396717.,
        22140768., 23264646., 44416628., 20590580., 25755050., 35953844.,
        27310058., 27261652., 20679168., 35671680.])
Layer: encoder.6.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([   27768.4004,    82263.3281, 24517668.0000,  ...,
          578107.6875,  3264519.2500,    66464.4297])
Layer: encoder.6.3.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3109901.0000, 1548856.7500, 1823419.6250, 3014097.5000, 1449846.0000,
        2007179.1250, 3479732.0000, 1562021.1250, 4956766.0000, 1074220.5000,
        1979205.7500, 2102765.5000,  947797.5000, 4800941.0000, 2182095.2500,
        2411179.2500, 3447508.5000, 1389330.3750, 3126513.2500, 3383200.5000,
        2562403.2500, 3745458.7500, 2239709.7500, 3131501.2500, 1807364.7500,
        1690568.8750, 3700159.2500, 2126809.7500, 1171452.0000, 2135028.7500,
        2548782.7500, 2347441.0000, 2419674.0000, 3627016.5000, 2896644.7500,
        1949935.6250, 1548760.7500, 1556833.7500, 1352291.6250, 4356871.5000,
        4806863.0000, 2823716.7500, 1515744.2500, 1827540.2500, 4635451.5000,
        4138524.2500,  934761.3750, 1579891.7500, 2347392.0000, 3001790.5000,
        3399040.5000, 1181867.1250, 1667889.3750, 1753615.1250, 2418939.2500,
        2181868.5000, 1785018.1250, 2154161.5000, 1866623.6250, 1893611.3750,
        1637924.3750, 2023839.5000, 4709094.0000, 1521854.3750, 1941397.6250,
        2550079.7500, 3192253.0000, 3091743.7500, 1865242.6250,  575952.2500,
        3152981.0000, 2048500.2500, 1238777.7500, 1479521.7500, 2402301.7500,
        3739668.7500, 2627441.7500, 2957828.7500, 2931940.0000, 1343058.6250,
         817966.6250, 1108351.6250,  836973.0625, 2020365.8750, 1212911.0000,
        3995296.0000, 1422836.3750, 2469280.5000, 1475535.5000, 2308802.0000,
         936413.8750, 2564136.2500, 1775200.1250, 3269045.7500, 2103557.5000,
        1520737.6250, 2822364.7500, 1849700.8750, 1769430.3750, 3385294.0000,
        3803011.5000, 3036725.5000, 1624701.2500, 3453166.7500, 1936953.3750,
        2322585.2500, 2451849.7500, 1820580.7500, 3450513.2500, 1784817.3750,
        1408106.0000, 1256965.7500, 1456969.5000, 1547459.5000, 3169270.7500,
        2972675.5000, 1444341.3750, 2767919.7500, 1732244.2500, 2966603.7500,
        2031451.7500, 3107268.7500, 1116124.1250, 1328392.3750,  949922.6250,
        3440435.2500, 3022177.0000, 2492860.5000, 2619818.2500,  779591.5000,
        2235991.7500, 2132877.7500, 1412650.6250, 1115935.3750, 2572939.5000,
        2875023.0000, 2471237.5000,  931502.0625, 1720380.6250, 2800808.5000,
        2936683.7500, 1399023.7500, 3357395.7500, 1370634.0000, 2666517.2500,
        1993340.3750, 1288342.6250, 1118668.0000, 1401013.7500, 2067584.3750,
        1269307.7500, 1516673.6250, 2096821.1250, 3188307.7500, 3045426.0000,
        2512679.5000,  887579.5625, 1903296.0000, 2836452.0000, 1514918.3750,
        1941274.3750, 1614794.5000,  944176.4375, 3039487.7500, 2088600.6250,
        1355086.7500, 2738960.5000,  995151.0625, 1729446.5000, 2849374.2500,
        3092802.2500, 1376132.0000, 1609582.8750, 3298222.5000, 1653012.6250,
        1390109.3750, 2338236.5000, 2856297.0000, 1772339.8750, 1562634.1250,
         765863.7500, 3594834.2500, 1781573.7500, 3483859.5000, 1627528.0000,
        2397694.7500, 1959190.5000, 1514693.3750, 2511114.5000, 1756008.1250,
        1488104.1250, 3363969.7500, 2737590.7500, 1895570.8750, 2800795.7500,
        2809373.5000, 1973769.2500, 1686103.5000, 1286902.3750, 2838089.5000,
        4574348.5000, 2349793.5000, 2596106.5000, 3784183.0000, 1522883.1250,
        2164042.2500, 1556472.2500, 3452536.2500, 6065391.0000, 2080374.2500,
        2690280.2500, 2474276.5000, 2219970.0000, 2469704.2500, 1788443.6250,
        1193251.2500, 1023031.2500, 1146905.8750, 3998740.2500, 1761310.8750,
        2112418.0000, 1745624.0000, 1334518.8750, 1729222.2500, 3296618.0000,
        1714612.2500, 1406166.2500,  902241.0000, 4017628.7500, 2052775.5000,
        2377284.0000, 1727975.7500, 2027339.3750, 1087266.1250, 2514053.0000,
        1583335.6250, 2429335.2500, 1427801.1250, 3737972.2500, 2097745.7500,
        2857226.2500, 1741600.7500,  862780.0625, 2853010.5000, 1442458.8750,
         750702.1875, 2843295.0000, 2445344.2500, 2980714.7500, 3752734.0000,
        2359083.2500, 1660991.6250, 3161988.7500, 2996725.0000, 2081217.1250,
        1564762.0000])
Layer: encoder.6.3.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 7028004.0000,  3985947.5000,  4186454.0000,  8550653.0000,
         4741721.5000,  7131514.0000,  2776332.5000,  9538905.0000,
         7544492.0000,  3308725.0000,  6366295.5000,  6884929.5000,
         8395552.0000,  5457014.0000,  8524569.0000,  3800396.2500,
         5861281.0000,  7818398.5000,  5148939.5000,  6016984.5000,
         2331972.5000,  7078005.5000,  8979465.0000,  5291149.5000,
         4170730.5000,  4216426.5000,  6197550.5000, 13892037.0000,
         8098418.0000,  5831873.0000,  5541230.0000,  4685594.0000,
         4997245.0000,  5949192.5000,  4268501.0000,  4928729.0000,
         5379651.5000,  4571156.5000, 10179665.0000,  4329704.5000,
         4246995.0000,  4924650.0000, 13090675.0000, 11458797.0000,
         4777737.0000,  7504867.5000, 12096663.0000,  9316150.0000,
        10364960.0000,  5686873.5000,  8257056.5000, 14968480.0000,
         8513606.0000,  6566289.5000, 14453570.0000, 13488856.0000,
         9770578.0000, 12132799.0000, 10387662.0000,  4456087.0000,
         6653745.5000,  6395625.5000,  7312745.0000, 11009323.0000,
         5056451.0000,  3159476.0000, 11361625.0000,  2663967.0000,
         3972953.5000,  4089976.7500,  7684781.0000,  3950192.2500,
         4143727.0000,  6937019.5000,  5294958.5000, 12189636.0000,
         6961864.5000,  5220845.5000,  3426293.7500,  7498632.0000,
         5890510.5000, 10645592.0000,  4386687.0000,  5749018.0000,
        12094565.0000,  3283043.7500,  7747105.0000,  4996995.5000,
         3648587.2500,  2837534.2500,  8598011.0000,  8916927.0000,
         5974588.5000,  5243126.0000,  3299499.0000,  6732279.0000,
         5444272.0000,  5767555.0000,  9244156.0000,  6889712.0000,
         4907437.5000,  8473430.0000,  7865169.5000,  5258489.0000,
         9315609.0000,  8013462.0000,  3072784.2500, 12886625.0000,
         5986485.5000,  4012775.7500,  8537730.0000,  7713829.0000,
        11895215.0000,  3813013.2500,  6670882.5000,  6821473.0000,
         7051509.0000,  6310158.5000,  4009676.0000,  3945288.0000,
         3924027.0000,  7667613.5000, 10071342.0000, 11199656.0000,
         8374382.0000,  4649867.5000,  8325663.5000,  5247837.5000,
         7238357.0000,  8014023.5000,  4558298.0000,  4019786.0000,
         5749819.0000,  3499136.0000,  7900447.5000,  6475823.5000,
         4385759.0000,  7244947.0000,  5262870.5000, 10281842.0000,
         3506809.7500,  3939097.5000,  5192185.5000,  6366144.0000,
         5911605.5000,  9295677.0000,  4314049.5000,  8699987.0000,
         7249973.5000,  4838458.0000,  4069441.0000,  9117177.0000,
         7739971.5000,  6236029.0000,  7725038.5000, 10607282.0000,
         7340303.5000,  5368120.0000,  4905887.5000,  6798173.5000,
         6443725.0000, 10273198.0000,  7462572.0000,  6503604.5000,
         5761926.0000,  7763613.0000,  4151470.5000,  9279444.0000,
         8496180.0000,  7541511.5000, 12789339.0000,  4632028.5000,
         7175413.5000, 11271176.0000, 10084073.0000,  7440567.0000,
        11067941.0000,  4896878.0000,  9060562.0000,  3308324.7500,
        12787947.0000, 15457659.0000,  8574431.0000,  6529310.0000,
         7438644.5000,  8946188.0000,  6005812.5000,  4801132.0000,
         7264113.0000,  5961792.5000,  4647405.5000,  4665787.0000,
         6104741.0000,  3313297.5000,  3563419.0000, 10213964.0000,
         5922792.0000,  8588319.0000,  8736943.0000,  6599880.5000,
         4390557.5000,  7650826.0000,  8334704.0000,  5998886.0000,
         4729341.5000,  6544112.5000,  8261653.0000,  5154399.5000,
        10180131.0000,  4405526.0000,  6779204.0000,  3273977.2500,
         8209722.0000,  9687538.0000,  5900289.0000,  7915382.5000,
         7703198.5000,  5952283.5000, 13457295.0000,  2180216.2500,
         5229822.5000,  9832174.0000,  4637621.5000,  5674450.0000,
        10830138.0000,  6225202.0000,  7842551.0000,  9399090.0000,
         6320243.0000,  6529202.5000,  4912014.5000,  5294755.5000,
        10394168.0000,  2931636.0000, 11401989.0000, 10247701.0000,
         4019734.0000,  5115193.0000,  6839434.5000,  6964124.5000,
         7854209.5000,  5825475.0000,  4488195.5000,  7207602.5000,
         6812375.0000,  6529517.5000,  3587929.0000,  8028213.5000,
         6862537.0000,  5020679.5000,  5255346.0000,  7909124.5000,
         6578465.5000,  4047646.7500,  5618272.5000, 12925419.0000])
Layer: encoder.6.3.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([  3643.4443,   4503.9678, 130490.8516,  ..., 115511.3203,
        185306.0312,  15453.8613])
Layer: encoder.6.4.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 389868.6562,  541632.1875,  338667.9062,  328670.3438,  461413.9375,
         284824.5312,  483290.8750,  377477.8750,  422348.8125,  569427.6250,
         550314.7500,  645200.1875,  606005.8750,  354088.6250,  256769.3438,
         374443.6875,  524367.6250,  525674.1875,  324932.8438, 1089532.5000,
         838110.8125,  246467.3281,  262500.6250,  366799.6250,  325071.6250,
         514993.0938,  433397.6562,  395855.1562,  687434.3750,  187496.2344,
         263650.0000,  792962.0625,  294073.6562,  424983.4375,  411736.0625,
         327283.0938,  342073.0000,  431110.2188,  469028.0000,  430235.0312,
         221635.2500,  162554.0312,  317130.4375,  320415.1562,  812012.1875,
         409149.3125,  419555.9688,  387687.0938,  331033.9062,  265411.7500,
         437314.0938,  639007.1875,  376311.5625,  642209.6250,  545336.6250,
         390765.9062,  557116.3750,  624626.7500,  518687.0312,  307562.5938,
         406179.3125,  378440.1250,  409705.7500,  254024.3438,  428711.4062,
         383989.0000,  289161.4062,  481361.6562,  414993.8750,  318756.8750,
         474471.9688,  900937.3750,  460093.4375,  378823.0938,  749269.5000,
         464835.3438,  488785.0312,  349395.9375,  561548.4375,  672034.5625,
         685341.1250,  384537.0312,  270497.2812,  431941.2188,  622242.1875,
         472698.7500,  365512.1875,  404941.0000,  839172.8125,  430564.8750,
         428598.3750,  632086.3750,  694299.9375,  544731.4375,  423351.2188,
         502498.3125,  567615.8125,  711670.4375,  272202.4375,  866178.6250,
         461564.4688,  393089.9062,  422049.3438,  558681.1875,  674356.0625,
         315500.3750,  447016.0938,  542236.8125,  380312.6250,  489206.8750,
         187840.7500,  399889.7812,  399922.6250,  666213.4375,  306688.3125,
         504274.2500,  257950.3125,  514011.3125,  388625.3438,  279881.1562,
         614391.5000,  444087.3125,  494673.5625,  235919.7812,  362503.7500,
         491438.6875,  225868.6875,  530870.1875,  410995.3438,  657669.7500,
         449843.0000,  476329.9375,  239586.3281,  564143.4375,  511806.8750,
         343074.9688,  397547.0938,  492523.2500,  278368.4062,  322342.9688,
         387391.8125,  718478.4375,  245363.8281,  702063.5000,  654420.5625,
         481434.5312,  394441.1250,  420575.3750,  316589.7812,  274820.2500,
         481649.3438,  451359.5000,  280384.4062,  259313.0469,  233427.0625,
         515433.2188,  304521.5938,  645217.6875,  216654.1719,  418761.4688,
         354593.6250,  646865.8750,  635478.1875,  739574.2500,  309124.9062,
         622044.6875,  336111.7188,  277896.7188,  609082.5625,  478382.8125,
         238019.3125,  484822.3125,  386792.1562,  310047.2188,  192816.2969,
         566219.3125,  288241.7812,  369273.0625,  330534.0000,  414790.1875,
         364963.0938,  604357.5000,  371226.0000,  527041.3750,  290928.7188,
         328222.5625,  438626.2812,  438720.8438,  709518.9375,  615761.5625,
         308323.0938,  211923.3281,  561176.0000,  296654.4062,  300505.6875,
         426326.5938,  685558.3750,  648172.1875,  433343.4688,  302169.5625,
         353650.2500,  333581.9688,  360985.7812,  716108.8750,  268247.5938,
         563535.8125,  316383.4375,  530989.8125,  457161.7812,  239695.1406,
         450233.2188,  554466.8125,  385742.4688,  295021.0938,  563670.1875,
         511736.0938,  340230.8125,  756405.2500,  246478.5000,  478599.2500,
         272910.0625,  312081.5312,  436752.6875,  504643.8125,  294986.4062,
         285100.7500,  427657.4375,  408697.7188,  402279.6562,  464311.3125,
         651080.3125,  232185.0000,  603514.1250,  492448.0312,  629869.6875,
         699381.0000,  451944.0312,  409240.9062,  596540.8125,  449040.0312,
         369716.2500,  894235.8125,  787109.0625,  258422.7812,  722076.8750,
         725659.4375,  429583.5312,  753298.9375,  355599.9375,  290486.4688,
         226039.4688,  365628.1562,  342985.4688,  618182.8750,  441932.6875,
         417505.1875])
Layer: encoder.6.4.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1291463.7500, 1126576.3750, 1726970.7500, 1642084.2500, 2127020.5000,
        1109300.5000, 1135622.5000, 2847528.2500, 1774394.6250, 1319083.8750,
        1926738.5000, 1468816.2500, 1785888.8750,  931325.5625, 2041908.3750,
        1317611.8750, 1515948.2500, 1704201.8750, 1332479.1250, 1559585.2500,
         832374.8125, 1092104.0000, 1114586.1250, 1044012.1875, 1155076.2500,
        1558519.3750, 2307455.0000, 1582450.7500,  792500.6875, 1227540.0000,
         935965.8750, 1235272.1250, 1477017.5000,  841393.6250, 1249192.0000,
        1380171.5000,  862825.0625,  976834.5625, 1772192.0000, 1826919.0000,
         773964.1250, 1340742.1250, 1084294.5000,  729337.0625, 1008172.3125,
         728923.6875, 1171755.0000, 1908429.0000,  835157.6250,  892007.9375,
        1028058.3125, 1955080.2500, 1361142.8750, 1387883.7500, 1100490.6250,
         790473.5625, 1800724.5000, 1884226.3750,  705003.0000, 1510447.8750,
        1338147.1250, 1224836.8750, 1695857.1250, 1364064.7500, 1685907.2500,
         594100.2500, 2019145.2500,  956997.8750, 1711538.8750,  934737.5000,
        1575039.7500, 1465237.5000, 1153733.6250, 1188145.8750, 1151198.5000,
        1158984.1250, 1890081.5000, 1854421.6250, 1503187.8750, 1158692.0000,
         955224.1875, 1813039.1250, 1298027.1250, 1441286.6250, 1435678.6250,
        1463248.7500, 1510987.5000, 1147949.3750, 2912927.2500, 2061646.1250,
        1087983.1250, 1148365.8750, 1023832.6250,  953343.2500,  716727.5625,
         771143.3750, 1086030.1250,  711923.1250, 1459800.5000, 1909410.0000,
        1530153.2500, 1190297.8750, 1817531.6250, 1002727.1875, 1403588.0000,
        1357465.2500, 1605578.0000, 1468358.5000,  994521.0000, 2850604.7500,
        1638644.5000, 1090780.8750, 1144825.6250,  990487.7500, 1394819.0000,
        2602842.2500,  829103.8750,  800323.0625, 1503048.1250, 2462428.2500,
        1239972.1250, 1377087.8750, 1530898.8750, 1196160.8750, 1010152.5625,
         621422.4375, 1126726.1250, 1239752.0000, 1582321.5000, 1349857.7500,
        1657613.7500, 1550907.1250, 1011905.7500, 1055214.6250, 1683816.5000,
        1312571.8750,  864914.1875, 1035965.3750, 1239978.6250,  749510.3125,
         989142.6875, 1269489.1250, 1894313.6250, 1327915.1250, 1714275.0000,
         836953.3125,  815275.4375, 1230036.6250, 1185925.1250, 1741599.2500,
        2225851.7500, 1134115.6250, 1488778.0000, 2150020.7500, 1509942.7500,
        1387293.1250, 2142434.7500,  964005.2500, 1655545.7500, 1977798.8750,
        1627913.2500, 1562962.6250, 1558274.1250, 1298771.0000, 1029197.3125,
        1262474.7500,  850718.5000,  867971.3125, 1371509.8750, 1349671.3750,
        2065518.5000, 1566717.0000, 1971529.1250, 2429660.5000, 1404694.7500,
        3938824.2500, 1027064.7500, 1870027.6250, 1886011.0000, 1148274.7500,
        1574232.2500, 1023901.6250, 1405457.1250, 2029479.5000, 1855604.1250,
        2294341.2500, 2153860.0000,  769246.6250, 1161005.2500,  901959.8750,
        1752084.2500, 1594234.5000, 1238812.0000, 1039975.3750, 1198751.5000,
        1616089.8750,  806313.4375, 1048790.1250, 2151646.0000, 1911550.7500,
        1648297.7500, 1588171.6250,  989550.7500,  762741.6250, 1462951.3750,
        1434938.3750, 1724038.8750, 1657788.8750, 2002034.2500,  912584.4375,
        1103891.2500, 1004249.6250, 1064335.0000,  942006.3125, 1704620.0000,
         903922.7500,  833900.9375, 2285468.7500, 1716850.8750, 1050518.2500,
        1171354.8750, 1907521.8750,  933041.5000, 2980823.7500,  898661.5000,
        1372266.8750, 1573819.6250, 1835265.7500, 1654595.5000,  967754.0625,
         795323.2500, 1934866.7500, 1808855.3750, 1844206.2500,  902335.4375,
         933914.5000, 1600332.6250, 1569563.8750, 1274785.3750, 2038588.8750,
        1125812.2500, 1814685.5000, 1091807.2500, 1893598.8750, 1342837.8750,
        1509684.2500,  677936.5625, 1944683.2500,  710434.7500,  999391.1875,
         896851.8750, 2262587.2500,  738790.1875, 1629125.0000, 1343092.0000,
        1235744.1250])
Layer: encoder.6.4.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 2265.3955,  6346.3135,  7619.0415,  ..., 83196.2109, 17326.7422,
         5168.6201])
Layer: encoder.6.5.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 73786.2266,  79782.1641,  54755.3281,  84906.3984,  53435.8320,
         69663.3594,  41886.6562,  69242.1562,  61864.7578, 108340.5469,
         61983.5117,  62905.9688,  43132.1406,  84822.2344,  54004.9102,
         85031.9844,  46994.8281,  29935.2207,  65826.2188,  44350.5625,
         77984.2500,  47374.5195,  56793.7148,  42454.0625,  47432.2500,
         54382.1680,  38750.2695,  46140.9688,  94025.7344,  47110.3008,
         40591.5664,  36508.3984,  72809.0156,  46008.0000,  40195.6992,
         43517.7734,  46009.7422,  34636.8516,  55187.8047, 121172.9375,
         87636.2969,  43943.3945,  64150.3711,  38409.8867,  43169.8555,
         46899.3828,  38961.8438,  38221.9570,  27332.7266,  38376.2383,
         61680.9844,  68809.2578,  55924.3477,  46482.3867,  57409.9961,
        104048.6875,  44509.3867,  39498.3867,  73210.7422,  66549.1328,
         33272.7148,  77902.5000,  55364.5000, 116381.8828,  50719.5273,
         59231.8164,  66848.2422,  62563.0938,  62846.2031,  67264.8125,
         89325.0625,  65956.4062,  65431.3672,  87266.7578,  82260.4375,
         85499.4844,  97717.7969,  33427.6172,  53095.5742,  51184.9180,
         48620.0742,  55841.5625,  53951.7812,  61758.6992,  50100.8164,
         56707.4453,  66769.6953,  47910.9883,  56758.3242,  84316.5938,
         51310.0469,  44521.4102,  57550.2539,  50946.3320,  59734.7266,
         77434.3594,  46365.3164,  94364.8750,  79832.1484,  42811.2617,
         51664.4375,  45995.7930,  54313.3477,  43537.3242, 109629.5078,
         56762.0742,  55162.7422,  40950.4414,  70755.2109,  54834.5898,
         73082.0391,  57048.9688,  84550.0547,  53707.8984,  50009.4062,
         48302.9219,  52109.5156,  58276.7891,  42629.6523,  38715.6172,
         60939.0977,  62362.6211,  56720.1992,  37686.5195,  67237.8203,
         54176.6484,  82031.0391,  86985.2656,  48942.4688,  40375.6680,
        105285.5156,  53065.3438,  39872.1211,  69824.5078,  46672.4375,
         51886.1445,  59625.1250,  49219.9336,  41654.2188,  85226.6172,
         49003.4727,  76338.8438,  73769.2656,  89032.5234,  49526.4102,
         54062.1719,  69608.8438,  47731.2344,  72674.1250,  57703.8594,
         62328.1172,  46928.7617,  80613.0234,  71043.9219,  32105.8066,
         50103.2773,  59901.5234,  41755.6328,  87921.4297,  38988.0742,
         72050.9844,  61683.6016,  61727.0938,  52243.2539,  61639.0977,
         56169.0234,  48001.5234,  42374.5117,  41696.7266,  75252.7188,
         70137.2266,  84732.0078,  63030.3281,  34249.6406,  62779.2617,
         56060.2344,  42132.8711,  46163.2070,  82152.2812,  68751.9688,
         44508.0938,  41122.4883,  69840.6328,  51760.7852,  71202.1328,
         56787.2695,  98024.5625, 121057.3672,  47116.4453,  56922.6641,
         52923.6016,  69153.4141,  44627.7930,  79965.8047,  59843.4219,
         50723.6758,  84162.5938,  72010.6719,  49956.3438,  37955.3633,
         56764.7812,  80964.4531,  44208.3633,  42311.6367,  46230.5820,
         69037.7031,  45148.7734,  48693.8086,  59719.1133,  83685.5000,
         79706.0781,  40974.7734,  51774.6797,  82073.7891,  88628.0312,
         60760.2969,  41616.2656,  77659.8594,  58666.4023, 118361.6094,
         48114.1250,  52030.4531,  47872.4844,  39130.1602,  52053.5273,
         68913.8516,  85743.1953,  57676.4062,  56429.1562,  57056.3398,
         69914.7891,  51319.3320,  61080.1172,  81421.8750,  78651.9688,
         91087.1562,  52951.7344,  59730.1680,  66727.5469,  93035.7891,
         78216.1484,  54249.4219,  54538.8984,  47148.2969,  48321.6523,
         60803.3789,  47842.5664,  77957.9844,  68401.7812,  89771.5781,
         33135.2578,  69729.6719,  85891.9531,  52563.1719,  52180.6523,
         58014.5352])
Layer: encoder.6.5.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([234590.5469, 201624.4375, 248696.0312, 323923.0312, 273654.0312,
        221161.3438, 203717.7500, 183269.0000, 333646.2500, 241834.0156,
        297373.1562, 263586.8125, 370756.9062, 236717.8750, 436183.6250,
        184229.4531, 322289.6875, 364579.0000, 226982.6875, 214244.4062,
        364160.2500, 243022.3125, 374924.0312, 276361.9688, 213580.5469,
        230624.0781, 418477.1250, 222446.3750, 291092.7812, 235000.5000,
        162667.5312, 259702.0938, 335030.7500, 262807.5938, 351594.9688,
        430010.3125, 223338.7656, 294112.4688, 240642.3438, 359880.2500,
        208738.1719, 229240.4531, 321352.3750, 191520.8125, 159849.4531,
        163354.0625, 230118.0781, 373364.9375, 247761.9062, 393695.1875,
        254709.2500, 359409.1562, 232571.5156, 240016.0938, 266486.0312,
        217054.4531, 264737.5000, 165213.5469, 216042.7969, 222968.8125,
        271220.6875, 239671.3125, 227565.6406, 485809.3438, 369222.7500,
        256166.7344, 231458.9375, 282645.8750, 225230.3906, 315216.8438,
        280795.7188, 354976.2500, 463862.7500, 261276.0469, 264276.2500,
        358716.8125, 225172.0312, 174021.7969, 335569.1562, 282240.4375,
        226942.2656, 278752.9375, 312854.3125, 231070.6875, 279798.4375,
        304966.3750, 331505.5000, 176868.8438, 220394.0156, 260532.4531,
        373625.5312, 374702.8750, 313160.4375, 252419.4062, 266868.1250,
        228103.7344, 158139.8906, 213879.5312, 182191.9219, 215357.4844,
        400135.6562, 278257.6250, 208370.7812, 173916.8125, 226539.6094,
        277765.9688, 189863.2656, 164541.7031, 148912.0469, 239814.1094,
        197384.2344, 173782.3906, 416847.6875, 266137.3750, 240045.0312,
        294132.2812, 208338.7656, 162014.5000, 261687.4844, 273310.1875,
        165206.9375, 240097.9062, 199045.0156, 215550.2344, 287112.6250,
        355359.2188, 367680.2500, 231228.7812, 266292.5938, 192220.1719,
        248610.0000, 197753.0000, 252192.7812, 282362.4062, 388212.5625,
        330698.3125, 348999.8125, 196835.9531, 306231.4062, 301956.8125,
        299199.0938, 346349.5938, 359653.9688, 461327.1562, 212257.3750,
        230161.5469, 251511.9375, 218885.9844, 253565.8594, 399732.8750,
        330254.5000, 184958.6562, 326272.9375, 350495.9062, 285726.7188,
        254153.2500, 243769.6875, 306894.1250, 301894.7500, 310908.9688,
        245778.6719, 227210.0312, 244468.9688, 250394.3281, 289109.7188,
        264489.2188, 289273.5938, 318615.3125, 308111.5312, 336918.2188,
        262779.2812, 396411.8750, 296902.8750, 186543.3750, 296729.8750,
        210415.2344, 217444.0000, 378582.8438, 275026.3438, 300455.3125,
        269619.2500, 281985.4688, 197036.5000, 272085.5312, 187635.7188,
        203702.6250, 480709.1250, 283784.2188, 183845.7031, 204079.9062,
        284914.1562, 271281.8438, 290023.1562, 167159.0469, 241282.1875,
        228248.4531, 237715.7031, 167795.8906, 256705.4219, 449442.5938,
        229086.1875, 261124.7656, 214833.0781, 350086.5312, 194755.1875,
        151022.7812, 307690.2500, 322986.7500, 377314.8125, 208475.1250,
        264060.0312, 187707.5938, 191168.9375, 312339.4375, 393117.0625,
        334751.0000, 193355.4375, 266759.2188, 291461.2812, 459877.3125,
        324599.4062, 211184.6875, 194263.4844, 253025.2344, 294735.9688,
        130789.5312, 226670.1875, 390764.1875, 220711.8438, 175367.3438,
        226990.6094, 321632.3125, 216835.2812, 275787.5938, 308842.0938,
        206598.0469, 245473.1875, 195685.5000, 184738.2344, 317310.4688,
        389778.4375, 331703.7188, 279596.5938, 267561.6250, 296156.0000,
        269384.0312, 309533.8438, 259546.4844, 188227.6094, 388483.4688,
        272540.0000, 289940.6250, 369336.9375, 279816.5312, 265661.7812,
        274357.5000])
Layer: encoder.6.5.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 964.9196, 1515.0824,  827.0955,  ..., 4117.0303,  510.7576,
        1302.0237])
Layer: encoder.7.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 5158.9634,  8317.6191, 10098.3848, 10157.0439,  7624.7920,  7157.0308,
         5283.1470,  6878.8564,  5391.6836,  8198.1924,  7817.4409,  6082.4619,
         8258.6895,  7899.5835,  5660.5513,  7759.0083,  7308.7485,  8390.6572,
         6228.6602,  7307.7808, 12315.2861,  7790.3086,  7407.2363,  9854.1045,
         5984.1597,  8916.9434,  8417.0176,  6936.0312,  8749.2100,  4785.0620,
        11965.0215,  6400.2627,  7828.7637,  6450.1865,  9901.3447,  7450.4204,
         9456.7930,  4868.1157,  7155.6953,  6031.4800, 11349.7783, 10151.9336,
         7298.0659, 13142.8818,  6583.0342,  5806.5928,  6387.2603,  4871.3594,
         6281.6479,  7513.7935,  7823.8105,  6852.1411,  9000.2246,  5979.7085,
         6524.0107,  7130.3271,  6576.7788,  6389.0566,  6727.4932,  7679.5254,
         7114.4844,  6490.0063,  6694.8213,  5242.2456, 14026.0498,  7864.2705,
         9079.7158,  6287.3916,  7164.8154,  6699.4561,  6049.4863,  9758.7422,
         6300.9331,  8173.1987, 11304.2617,  7485.3271,  7727.4370, 10096.5176,
         6662.3872, 11450.3633,  6079.3862, 10687.2900,  7684.3608, 10510.3125,
         9300.4658, 14737.5547,  6469.5605,  6100.1011,  9409.2637,  8096.8125,
         8223.4824,  7721.6719,  7363.8306,  7203.8696,  7670.5396,  9633.7725,
         6336.3354,  7490.1006,  7828.1396,  4580.4180,  6638.2026,  5911.5420,
         5562.8608,  9412.1045,  7482.7754,  9230.2490,  9305.3018,  5881.2192,
         9200.4717, 10357.7129,  6469.1997,  5589.5850, 12793.6885,  6460.4863,
         6341.9072,  6292.5591,  6020.5322,  8011.2705,  8480.8838,  5322.0308,
         7638.5581,  6352.7305, 13138.5615,  5860.5005,  7323.7397,  9320.9863,
         5349.4229,  8921.0312,  5841.7163,  5829.4058,  6858.4150,  8376.1494,
         6815.7446,  9739.0371,  5764.2100,  9895.7764,  8873.7510,  7722.4009,
         7556.5044,  5271.3164, 10039.4482, 12011.9404,  8926.8633,  8420.5615,
         6497.3306,  9985.8145,  6618.8760,  5487.0571,  5797.4351,  5425.3618,
         9177.7314,  6266.6904,  9227.4395, 11442.8877,  7661.6885,  9110.4512,
        14048.5693,  5231.2573,  6238.1694,  7259.7456, 10114.1934,  6042.4243,
         8058.3120,  7587.7847,  6829.4146,  6305.8350,  7375.4053,  8676.8916,
         7056.2725,  8933.7363,  5942.7695, 11280.4238,  7358.3735,  7544.8599,
         6669.7397,  9287.6064,  8036.9556,  5163.8838, 10566.7471,  6636.6001,
         5904.7573,  6676.2432,  7050.7466,  5980.2495,  8070.2051,  8773.6455,
         5559.6772,  9095.5742,  9769.9951,  6880.3066,  7162.6890,  7576.2422,
         7182.8887,  5983.8701,  8172.6968,  6819.9258,  8079.9819,  8404.8516,
         5292.1641,  5055.5674,  6972.0811,  5945.0015,  8204.7686,  6215.2163,
        10176.4570,  6499.5884,  5729.0508,  8477.6562,  5911.5864,  5169.7886,
         5840.5957,  6467.5850,  7058.3838,  7397.0347,  7776.1528,  5465.4331,
         6020.7827, 10363.0605,  8585.0879,  9436.5850,  7353.1030,  5516.9238,
         7098.7305,  8095.2046,  6061.6343,  6409.0249,  8155.3916,  6826.3057,
         5430.8843,  7523.9707,  5965.8867,  9704.8799,  7197.0259,  5890.2305,
         6328.1001,  6327.5962, 10612.2646, 11102.7178, 10520.3535,  8434.9951,
         8385.1982,  6548.4443,  9952.2256,  9138.6230,  5475.3022,  5367.1289,
         8935.0635,  6278.2910,  5878.6421,  8272.8906,  6574.6436,  9548.6133,
         9060.2393,  7445.6792,  9385.8379, 13435.1494,  7684.1914,  6200.0171,
         8488.2500,  6402.6035,  9262.3027,  5526.5610,  8531.9209,  8756.4238,
         6544.5044,  7514.0815,  6078.3799,  6318.0684,  8932.0752,  5619.8398,
        10700.7988,  5872.6719,  8332.4600,  7292.5859,  5803.5430,  7793.9961,
         6918.0078,  6196.0034,  7164.6704,  7764.6372,  6504.2095, 10744.2109,
         7110.7725,  9194.7432,  9675.5996,  7140.0874,  9140.6914, 10164.7510,
         5089.0942,  7416.9639,  7361.7095,  8101.6733,  6741.7012,  5088.7261,
         5719.1187,  6225.5811,  7312.9883,  6849.5645,  5166.3110,  5274.7920,
         6023.3149,  5642.6152, 10255.1758,  7981.6890,  9062.6123, 10038.1865,
         7798.9263,  6880.6655,  8705.5947,  7424.3477, 11784.1787,  5919.4160,
         9895.0508,  7640.6064,  6874.9004,  6264.7471,  8852.8564,  9045.0645,
         7678.9053,  6759.0498,  9454.5039,  5934.5884,  7986.2642,  9128.7676,
         6627.8955, 10298.3018, 11259.1670,  7579.1167,  5681.1323, 11411.1826,
         6753.1626, 10024.8271,  6223.1294,  7244.5278,  5952.3252,  8276.4873,
         7021.8115,  7702.2437,  7763.6074,  8676.9912,  6904.1099,  7270.0791,
         6956.1387,  5070.6768, 10751.1055,  9313.9473,  5666.7446,  5719.2280,
        10674.4932,  7720.9033,  6130.6572,  5389.6885, 10810.0635, 11890.3506,
         6086.7920,  7901.7549,  8854.1328,  4954.8247,  6791.7124, 10649.9561,
         5264.2554,  9321.6875, 11232.5244,  9161.7324,  5980.7676,  5964.7559,
         6905.5327,  5556.0557,  9662.2637,  7074.9126,  7248.0400,  9601.6504,
         6919.8594,  6812.2695,  9345.8535, 11383.3799,  8935.3799,  5456.3052,
         8551.4072,  9064.6357,  5164.8809,  5439.7515,  7843.3291,  9041.9756,
         4967.1328,  7152.3706,  7116.5728,  5580.5977,  5027.7285,  6310.3862,
         7462.1382,  5542.2617,  7853.3877,  7426.7378,  7153.6724,  9688.5938,
         7448.8926,  5890.0386,  5601.5674,  8645.0938,  6087.0908,  6012.5806,
        11006.6182,  7222.6182,  6285.0493,  6309.3965, 10303.0039,  8387.0312,
         6065.2554,  6485.4780,  5886.1421,  6443.8716,  6960.3706,  7456.2573,
         9459.6377,  6092.6865,  5320.6499,  6975.1909, 16497.0430,  6519.4927,
         7899.6592,  7313.7324,  5927.9717,  8423.8242,  6367.3804,  7450.4565,
         5495.5532,  8170.8608,  7830.8789,  6623.0522,  6988.3369,  7734.2759,
         7134.9639,  6146.1685,  4861.5415,  6329.1079,  9599.6738,  8492.9658,
         7000.6504,  5690.0469,  5607.8604,  9526.8877,  7329.9971, 10386.0439,
         7645.6543,  5940.4502, 10160.9932, 10536.3438,  8866.2803,  8661.2412,
         5821.7856,  8711.0361,  9895.5605,  9807.0811, 11762.5986,  8410.7051,
         8147.6450,  7668.8120,  5793.8164,  4935.9917,  6374.0894,  9030.3154,
         5475.3442,  9171.2988,  8066.0679,  7922.3540,  5917.5127, 10749.7744,
         8464.4365,  6908.7949,  7861.0752,  7649.0913, 13104.8105, 10352.6143,
         5405.3477,  8044.9966,  7448.8901,  8281.8037,  8589.5244,  8088.9082,
         5809.4639,  8278.7324,  7041.6396, 12128.1064,  9344.6035,  6851.1670,
         8895.4492,  7811.9268,  6560.7188, 10552.4590,  5650.2559,  6455.7363,
        11467.0283, 10200.0674, 12381.8828,  6153.4810,  7629.6221,  7969.7285,
         6848.7827,  8015.9971, 11018.5879,  7931.3047,  9054.6211,  8248.3203,
         6772.0273,  6179.7720,  5025.1294,  8701.5195,  8914.0889,  8363.6885,
         8053.6602,  7136.2651])
Layer: encoder.7.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([55380.5664, 66952.9219, 64602.9180, 59891.9922, 60873.8516, 46022.5234,
        30465.7520, 45314.8438, 59380.3477, 46241.6016, 61070.3594, 62159.7930,
        44881.9453, 64349.1055, 53687.1211, 48095.9766, 50564.7969, 44217.6719,
        46243.7031, 48254.1367, 37229.7578, 42685.3828, 58420.4805, 57847.0234,
        58485.9141, 87181.1016, 38245.3203, 78334.6328, 57014.7266, 62202.2695,
        83226.7109, 54337.1328, 49166.7188, 48864.4375, 38214.9336, 44789.0625,
        51062.9219, 44454.0195, 39412.0820, 40691.2031, 33880.5703, 58287.1172,
        37855.2148, 45356.6523, 40125.9141, 47467.9766, 58810.8711, 42101.0703,
        60920.2305, 40318.1289, 53654.9844, 53725.5547, 38245.8633, 52213.7969,
        37339.2617, 50589.6445, 51534.4688, 77396.2969, 48635.5469, 39950.9336,
        46640.2109, 44328.9453, 52243.8125, 56008.1914, 38808.3672, 57259.2539,
        46261.5742, 45941.5312, 43715.2656, 51600.3828, 46236.7656, 34422.3867,
        57256.4180, 42111.5898, 55215.1836, 86232.0234, 41862.6562, 35558.0859,
        52958.0234, 58906.4141, 47367.5195, 59536.3359, 48730.0625, 49165.6445,
        82667.1562, 59057.1602, 83019.1562, 62325.5352, 52749.1172, 48877.1172,
        48647.0664, 61474.0664, 41312.0938, 39061.9609, 45541.7773, 56346.0781,
        42712.5547, 49487.0156, 56343.3906, 41196.9062, 49921.4883, 62703.4258,
        37160.7422, 68732.0938, 38223.1172, 45989.7578, 41772.0742, 50620.5508,
        43516.2539, 48721.2891, 38118.7070, 37164.0234, 42556.9414, 53544.2148,
        61883.3789, 48390.2891, 35649.1484, 48515.8594, 48848.1406, 44180.6250,
        59820.8008, 84518.1094, 43941.7578, 45479.0312, 42183.0508, 71525.0000,
        39894.2383, 46086.4609, 63717.6289, 67857.8984, 33322.3320, 51075.4531,
        45254.2383, 56469.2070, 78422.2031, 43605.4258, 56391.0000, 40467.0586,
        46899.9531, 46618.1953, 54054.7031, 54785.8008, 56322.6602, 41006.8906,
        40669.7070, 60666.5117, 36887.5703, 53658.2266, 75511.0781, 36393.5000,
        45678.5078, 42078.6992, 49113.0938, 51881.7852, 62504.5195, 73070.2188,
        41436.2070, 51033.3242, 59997.1211, 52290.8594, 66082.1406, 49710.8672,
        94743.4141, 52579.5078, 55053.4062, 63729.6523, 64946.3828, 48284.5859,
        54857.2891, 39777.7305, 53318.2969, 47820.7305, 37279.9492, 63817.8789,
        53718.4297, 45779.4414, 67375.8203, 40804.3125, 64347.5859, 41477.8672,
        54556.1016, 38785.3945, 51178.1836, 41464.2383, 34779.7656, 41206.2070,
        57994.0898, 37728.0898, 39901.6367, 39247.2109, 45057.2305, 47952.9648,
        62284.7305, 53645.2969, 90299.8828, 36714.0547, 41874.9961, 54548.5586,
        82235.1719, 44076.5859, 62614.8047, 56000.8125, 55184.8633, 74659.8906,
        56839.2422, 59214.1758, 39059.1094, 42049.6836, 65996.6094, 58557.7617,
        44023.0195, 47493.2148, 75060.3594, 36647.7188, 73819.0078, 46022.8477,
        37708.2148, 56735.6641, 63631.2695, 39621.6328, 43169.6484, 94431.5234,
        48389.6484, 49614.1562, 60854.9531, 40369.1250, 57253.9297, 49495.9688,
        64062.7461, 46684.8047, 53530.7188, 38200.1328, 58788.1484, 39328.1641,
        46438.5977, 55861.9297, 48527.8633, 59351.4609, 59649.0898, 58198.8086,
        44250.8945, 41811.2578, 64215.0234, 35589.8398, 44010.5703, 55278.1641,
        36038.0938, 36897.0625, 59932.6484, 63599.0430, 55251.6914, 37230.0117,
        60786.4727, 50450.5938, 96421.2734, 57808.0664, 55482.4023, 47481.8555,
        58654.1289, 57412.3672, 67254.2266, 51283.7812, 34535.6250, 42082.9023,
        69452.5703, 43335.3125, 50653.1602, 46677.5078, 36475.0039, 45027.8594,
        98156.2969, 37273.5000, 86356.9844, 46231.3555, 65921.3516, 40853.4883,
        47501.9961, 57139.1797, 42461.9688, 45795.0508, 39513.8633, 57364.2812,
        42817.8047, 63877.8242, 45843.6680, 46966.4609, 37580.5898, 58004.5781,
        69583.4609, 50832.2852, 66104.8438, 53370.3242, 45558.0898, 53342.5195,
        49347.0664, 37970.4883, 78284.8594, 47861.9570, 41141.3086, 67648.1875,
        49533.4609, 37090.0312, 65454.0117, 73847.3125, 49443.8281, 66099.4219,
        54565.9531, 46439.2617, 36817.0898, 57413.3711, 44312.4609, 45437.8281,
        84584.7578, 53510.6367, 49107.6094, 57245.4062, 38397.6250, 44318.7734,
        43512.7109, 39708.7539, 65291.1875, 41666.3555, 50898.7188, 40865.2266,
        46247.0898, 37784.2266, 63023.7852, 54657.8320, 79724.2031, 59223.7305,
        41297.0820, 50577.9961, 30403.3789, 38963.4570, 47210.3086, 47646.1055,
        57233.8086, 50751.2930, 78818.8047, 43177.9492, 44985.9336, 33270.8984,
        62089.0508, 43752.0117, 48590.5938, 44134.1797, 58540.3398, 42283.8555,
        42418.9648, 82580.8125, 42298.8047, 59883.8633, 47398.2500, 57590.9102,
        44405.6289, 46906.0391, 48422.0625, 54547.1992, 36718.3398, 40274.2773,
        53353.4023, 51790.5391, 49517.4180, 52065.1484, 56376.3242, 63053.5703,
        41699.7734, 55714.5430, 41300.5430, 40046.5234, 59075.1797, 57983.8672,
        37651.5664, 64805.3555, 44544.6523, 41953.4922, 39505.1133, 51336.2539,
        65120.6758, 35718.4961, 45180.2656, 50630.6602, 42526.0820, 63081.0156,
        49869.2266, 70572.1641, 76291.1641, 66069.7188, 38073.6367, 57664.4375,
        41039.6875, 33570.9219, 76847.1094, 70365.2500, 35668.7617, 41283.9062,
        73207.3906, 45084.6445, 44097.8867, 44927.8477, 50127.9219, 54103.9883,
        43770.9453, 48260.3203, 42267.6406, 41306.8906, 37985.8633, 77955.7109,
        41837.3398, 58931.3750, 46377.6680, 43222.7773, 42788.7578, 85157.0781,
        79815.6953, 66025.4922, 37215.8008, 37577.9453, 52737.1211, 62933.3125,
        64512.2812, 49361.2305, 69049.2578, 67517.3750, 55215.8672, 36929.9688,
        58501.8750, 35418.1641, 61026.5039, 46043.4141, 39156.4102, 67019.7500,
        62797.4180, 49617.9727, 59028.2734, 55825.1719, 45832.2109, 46342.4102,
        49752.4023, 40691.9023, 65816.9453, 37892.8047, 41536.0156, 38187.1016,
        48826.0664, 31553.6328, 46279.1133, 43918.9727, 62607.1992, 54547.4844,
        46655.5625, 36238.2422, 45544.3477, 40290.9531, 59235.7109, 62712.1523,
        49981.6484, 64925.1250, 42069.4102, 63034.4102, 46728.3828, 51378.9062,
        37963.2188, 55309.5391, 42425.5625, 64736.0156, 51678.1914, 60182.2852,
        55601.3320, 43831.3398, 43558.6523, 49465.8555, 69848.9297, 58289.7305,
        52066.8984, 41626.2656, 38108.9258, 68607.1562, 56651.7852, 40637.3945,
        91218.9766, 82276.8047, 47873.5156, 62580.5820, 46943.7891, 52229.0352,
        51171.6836, 51556.0039, 57240.6289, 41735.6211, 51715.3633, 69732.4453,
        44154.8359, 50603.2109, 44226.9492, 49271.1875, 47709.1289, 52617.3711,
        54713.4297, 88645.2734, 62395.7500, 46327.6289, 67661.7578, 54768.1406,
        65853.5938, 70915.2109, 45045.5781, 47738.3633, 58360.9102, 56391.9609,
        50445.5938, 37795.5273])
Layer: encoder.7.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 134.5686,  673.6378,  936.5013,  ...,   18.1287, 1443.4401,
         948.4366])
Layer: encoder.7.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 697.8947,  846.4402,  885.3828,  ...,  761.5619, 2153.8557,
         732.9694])
Layer: encoder.7.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2342.7087, 1610.7771, 1842.6903, 2203.8350, 1730.6040, 1730.1696,
        2165.0754, 1720.7286, 1916.0823, 1702.2271, 1685.6769, 2001.4058,
        1845.6553, 2557.7405, 2063.9409, 2531.2214, 2163.0535, 1660.5215,
        1873.0068, 1957.2109, 1945.6060, 1941.3326, 2174.4800, 2295.0442,
        2066.8015, 1710.9489, 1642.4336, 2246.1731, 1448.6010, 1598.7423,
        1659.9265, 1883.9440, 2431.9624, 2230.5425, 1947.4402, 1481.5342,
        1688.2255, 2179.8489, 1862.6852, 1831.0640, 2001.7106, 1793.9447,
        2097.2769, 1735.4863, 1954.9784, 2222.9055, 1661.6086, 1847.6565,
        1649.5690, 1420.6978, 1962.3269, 1817.6655, 2011.1993, 1707.3037,
        1997.7865, 2281.2776, 2207.2554, 1968.8682, 1739.4147, 1928.0206,
        1907.3859, 2074.9155, 1760.4515, 2067.3672, 2198.8025, 2439.8738,
        1542.9108, 1841.3013, 2186.2654, 2127.2014, 1814.0277, 1702.9269,
        1797.5609, 2037.1405, 1570.2103, 2138.2285, 2186.3667, 1799.0323,
        1811.7775, 2614.3845, 1954.6510, 1719.2444, 1815.5325, 1756.3380,
        1780.3282, 1747.4091, 1794.1752, 1685.3478, 1735.5675, 1890.2794,
        2411.7051, 1788.6544, 1849.8600, 2128.5974, 1730.7562, 1664.3358,
        2265.8489, 2110.1340, 1633.1879, 2327.8252, 1637.1793, 1703.0724,
        1796.0416, 1744.5874, 1666.5748, 1987.0258, 2130.3796, 1836.2094,
        1780.8572, 1724.2347, 1722.3300, 1851.3002, 1852.6178, 2556.8320,
        1727.6761, 1485.2904, 2624.2993, 1812.1810, 1728.4642, 1930.8473,
        2218.4075, 1732.3176, 1501.4417, 2120.4294, 1889.5457, 1852.7745,
        1966.5216, 1808.1514, 1957.6763, 2282.9053, 2574.7402, 2164.1030,
        1976.7568, 2054.9644, 1395.2125, 2038.6594, 2367.4780, 1780.9528,
        1985.4388, 1941.1440, 1978.3804, 1783.4404, 2328.3816, 2109.2417,
        1815.5040, 1724.7959, 2057.4473, 1780.6265, 2006.5272, 1879.2434,
        1584.3777, 1572.8246, 1800.6799, 2434.4944, 1495.7987, 1864.0446,
        1929.9789, 2080.3398, 1690.6143, 1511.1604, 1811.7997, 1529.9136,
        2163.2046, 2394.0308, 1980.6974, 1687.1968, 2433.9453, 1987.1908,
        1846.9985, 1934.1300, 1935.4460, 2321.6702, 1962.1879, 1492.8218,
        2050.4919, 1655.3711, 1680.0051, 1892.2493, 1730.5938, 1590.9686,
        2270.7522, 1901.6427, 2076.5723, 1670.9821, 1859.9244, 1505.8082,
        2162.3452, 2389.4153, 1919.5750, 1914.9155, 1643.9481, 1663.1813,
        1538.5194, 1890.0219, 1886.6316, 2240.3997, 1790.7634, 2033.8524,
        1841.0717, 1978.0552, 1726.2211, 1984.3674, 1694.4219, 1891.5328,
        2296.2427, 1976.5442, 1757.2922, 2031.3951, 2620.8870, 2305.2268,
        1845.9175, 1879.6631, 2011.6754, 2025.5454, 1740.3734, 1971.4303,
        1457.0583, 1806.9668, 1517.5814, 1863.9943, 1589.3186, 1737.0178,
        2354.2500, 2485.9104, 2321.4451, 1526.0151, 2302.9421, 1694.8705,
        1883.1261, 2112.2014, 1789.9901, 2424.1243, 2256.8752, 1574.7058,
        1876.0579, 1952.7551, 1795.3265, 1921.8378, 1693.1903, 1956.5311,
        1797.7542, 1844.4042, 2001.7954, 1756.0652, 2165.2202, 1957.1123,
        2422.0693, 1668.1150, 1722.9508, 1592.8098, 1856.8481, 1510.9882,
        1967.9980, 1892.5825, 2257.9019, 2092.2368, 2003.6448, 2023.6904,
        1970.3546, 2274.6550, 1918.0944, 1526.7047, 1879.5093, 1727.6838,
        1701.9902, 1953.1403, 1689.7301, 1871.1339, 1994.3444, 2200.6211,
        1907.9957, 2057.6133, 1660.8239, 1436.4617, 1810.6233, 1881.0743,
        1999.0616, 1453.1749, 1727.2239, 1840.7092, 1819.0435, 1740.5277,
        1494.2250, 2094.1980, 1422.8335, 1594.2241, 1868.9525, 1554.4529,
        1751.6399, 1851.3676, 2548.7615, 1644.4371, 1782.7924, 2469.9690,
        1779.4868, 1667.1394, 1851.6777, 2284.9021, 2121.7217, 1748.9548,
        1632.4814, 1701.8280, 1735.7772, 1538.6487, 2027.6281, 1798.7208,
        1807.9896, 1938.5601, 1616.0082, 2075.7229, 1725.0083, 1922.6420,
        1684.9113, 1879.6029, 2094.9390, 1751.2908, 1607.3882, 1843.7949,
        1801.5605, 1601.1857, 1555.3719, 1775.0266, 1673.2471, 1674.5400,
        1771.4019, 2178.2712, 1789.1195, 1972.5101, 2049.0679, 2068.7876,
        2194.0251, 2656.4949, 1595.6270, 1959.6871, 1506.3185, 1729.5426,
        1741.0245, 1812.3715, 1749.9282, 1479.1309, 1769.2963, 1862.9318,
        2195.6040, 1740.5957, 1925.8645, 1789.9136, 1613.5311, 2049.2954,
        1769.9392, 1651.6427, 2149.5427, 1902.3531, 1567.7419, 2191.2744,
        1595.5433, 2429.8281, 1830.0834, 1545.1565, 2051.3721, 2143.0239,
        1728.5704, 1509.9762, 1797.1661, 1458.4515, 2045.1089, 1933.7753,
        1646.8478, 1996.3629, 1898.5594, 1859.4490, 2149.1279, 1982.4125,
        1714.5889, 1800.9166, 1453.7201, 1812.1498, 2079.5735, 1792.5663,
        1862.1866, 1551.3699, 1484.0316, 1808.6006, 1888.2310, 2230.4951,
        1588.0927, 1770.5111, 2162.3396, 2266.3054, 1837.4055, 2093.2380,
        1784.8148, 1692.4221, 1980.7048, 1700.9053, 2180.6978, 1547.6404,
        1764.1404, 1555.8138, 1894.0640, 1914.1150, 1570.7408, 1949.7145,
        2232.9495, 2153.4890, 1875.0197, 1801.9279, 2008.7915, 1470.9871,
        2027.6803, 1666.0481, 2449.7622, 1768.0695, 1792.5822, 1882.4705,
        1588.9860, 2192.5361, 1776.7377, 2180.3921, 1924.1002, 1945.3356,
        2129.3762, 1612.3253, 1840.7653, 1753.7130, 1684.8223, 1765.2914,
        2307.3958, 2396.2637, 2489.4363, 1959.5630, 1945.8776, 2157.0908,
        1683.6243, 1668.6259, 1881.1039, 2254.7485, 2429.3691, 2477.1641,
        1453.0291, 1640.7898, 1938.3384, 2315.8308, 1948.8914, 2125.3137,
        2131.1311, 1724.2131, 1708.0048, 2033.2098, 1581.6150, 2435.9360,
        2247.4028, 2118.6484, 2460.7444, 1708.3619, 2148.1838, 1679.3541,
        1529.6158, 1806.9432, 1747.1465, 1487.2512, 1810.0531, 2312.1387,
        1517.6437, 1522.4146, 2093.5393, 1803.8893, 1610.6841, 1688.4512,
        2244.0137, 1885.7950, 1739.3153, 2021.3048, 1826.3049, 2032.1785,
        1741.0389, 1888.5880, 2343.6165, 1597.7799, 2290.2571, 1770.9567,
        2156.6951, 1878.1957, 2222.9736, 1831.6249, 1842.0366, 1697.0944,
        1739.1992, 1701.9680, 1417.7606, 1730.9993, 1682.3303, 2213.8140,
        1457.3455, 1897.8375, 2072.4558, 1740.3319, 1610.9213, 2494.2422,
        2269.1863, 1761.1407, 1565.0203, 2388.7288, 2011.1523, 1883.2925,
        2017.9413, 2012.3176, 1854.6981, 1870.7819, 2244.0918, 1941.4989,
        1928.7799, 2114.5996])
Layer: encoder.7.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([11988.2861, 14164.0625, 15068.6855, 11473.5410, 13034.7695, 12975.0908,
        13904.6650, 13148.4014, 16371.0645, 11914.5879, 11957.6094, 14269.3057,
        14662.1133, 16154.0957, 11417.9473, 17125.1660, 14279.3750, 11569.4453,
        15236.9844, 13605.8389, 11505.7627, 11290.7490, 12732.3662, 11148.0293,
        11973.1895, 12758.1152, 12023.6270, 10744.3760, 15064.4941, 14974.3076,
        15666.0527, 12455.9766, 15714.2773, 12877.2031, 11565.9795, 13214.6494,
        16208.1387, 12974.6270, 12443.3877, 11605.6504, 12992.0723, 14849.4785,
        11852.9209, 14306.9385, 10033.2256, 12059.6865, 14784.3594, 15292.8965,
        13471.5859, 15003.8242, 18177.1973, 14688.3096, 18170.9707, 12772.8057,
        13120.0195, 13115.5010, 11688.5439, 12358.8506, 13495.0459, 20180.9023,
        11681.7051, 11548.4502, 12409.4717, 13056.0967, 18360.9512, 13296.7129,
        10227.1084, 13039.8008, 12581.2656, 15338.6309, 11961.8047, 13352.9561,
        18333.5078, 11426.9307, 12162.7021, 11282.5029, 13444.8945, 15596.9219,
        15849.7500, 11984.8379, 14253.9912, 14474.4043, 13614.5762, 13363.1025,
        12034.9873, 16878.2578, 15157.3096, 11152.2510, 15423.4443, 15366.3848,
        14346.8486, 14930.1104, 12107.9873, 15407.6016, 13692.8730, 11619.0635,
        15517.5957, 14299.1777, 12911.3311, 17453.4512, 10487.4707, 13592.0625,
        11882.0186, 15514.2197, 12722.1182, 15091.5166, 18352.3965, 11476.6348,
        18612.9590, 13037.4609, 15275.4209, 13179.1582, 11512.4414, 14685.6172,
        17488.0410, 15209.2109, 14086.2148, 16153.0850, 12623.3770, 13364.5771,
        12200.4189,  9905.7529, 14721.3750, 12871.9248, 15678.3770, 12453.3838,
        12705.4434, 14015.6484, 12422.9707, 14514.0098, 15903.1953, 13641.7314,
        15159.8350, 15460.1621, 13700.3643, 14592.1123, 13679.4150, 11703.4102,
        15462.0322, 17246.4258, 14032.4824, 13591.5801, 11557.9521, 14012.9551,
        11061.1748, 13161.8584, 13382.7656, 12696.5283, 13637.5430, 16218.0137,
        13509.4375, 14666.6777, 14427.1582, 11735.0312, 13618.8115, 11568.1582,
        12028.9170, 12962.4297, 12048.3457, 14860.9648, 11812.6211, 13146.4170,
        12103.0264, 13331.6855, 12071.9639, 15331.2295, 14369.1123, 13322.2227,
        13112.0010, 12127.6895, 17159.9609, 17380.1816, 12597.4893, 15917.5918,
        13083.7080, 14243.7598, 11359.9268, 10886.2949, 12321.6641, 17577.0781,
        13592.0928, 14047.5566, 15546.6611, 10492.6299, 13898.3721, 11608.6436,
        12986.1367, 14088.3662, 13748.6768, 14495.5645, 13035.6670, 15638.1309,
        12243.3174, 13742.7578, 13169.4932, 15472.1758, 16309.2500, 11548.9355,
        14658.6240, 12187.9365, 15362.1230, 11565.4629, 11186.3877, 13800.1807,
        12439.1719, 11622.1064, 17821.7148, 13836.3232, 12357.8760, 14125.2402,
        13172.3027, 16634.0000, 11070.1582, 13841.3330, 15930.6055, 15371.8711,
        14346.5107, 12621.4619, 14046.5244, 12984.9941, 14949.6064, 15426.3730,
        10322.0674, 12433.9268, 14800.5146, 13700.3359, 14402.1719, 13004.7432,
        15961.2109, 13628.6426, 13609.1475, 13488.9072, 12486.6152, 12311.2979,
        14633.7949, 13653.4180, 14502.6025, 14343.4199, 15291.9736, 12134.3838,
        12239.4355, 17163.3926, 16029.4824, 14627.0586, 18287.0488, 13889.8506,
        11959.0654, 12445.8223, 11059.1963, 12253.6289, 15188.1826, 12960.5449,
        14913.9414, 10013.0596, 15518.7725, 14130.5273, 12595.1289, 13239.0107,
        14000.0879, 10640.1855, 17226.7773, 15328.4707, 15215.5273, 15190.8965,
        11781.1201, 15618.4863, 14705.5244, 12842.9316, 10806.0000, 12902.7852,
        13617.6582, 12207.9561, 10544.7080, 15720.4697, 13797.6592, 10305.8184,
        11491.9160, 10947.4785, 14788.6484, 12962.7510, 12947.0957, 14184.3379,
        14274.9336, 11838.5732, 15027.9023,  9599.1338, 17029.7832, 16519.2578,
        13196.6465, 12151.0479, 11820.2090, 14541.4131, 13666.6172, 13133.0361,
        13995.4609, 13844.7656, 11502.5068, 12423.3877, 13356.8633, 13216.8525,
        13839.5244, 15060.0068, 13042.6016, 11311.5791, 11993.1533, 13870.5928,
        11927.7354, 12567.6797, 13660.3281, 13872.5635, 10774.6934, 14326.7793,
        13318.3896, 16085.1855, 12980.5693, 12108.7275, 14172.3984, 14464.6514,
        12956.1709, 15446.0186, 14119.8770, 15846.7354,  9360.3760, 12159.3838,
        12257.9844, 12854.4297, 12946.0576, 13912.8848, 15816.2998, 12325.4727,
        15033.2363, 14487.2441, 15473.8721, 13502.7334, 15922.5586, 11870.6328,
        14547.9814, 14760.9277, 15786.3369, 17306.6270, 14188.8145, 15041.4072,
        12086.8154, 11381.6943, 12785.5957, 14041.4854, 15084.5205, 13632.6104,
        13050.8486, 13002.7100, 12334.6797, 15753.9053, 13920.3594, 14877.5127,
        13118.3125, 15088.4258, 15678.5947, 14732.0869, 11901.6406, 15820.8604,
        14923.2490, 10027.9316, 12753.8828, 10644.3584, 12868.8564, 15389.4639,
        13398.8936, 15993.8730, 12368.9326, 13768.9561, 13841.3193, 13773.2207,
        13061.4736, 13287.5732,  9689.9365, 15266.1787, 12216.5146, 16125.5020,
        17494.7578, 13362.6289, 14298.7266,  9016.5400, 15483.7764, 14256.2510,
        16319.8115, 12530.1924, 11157.3525, 14268.5439, 12909.0059, 10878.1992,
        14832.1895, 11367.6963, 12043.9775, 13049.7705, 13679.0273, 17139.5547,
        16510.5098, 15988.5459, 16837.7031, 10837.8770, 13344.8506, 14047.1396,
        12729.5049, 12336.5498, 14723.9307, 11164.4219, 15927.1201, 14405.2881,
        13241.2012, 12199.2832, 11938.2979, 14896.3779, 13642.6807, 14809.9355,
        13663.5488, 12769.0684, 14346.4443, 13185.8164, 16166.6211, 13261.4209,
        12540.7998, 12927.5596, 12097.9043, 18865.9531, 11299.7207, 13382.3213,
        12782.7754, 13793.2227, 12080.8809, 15342.6094, 13140.4795, 14505.4541,
        15872.1631, 11476.5967, 11911.8418, 16087.2646, 15273.9707, 12799.2295,
        14467.7090, 15233.3242, 14735.1211, 10252.3604, 15337.1689, 10275.9121,
        12954.3643, 12268.6445, 12226.1143, 13799.5352, 19465.6133, 13591.3047,
        12599.1143, 14383.5059, 12251.1934, 13125.7490, 14312.8154, 15982.6172,
        11745.2715, 16154.2842, 15699.3896, 10863.2783, 11390.1338, 15560.7178,
        11586.7139, 13137.5605, 11025.6309, 11970.9766, 17129.6309, 14605.6025,
        12890.5029, 13406.6553, 12281.8574, 17391.6074, 12580.2744, 13052.9609,
        13225.4404, 13027.0195, 14265.0068, 13867.6660, 11738.9424, 14317.8184,
        15413.2871, 13215.3535, 17123.5801, 16650.2070, 13209.9404, 13444.5156,
        13557.8584, 16080.5449, 11820.0068, 11927.3584, 10731.1846, 15302.0820,
        12896.0957, 17921.2793, 12567.5000, 15611.1699, 13119.3965, 14497.4453,
        11062.8535, 19236.2227, 13712.4697, 11401.1309, 12040.1377, 15242.1689,
        13754.3916, 10420.5830, 11633.8467, 13239.3887, 15543.6895, 17588.9492,
        14019.3223, 12705.0645])
Layer: encoder.7.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([124.2581, 306.7415, 338.7433,  ..., 123.2919, 601.8302, 275.4418])
Layer: encoder.7.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1445.2629, 1534.1294, 1575.9619, 1191.4706, 1271.5485, 1475.9098,
        1561.0696, 1500.0955, 1431.9408, 1038.9537, 1397.6768, 1339.7377,
        1494.5161, 1464.5353, 1790.8435, 1367.4624, 1498.0823, 1583.5657,
        1411.1565, 1601.1294, 1190.7048, 1503.7250, 1654.2280, 1884.5995,
        1374.5291, 1844.9764, 1628.6333, 1622.3436, 1495.6342, 1321.5923,
        1387.3207, 1251.1294, 1225.7279, 1226.6759, 1417.9775, 1586.4341,
        1603.9695, 1725.0895, 1637.8605, 1644.0581, 1355.0684, 1397.4054,
        1532.2635, 1515.7800, 1297.1844, 1432.7888, 1357.9062, 1062.8799,
        1100.7830, 1546.2262, 1332.0601, 1153.7913, 1765.5563, 1878.2196,
        1427.8938, 1414.0063, 1489.1364, 1488.3157, 1558.3491, 1096.2092,
        1513.6963, 1549.1061, 1517.2400, 1734.7959, 1165.0713, 1415.6426,
        1185.8088, 1797.9128, 1442.0693, 1871.2789, 1231.4348, 1264.0648,
        1534.2998, 1551.6675, 1310.6621, 1294.3093, 1411.7777, 1326.4324,
        1758.3396, 1405.6664, 1575.3375, 1431.8273, 1708.8009, 1574.0027,
        1206.1343, 1464.0121, 1395.5061, 1302.7529, 1247.9315, 1378.2815,
        1275.7179, 1805.5681, 1405.1910, 1267.8739, 1372.5636, 1848.2794,
        1207.1400, 1588.1956, 1349.2948, 1462.6992, 1362.1755, 1319.3035,
        1580.9088, 1515.8722, 1430.5281, 2180.5042, 1030.3763, 1293.7266,
        1364.3336, 1001.2011, 1112.6689, 1280.7898, 1377.1396, 1640.1479,
        1537.0613, 1542.5231, 1291.5688, 1358.7877, 1534.5968, 1314.4954,
        1429.2794, 1189.8661, 1470.7056, 1222.8020, 1237.1543, 1654.7053,
        1448.0602, 1283.8679, 1120.9456, 1476.5758, 1415.7430, 1741.1353,
        1385.8915, 1298.7596, 1506.7528, 1349.4478, 1034.1636, 1236.4830,
        1164.4447, 1152.9330, 1211.5110, 1598.6846, 1638.9957, 1335.4602,
        1604.4067, 1373.6837, 1164.4425, 1050.7577, 1731.2760, 1277.7939,
        1519.0446, 1463.0488, 1429.2150, 1877.1526, 1289.4531, 1407.4032,
        1262.3737, 1059.7987, 1470.4097, 1464.3413, 1374.2000, 1438.4929,
        1235.3711, 1726.5463, 1516.9529, 1280.7201, 1691.6398, 1475.2020,
        1565.9976, 1025.3455, 1059.6143, 1258.7400, 1182.7793, 1551.9080,
        1330.1030, 1491.7303, 1330.1226, 1535.8433, 1357.1677, 1687.3940,
        1215.8394, 1532.3521, 1501.8826, 1367.0461, 1247.1805, 1273.7079,
        1752.4655, 1262.8801, 1527.7777, 1389.1292, 1503.6772, 1622.0334,
        1753.0321, 1701.6636, 1272.6008, 1614.2635, 1251.6378, 1163.6564,
        1452.8002, 1747.6343, 1471.0439, 1817.0647, 1215.8286, 1431.1498,
        1198.2296, 1496.1526, 1645.3605, 1602.9336, 1265.4191, 1386.2594,
        1024.9758, 1404.2306, 1312.3646, 1492.1310, 1210.0533, 1621.8311,
        1318.3752, 1338.3683, 1347.7430, 2098.8811, 1068.2698, 1000.0221,
        1545.1345, 1936.9806, 1332.3702, 1492.5439, 1523.8131, 1516.4122,
        1255.7561, 1044.5913, 1541.7797, 1212.6320, 1258.3206, 1807.8431,
        1601.7703, 1560.1998, 1611.0815, 1432.7317, 1664.6425, 1439.7125,
        1446.1592, 1199.2773, 1043.1836, 1371.6843, 1549.9956, 1870.9576,
        1366.5134, 1704.3937, 1586.3303, 1263.7306, 1305.5450, 1273.5992,
        1497.9662, 1402.1354, 1275.6582, 2088.0181, 1124.0001, 1609.9543,
        1522.4628, 1509.8458, 1427.4657, 1477.1138, 1915.1183, 1331.8481,
        1307.3890, 1891.4630, 1355.7939, 1679.5026, 1531.6686, 1459.9285,
        1530.6624, 1084.3389, 1196.9961, 1738.9187, 1507.2301, 1712.4814,
        1504.2880, 1059.2563, 1341.1338, 1944.9344, 2224.0457, 1182.3857,
        1688.5847, 1366.7686, 1873.6654, 1561.7805, 1231.0261, 1116.4330,
        1291.0472, 1462.7751, 1320.3435, 1985.0303, 1354.9813, 1511.9993,
        1306.6566, 1781.3495, 1879.6250, 1632.2546, 1922.2205, 1232.9292,
        1367.2583, 1255.6741, 1177.5718, 1331.0764, 1918.5417, 1603.3113,
        1369.7894, 1351.9722, 1341.9832, 1575.3108, 1692.8623, 1641.1821,
        1643.7932, 1335.6915, 1279.3234, 1591.6129, 1466.8508, 1463.5370,
        1333.0771, 1564.3573, 1267.1486, 1647.2650, 1659.4828, 1670.4749,
        1235.8239, 1308.7727, 1191.5942, 1336.2097, 1208.3042, 1668.4739,
        1419.3990, 1518.8218, 1621.1891, 1289.7693, 1376.8168, 1578.3069,
        1762.9968, 1649.0991, 1539.9260, 1408.4688, 1394.5820, 1373.7887,
        1232.6747, 1533.8505, 1394.0450, 1642.5463, 1458.4504, 1559.6567,
        1287.6014, 1317.3634, 1608.0992, 1653.1484, 1451.4922, 1249.9698,
        1132.3674, 1232.0658, 1674.0450, 1295.7233, 1642.2056, 1232.3555,
        1308.5907, 1389.5917, 1713.9458, 1181.8077, 1190.1276, 1072.3461,
        1283.9867, 1343.2179, 1500.2695, 1837.1643, 1262.4347, 1648.2239,
        1193.0959, 1703.0934, 1376.0172, 1532.4629, 1392.8545, 1342.5944,
        1138.7444, 1198.3848, 1506.4639, 1374.9376, 1388.7623, 1027.9086,
        1687.0238, 1351.6478, 1572.5016, 1542.4196, 1967.4427, 1076.1511,
        1491.7150, 1062.0221, 1309.5328, 1726.3125, 1406.0320, 1396.7942,
        1323.4222, 1161.5582, 1237.3885, 1678.8073, 1227.8735, 1228.8796,
        1390.6394, 1514.4242, 1416.5829, 1411.0812, 1335.4790, 1241.2043,
        1522.0438, 1334.2222, 1152.2422, 1623.5786, 1622.3707, 1456.0583,
        1251.3140, 1187.5042, 1371.0276, 1318.2369, 1522.6528, 1447.0579,
        1454.2863, 1444.1630, 1590.9100, 1533.2969, 1565.4106, 1464.6680,
        1327.5466, 1192.0166, 1460.5728, 1173.0928, 1158.5734, 1482.4924,
        1693.9923, 1502.3822, 1481.1312, 1540.3113, 1432.2379, 1374.3562,
        1404.5465, 1252.9899, 1702.1750, 1484.7517, 1367.2875, 1568.2434,
        1363.4301, 1301.7277, 1418.0087, 1246.2021, 1269.9880, 1303.9877,
        1398.4021, 1286.1737, 1420.9829, 1120.8960, 1382.5878, 1477.1891,
        1396.9636, 1817.7163, 1558.0564, 1423.6549, 1325.8042, 1365.9680,
        1698.2252, 1600.3058, 1258.0408, 1064.9751,  929.0083, 2078.4331,
        1367.2883, 1487.1630, 1218.1492, 1294.2258, 1605.4536, 1751.0918,
        1472.9575, 1283.1545, 1467.0378, 1924.9211, 1856.0847, 1578.4857,
        1223.3911, 1153.7896, 1046.0348, 1061.8567, 1454.3021, 1562.3285,
        1320.9398, 1587.5808, 1668.2277, 1340.1312, 1267.4908, 1668.2025,
        1468.2917, 1516.5256, 1535.6942, 1373.5847, 1539.0884, 1716.2777,
        1596.4506, 1344.5675, 1763.2255, 1244.3307, 1441.8563, 1485.6338,
        1300.8701, 1210.5559, 1037.4652, 1526.3734, 1333.7651, 1110.8619,
        1245.1049, 1650.9962])
Layer: encoder.7.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([11537.3701, 11474.2217, 12680.6270, 10290.1260, 12485.4102, 15717.9727,
        13380.8262,  8950.5098, 14488.1094, 11889.0312, 11446.5361, 10397.3760,
        12340.7939, 10255.4629, 10732.5137, 10928.2627, 12850.1123, 10270.1211,
         9586.2910, 13163.1279, 14888.5303, 10904.7051, 10804.0020, 11141.9717,
        12351.4170, 15085.6621, 12375.9141, 10471.1699, 13821.6689,  9447.0781,
        11186.1572,  8537.8662, 12244.7158, 15483.5146,  9517.7686, 10619.8965,
        11434.6094,  9221.2959, 11892.8955, 11070.9531,  9570.4160, 11099.7871,
        11935.7646, 13799.9990,  9262.5898,  9723.4570, 11958.8447, 11133.2607,
         9324.5830, 10774.2715,  9157.7100,  9045.8350, 13037.2637,  9863.4004,
        15588.4014, 11690.0449, 13337.0732, 11726.4600, 11617.5059, 11442.3193,
        12573.7344, 11647.4580, 10156.2354, 17718.0273, 14144.7168, 11094.0732,
        11052.2881, 14840.8047, 13644.2461, 10909.2402, 12133.6621, 13663.3965,
        10937.2959, 14187.6475, 11608.2812, 14481.7441,  9455.4541, 10707.0361,
         9078.2637, 10027.5928, 12545.2373, 12041.3193, 10216.5889,  9182.9883,
        15707.1279, 13332.6318, 11469.9893,  9064.8438, 15130.7998, 11425.2471,
        12461.9521, 10379.3584, 11779.7100, 11600.0010,  9105.5986, 11057.9561,
        10361.2783, 12277.5840, 12033.0635, 13560.6123, 12095.9365, 13529.8994,
        11864.2871, 11592.8672, 10365.5156, 11495.9180, 10972.6260, 12314.8770,
         9146.3359, 12345.5166, 11476.4141, 11413.8877, 12432.7559, 12258.0371,
        10499.9131, 10786.7783, 11508.1465, 11720.4199, 11063.4414, 12441.5234,
        10880.8633,  9208.0693, 13566.3164, 13193.6221, 12139.7451, 11471.4668,
        11391.7148, 11940.0996,  9758.4570, 11505.7285, 11804.9570, 12256.0254,
        11442.9609, 11090.9473, 11658.0518,  9736.8994, 12499.6934, 11493.6807,
        11725.8330, 16655.5488, 12562.1836, 12190.4160,  9662.3467, 10621.5830,
        12312.1934, 11294.4844, 14060.8271, 10314.0566, 14507.3730, 11259.6484,
        12974.9014, 11538.6787, 15613.3896, 10415.9121, 11610.0391, 10038.0586,
        11759.0039, 12755.2168,  9512.8877, 12076.7910, 12601.9893, 12891.6152,
        11938.6836, 10750.4707,  9640.5908, 10676.2578, 12500.5557, 14064.9814,
        12126.5674, 10816.6680, 12941.8281, 10778.4170, 10182.7334, 11945.8125,
        12081.4424, 13189.0928, 13688.6074,  9653.4814, 11121.0312, 12180.1934,
        15897.0469, 10100.7432,  9845.1689, 12905.5596, 10938.7314, 12174.3545,
         9848.3652, 10521.6367,  9652.6025, 10798.4922, 12841.1445, 13563.4893,
        11088.8721, 14209.7002,  9763.9961,  9664.1914, 10389.5459, 11620.0146,
        13241.3252, 10026.4277,  9302.2861,  9005.1504, 15395.2500, 12296.7441,
        12613.7080, 11933.6084, 12319.7441, 12614.9541, 13668.4883, 12888.4658,
        10956.7480,  8494.5186, 13601.8047, 11809.6221, 10542.7295, 14780.5078,
        11549.6123,  9838.8125, 12277.0898, 12256.8643, 12464.5859,  8801.6660,
        12962.8613, 13844.4248,  9514.8799, 12956.9648, 13252.9434,  9142.0566,
        10846.2314, 12143.9678, 11794.5645, 10155.4414, 12695.7168, 12275.7979,
         7622.6763, 12480.2246, 13073.3164, 13390.8711, 10281.4121, 10918.5078,
        10140.0664, 11014.6279, 13415.9170, 12288.9170, 12346.1240, 10874.6660,
        12107.5762, 12358.6465, 10818.1934, 11233.7217, 11698.1367, 10398.7031,
        11479.5938, 10592.1426, 13908.6309,  9793.2969, 13453.5762, 12185.8652,
        12865.1602, 10060.3604,  9618.1055, 10194.3281, 11186.9336, 14604.1982,
        12157.9365, 11929.3643, 11094.2979, 12125.1982,  9171.9590,  9267.0801,
         8479.0957, 12232.9355, 11966.9824,  9872.7715, 11128.6836, 11583.1660,
        10222.0771,  9995.9873, 12069.6748, 13365.4580,  9671.5977, 10546.2070,
        10001.0732, 11911.5791, 12333.5508, 11873.2871, 10759.1436, 11890.7588,
        13227.5107, 13508.2002, 11448.4434, 11409.6699, 12574.1699, 12300.1543,
        14769.4688, 12299.8174,  9944.3799, 10133.9844, 10995.2080, 13488.0732,
        10692.3887, 13368.8545, 12030.8271, 11184.2725, 12829.0557, 10875.7734,
        14178.1240, 14137.9150, 14660.7617, 10682.9629, 11139.0068, 11918.4893,
        14655.2666,  9878.2715, 10319.1289, 12155.4082, 13661.0537, 13541.6602,
        10767.3311, 12703.5654, 12109.7490,  9235.8623, 10773.4600, 11763.0303,
         9958.0928, 11458.9854, 11456.2471, 11307.1562, 11946.4570,  7959.0508,
        10930.9502, 12753.8281, 11464.2295, 13097.1611, 17001.5469, 10935.3691,
        14316.0752, 12277.1924, 11305.1787, 12069.7441, 11420.8076,  9727.1074,
         9860.7510, 14394.7891, 11106.8975, 11131.4639,  9089.3281, 12133.6621,
        11416.5781, 11379.8506, 10948.1709, 12863.6572, 11751.3848, 12957.5420,
        11558.0166, 10557.7598, 13835.3594,  9818.0420, 13410.2539,  7170.8359,
        10022.5215,  9071.3848, 12538.2285, 13169.7031,  9126.9102, 10204.9355,
        11325.7227, 10665.3467, 11880.4502, 12670.1465, 10108.6699, 10610.1953,
        12953.8760, 12349.2539, 10007.5352, 15356.3008, 12073.1689, 16512.3867,
        16258.4121, 13951.7373, 12532.7617,  9703.8506, 15949.0273, 16234.5986,
         9756.6133, 12961.3047, 10073.7188,  8203.6768, 14249.1172,  9614.7861,
         9076.2148, 11134.1250, 10577.0176, 11191.3486, 10512.0410,  9062.9346,
        10260.1904, 13765.9863, 10118.0449, 11822.5049, 11373.3066, 13029.0537,
         9911.7705, 13855.0127, 10379.7285, 11640.0293, 10733.8467, 13598.7861,
        14255.9590, 13360.7373, 13288.4043, 11260.7969, 13357.3623, 13062.0811,
        11481.6660, 11120.1055, 11337.8672, 12467.9268, 12023.7842, 13903.6943,
        11260.8506, 10981.7959, 11621.2646, 13649.9521, 14087.8779,  9964.5645,
        13453.3760,  9273.8711, 12508.9385, 10155.4492,  9381.2666, 11561.5186,
        10228.5967, 11229.8076, 10379.7031, 11166.8711, 10180.9189, 10574.4463,
        15486.9961,  9392.2520,  9501.6426, 12853.5723, 14294.0693,  9388.8545,
         9154.6113, 10094.2285, 11471.3184,  9037.8701, 13729.0146, 13841.8828,
        12737.0684,  9376.2607, 11561.9746, 14823.3594, 14981.5820, 13324.6250,
        11136.5342,  8889.7227,  9836.6250, 10364.2773, 12150.3857,  9967.3945,
        11953.1660, 15314.6221, 11674.3428, 16237.7451, 12394.5078, 10515.9434,
        10330.5020, 10319.4434, 11051.2725, 10768.1914, 11308.5000,  9712.0908,
        11150.0430, 14117.9883, 12908.6631, 11883.6055,  8760.8975, 13893.9355,
        14590.3262, 12439.2471, 10345.0010, 11891.4150, 14040.1748, 11564.1465,
         9820.0371, 11752.0908, 10862.3154, 10988.1865, 13592.7021, 11112.8477,
         9176.8760, 12197.2285, 12537.8486, 11545.9512, 13858.9980, 11751.1143,
        13386.7744, 14978.5596, 12137.2021, 11582.1230, 11311.7979, 10855.4346,
        12404.5938, 12990.2676,  8657.7334, 10580.9795, 12040.8037, 11431.5469,
        11031.4609,  9868.1221])
Layer: encoder.7.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 18.2915,  33.5871, 361.1929,  ...,  30.7156,  56.7179, 307.8613])
[DEBUG] Global concept maps computed with 53 layers.
Layer: conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.4.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.4.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.4.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.4.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.4.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.4.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.4.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.4.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.4.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.4.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.5.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.5.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.5.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        1., 0.], device='cuda:0')}}
Layer: encoder.5.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.5.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0.], device='cuda:0')}}
Layer: encoder.5.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.5.3.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.3.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.3.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.6.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.6.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
        0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
        0., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.6.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.6.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.6.3.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.3.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.6.3.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.4.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.4.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.4.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.6.5.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.5.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.5.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.7.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.7.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}
[DEBUG] Global pruning mask: OrderedDict([('conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.4.0.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0')}}), ('encoder.4.0.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0')}}), ('encoder.4.0.conv3', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.4.0.downsample.0', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.4.1.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0')}}), ('encoder.4.1.conv2', {'Conv2d': {'weight': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}}), ('encoder.4.1.conv3', {'Conv2d': {'weight': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.4.2.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.4.2.conv2', {'Conv2d': {'weight': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}}), ('encoder.4.2.conv3', {'Conv2d': {'weight': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.5.0.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}}), ('encoder.5.0.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        0., 0.], device='cuda:0')}}), ('encoder.5.0.conv3', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.5.0.downsample.0', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.5.1.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        1., 0.], device='cuda:0')}}), ('encoder.5.1.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}}), ('encoder.5.1.conv3', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0')}}), ('encoder.5.2.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}}), ('encoder.5.2.conv2', {'Conv2d': {'weight': tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0.], device='cuda:0')}}), ('encoder.5.2.conv3', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}}), ('encoder.5.3.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0.], device='cuda:0')}}), ('encoder.5.3.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0.], device='cuda:0')}}), ('encoder.5.3.conv3', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0')}}), ('encoder.6.0.conv1', {'Conv2d': {'weight': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0.], device='cuda:0')}}), ('encoder.6.0.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
        0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,
        0., 0., 0., 1.], device='cuda:0')}}), ('encoder.6.0.conv3', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.0.downsample.0', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.1.conv1', {'Conv2d': {'weight': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1.], device='cuda:0')}}), ('encoder.6.1.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.1.conv3', {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.2.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.2.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.2.conv3', {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 1., 0.], device='cuda:0')}}), ('encoder.6.3.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.3.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1.], device='cuda:0')}}), ('encoder.6.3.conv3', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.4.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.4.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.4.conv3', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}}), ('encoder.6.5.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        1., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.5.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.5.conv3', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.0.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.0.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,
        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.0.conv3', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.0.downsample.0', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.1.conv1', {'Conv2d': {'weight': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.1.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')}}), ('encoder.7.1.conv3', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.2.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.2.conv2', {'Conv2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,
        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.7.2.conv3', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')}})])
Full profiling results saved to /home/paul/projects/CV4RS-main/pruning_callgraph.txt
=== Round 2/3 ===
Applying pruning mask for Round 2...
[DEBUG] Validating mask for layer: conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: conv1
[DEBUG] Applying mask to layer: conv1
[DEBUG] Layer weight shape: torch.Size([64, 10, 7, 7])
[DEBUG] Mask shape: torch.Size([64])
[WARNING] Adjusting mask shape for layer: conv1
[ERROR] Failed to apply pruning mask to layer conv1: shape '[64, 10, 7, 7]' is invalid for input of size 64

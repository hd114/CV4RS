Using device: cuda:0
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    8209 filtered patches indexed
    8209 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7150 filtered patches indexed
    7150 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    4263 filtered patches indexed
    4263 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7180 filtered patches indexed
    7180 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    3248 filtered patches indexed
    3248 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 10372 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    5941 filtered patches indexed
    5941 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 10372 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    1871 filtered patches indexed
    1871 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 1939 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    1323 filtered patches indexed
    1323 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 1939 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    32 filtered patches indexed
    32 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 8775 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    4206 filtered patches indexed
    4206 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 8775 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    2151 filtered patches indexed
    2151 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 16438 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    8037 filtered patches indexed
    8037 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 16438 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    4220 filtered patches indexed
    4220 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 4874 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    1692 filtered patches indexed
    1692 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 4874 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    2039 filtered patches indexed
    2039 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    15720 filtered patches indexed
    15720 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    29135 filtered patches indexed
    29135 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Loading BEN data for train...
    237871 patches indexed
    237871 filtered patches indexed
    237871 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
==================================================
ROUND 1/40
==================================================
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
micro     precision: 1.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 40183 | mAP: 0.3644
macro     precision: 0.0526 | recall: 0.0000 | f1-score: 0.0000 | support: 40183 | mAP: 0.2591

==================================================
ROUND 2/40
==================================================
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
micro     precision: 0.4913 | recall: 0.2250 | f1-score: 0.3086 | support: 40183 | mAP: 0.4259
macro     precision: 0.0814 | recall: 0.1024 | f1-score: 0.0859 | support: 40183 | mAP: 0.3101

==================================================
ROUND 3/40
==================================================
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
Epoch 1/1
----------
micro     precision: 0.3354 | recall: 0.1339 | f1-score: 0.1914 | support: 40183 | mAP: 0.3325
macro     precision: 0.1515 | recall: 0.0759 | f1-score: 0.0588 | support: 40183 | mAP: 0.2799

==================================================
ROUND 4/40
==================================================
Finale Anzahl der Pruning-Patches: 17
Anzahl eindeutiger Klassen: 18
Klassenverteilung in den Pruning-Patches (Häufigkeiten): {'Marine waters': 9, 'Transitional woodland, shrub': 7, 'Mixed forest': 7, 'Coniferous forest': 6, 'Land principally occupied by agriculture, with significant areas of natural vegetation': 2, 'Inland waters': 1, 'Broad-leaved forest': 2, 'Arable land': 4, 'Urban fabric': 1, 'Industrial or commercial units': 1, 'Coastal wetlands': 2, 'Inland wetlands': 2, 'Pastures': 4, 'Complex cultivation patterns': 1, 'Moors, heathland and sclerophyllous vegetation': 1, 'Natural grassland and sparsely vegetated areas': 1, 'Beaches, dunes, sands': 1, 'Permanent crops': 1}
[INFO] Erstelle Prune Loader...
[INFO] 12 Patches nach Filterung übrig.
[SUCCESS] Prune Loader erfolgreich erstellt.
Starting relevance computation and pruning mask generation.
Type of components_relevances: <class 'collections.OrderedDict'>
Layer: conv1
Total layer relevance: 6.493624578209493e+24
--------------------------------------------------
Layer: encoder.4.0.conv1
Total layer relevance: 3.4147425120101377e+24
--------------------------------------------------
Layer: encoder.4.0.conv2
Total layer relevance: 2.492699879769087e+24
--------------------------------------------------
Layer: encoder.4.0.conv3
Total layer relevance: 6.455893492588977e+23
--------------------------------------------------
Layer: encoder.4.0.downsample.0
Total layer relevance: 6.546534740129287e+23
--------------------------------------------------
Layer: encoder.4.1.conv1
Total layer relevance: 3.463028972307698e+22
--------------------------------------------------
Layer: encoder.4.1.conv2
Total layer relevance: 2.0837533979094708e+22
--------------------------------------------------
Layer: encoder.4.1.conv3
Total layer relevance: 3.40780403223703e+21
--------------------------------------------------
Layer: encoder.4.2.conv1
Total layer relevance: 4.2664590705540936e+20
--------------------------------------------------
Layer: encoder.4.2.conv2
Total layer relevance: 3.2200863999438566e+20
--------------------------------------------------
Layer: encoder.4.2.conv3
Total layer relevance: 4.480857328861577e+19
--------------------------------------------------
Layer: encoder.5.0.conv1
Total layer relevance: 7.388085919468749e+18
--------------------------------------------------
Layer: encoder.5.0.conv2
Total layer relevance: 5.590400900729405e+18
--------------------------------------------------
Layer: encoder.5.0.conv3
Total layer relevance: 5.487966274317189e+17
--------------------------------------------------
Layer: encoder.5.0.downsample.0
Total layer relevance: 5.502494946088714e+17
--------------------------------------------------
Layer: encoder.5.1.conv1
Total layer relevance: 2.6709181843111936e+16
--------------------------------------------------
Layer: encoder.5.1.conv2
Total layer relevance: 1.909919557930189e+16
--------------------------------------------------
Layer: encoder.5.1.conv3
Total layer relevance: 2758778827046912.0
--------------------------------------------------
Layer: encoder.5.2.conv1
Total layer relevance: 173781255454720.0
--------------------------------------------------
Layer: encoder.5.2.conv2
Total layer relevance: 159976962129920.0
--------------------------------------------------
Layer: encoder.5.2.conv3
Total layer relevance: 29112991219712.0
--------------------------------------------------
Layer: encoder.5.3.conv1
Total layer relevance: 1966549237760.0
--------------------------------------------------
Layer: encoder.5.3.conv2
Total layer relevance: 1561407782912.0
--------------------------------------------------
Layer: encoder.5.3.conv3
Total layer relevance: 445901897728.0
--------------------------------------------------
Layer: encoder.6.0.conv1
Total layer relevance: 64131080192.0
--------------------------------------------------
Layer: encoder.6.0.conv2
Total layer relevance: 71614939136.0
--------------------------------------------------
Layer: encoder.6.0.conv3
Total layer relevance: 29129809920.0
--------------------------------------------------
Layer: encoder.6.0.downsample.0
Total layer relevance: 30671675392.0
--------------------------------------------------
Layer: encoder.6.1.conv1
Total layer relevance: 5264711680.0
--------------------------------------------------
Layer: encoder.6.1.conv2
Total layer relevance: 6037024256.0
--------------------------------------------------
Layer: encoder.6.1.conv3
Total layer relevance: 578034048.0
--------------------------------------------------
Layer: encoder.6.2.conv1
Total layer relevance: 92150696.0
--------------------------------------------------
Layer: encoder.6.2.conv2
Total layer relevance: 121815616.0
--------------------------------------------------
Layer: encoder.6.2.conv3
Total layer relevance: 34903320.0
--------------------------------------------------
Layer: encoder.6.3.conv1
Total layer relevance: 9112536.0
--------------------------------------------------
Layer: encoder.6.3.conv2
Total layer relevance: 15995740.0
--------------------------------------------------
Layer: encoder.6.3.conv3
Total layer relevance: 1865657.75
--------------------------------------------------
Layer: encoder.6.4.conv1
Total layer relevance: 501237.28125
--------------------------------------------------
Layer: encoder.6.4.conv2
Total layer relevance: 912978.0
--------------------------------------------------
Layer: encoder.6.4.conv3
Total layer relevance: 119019.46875
--------------------------------------------------
Layer: encoder.6.5.conv1
Total layer relevance: 39007.5234375
--------------------------------------------------
Layer: encoder.6.5.conv2
Total layer relevance: 82236.328125
--------------------------------------------------
Layer: encoder.6.5.conv3
Total layer relevance: 23137.25390625
--------------------------------------------------
Layer: encoder.7.0.conv1
Total layer relevance: 7007.0322265625
--------------------------------------------------
Layer: encoder.7.0.conv2
Total layer relevance: 31468.86328125
--------------------------------------------------
Layer: encoder.7.0.conv3
Total layer relevance: 10893.7451171875
--------------------------------------------------
Layer: encoder.7.0.downsample.0
Total layer relevance: 13031.240234375
--------------------------------------------------
Layer: encoder.7.1.conv1
Total layer relevance: 2394.82275390625
--------------------------------------------------
Layer: encoder.7.1.conv2
Total layer relevance: 9567.296875
--------------------------------------------------
Layer: encoder.7.1.conv3
Total layer relevance: 3686.743896484375
--------------------------------------------------
Layer: encoder.7.2.conv1
Total layer relevance: 2091.76708984375
--------------------------------------------------
Layer: encoder.7.2.conv2
Total layer relevance: 5039.36474609375
--------------------------------------------------
Layer: encoder.7.2.conv3
Total layer relevance: 2293.7646484375
--------------------------------------------------
--------------------------------------------------
Global Pruning Mask
Pruning-rate: 0.3
Layer: conv1		% of pruned neurons: 0.00%
Layer: encoder.4.0.conv1		% of pruned neurons: 0.00%
Layer: encoder.4.0.conv2		% of pruned neurons: 0.00%
Layer: encoder.4.0.conv3		% of pruned neurons: 0.00%
Layer: encoder.4.0.downsample.0		% of pruned neurons: 0.00%
Layer: encoder.4.1.conv1		% of pruned neurons: 0.00%
Layer: encoder.4.1.conv2		% of pruned neurons: 0.00%
Layer: encoder.4.1.conv3		% of pruned neurons: 0.00%
Layer: encoder.4.2.conv1		% of pruned neurons: 0.00%
Layer: encoder.4.2.conv2		% of pruned neurons: 0.00%
Layer: encoder.4.2.conv3		% of pruned neurons: 0.00%
Layer: encoder.5.0.conv1		% of pruned neurons: 0.00%
Layer: encoder.5.0.conv2		% of pruned neurons: 0.00%
Layer: encoder.5.0.conv3		% of pruned neurons: 0.00%
Layer: encoder.5.0.downsample.0		% of pruned neurons: 0.00%
Layer: encoder.5.1.conv1		% of pruned neurons: 0.00%
Layer: encoder.5.1.conv2		% of pruned neurons: 0.00%
Layer: encoder.5.1.conv3		% of pruned neurons: 0.00%
Layer: encoder.5.2.conv1		% of pruned neurons: 0.00%
Layer: encoder.5.2.conv2		% of pruned neurons: 0.00%
Layer: encoder.5.2.conv3		% of pruned neurons: 0.00%
Layer: encoder.5.3.conv1		% of pruned neurons: 0.00%
Layer: encoder.5.3.conv2		% of pruned neurons: 0.00%
Layer: encoder.5.3.conv3		% of pruned neurons: 0.00%
Layer: encoder.6.0.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.0.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.0.conv3		% of pruned neurons: 0.00%
Layer: encoder.6.0.downsample.0		% of pruned neurons: 0.00%
Layer: encoder.6.1.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.1.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.1.conv3		% of pruned neurons: 0.00%
Layer: encoder.6.2.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.2.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.2.conv3		% of pruned neurons: 0.00%
Layer: encoder.6.3.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.3.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.3.conv3		% of pruned neurons: 0.10%
Layer: encoder.6.4.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.4.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.4.conv3		% of pruned neurons: 12.79%
Layer: encoder.6.5.conv1		% of pruned neurons: 0.00%
Layer: encoder.6.5.conv2		% of pruned neurons: 0.00%
Layer: encoder.6.5.conv3		% of pruned neurons: 41.80%
Layer: encoder.7.0.conv1		% of pruned neurons: 0.39%
Layer: encoder.7.0.conv2		% of pruned neurons: 0.00%
Layer: encoder.7.0.conv3		% of pruned neurons: 78.61%
Layer: encoder.7.0.downsample.0		% of pruned neurons: 73.44%
Layer: encoder.7.1.conv1		% of pruned neurons: 34.18%
Layer: encoder.7.1.conv2		% of pruned neurons: 0.00%
Layer: encoder.7.1.conv3		% of pruned neurons: 93.26%
Layer: encoder.7.2.conv1		% of pruned neurons: 44.34%
Layer: encoder.7.2.conv2		% of pruned neurons: 2.93%
Layer: encoder.7.2.conv3		% of pruned neurons: 95.95%
Sendeing pruning mask to clients...
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
[INFO] Pruner and pruning mask received and stored.
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.4584 | recall: 0.2769 | f1-score: 0.3453 | support: 40183 | mAP: 0.4093
macro     precision: 0.1733 | recall: 0.1270 | f1-score: 0.1024 | support: 40183 | mAP: 0.3229

==================================================
ROUND 5/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.4593 | recall: 0.2293 | f1-score: 0.3059 | support: 40183 | mAP: 0.3917
macro     precision: 0.1714 | recall: 0.1114 | f1-score: 0.1147 | support: 40183 | mAP: 0.3207

==================================================
ROUND 6/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6290 | recall: 0.3951 | f1-score: 0.4854 | support: 40183 | mAP: 0.5485
macro     precision: 0.2680 | recall: 0.1753 | f1-score: 0.1734 | support: 40183 | mAP: 0.3360

==================================================
ROUND 7/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.5586 | recall: 0.2802 | f1-score: 0.3732 | support: 40183 | mAP: 0.5079
macro     precision: 0.3518 | recall: 0.1305 | f1-score: 0.1351 | support: 40183 | mAP: 0.3458

==================================================
ROUND 8/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7483 | recall: 0.5735 | f1-score: 0.6493 | support: 40183 | mAP: 0.6888
macro     precision: 0.4053 | recall: 0.2865 | f1-score: 0.3025 | support: 40183 | mAP: 0.3963

==================================================
ROUND 9/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6067 | recall: 0.3947 | f1-score: 0.4783 | support: 40183 | mAP: 0.5036
macro     precision: 0.3606 | recall: 0.1951 | f1-score: 0.2026 | support: 40183 | mAP: 0.3633

==================================================
ROUND 10/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7127 | recall: 0.6085 | f1-score: 0.6565 | support: 40183 | mAP: 0.6986
macro     precision: 0.4039 | recall: 0.2992 | f1-score: 0.2966 | support: 40183 | mAP: 0.3905

==================================================
ROUND 11/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6183 | recall: 0.5458 | f1-score: 0.5798 | support: 40183 | mAP: 0.5206
macro     precision: 0.3589 | recall: 0.2664 | f1-score: 0.2602 | support: 40183 | mAP: 0.3841

==================================================
ROUND 12/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7373 | recall: 0.5906 | f1-score: 0.6559 | support: 40183 | mAP: 0.6868
macro     precision: 0.4033 | recall: 0.2924 | f1-score: 0.2973 | support: 40183 | mAP: 0.3916

==================================================
ROUND 13/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.5794 | recall: 0.5015 | f1-score: 0.5377 | support: 40183 | mAP: 0.5739
macro     precision: 0.3451 | recall: 0.2515 | f1-score: 0.2449 | support: 40183 | mAP: 0.3772

==================================================
ROUND 14/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6675 | recall: 0.5991 | f1-score: 0.6314 | support: 40183 | mAP: 0.6873
macro     precision: 0.4962 | recall: 0.2968 | f1-score: 0.2861 | support: 40183 | mAP: 0.4057

==================================================
ROUND 15/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.5788 | recall: 0.5796 | f1-score: 0.5792 | support: 40183 | mAP: 0.5351
macro     precision: 0.3489 | recall: 0.2693 | f1-score: 0.2494 | support: 40183 | mAP: 0.3565

==================================================
ROUND 16/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6413 | recall: 0.5694 | f1-score: 0.6032 | support: 40183 | mAP: 0.6606
macro     precision: 0.4855 | recall: 0.2839 | f1-score: 0.2867 | support: 40183 | mAP: 0.4183

==================================================
ROUND 17/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7025 | recall: 0.5849 | f1-score: 0.6383 | support: 40183 | mAP: 0.6760
macro     precision: 0.4144 | recall: 0.2849 | f1-score: 0.2963 | support: 40183 | mAP: 0.3840

==================================================
ROUND 18/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7682 | recall: 0.5684 | f1-score: 0.6533 | support: 40183 | mAP: 0.7111
macro     precision: 0.5139 | recall: 0.2796 | f1-score: 0.3080 | support: 40183 | mAP: 0.4226

==================================================
ROUND 19/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6128 | recall: 0.5428 | f1-score: 0.5757 | support: 40183 | mAP: 0.5999
macro     precision: 0.3824 | recall: 0.2749 | f1-score: 0.2733 | support: 40183 | mAP: 0.3961

==================================================
ROUND 20/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7620 | recall: 0.5912 | f1-score: 0.6658 | support: 40183 | mAP: 0.7166
macro     precision: 0.5105 | recall: 0.2881 | f1-score: 0.3093 | support: 40183 | mAP: 0.4188

==================================================
ROUND 21/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6202 | recall: 0.5318 | f1-score: 0.5726 | support: 40183 | mAP: 0.5393
macro     precision: 0.3725 | recall: 0.2787 | f1-score: 0.2797 | support: 40183 | mAP: 0.3958

==================================================
ROUND 22/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7472 | recall: 0.6096 | f1-score: 0.6714 | support: 40183 | mAP: 0.7198
macro     precision: 0.5139 | recall: 0.3132 | f1-score: 0.3307 | support: 40183 | mAP: 0.4245

==================================================
ROUND 23/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6434 | recall: 0.5380 | f1-score: 0.5860 | support: 40183 | mAP: 0.5992
macro     precision: 0.3777 | recall: 0.2709 | f1-score: 0.2783 | support: 40183 | mAP: 0.3952

==================================================
ROUND 24/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7634 | recall: 0.5716 | f1-score: 0.6537 | support: 40183 | mAP: 0.7260
macro     precision: 0.5088 | recall: 0.2880 | f1-score: 0.3229 | support: 40183 | mAP: 0.4350

==================================================
ROUND 25/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6343 | recall: 0.5906 | f1-score: 0.6117 | support: 40183 | mAP: 0.6515
macro     precision: 0.4433 | recall: 0.2939 | f1-score: 0.2913 | support: 40183 | mAP: 0.3945

==================================================
ROUND 26/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7248 | recall: 0.5349 | f1-score: 0.6155 | support: 40183 | mAP: 0.6781
macro     precision: 0.4869 | recall: 0.2556 | f1-score: 0.2777 | support: 40183 | mAP: 0.4107

==================================================
ROUND 27/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6648 | recall: 0.6065 | f1-score: 0.6343 | support: 40183 | mAP: 0.6781
macro     precision: 0.4813 | recall: 0.3114 | f1-score: 0.3149 | support: 40183 | mAP: 0.4125

==================================================
ROUND 28/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6194 | recall: 0.5571 | f1-score: 0.5866 | support: 40183 | mAP: 0.6223
macro     precision: 0.4834 | recall: 0.2604 | f1-score: 0.2538 | support: 40183 | mAP: 0.3885

==================================================
ROUND 29/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6224 | recall: 0.5024 | f1-score: 0.5560 | support: 40183 | mAP: 0.5995
macro     precision: 0.3887 | recall: 0.2529 | f1-score: 0.2594 | support: 40183 | mAP: 0.3838

==================================================
ROUND 30/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7042 | recall: 0.5898 | f1-score: 0.6419 | support: 40183 | mAP: 0.6957
macro     precision: 0.5429 | recall: 0.2932 | f1-score: 0.3035 | support: 40183 | mAP: 0.4366

==================================================
ROUND 31/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6569 | recall: 0.5629 | f1-score: 0.6063 | support: 40183 | mAP: 0.6443
macro     precision: 0.3673 | recall: 0.2840 | f1-score: 0.2862 | support: 40183 | mAP: 0.4001

==================================================
ROUND 32/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6792 | recall: 0.6064 | f1-score: 0.6408 | support: 40183 | mAP: 0.6897
macro     precision: 0.5840 | recall: 0.3078 | f1-score: 0.3151 | support: 40183 | mAP: 0.4452

==================================================
ROUND 33/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6289 | recall: 0.5774 | f1-score: 0.6021 | support: 40183 | mAP: 0.6191
macro     precision: 0.3703 | recall: 0.2923 | f1-score: 0.2875 | support: 40183 | mAP: 0.4018

==================================================
ROUND 34/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6767 | recall: 0.6183 | f1-score: 0.6462 | support: 40183 | mAP: 0.6711
macro     precision: 0.5248 | recall: 0.3298 | f1-score: 0.3340 | support: 40183 | mAP: 0.4388

==================================================
ROUND 35/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6270 | recall: 0.5593 | f1-score: 0.5912 | support: 40183 | mAP: 0.6253
macro     precision: 0.4339 | recall: 0.2653 | f1-score: 0.2564 | support: 40183 | mAP: 0.3886

==================================================
ROUND 36/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6790 | recall: 0.6130 | f1-score: 0.6443 | support: 40183 | mAP: 0.6705
macro     precision: 0.5233 | recall: 0.3138 | f1-score: 0.3175 | support: 40183 | mAP: 0.4245

==================================================
ROUND 37/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.5619 | recall: 0.5741 | f1-score: 0.5679 | support: 40183 | mAP: 0.5781
macro     precision: 0.4494 | recall: 0.2918 | f1-score: 0.2786 | support: 40183 | mAP: 0.3859

==================================================
ROUND 38/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6720 | recall: 0.6022 | f1-score: 0.6352 | support: 40183 | mAP: 0.6408
macro     precision: 0.5068 | recall: 0.3005 | f1-score: 0.2975 | support: 40183 | mAP: 0.4134

==================================================
ROUND 39/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.6244 | recall: 0.5644 | f1-score: 0.5929 | support: 40183 | mAP: 0.6353
macro     precision: 0.4672 | recall: 0.2731 | f1-score: 0.2670 | support: 40183 | mAP: 0.4049

==================================================
ROUND 40/40
==================================================
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
Epoch 1/1
----------
Prune before sending to global...
micro     precision: 0.7145 | recall: 0.5986 | f1-score: 0.6514 | support: 40183 | mAP: 0.7001
macro     precision: 0.4555 | recall: 0.2836 | f1-score: 0.2876 | support: 40183 | mAP: 0.4139

[{'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}, {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '2': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '3': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '4': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '5': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '6': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '7': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '8': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '9': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '10': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '11': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '12': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '13': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '14': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '15': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '16': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '17': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, '18': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'micro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, 'ap_mic': [], 'ap_mac': []}]

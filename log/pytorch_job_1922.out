Lines that potentially need to be canonized 309
/home/paul/projects/CV4RS-main/pxp/prune.py
Using device: cuda:0
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7150 filtered patches indexed
    7150 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    4263 filtered patches indexed
    4263 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    15720 filtered patches indexed
    15720 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
[INFO] Initializing LRP Pruning...
[INFO] LRP initialized successfully.
=== Round 1/3 ===
[INFO] Training and communication for Round 1...
Epoch 1/2
----------
Updated learning rate: [0.0002]
Epoch 2/2
----------
Updated learning rate: [0.0002]
[INFO] Starting validation after Round 1...
Bug fix for empty classification report.
[DEBUG] Validation report: {'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '13': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, 'micro avg': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, 'macro avg': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, 'weighted avg': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0}, 'ap_mic': 0.13596226260772326, 'ap_mac': 0.13453528860318734}
micro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.1360
macro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.1345

[INFO] Performing LRP Pruning in Round 1...
[DEBUG] Starte Berechnung der LRP-Pruning-Maske für Land: Finland
[DEBUG] Pruning-Rate: 0.3
Erstelle DataLoader für Land: Finland
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
[DEBUG] Dataloader für 'Finland' geladen mit Batch-Größe 16 und 4 Arbeitern.
[DEBUG] Starte Berechnung der Relevanzwerte...
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([16])
Unexpected input shape for LRP: torch.Size([16]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 16])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 16
Input shape before relevance computation: torch.Size([16, 10, 1, 16])
Model output shape: torch.Size([16, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([16, 19]) to 16 for one-hot encoding.
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Grad output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Input shape before model forward: torch.Size([5])
Unexpected input shape for LRP: torch.Size([5]). Adding dummy dimensions.
Modified input shape for LRP: torch.Size([1, 1, 5])
Adjusting input channels from 1 to 10
Adjusting input batch size from 1 to match targets batch size 5
Input shape before relevance computation: torch.Size([5, 10, 1, 5])
Model output shape: torch.Size([5, 19])
Converting targets from torch.float64 to torch.long
Reducing targets shape from torch.Size([5, 19]) to 5 for one-hot encoding.
Targets shape: torch.Size([5])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([5, 19])
Grad output shape: torch.Size([5, 19])
Relevance computation successful. Relevance shape: torch.Size([5, 10, 1, 5])
[DEBUG] Relevanzwerte berechnet. Anzahl der Layer mit Relevanzwerten: 53
[DEBUG] Überprüfe Struktur und Inhalt von global_concept_maps vor Pruning-Maske...
[DEBUG] Layer 'conv1' enthält Tensor: Shape = torch.Size([64])
[DEBUG] Layer 'encoder.4.0.conv1' enthält Tensor: Shape = torch.Size([64])
[DEBUG] Layer 'encoder.4.0.conv2' enthält Tensor: Shape = torch.Size([64])
[DEBUG] Layer 'encoder.4.0.conv3' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.4.0.downsample.0' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.4.1.conv1' enthält Tensor: Shape = torch.Size([64])
[DEBUG] Layer 'encoder.4.1.conv2' enthält Tensor: Shape = torch.Size([64])
[DEBUG] Layer 'encoder.4.1.conv3' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.4.2.conv1' enthält Tensor: Shape = torch.Size([64])
[DEBUG] Layer 'encoder.4.2.conv2' enthält Tensor: Shape = torch.Size([64])
[DEBUG] Layer 'encoder.4.2.conv3' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.5.0.conv1' enthält Tensor: Shape = torch.Size([128])
[DEBUG] Layer 'encoder.5.0.conv2' enthält Tensor: Shape = torch.Size([128])
[DEBUG] Layer 'encoder.5.0.conv3' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.5.0.downsample.0' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.5.1.conv1' enthält Tensor: Shape = torch.Size([128])
[DEBUG] Layer 'encoder.5.1.conv2' enthält Tensor: Shape = torch.Size([128])
[DEBUG] Layer 'encoder.5.1.conv3' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.5.2.conv1' enthält Tensor: Shape = torch.Size([128])
[DEBUG] Layer 'encoder.5.2.conv2' enthält Tensor: Shape = torch.Size([128])
[DEBUG] Layer 'encoder.5.2.conv3' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.5.3.conv1' enthält Tensor: Shape = torch.Size([128])
[DEBUG] Layer 'encoder.5.3.conv2' enthält Tensor: Shape = torch.Size([128])
[DEBUG] Layer 'encoder.5.3.conv3' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.6.0.conv1' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.0.conv2' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.0.conv3' enthält Tensor: Shape = torch.Size([1024])
[DEBUG] Layer 'encoder.6.0.downsample.0' enthält Tensor: Shape = torch.Size([1024])
[DEBUG] Layer 'encoder.6.1.conv1' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.1.conv2' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.1.conv3' enthält Tensor: Shape = torch.Size([1024])
[DEBUG] Layer 'encoder.6.2.conv1' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.2.conv2' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.2.conv3' enthält Tensor: Shape = torch.Size([1024])
[DEBUG] Layer 'encoder.6.3.conv1' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.3.conv2' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.3.conv3' enthält Tensor: Shape = torch.Size([1024])
[DEBUG] Layer 'encoder.6.4.conv1' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.4.conv2' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.4.conv3' enthält Tensor: Shape = torch.Size([1024])
[DEBUG] Layer 'encoder.6.5.conv1' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.5.conv2' enthält Tensor: Shape = torch.Size([256])
[DEBUG] Layer 'encoder.6.5.conv3' enthält Tensor: Shape = torch.Size([1024])
[DEBUG] Layer 'encoder.7.0.conv1' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.7.0.conv2' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.7.0.conv3' enthält Tensor: Shape = torch.Size([2048])
[DEBUG] Layer 'encoder.7.0.downsample.0' enthält Tensor: Shape = torch.Size([2048])
[DEBUG] Layer 'encoder.7.1.conv1' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.7.1.conv2' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.7.1.conv3' enthält Tensor: Shape = torch.Size([2048])
[DEBUG] Layer 'encoder.7.2.conv1' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.7.2.conv2' enthält Tensor: Shape = torch.Size([512])
[DEBUG] Layer 'encoder.7.2.conv3' enthält Tensor: Shape = torch.Size([2048])
[DEBUG] Initialisiere GlobalPruningOperations...
[INFO] Using device: cuda:0
[DEBUG] Ziel-Layer: ['conv1', 'encoder.4.0.conv1', 'encoder.4.0.conv2', 'encoder.4.0.conv3', 'encoder.4.0.downsample.0', 'encoder.4.1.conv1', 'encoder.4.1.conv2', 'encoder.4.1.conv3', 'encoder.4.2.conv1', 'encoder.4.2.conv2', 'encoder.4.2.conv3', 'encoder.5.0.conv1', 'encoder.5.0.conv2', 'encoder.5.0.conv3', 'encoder.5.0.downsample.0', 'encoder.5.1.conv1', 'encoder.5.1.conv2', 'encoder.5.1.conv3', 'encoder.5.2.conv1', 'encoder.5.2.conv2', 'encoder.5.2.conv3', 'encoder.5.3.conv1', 'encoder.5.3.conv2', 'encoder.5.3.conv3', 'encoder.6.0.conv1', 'encoder.6.0.conv2', 'encoder.6.0.conv3', 'encoder.6.0.downsample.0', 'encoder.6.1.conv1', 'encoder.6.1.conv2', 'encoder.6.1.conv3', 'encoder.6.2.conv1', 'encoder.6.2.conv2', 'encoder.6.2.conv3', 'encoder.6.3.conv1', 'encoder.6.3.conv2', 'encoder.6.3.conv3', 'encoder.6.4.conv1', 'encoder.6.4.conv2', 'encoder.6.4.conv3', 'encoder.6.5.conv1', 'encoder.6.5.conv2', 'encoder.6.5.conv3', 'encoder.7.0.conv1', 'encoder.7.0.conv2', 'encoder.7.0.conv3', 'encoder.7.0.downsample.0', 'encoder.7.1.conv1', 'encoder.7.1.conv2', 'encoder.7.1.conv3', 'encoder.7.2.conv1', 'encoder.7.2.conv2', 'encoder.7.2.conv3']
[DEBUG] Starte Generierung der globalen Pruning-Maske...
[DEBUG] Validierung von global_concept_maps vor Beginn der Maskengenerierung...
[DEBUG] Layer 'conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.0.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.0.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.0.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.0.downsample.0' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.1.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.1.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.1.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.2.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.2.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.4.2.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.0.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.0.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.0.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.0.downsample.0' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.1.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.1.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.1.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.2.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.2.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.2.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.3.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.3.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.5.3.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.0.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.0.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.0.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.0.downsample.0' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.1.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.1.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.1.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.2.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.2.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.2.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.3.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.3.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.3.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.4.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.4.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.4.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.5.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.5.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.6.5.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.0.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.0.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.0.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.0.downsample.0' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.1.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.1.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.1.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.2.conv1' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.2.conv2' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Layer 'encoder.7.2.conv3' hat Typ: <class 'torch.Tensor'>.
[DEBUG] Überprüfe Layer 'conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.0.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.0.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.0.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.0.downsample.0' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.1.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.1.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.1.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.2.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.2.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.4.2.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.0.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.0.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.0.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.0.downsample.0' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.1.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.1.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.1.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.2.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.2.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.2.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.3.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.3.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.5.3.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.0.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.0.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.0.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.0.downsample.0' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.1.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.1.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.1.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.2.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.2.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.2.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.3.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.3.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.3.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.4.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.4.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.4.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.5.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.5.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.6.5.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.0.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.0.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.0.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.0.downsample.0' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.1.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.1.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.1.conv3' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.2.conv1' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.2.conv2' in global_concept_maps...
[DEBUG] Überprüfe Layer 'encoder.7.2.conv3' in global_concept_maps...
[DEBUG] Überprüfung abgeschlossen. Alle relevanten Layer sind jetzt Tensoren.
[DEBUG] Intervallindizes initialisiert: OrderedDict([('conv1', (0, 63)), ('encoder.4.0.conv1', (64, 127)), ('encoder.4.0.conv2', (128, 191)), ('encoder.4.0.conv3', (192, 447)), ('encoder.4.0.downsample.0', (448, 703)), ('encoder.4.1.conv1', (704, 767)), ('encoder.4.1.conv2', (768, 831)), ('encoder.4.1.conv3', (832, 1087)), ('encoder.4.2.conv1', (1088, 1151)), ('encoder.4.2.conv2', (1152, 1215)), ('encoder.4.2.conv3', (1216, 1471)), ('encoder.5.0.conv1', (1472, 1599)), ('encoder.5.0.conv2', (1600, 1727)), ('encoder.5.0.conv3', (1728, 2239)), ('encoder.5.0.downsample.0', (2240, 2751)), ('encoder.5.1.conv1', (2752, 2879)), ('encoder.5.1.conv2', (2880, 3007)), ('encoder.5.1.conv3', (3008, 3519)), ('encoder.5.2.conv1', (3520, 3647)), ('encoder.5.2.conv2', (3648, 3775)), ('encoder.5.2.conv3', (3776, 4287)), ('encoder.5.3.conv1', (4288, 4415)), ('encoder.5.3.conv2', (4416, 4543)), ('encoder.5.3.conv3', (4544, 5055)), ('encoder.6.0.conv1', (5056, 5311)), ('encoder.6.0.conv2', (5312, 5567)), ('encoder.6.0.conv3', (5568, 6591)), ('encoder.6.0.downsample.0', (6592, 7615)), ('encoder.6.1.conv1', (7616, 7871)), ('encoder.6.1.conv2', (7872, 8127)), ('encoder.6.1.conv3', (8128, 9151)), ('encoder.6.2.conv1', (9152, 9407)), ('encoder.6.2.conv2', (9408, 9663)), ('encoder.6.2.conv3', (9664, 10687)), ('encoder.6.3.conv1', (10688, 10943)), ('encoder.6.3.conv2', (10944, 11199)), ('encoder.6.3.conv3', (11200, 12223)), ('encoder.6.4.conv1', (12224, 12479)), ('encoder.6.4.conv2', (12480, 12735)), ('encoder.6.4.conv3', (12736, 13759)), ('encoder.6.5.conv1', (13760, 14015)), ('encoder.6.5.conv2', (14016, 14271)), ('encoder.6.5.conv3', (14272, 15295)), ('encoder.7.0.conv1', (15296, 15807)), ('encoder.7.0.conv2', (15808, 16319)), ('encoder.7.0.conv3', (16320, 18367)), ('encoder.7.0.downsample.0', (18368, 20415)), ('encoder.7.1.conv1', (20416, 20927)), ('encoder.7.1.conv2', (20928, 21439)), ('encoder.7.1.conv3', (21440, 23487)), ('encoder.7.2.conv1', (23488, 23999)), ('encoder.7.2.conv2', (24000, 24511)), ('encoder.7.2.conv3', (24512, 26559))])
[DEBUG] Generierte Pruning-Indizes überprüft:
  Layer: conv1 | Indizes: torch.Size([0])
  Layer: encoder.4.0.conv1 | Indizes: torch.Size([0])
  Layer: encoder.4.0.conv2 | Indizes: torch.Size([0])
  Layer: encoder.4.0.conv3 | Indizes: torch.Size([0])
  Layer: encoder.4.0.downsample.0 | Indizes: torch.Size([0])
  Layer: encoder.4.1.conv1 | Indizes: torch.Size([0])
  Layer: encoder.4.1.conv2 | Indizes: torch.Size([0])
  Layer: encoder.4.1.conv3 | Indizes: torch.Size([0])
  Layer: encoder.4.2.conv1 | Indizes: torch.Size([0])
  Layer: encoder.4.2.conv2 | Indizes: torch.Size([0])
  Layer: encoder.4.2.conv3 | Indizes: torch.Size([0])
  Layer: encoder.5.0.conv1 | Indizes: torch.Size([0])
  Layer: encoder.5.0.conv2 | Indizes: torch.Size([0])
  Layer: encoder.5.0.conv3 | Indizes: torch.Size([0])
  Layer: encoder.5.0.downsample.0 | Indizes: torch.Size([0])
  Layer: encoder.5.1.conv1 | Indizes: torch.Size([0])
  Layer: encoder.5.1.conv2 | Indizes: torch.Size([0])
  Layer: encoder.5.1.conv3 | Indizes: torch.Size([0])
  Layer: encoder.5.2.conv1 | Indizes: torch.Size([0])
  Layer: encoder.5.2.conv2 | Indizes: torch.Size([0])
  Layer: encoder.5.2.conv3 | Indizes: torch.Size([0])
  Layer: encoder.5.3.conv1 | Indizes: torch.Size([0])
  Layer: encoder.5.3.conv2 | Indizes: torch.Size([0])
  Layer: encoder.5.3.conv3 | Indizes: torch.Size([0])
  Layer: encoder.6.0.conv1 | Indizes: torch.Size([0])
  Layer: encoder.6.0.conv2 | Indizes: torch.Size([0])
  Layer: encoder.6.0.conv3 | Indizes: torch.Size([0])
  Layer: encoder.6.0.downsample.0 | Indizes: torch.Size([0])
  Layer: encoder.6.1.conv1 | Indizes: torch.Size([0])
  Layer: encoder.6.1.conv2 | Indizes: torch.Size([0])
  Layer: encoder.6.1.conv3 | Indizes: torch.Size([0])
  Layer: encoder.6.2.conv1 | Indizes: torch.Size([0])
  Layer: encoder.6.2.conv2 | Indizes: torch.Size([0])
  Layer: encoder.6.2.conv3 | Indizes: torch.Size([0])
  Layer: encoder.6.3.conv1 | Indizes: torch.Size([0])
  Layer: encoder.6.3.conv2 | Indizes: torch.Size([0])
  Layer: encoder.6.3.conv3 | Indizes: torch.Size([0])
  Layer: encoder.6.4.conv1 | Indizes: torch.Size([0])
  Layer: encoder.6.4.conv2 | Indizes: torch.Size([0])
  Layer: encoder.6.4.conv3 | Indizes: torch.Size([0])
  Layer: encoder.6.5.conv1 | Indizes: torch.Size([0])
  Layer: encoder.6.5.conv2 | Indizes: torch.Size([0])
  Layer: encoder.6.5.conv3 | Indizes: torch.Size([0])
  Layer: encoder.7.0.conv1 | Indizes: torch.Size([0])
  Layer: encoder.7.0.conv2 | Indizes: torch.Size([0])
  Layer: encoder.7.0.conv3 | Indizes: torch.Size([1508])
  Layer: encoder.7.0.downsample.0 | Indizes: torch.Size([1344])
  Layer: encoder.7.1.conv1 | Indizes: torch.Size([7])
  Layer: encoder.7.1.conv2 | Indizes: torch.Size([0])
  Layer: encoder.7.1.conv3 | Indizes: torch.Size([2037])
  Layer: encoder.7.2.conv1 | Indizes: torch.Size([512])
  Layer: encoder.7.2.conv2 | Indizes: torch.Size([512])
  Layer: encoder.7.2.conv3 | Indizes: torch.Size([2048])
[DEBUG] Verwende 'subsequent_layer_pruning': Both
[DEBUG] Generiere Pruning-Maske für Layer 'conv1'...
[ERROR] Failed to compute pruning mask: LocalPruningOperations.generate_local_pruning_mask() got an unexpected keyword argument 'device'

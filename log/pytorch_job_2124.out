Lines that potentially need to be canonized 309
Using device: cuda:0
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    8209 filtered patches indexed
    8209 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7150 filtered patches indexed
    7150 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    4263 filtered patches indexed
    4263 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7180 filtered patches indexed
    7180 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    3248 filtered patches indexed
    3248 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    15720 filtered patches indexed
    15720 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Initializing LRP Pruning...
LRP initialized successfully.
=== Round 1/3 ===
Training and communication for Round 1...
Epoch 1/2
----------
Epoch 2/2
----------
Epoch 1/2
----------
Epoch 2/2
----------
Epoch 1/2
----------
Epoch 2/2
----------
[INFO] Starting validation for Round 1...
True labels sample: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]
Predicted labels sample: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
         0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
         0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
         0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
         0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,
         0.]])
Predicted probabilities sample: [[0.00070344 0.03492633 0.0056228  0.03446498 0.00281834 0.00885654
  0.06124938 0.00503223 0.15910813 0.04320176 0.11690052 0.5283369
  0.03505202 0.01035404 0.01729538 0.02837537 0.00241323 0.09504053
  0.00972549]
 [0.00069973 0.03499125 0.00563374 0.03471374 0.00279853 0.00884576
  0.06199048 0.00501697 0.1588858  0.04341126 0.11637394 0.5250796
  0.0355273  0.01037687 0.01733392 0.02845052 0.00240925 0.09603555
  0.00968284]
 [0.00069986 0.03526264 0.00565586 0.03490967 0.00279574 0.00889677
  0.06234151 0.0050262  0.15956013 0.04369441 0.11679301 0.5226955
  0.03573723 0.01039829 0.01728962 0.02854005 0.00240911 0.09618457
  0.00967181]
 [0.00070163 0.03515562 0.00563119 0.03500213 0.00280571 0.00887313
  0.0626395  0.00502282 0.16002549 0.04353571 0.11697713 0.52256215
  0.03562773 0.01039009 0.01732353 0.02852377 0.0024079  0.09578601
  0.00968098]
 [0.00069933 0.03530186 0.00565569 0.03505543 0.00280566 0.00883741
  0.06260176 0.00502924 0.15999505 0.04363268 0.11695987 0.52200675
  0.03561885 0.01033553 0.01731349 0.02857341 0.00239933 0.09595855
  0.00966502]]
Bug fix for empty classification report.
micro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.3673
macro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.2553

[INFO] Performing LRP Pruning in Round 1...
[INFO] Computing LRP pruning mask...
Erstelle DataLoader f√ºr Land: Finland
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([5])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([5, 19])
Relevance computation successful. Relevance shape: torch.Size([5, 10, 1, 5])
[INFO] Relevance maps computed for 53 layers.
[DEBUG] Layer: conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.0.downsample.0
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.1.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.1.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.1.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.2.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.2.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.2.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.5.0.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.0.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.0.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.0.downsample.0
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.1.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.1.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.1.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.2.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.2.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.2.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.3.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.3.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.3.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.6.0.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.0.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.0.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.0.downsample.0
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.1.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.1.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.1.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.2.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.2.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.2.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.3.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.3.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.3.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.4.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.4.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.4.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.5.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.5.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.5.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.7.0.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.0.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.0.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.0.downsample.0
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.1.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.1.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.1.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.2.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.2.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.2.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 1844
Layer: conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.7848e+17, 1.7623e+17, 9.4712e+16, 2.3556e+17, 1.2616e+17, 1.9620e+17,
        1.6167e+17, 3.5583e+17, 2.5399e+17, 1.6411e+17, 1.3401e+17, 1.6213e+17,
        1.6159e+17, 1.5872e+17, 1.1657e+17, 2.9401e+17, 1.8331e+17, 3.1810e+17,
        2.2621e+17, 2.3754e+17, 2.7615e+17, 2.5300e+17, 2.4113e+17, 7.5785e+16,
        1.7052e+17, 1.5280e+17, 2.3110e+17, 3.4912e+17, 1.3947e+17, 1.7023e+17,
        2.9110e+17, 2.7207e+17, 3.0338e+17, 1.4033e+17, 2.8747e+17, 1.9781e+17,
        1.8716e+17, 1.6503e+17, 2.0853e+17, 2.0857e+17, 1.8504e+17, 1.3740e+17,
        3.0879e+17, 1.7762e+17, 1.6427e+17, 1.2615e+17, 1.5620e+17, 2.4132e+17,
        2.4088e+17, 9.7759e+16, 2.1317e+17, 1.4773e+17, 1.2630e+17, 2.0418e+17,
        1.6837e+17, 1.0071e+17, 3.3028e+17, 1.6964e+17, 2.1866e+17, 1.8642e+17,
        1.2218e+17, 1.6062e+17, 2.6152e+17, 2.0469e+17])
Layer: encoder.4.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.1782e+17, 6.0726e+16, 7.3074e+16, 5.8744e+16, 1.2178e+17, 1.2082e+17,
        1.1432e+17, 6.4385e+16, 5.5141e+16, 8.7921e+16, 7.8982e+16, 1.0221e+17,
        9.2083e+16, 1.5493e+17, 9.4488e+16, 7.1930e+16, 4.9125e+16, 7.3305e+16,
        1.1043e+17, 1.8201e+17, 5.4173e+16, 7.2784e+16, 9.2999e+16, 1.1415e+17,
        8.7678e+16, 8.8158e+16, 1.6083e+17, 1.0816e+17, 1.7630e+17, 7.9850e+16,
        5.1103e+16, 1.0628e+17, 9.9253e+16, 6.6859e+16, 8.7551e+16, 6.2952e+16,
        1.1630e+17, 6.5706e+16, 9.5007e+16, 1.7337e+17, 6.3818e+16, 4.9031e+16,
        1.0716e+17, 1.5613e+17, 1.1726e+17, 8.3885e+16, 8.9193e+16, 9.2974e+16,
        8.7502e+16, 7.6861e+16, 7.0072e+16, 1.0652e+17, 1.3395e+17, 1.3461e+17,
        6.3693e+16, 1.2072e+17, 9.4386e+16, 5.0177e+16, 8.0610e+16, 6.9521e+16,
        6.5198e+16, 6.0539e+16, 7.5554e+16, 6.2840e+16])
Layer: encoder.4.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.1997e+17, 1.4617e+17, 2.8556e+17, 1.0957e+17, 1.4689e+17, 6.2219e+16,
        1.2484e+17, 1.9846e+17, 1.0996e+17, 1.2662e+17, 1.5801e+17, 1.5760e+17,
        1.0455e+17, 1.4264e+17, 8.4858e+16, 1.3425e+17, 1.3984e+17, 1.7689e+17,
        1.0784e+17, 6.3698e+16, 6.5671e+16, 6.3638e+16, 9.6849e+16, 1.2075e+17,
        1.7658e+17, 1.5349e+17, 1.1012e+17, 1.1102e+17, 1.0371e+17, 1.0902e+17,
        1.6484e+17, 2.2736e+17, 1.0794e+17, 9.5911e+16, 2.0167e+17, 1.1476e+17,
        1.1041e+17, 1.3187e+17, 2.2583e+17, 2.4368e+17, 1.3222e+17, 1.3162e+17,
        2.3586e+17, 1.4887e+17, 9.1156e+16, 1.9489e+17, 5.9359e+16, 1.1882e+17,
        1.8062e+17, 1.5457e+17, 6.5834e+16, 2.0433e+17, 1.0324e+17, 1.6388e+17,
        8.1577e+16, 1.5038e+17, 1.2664e+17, 7.1465e+16, 2.0370e+17, 1.4017e+17,
        1.0618e+17, 1.3346e+17, 1.4396e+17, 2.0258e+17])
Layer: encoder.4.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([9.4338e+15, 5.0513e+15, 7.7645e+14, 3.6613e+15, 8.9629e+14, 2.9748e+15,
        1.6392e+15, 4.4490e+15, 1.3197e+14, 1.2322e+15, 3.1824e+15, 6.5510e+14,
        5.7766e+14, 3.4778e+15, 5.7864e+14, 5.8090e+14, 1.7809e+15, 1.3077e+15,
        1.6592e+16, 1.4690e+15, 1.0741e+15, 5.0351e+15, 2.7426e+15, 1.3497e+15,
        3.0034e+15, 8.7348e+14, 3.9696e+15, 9.3470e+14, 4.1794e+14, 3.5474e+17,
        2.3654e+15, 2.4369e+14, 9.6958e+13, 7.6727e+14, 5.7096e+15, 3.9589e+15,
        4.6108e+14, 1.8352e+16, 5.5204e+14, 1.6038e+15, 1.0980e+16, 4.7132e+14,
        6.9933e+14, 1.4372e+15, 8.0927e+14, 3.9410e+15, 1.5148e+15, 6.3792e+15,
        5.7081e+15, 2.0983e+15, 2.4509e+15, 3.5501e+16, 3.7668e+14, 5.9268e+14,
        4.8302e+14, 4.6296e+14, 1.1444e+15, 7.5530e+14, 2.0854e+15, 2.3754e+15,
        7.8383e+14, 4.0840e+14, 6.4667e+14, 4.0809e+14, 6.4832e+14, 3.5545e+15,
        7.3787e+14, 9.8862e+15, 6.9590e+15, 9.3536e+15, 3.0911e+15, 1.8761e+16,
        1.7714e+15, 5.4061e+15, 2.0472e+15, 3.8853e+16, 6.5276e+14, 5.0508e+15,
        8.0133e+14, 3.4534e+15, 6.5171e+14, 2.0884e+15, 3.7536e+16, 1.8438e+15,
        7.1975e+14, 4.3922e+15, 1.2778e+15, 2.1114e+15, 1.7537e+15, 6.9665e+15,
        1.7713e+14, 4.3890e+15, 1.0076e+16, 3.1540e+16, 7.9800e+15, 1.3183e+15,
        2.0967e+16, 1.4888e+14, 1.4427e+15, 5.8979e+14, 2.3743e+16, 3.3742e+14,
        2.2110e+15, 5.6902e+15, 8.7418e+16, 3.8936e+14, 1.3037e+16, 4.2386e+16,
        7.3880e+15, 2.0836e+16, 9.1088e+15, 1.8748e+15, 5.7960e+14, 3.3445e+15,
        2.5179e+16, 1.7851e+16, 4.4862e+14, 2.6871e+15, 4.6013e+16, 2.4575e+15,
        8.4361e+14, 8.7469e+14, 2.6080e+15, 1.1839e+15, 2.6997e+14, 1.0387e+16,
        4.3968e+15, 7.2103e+14, 1.7535e+15, 7.1274e+14, 1.2638e+15, 2.0518e+15,
        2.4183e+15, 1.3336e+15, 3.8903e+14, 5.7275e+14, 1.1147e+16, 2.1445e+15,
        8.7120e+14, 5.4900e+15, 1.1256e+15, 6.6901e+14, 1.4872e+15, 1.5773e+15,
        1.2229e+15, 8.3336e+14, 2.7869e+15, 1.1640e+16, 1.0143e+16, 2.1865e+15,
        6.8947e+14, 5.3254e+14, 4.8355e+15, 3.9659e+14, 7.3116e+15, 2.3293e+14,
        1.6976e+15, 8.6818e+15, 1.0088e+15, 6.5877e+15, 1.9737e+16, 1.5131e+15,
        5.7291e+14, 3.5756e+14, 2.1246e+14, 4.6408e+15, 3.1032e+15, 4.6407e+15,
        2.4205e+15, 7.8412e+14, 2.6142e+15, 9.4184e+15, 1.3116e+16, 2.0878e+15,
        1.4683e+15, 4.1472e+14, 1.7588e+15, 1.7283e+15, 1.3519e+15, 1.1827e+14,
        3.1264e+16, 3.7165e+15, 5.7282e+14, 2.7506e+15, 4.1631e+15, 9.6206e+14,
        7.6476e+14, 9.2791e+15, 2.9659e+16, 7.8949e+15, 3.1792e+14, 1.9440e+16,
        4.4729e+15, 1.1922e+16, 1.8332e+15, 1.0518e+15, 7.7551e+14, 2.5697e+15,
        4.6367e+14, 1.8182e+14, 2.4070e+14, 2.1617e+15, 1.3017e+16, 1.3221e+15,
        1.4788e+15, 1.3079e+15, 1.9774e+15, 2.9419e+14, 3.6681e+15, 4.9075e+15,
        1.2985e+15, 5.4929e+16, 2.2170e+15, 9.1412e+15, 6.4144e+15, 3.0167e+14,
        1.6391e+15, 8.0855e+15, 6.4512e+14, 8.7764e+15, 1.1721e+15, 6.1227e+14,
        3.5075e+15, 1.4522e+16, 2.6132e+14, 1.6240e+14, 9.2170e+15, 1.0837e+15,
        3.2361e+14, 4.9778e+16, 6.5034e+14, 1.0228e+15, 7.5646e+15, 9.5357e+14,
        1.5307e+15, 1.1755e+15, 1.5324e+15, 2.4257e+14, 3.0264e+14, 4.4139e+14,
        2.7517e+15, 7.4458e+14, 2.2181e+14, 1.3539e+15, 1.3223e+15, 7.3249e+14,
        4.5066e+14, 3.1170e+14, 2.4419e+15, 1.9904e+16, 1.8096e+14, 1.5278e+16,
        8.1972e+14, 6.8023e+14, 7.3598e+14, 5.7358e+16])
Layer: encoder.4.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.0516e+15, 4.5802e+15, 2.8126e+15, 3.3324e+15, 7.0625e+14, 1.3474e+15,
        1.8557e+15, 5.3565e+15, 1.5614e+15, 1.2009e+15, 1.3774e+15, 1.0008e+15,
        1.2671e+15, 1.5885e+15, 1.8063e+15, 1.2220e+15, 4.1529e+14, 1.5395e+15,
        1.7565e+16, 1.4673e+15, 7.1745e+14, 6.2302e+15, 4.2942e+15, 8.6039e+14,
        2.0805e+15, 2.8220e+15, 4.8179e+15, 1.1628e+15, 1.8697e+15, 3.5645e+17,
        2.9939e+15, 1.8093e+15, 9.5912e+14, 2.1438e+15, 6.3679e+15, 6.8089e+15,
        6.1745e+14, 1.8672e+16, 1.5909e+15, 3.1483e+15, 1.1350e+16, 2.4071e+15,
        2.6756e+15, 3.2808e+15, 6.8601e+14, 5.4919e+15, 2.9484e+15, 4.6139e+15,
        5.4736e+15, 1.0384e+15, 1.7677e+15, 3.5830e+16, 1.6086e+15, 2.7706e+15,
        8.9101e+14, 1.1166e+15, 1.1181e+15, 1.6651e+15, 1.4473e+15, 3.7329e+15,
        2.9633e+15, 1.0184e+15, 8.9108e+14, 1.0532e+15, 1.1006e+15, 4.2364e+15,
        2.7478e+15, 1.0025e+16, 7.1166e+15, 1.0439e+16, 2.1657e+15, 1.8494e+16,
        2.8104e+15, 6.6284e+15, 4.7288e+14, 3.9837e+16, 7.1499e+14, 4.8703e+15,
        1.4877e+15, 2.4866e+15, 8.9279e+14, 4.1640e+15, 3.8253e+16, 8.5050e+15,
        1.0782e+15, 6.0157e+15, 1.0940e+15, 3.7430e+15, 2.3664e+15, 7.7241e+15,
        2.4813e+15, 7.1544e+15, 9.2280e+15, 3.0747e+16, 8.6032e+15, 2.9087e+15,
        2.1385e+16, 1.4679e+15, 2.8965e+15, 1.0229e+15, 2.3136e+16, 8.8294e+14,
        7.9040e+15, 5.6978e+15, 8.7387e+16, 4.6635e+14, 1.4082e+16, 4.2063e+16,
        5.3818e+15, 2.0064e+16, 9.6355e+15, 8.4036e+14, 2.0462e+15, 3.8364e+15,
        2.5007e+16, 1.9643e+16, 2.1217e+15, 3.0849e+15, 4.6277e+16, 2.9419e+15,
        1.7293e+15, 8.4606e+14, 8.6319e+14, 1.1521e+15, 8.1580e+14, 1.0361e+16,
        4.0898e+15, 7.2888e+14, 1.4582e+15, 1.9283e+15, 1.3738e+15, 4.0668e+14,
        1.7408e+15, 1.1183e+15, 2.3544e+15, 8.7428e+14, 9.1314e+15, 1.3828e+15,
        3.3350e+14, 5.6487e+15, 3.3257e+15, 5.7233e+14, 7.0820e+14, 5.4481e+14,
        2.6216e+15, 1.4640e+15, 1.6058e+15, 1.0020e+16, 9.3756e+15, 3.8892e+15,
        7.6903e+14, 1.9884e+15, 3.9482e+15, 1.8765e+15, 7.2274e+15, 1.8564e+15,
        4.6635e+14, 9.7744e+15, 1.8950e+15, 7.2316e+15, 2.0111e+16, 1.8496e+15,
        8.2125e+14, 1.7907e+15, 6.9372e+14, 4.4015e+15, 3.8752e+15, 4.7574e+15,
        2.5581e+15, 1.3160e+15, 2.3079e+15, 1.0063e+16, 1.3436e+16, 2.6940e+15,
        1.3093e+15, 2.8470e+15, 1.8040e+15, 9.0041e+14, 8.4347e+14, 1.8470e+15,
        3.1334e+16, 1.8567e+15, 1.3658e+15, 2.5654e+15, 5.5634e+15, 1.3909e+15,
        1.0303e+15, 7.6045e+15, 3.0584e+16, 6.7272e+15, 9.2909e+14, 1.9581e+16,
        4.4307e+15, 9.7810e+15, 2.2621e+15, 1.0297e+15, 6.3787e+14, 2.4571e+15,
        6.6105e+14, 8.2389e+14, 9.3491e+14, 2.5143e+15, 1.1665e+16, 2.5581e+15,
        1.7486e+15, 7.8707e+14, 1.7892e+15, 1.7058e+15, 2.6243e+15, 5.8001e+15,
        4.9115e+14, 5.4696e+16, 1.3536e+15, 1.0115e+16, 7.3972e+15, 1.2900e+15,
        2.6859e+15, 9.1692e+15, 1.0660e+15, 8.9651e+15, 2.9194e+15, 9.0611e+14,
        5.5040e+15, 1.4650e+16, 1.9800e+15, 1.3145e+15, 7.4467e+15, 1.0489e+15,
        1.4465e+15, 5.0163e+16, 1.9158e+15, 1.6734e+15, 7.4587e+15, 1.4802e+15,
        6.9293e+15, 1.4311e+15, 2.2311e+15, 1.6029e+15, 1.5806e+15, 1.4145e+15,
        2.1147e+15, 2.3039e+15, 1.0165e+15, 3.0536e+14, 2.2001e+14, 7.4341e+14,
        1.4097e+15, 1.9399e+15, 1.4429e+15, 1.9947e+16, 2.7683e+15, 1.6114e+16,
        1.3484e+15, 2.0804e+15, 6.1091e+14, 5.8674e+16])
Layer: encoder.4.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.7110e+15, 2.1050e+15, 3.9534e+15, 4.6661e+15, 4.3454e+15, 3.3204e+15,
        5.0878e+15, 1.7778e+15, 3.9312e+15, 3.7396e+15, 3.4047e+15, 2.0479e+15,
        2.2492e+15, 2.1289e+15, 1.8827e+15, 5.9503e+15, 3.0736e+15, 2.9285e+15,
        3.4123e+15, 3.1666e+15, 3.7628e+15, 2.7896e+15, 3.8356e+15, 2.5172e+15,
        2.9938e+15, 2.5904e+15, 3.3418e+15, 3.1718e+15, 2.6157e+15, 2.4334e+15,
        2.4324e+15, 3.4134e+15, 1.7273e+15, 2.9240e+15, 2.3222e+15, 3.6438e+15,
        4.7595e+15, 2.3626e+15, 2.5639e+15, 2.1184e+15, 3.3096e+15, 2.4922e+15,
        3.0259e+15, 1.6748e+15, 3.5901e+15, 3.0191e+15, 2.4177e+15, 1.7429e+15,
        3.9865e+15, 3.9066e+15, 2.1046e+15, 3.0476e+15, 3.7109e+15, 3.3730e+15,
        4.9789e+15, 1.6463e+15, 2.4781e+15, 2.5578e+15, 3.6242e+15, 2.1730e+15,
        2.1592e+15, 3.0570e+15, 3.1009e+15, 3.4570e+15])
Layer: encoder.4.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.5944e+15, 4.2550e+15, 3.6323e+15, 3.1178e+15, 3.7348e+15, 2.7748e+15,
        3.3902e+15, 2.6858e+15, 4.1855e+15, 3.3250e+15, 4.0931e+15, 4.0816e+15,
        2.5506e+15, 4.3544e+15, 3.8259e+15, 2.8545e+15, 2.7540e+15, 3.3261e+15,
        2.9473e+15, 2.4298e+15, 3.4797e+15, 3.9366e+15, 4.9937e+15, 3.3430e+15,
        4.7011e+15, 4.5359e+15, 3.9700e+15, 4.7847e+15, 3.1033e+15, 2.3150e+15,
        5.9800e+15, 4.2089e+15, 3.2341e+15, 3.2898e+15, 4.4166e+15, 3.7605e+15,
        4.6192e+15, 2.7329e+15, 1.9430e+15, 3.1669e+15, 3.3147e+15, 3.9859e+15,
        5.5851e+15, 4.6660e+15, 3.3177e+15, 2.5533e+15, 3.9921e+15, 1.7285e+15,
        4.7554e+15, 3.1372e+15, 2.8863e+15, 3.7150e+15, 2.4211e+15, 3.6603e+15,
        2.1116e+15, 3.0015e+15, 2.8366e+15, 3.2733e+15, 4.3388e+15, 2.7007e+15,
        4.6368e+15, 1.7359e+15, 2.6608e+15, 2.8179e+15])
Layer: encoder.4.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([9.9006e+13, 3.4135e+14, 6.3951e+13, 4.6152e+14, 1.0411e+14, 2.4365e+14,
        8.2349e+14, 4.3422e+14, 1.6431e+14, 7.1700e+13, 1.6930e+14, 2.3494e+13,
        2.5013e+13, 9.4900e+14, 1.7136e+14, 1.8553e+14, 1.0280e+14, 2.2744e+13,
        1.4481e+14, 1.0435e+14, 5.0488e+13, 1.4752e+14, 1.3248e+15, 1.4982e+14,
        1.1999e+14, 1.7812e+14, 8.5071e+13, 5.0001e+13, 1.2378e+14, 5.9976e+13,
        5.4665e+13, 1.9660e+14, 1.4432e+14, 1.2285e+15, 2.6937e+14, 7.2703e+14,
        1.8514e+14, 1.6843e+14, 2.5303e+13, 5.4210e+14, 2.1645e+14, 2.7015e+13,
        6.4481e+14, 1.2616e+14, 1.6990e+14, 5.2918e+13, 1.0333e+14, 2.5529e+14,
        2.5010e+14, 1.0622e+14, 2.3769e+14, 4.4169e+14, 1.5205e+14, 5.6386e+13,
        3.6705e+13, 9.4457e+12, 5.7832e+13, 4.1897e+13, 1.3757e+14, 8.5643e+14,
        1.6375e+14, 6.1406e+13, 5.8163e+14, 3.9574e+13, 1.1763e+13, 1.4828e+14,
        3.7439e+13, 6.7426e+14, 1.0366e+14, 6.5114e+13, 6.8194e+13, 9.0876e+13,
        8.6728e+13, 1.6433e+14, 4.6463e+14, 1.0276e+14, 9.3057e+12, 2.1447e+14,
        6.6423e+13, 4.4256e+14, 2.7390e+14, 1.4017e+14, 4.3639e+14, 5.6371e+15,
        2.5478e+13, 8.4786e+14, 1.3520e+14, 1.1088e+14, 2.7336e+14, 4.5058e+13,
        1.3968e+13, 1.0450e+15, 2.7458e+14, 2.3616e+14, 1.0114e+14, 9.9376e+14,
        1.1205e+14, 8.6007e+13, 6.4760e+14, 2.4777e+13, 5.5872e+14, 7.5206e+13,
        3.4956e+15, 1.8156e+14, 1.2831e+14, 1.1609e+13, 1.2073e+14, 1.1088e+14,
        1.2479e+14, 1.6589e+14, 1.0615e+14, 6.6945e+13, 9.7582e+13, 1.1805e+14,
        1.3497e+14, 1.6906e+14, 1.1952e+14, 5.4681e+13, 1.3477e+14, 1.1368e+14,
        1.9495e+13, 2.0290e+13, 1.4637e+14, 1.1708e+14, 1.1198e+14, 5.7852e+14,
        9.5054e+13, 1.8027e+13, 6.7230e+14, 1.6827e+14, 1.5736e+13, 4.1481e+13,
        1.2236e+14, 5.3545e+13, 1.1638e+14, 8.6694e+12, 1.4790e+14, 1.8533e+14,
        9.0267e+13, 2.2635e+14, 2.4813e+15, 1.5193e+14, 1.7590e+14, 6.7912e+14,
        4.5263e+14, 7.3372e+13, 6.4556e+13, 6.2619e+14, 1.1967e+14, 6.3035e+13,
        7.6503e+13, 9.9506e+13, 1.3219e+14, 1.3307e+14, 5.0461e+14, 2.7670e+13,
        5.1034e+13, 2.5162e+14, 1.8768e+14, 1.3283e+14, 6.3174e+13, 1.0978e+14,
        2.7756e+13, 1.3621e+14, 1.4021e+14, 1.6677e+14, 1.3363e+14, 1.3597e+14,
        1.0729e+14, 1.3806e+14, 4.8430e+14, 1.2262e+14, 9.6183e+14, 7.3508e+13,
        1.1781e+14, 4.0006e+13, 1.0945e+14, 1.1888e+14, 1.7383e+14, 1.3439e+14,
        8.7516e+13, 8.4032e+13, 1.7197e+14, 3.7739e+13, 1.4243e+14, 5.7573e+13,
        4.8852e+13, 3.7010e+14, 7.3815e+13, 1.2485e+14, 1.4691e+14, 1.2283e+14,
        8.3398e+13, 3.6707e+14, 7.6921e+13, 1.2391e+14, 1.2438e+14, 6.6718e+14,
        2.9059e+14, 1.6114e+14, 2.1358e+13, 8.9365e+13, 2.5597e+14, 1.5528e+14,
        9.3808e+13, 1.7977e+14, 2.8355e+14, 1.2360e+14, 1.4824e+14, 2.2783e+14,
        7.0713e+13, 2.3547e+14, 2.2638e+14, 1.6140e+14, 7.9789e+13, 3.3866e+13,
        1.7375e+14, 1.6688e+14, 1.6111e+14, 1.5366e+14, 6.1931e+13, 1.5434e+14,
        9.7516e+14, 1.7307e+14, 1.6201e+13, 1.0053e+13, 1.1451e+14, 2.7643e+13,
        1.9647e+13, 3.5467e+14, 9.4409e+14, 1.1562e+14, 4.6270e+14, 1.7620e+14,
        4.0288e+15, 3.9616e+14, 4.9501e+13, 1.6691e+14, 1.9274e+14, 3.9765e+13,
        1.7859e+14, 1.7884e+13, 1.0002e+14, 2.1331e+14, 3.1599e+13, 3.0062e+14,
        9.8721e+13, 6.0798e+13, 7.8080e+13, 2.1487e+14, 6.1940e+13, 1.4057e+14,
        6.4004e+13, 2.4005e+14, 1.1790e+14, 6.0978e+14])
Layer: encoder.4.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.9143e+14, 5.0238e+14, 2.9805e+14, 3.2179e+14, 2.4645e+14, 3.8616e+14,
        3.5478e+14, 2.0844e+14, 1.8965e+14, 1.9198e+14, 1.9807e+14, 3.7702e+14,
        2.0715e+14, 4.2776e+14, 1.3489e+14, 2.7839e+14, 2.7150e+14, 1.9858e+14,
        5.3286e+14, 2.6535e+14, 1.5240e+14, 1.4818e+14, 2.3918e+14, 4.8780e+14,
        3.4921e+14, 2.0488e+14, 3.6651e+14, 1.8876e+14, 2.6584e+14, 2.6942e+14,
        3.5262e+14, 2.9103e+14, 3.2937e+14, 1.9005e+14, 2.7592e+14, 1.8759e+14,
        3.3424e+14, 2.9970e+14, 3.2789e+14, 2.8929e+14, 2.3021e+14, 2.8366e+14,
        3.2946e+14, 1.7252e+14, 3.3964e+14, 3.0661e+14, 3.1921e+14, 2.2205e+14,
        2.1401e+14, 1.4843e+14, 2.5848e+14, 3.5287e+14, 1.9510e+14, 3.1477e+14,
        1.6256e+14, 1.7276e+14, 2.8715e+14, 3.2977e+14, 1.9867e+14, 1.8698e+14,
        2.4390e+14, 2.6817e+14, 4.0878e+14, 1.6105e+14])
Layer: encoder.4.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.2545e+14, 3.4613e+14, 2.5789e+14, 4.0687e+14, 3.5978e+14, 3.6840e+14,
        2.6052e+14, 4.1995e+14, 2.5502e+14, 3.9208e+14, 1.6001e+14, 2.2031e+14,
        3.2375e+14, 3.5271e+14, 2.8378e+14, 5.1799e+14, 2.1310e+14, 2.6847e+14,
        3.5318e+14, 1.7215e+14, 4.0434e+14, 3.6232e+14, 2.8262e+14, 2.2550e+14,
        2.8329e+14, 1.6113e+14, 4.5454e+14, 3.2630e+14, 4.8311e+14, 4.0801e+14,
        4.2289e+14, 3.5206e+14, 3.2579e+14, 1.8927e+14, 3.6245e+14, 2.7136e+14,
        2.9375e+14, 2.8393e+14, 3.2713e+14, 2.7469e+14, 2.1623e+14, 2.5051e+14,
        2.5730e+14, 2.5497e+14, 1.8082e+14, 2.9528e+14, 4.6310e+14, 2.7008e+14,
        2.0793e+14, 2.3677e+14, 2.9553e+14, 3.4429e+14, 4.7176e+14, 4.2364e+14,
        3.6753e+14, 4.8560e+14, 4.6250e+14, 3.9211e+14, 4.1215e+14, 2.3026e+14,
        2.4397e+14, 2.7612e+14, 3.0279e+14, 2.6936e+14])
Layer: encoder.4.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([9.2525e+12, 6.5323e+12, 4.0877e+11, 4.8841e+14, 6.1429e+12, 9.1636e+12,
        4.3395e+12, 5.3164e+12, 2.4255e+13, 6.6203e+12, 9.1989e+12, 2.7465e+12,
        2.2408e+12, 2.4014e+13, 3.4998e+13, 6.5135e+12, 1.2203e+13, 7.1968e+11,
        3.9423e+13, 8.5435e+12, 1.9850e+12, 1.2803e+12, 1.8000e+13, 1.1281e+13,
        2.4159e+12, 8.2218e+12, 4.8545e+12, 1.1633e+13, 7.5394e+12, 2.3020e+12,
        9.4885e+11, 3.3598e+12, 1.1609e+13, 3.1054e+12, 3.4606e+12, 1.3343e+13,
        4.1217e+12, 1.4029e+13, 1.4447e+13, 3.6303e+13, 6.1899e+12, 2.2601e+12,
        5.1909e+14, 9.8669e+12, 1.1525e+13, 7.6548e+11, 9.9622e+12, 1.1872e+14,
        1.2322e+14, 3.3257e+13, 1.7534e+14, 1.0416e+13, 1.5824e+12, 4.5964e+12,
        1.9423e+12, 6.5036e+11, 1.1177e+12, 1.7517e+12, 1.0871e+13, 7.5791e+12,
        1.2112e+14, 8.8000e+13, 1.1638e+14, 3.8460e+12, 6.3795e+11, 5.4952e+12,
        2.6154e+12, 4.0626e+12, 1.1405e+13, 1.5079e+12, 8.1449e+12, 5.0769e+12,
        6.7811e+12, 1.4322e+13, 3.3990e+12, 8.5364e+12, 3.0951e+12, 6.5996e+12,
        3.2196e+12, 6.2046e+12, 8.7721e+13, 4.1373e+12, 1.1133e+13, 5.8704e+12,
        2.8848e+12, 3.4658e+12, 3.0256e+13, 3.4137e+13, 4.6486e+13, 3.0325e+12,
        4.4334e+11, 6.6711e+12, 1.0489e+14, 4.5500e+12, 3.1188e+13, 6.4617e+13,
        2.3486e+12, 7.1476e+12, 4.5356e+12, 8.9910e+11, 5.3145e+12, 5.6954e+12,
        5.1092e+12, 1.4096e+13, 7.1854e+12, 4.6614e+11, 1.9554e+13, 3.1537e+12,
        5.5128e+13, 1.7264e+13, 2.1046e+12, 9.0828e+12, 3.2529e+12, 3.9656e+13,
        1.6836e+13, 3.9276e+13, 7.2865e+12, 3.0544e+12, 4.9159e+13, 4.4452e+12,
        4.0762e+12, 1.8675e+12, 4.9112e+12, 4.8477e+12, 9.8063e+12, 2.5511e+13,
        9.5735e+12, 1.0123e+12, 8.3678e+12, 7.0195e+12, 1.1154e+12, 2.1224e+13,
        2.0060e+12, 1.4206e+12, 9.8687e+12, 1.2725e+13, 1.5914e+13, 5.6601e+12,
        7.9884e+12, 7.2116e+12, 1.1985e+13, 5.0470e+12, 2.2168e+12, 3.2556e+12,
        1.1999e+13, 1.2668e+13, 4.4427e+13, 5.4600e+13, 2.3691e+13, 3.7753e+12,
        2.9805e+13, 4.2479e+12, 6.3114e+12, 2.8899e+13, 1.8476e+13, 1.3644e+12,
        1.4062e+12, 5.5799e+12, 1.4394e+14, 3.2741e+12, 2.0133e+12, 3.7124e+12,
        4.5809e+11, 8.1755e+12, 1.1019e+13, 2.7419e+12, 3.6853e+12, 8.9671e+12,
        7.9384e+12, 9.5563e+12, 1.0261e+13, 6.3180e+12, 5.7210e+12, 2.8411e+13,
        8.3337e+12, 9.3094e+13, 4.0433e+12, 7.4992e+12, 3.6448e+13, 3.7639e+12,
        5.8358e+12, 3.0065e+13, 4.8992e+13, 7.4877e+12, 6.0204e+12, 4.7803e+13,
        3.2229e+11, 9.4060e+12, 5.1513e+13, 2.0013e+13, 5.3392e+13, 1.1314e+13,
        9.8531e+12, 2.8146e+12, 2.9378e+13, 7.3092e+12, 3.2478e+12, 1.2724e+13,
        1.4996e+14, 9.5538e+12, 7.3344e+11, 1.9414e+12, 1.5070e+13, 2.9464e+13,
        9.8543e+12, 8.0143e+13, 7.6402e+12, 7.7556e+12, 6.0763e+13, 1.4660e+13,
        6.6178e+12, 1.7190e+13, 5.3609e+12, 2.4181e+13, 2.1388e+12, 4.0052e+12,
        1.2279e+13, 3.1429e+13, 2.3802e+13, 4.3266e+12, 6.0480e+12, 8.7383e+12,
        6.5360e+12, 7.6462e+12, 8.6067e+11, 1.0262e+12, 1.0056e+13, 2.0313e+13,
        1.9854e+12, 4.0798e+12, 1.8153e+13, 4.6944e+12, 6.3314e+12, 5.8309e+12,
        2.7289e+13, 1.5513e+12, 8.6802e+12, 5.7882e+12, 6.4875e+12, 1.7061e+12,
        1.6068e+13, 1.4299e+13, 5.3557e+13, 1.5789e+13, 6.9829e+11, 4.5181e+13,
        5.0601e+12, 1.8508e+12, 5.4706e+12, 3.8023e+13, 7.6684e+12, 6.2606e+12,
        9.1625e+12, 9.5189e+12, 2.0527e+13, 1.2503e+13])
Layer: encoder.5.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.0907e+12, 7.1712e+12, 1.4573e+13, 9.4152e+12, 6.0280e+12, 7.5060e+12,
        5.9160e+12, 1.3416e+13, 9.7128e+12, 1.2122e+13, 1.0518e+13, 8.4211e+12,
        7.5239e+12, 1.1194e+13, 7.3658e+12, 1.0913e+13, 8.9030e+12, 1.3187e+13,
        1.5635e+13, 1.1857e+13, 1.0901e+13, 1.2470e+13, 1.1650e+13, 8.9425e+12,
        1.2628e+13, 8.2402e+12, 8.1221e+12, 1.1972e+13, 1.2542e+13, 9.5383e+12,
        6.3939e+12, 1.4263e+13, 1.1698e+13, 1.1717e+13, 1.1462e+13, 1.4516e+13,
        6.2490e+12, 8.9125e+12, 6.8753e+12, 6.2541e+12, 8.6385e+12, 9.4527e+12,
        1.1258e+13, 7.7123e+12, 1.1564e+13, 8.7197e+12, 1.0426e+13, 1.3123e+13,
        8.4259e+12, 1.1442e+13, 7.4350e+12, 8.8229e+12, 8.0754e+12, 7.6109e+12,
        7.8952e+12, 1.4330e+13, 9.4981e+12, 1.0330e+13, 7.9831e+12, 9.6047e+12,
        9.6623e+12, 7.5727e+12, 1.2470e+13, 1.0559e+13, 1.1845e+13, 7.9117e+12,
        9.8052e+12, 7.6057e+12, 1.2702e+13, 9.2305e+12, 7.5577e+12, 8.5209e+12,
        7.7090e+12, 8.4364e+12, 6.0449e+12, 5.8394e+12, 1.6135e+13, 9.9106e+12,
        8.4939e+12, 8.3996e+12, 6.6914e+12, 7.7488e+12, 8.5555e+12, 8.1258e+12,
        7.6418e+12, 1.2372e+13, 8.3665e+12, 1.0594e+13, 9.9984e+12, 1.2439e+13,
        1.3640e+13, 7.1110e+12, 7.5139e+12, 8.9855e+12, 7.8475e+12, 6.6859e+12,
        9.3023e+12, 1.0148e+13, 1.0955e+13, 6.4568e+12, 8.3727e+12, 1.4010e+13,
        1.1714e+13, 7.6632e+12, 5.1159e+12, 7.4046e+12, 6.7826e+12, 1.0097e+13,
        9.7373e+12, 6.1656e+12, 9.2188e+12, 1.1327e+13, 8.0122e+12, 9.8945e+12,
        6.8340e+12, 8.6563e+12, 8.8466e+12, 1.2495e+13, 1.2483e+13, 1.0002e+13,
        5.9399e+12, 8.4048e+12, 7.1607e+12, 1.1570e+13, 8.1289e+12, 1.2467e+13,
        7.2579e+12, 1.0883e+13])
Layer: encoder.5.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.5760e+13, 1.6962e+13, 1.9297e+13, 1.4644e+13, 1.1552e+13, 1.3472e+13,
        8.6731e+12, 9.4986e+12, 9.2173e+12, 1.3250e+13, 1.8383e+13, 9.2370e+12,
        1.3607e+13, 1.2479e+13, 8.4834e+12, 2.1489e+13, 1.3899e+13, 1.7576e+13,
        9.3800e+12, 9.4157e+12, 9.8194e+12, 1.1034e+13, 1.5322e+13, 1.1301e+13,
        1.2982e+13, 1.2509e+13, 8.1260e+12, 1.1049e+13, 1.0388e+13, 1.1907e+13,
        1.0683e+13, 1.2969e+13, 9.0920e+12, 8.2876e+12, 9.4903e+12, 1.1953e+13,
        1.7072e+13, 1.4048e+13, 1.0597e+13, 1.4645e+13, 1.2563e+13, 1.1711e+13,
        9.4844e+12, 1.3670e+13, 1.3686e+13, 1.9010e+13, 1.4494e+13, 1.1083e+13,
        1.3553e+13, 1.5159e+13, 1.0821e+13, 7.4929e+12, 1.0907e+13, 1.3202e+13,
        1.5791e+13, 1.3375e+13, 1.1268e+13, 1.9921e+13, 1.4278e+13, 1.0165e+13,
        1.6457e+13, 1.2737e+13, 1.0997e+13, 1.5546e+13, 1.2632e+13, 1.5918e+13,
        1.7244e+13, 1.4767e+13, 9.1345e+12, 1.3688e+13, 1.0326e+13, 1.4504e+13,
        1.3164e+13, 9.3284e+12, 1.1906e+13, 1.0616e+13, 1.5754e+13, 1.4088e+13,
        1.4341e+13, 9.1889e+12, 1.3470e+13, 1.6089e+13, 1.2631e+13, 1.6793e+13,
        1.6916e+13, 8.8926e+12, 1.2156e+13, 1.0781e+13, 1.3620e+13, 1.2400e+13,
        1.5818e+13, 1.4352e+13, 9.1368e+12, 1.7324e+13, 1.3626e+13, 9.5242e+12,
        1.3980e+13, 1.5463e+13, 9.7396e+12, 8.1321e+12, 1.5805e+13, 1.6446e+13,
        1.3688e+13, 1.2099e+13, 1.4586e+13, 1.3050e+13, 1.1122e+13, 1.5946e+13,
        1.8034e+13, 1.2039e+13, 1.4873e+13, 1.1649e+13, 1.0452e+13, 1.3999e+13,
        1.0861e+13, 1.0878e+13, 1.4276e+13, 8.7625e+12, 1.4879e+13, 1.1152e+13,
        1.2601e+13, 1.6175e+13, 1.9824e+13, 1.2682e+13, 1.4721e+13, 1.1952e+13,
        1.4601e+13, 1.5585e+13])
Layer: encoder.5.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.8128e+11, 4.7143e+12, 1.0470e+12, 1.2588e+11, 2.2890e+12, 4.8435e+12,
        9.4787e+10, 1.1196e+12, 7.9956e+11, 4.8947e+10, 1.4923e+11, 8.8998e+10,
        2.1868e+11, 2.3329e+11, 3.9074e+11, 9.4765e+11, 2.0458e+11, 3.9353e+11,
        5.6993e+11, 2.7199e+11, 4.8661e+10, 9.8338e+10, 7.8859e+11, 5.8704e+10,
        7.5466e+11, 1.8936e+11, 6.6468e+10, 9.6981e+11, 3.3267e+12, 4.7116e+10,
        3.8933e+11, 1.8979e+11, 3.0856e+11, 2.9688e+11, 3.2270e+10, 9.9117e+11,
        4.2263e+11, 1.5641e+11, 4.4676e+10, 2.2934e+11, 5.7865e+11, 3.2097e+12,
        5.3365e+10, 8.3096e+11, 8.3202e+10, 3.1365e+12, 2.0095e+10, 2.2706e+11,
        7.4977e+10, 5.9548e+10, 4.2458e+11, 2.3876e+11, 1.6552e+11, 1.0022e+12,
        2.2899e+12, 9.6829e+11, 3.3761e+11, 1.9573e+11, 1.2261e+12, 3.2139e+10,
        7.9698e+11, 3.8774e+11, 4.5801e+11, 1.3120e+12, 8.4230e+10, 2.3881e+11,
        4.6334e+11, 8.5070e+11, 9.8523e+11, 3.8238e+11, 6.3486e+11, 7.3532e+11,
        6.4151e+10, 5.8346e+10, 2.7214e+10, 7.0099e+10, 5.6352e+11, 5.8430e+10,
        4.5188e+10, 6.5601e+11, 9.2829e+10, 1.7357e+11, 1.6814e+11, 1.0840e+11,
        5.8737e+11, 9.3739e+10, 2.6682e+11, 9.6161e+11, 2.0540e+11, 2.0653e+11,
        4.2550e+11, 7.4202e+10, 3.5402e+10, 3.1446e+11, 9.0116e+11, 2.2394e+11,
        6.5959e+10, 1.2415e+11, 7.7738e+10, 3.8187e+12, 4.6829e+10, 1.8645e+11,
        4.4815e+11, 1.4795e+11, 2.5855e+11, 2.3532e+11, 9.7105e+11, 1.6120e+11,
        1.1611e+12, 3.9402e+11, 5.6922e+10, 1.1015e+11, 4.5388e+11, 1.3509e+11,
        1.7740e+11, 4.8544e+10, 2.5929e+10, 6.8147e+10, 7.6032e+11, 6.8280e+11,
        2.9544e+10, 2.4309e+11, 4.1413e+11, 7.3337e+11, 4.6625e+11, 3.8238e+11,
        1.3577e+12, 2.6488e+11, 7.0754e+10, 8.4807e+10, 4.5476e+11, 1.2390e+11,
        9.1638e+10, 2.0456e+11, 1.2208e+12, 1.9923e+11, 5.8018e+11, 2.6967e+12,
        1.3127e+11, 1.4252e+12, 3.5118e+10, 1.7177e+11, 1.9941e+11, 8.2262e+10,
        8.0215e+11, 2.4018e+13, 3.8100e+11, 1.0449e+12, 6.0930e+11, 7.7279e+10,
        3.8733e+11, 1.3296e+11, 1.2347e+12, 9.9742e+10, 6.5451e+10, 2.8875e+11,
        1.7240e+12, 7.9071e+10, 8.2500e+12, 8.2186e+10, 2.1862e+11, 2.0561e+12,
        6.7952e+10, 4.2684e+10, 1.3202e+11, 2.4626e+10, 5.9075e+10, 4.0329e+11,
        3.6532e+11, 4.7876e+10, 3.0730e+11, 1.3070e+11, 5.9725e+10, 9.1012e+11,
        6.6295e+11, 4.1291e+11, 7.4390e+10, 2.9833e+10, 1.5193e+11, 1.9478e+11,
        4.9331e+10, 3.1782e+11, 1.2794e+11, 2.1968e+12, 6.7111e+10, 1.0130e+11,
        1.2119e+12, 9.2835e+10, 1.0649e+11, 1.0463e+12, 5.7733e+11, 1.5662e+11,
        4.2663e+10, 1.8699e+11, 1.6015e+11, 3.6895e+11, 2.0207e+10, 1.9684e+11,
        1.5064e+12, 3.6714e+11, 2.4478e+12, 3.9209e+10, 5.2559e+10, 1.0411e+11,
        5.2396e+10, 1.2824e+11, 1.4861e+12, 5.0554e+11, 6.2964e+10, 3.3274e+10,
        7.7967e+10, 1.8141e+11, 6.6510e+11, 3.3201e+10, 1.0496e+11, 5.2521e+11,
        8.3665e+11, 4.8467e+10, 3.6956e+11, 3.0504e+10, 9.3921e+10, 7.3856e+10,
        4.5776e+10, 3.3353e+10, 1.0718e+11, 3.0094e+10, 1.1115e+12, 4.6491e+10,
        1.5147e+11, 1.5457e+12, 7.4478e+11, 1.0087e+11, 2.5652e+11, 2.4062e+12,
        1.0172e+11, 7.6519e+11, 7.7389e+10, 8.9873e+10, 1.7112e+11, 1.1722e+11,
        2.7114e+12, 1.5122e+12, 1.2561e+12, 2.2273e+11, 3.0721e+12, 3.5692e+11,
        1.1592e+11, 1.9785e+11, 3.5964e+11, 3.0827e+11, 1.5734e+12, 9.9180e+11,
        2.7830e+11, 3.5014e+10, 1.6979e+12, 1.1455e+12, 3.7394e+11, 4.3526e+12,
        6.7168e+11, 2.0411e+11, 5.7555e+10, 7.2062e+12, 1.3963e+12, 9.1245e+11,
        3.2381e+11, 2.0085e+11, 5.0488e+10, 6.3365e+11, 1.2122e+11, 2.1713e+11,
        1.0093e+12, 5.0293e+11, 5.8278e+11, 4.7233e+11, 1.6501e+11, 5.3558e+10,
        1.1229e+11, 2.0959e+11, 1.6063e+12, 1.4911e+11, 1.4596e+12, 3.8947e+11,
        1.7550e+11, 3.1667e+11, 9.6217e+10, 3.0933e+12, 1.2502e+11, 1.6471e+12,
        2.6873e+12, 5.8696e+10, 4.2306e+11, 5.1729e+11, 2.6772e+11, 2.6163e+10,
        5.7933e+10, 1.1971e+12, 4.4708e+10, 9.8294e+11, 6.8137e+10, 1.9421e+10,
        3.8577e+11, 2.4736e+11, 6.0677e+11, 5.7445e+10, 4.9816e+11, 6.0521e+11,
        1.0730e+11, 3.2757e+11, 7.0155e+10, 6.3938e+11, 6.7803e+10, 2.3892e+10,
        5.0666e+11, 9.1883e+11, 9.8842e+10, 9.5841e+11, 7.4673e+10, 6.3111e+11,
        5.8044e+11, 8.5341e+11, 1.0997e+11, 1.4818e+11, 5.4767e+11, 2.3346e+10,
        1.3932e+11, 1.6088e+11, 1.4920e+11, 5.3838e+10, 1.1315e+11, 8.5431e+10,
        2.2475e+11, 2.4675e+11, 8.6492e+11, 6.4773e+11, 1.0692e+12, 3.1489e+11,
        1.1021e+12, 9.4749e+11, 2.7872e+10, 1.2517e+11, 9.3865e+11, 9.2861e+11,
        6.6440e+11, 5.3605e+11, 1.0383e+11, 1.6800e+11, 1.1088e+12, 9.2837e+10,
        4.6508e+11, 4.3697e+11, 4.0336e+11, 7.1898e+11, 9.3039e+11, 9.5334e+10,
        3.9721e+11, 5.6194e+11, 6.0647e+10, 2.7605e+11, 2.2336e+12, 1.1428e+12,
        4.6331e+10, 6.1488e+10, 2.2266e+11, 4.1509e+11, 1.1956e+11, 1.8187e+11,
        1.6157e+11, 1.3297e+12, 4.2491e+11, 1.2534e+11, 5.0174e+10, 1.3176e+11,
        3.6081e+11, 2.4044e+11, 1.0780e+11, 2.4374e+11, 9.4867e+11, 6.3119e+10,
        1.4557e+11, 6.4295e+10, 2.5881e+12, 5.8206e+11, 1.5113e+11, 4.5949e+12,
        8.1733e+10, 4.0068e+10, 4.6264e+11, 7.3211e+10, 9.1090e+10, 9.2261e+11,
        6.2624e+10, 8.7229e+10, 3.6731e+10, 1.9483e+12, 2.8456e+10, 1.9451e+11,
        4.4156e+10, 1.5796e+11, 4.0481e+11, 3.4520e+11, 8.7941e+10, 2.6259e+11,
        3.6313e+11, 1.8365e+11, 2.2839e+11, 8.4011e+10, 4.8003e+10, 1.8625e+11,
        1.6675e+12, 1.0245e+11, 3.0332e+11, 1.2913e+11, 9.8454e+10, 5.5500e+10,
        1.9863e+11, 3.3420e+11, 8.0121e+11, 2.1463e+11, 4.7738e+11, 2.5248e+11,
        1.3721e+12, 9.9662e+10, 6.7402e+10, 7.8811e+11, 4.8716e+11, 1.0626e+12,
        9.3010e+11, 2.6127e+12, 8.1407e+10, 9.2261e+10, 1.7991e+12, 7.2851e+11,
        1.9121e+11, 7.0853e+11, 5.6656e+10, 1.3213e+12, 3.0719e+11, 1.6352e+11,
        5.0603e+10, 4.4917e+11, 5.0486e+10, 5.3494e+10, 6.6466e+10, 1.0826e+11,
        8.9633e+10, 1.6402e+11, 1.2539e+13, 5.0583e+11, 2.1153e+12, 1.5350e+12,
        4.3720e+11, 3.6538e+10, 1.9450e+11, 2.0737e+12, 1.7481e+10, 2.0416e+11,
        1.7614e+11, 1.6208e+10, 1.8461e+11, 1.7583e+12, 2.9710e+10, 1.8323e+12,
        1.4838e+11, 5.4095e+11, 2.2027e+11, 3.8362e+10, 2.5297e+12, 1.8060e+11,
        1.0434e+11, 2.6791e+10, 4.6321e+11, 2.2456e+11, 1.6809e+11, 1.3181e+12,
        5.7036e+11, 5.1741e+11, 5.4646e+11, 1.3284e+12, 3.5099e+11, 7.9030e+10,
        1.4741e+11, 3.2943e+11, 2.7195e+10, 6.8383e+10, 3.8488e+10, 5.3023e+11,
        8.0331e+10, 3.6279e+12, 2.4801e+11, 4.0192e+10, 1.5005e+12, 2.0914e+11,
        8.1879e+10, 2.3872e+11, 2.5148e+11, 1.2304e+12, 1.5994e+12, 1.6240e+11,
        8.6861e+10, 5.1219e+11, 2.2841e+10, 2.0034e+12, 2.7693e+11, 3.9363e+10,
        2.0860e+11, 7.6267e+11, 1.9968e+11, 9.7744e+11, 2.0667e+10, 2.1136e+10,
        2.4928e+11, 1.5993e+11])
Layer: encoder.5.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.7236e+11, 4.6981e+12, 1.1284e+12, 1.7606e+11, 2.2398e+12, 4.8716e+12,
        2.0208e+11, 1.1801e+12, 8.2672e+11, 2.3584e+11, 1.9217e+11, 2.5629e+11,
        3.1255e+11, 3.2357e+11, 2.8371e+11, 2.0522e+12, 3.5300e+11, 5.5607e+11,
        5.2437e+11, 1.5845e+11, 1.6405e+11, 2.5571e+11, 8.1430e+11, 1.7223e+11,
        6.7911e+11, 3.2928e+11, 1.9031e+11, 8.8857e+11, 3.2884e+12, 3.1384e+11,
        5.1716e+11, 3.8374e+11, 3.9688e+11, 4.4096e+11, 1.6232e+11, 7.6497e+11,
        3.8309e+11, 2.5531e+11, 1.7974e+11, 1.7656e+11, 5.6393e+11, 3.3267e+12,
        2.4093e+11, 8.5764e+11, 2.0762e+11, 3.1573e+12, 1.4045e+11, 4.8268e+11,
        1.5941e+11, 1.5790e+11, 5.0679e+11, 2.4295e+11, 3.6041e+11, 8.7969e+11,
        2.2215e+12, 9.8948e+11, 4.7544e+11, 4.5162e+11, 1.2798e+12, 2.7618e+11,
        8.8776e+11, 1.9123e+11, 4.9102e+11, 1.3200e+12, 1.7279e+11, 2.9103e+11,
        6.2173e+11, 8.5298e+11, 1.1123e+12, 4.0549e+11, 8.9789e+11, 5.9085e+11,
        2.5877e+11, 1.6684e+11, 2.2295e+11, 1.3562e+11, 4.9899e+11, 1.0300e+11,
        1.3180e+11, 6.7532e+11, 1.4822e+11, 3.4129e+11, 2.9891e+11, 8.1997e+10,
        6.3973e+11, 2.1093e+11, 2.2022e+11, 1.0609e+12, 2.2613e+11, 4.1998e+11,
        5.0717e+11, 1.4679e+11, 1.4427e+11, 4.5863e+11, 7.3686e+11, 2.1369e+11,
        1.5484e+11, 2.1799e+11, 2.8409e+11, 3.8097e+12, 1.8575e+11, 2.7552e+11,
        4.1701e+11, 2.9336e+11, 3.7048e+11, 1.9903e+11, 9.8049e+11, 2.5689e+11,
        1.2357e+12, 2.5307e+11, 1.3666e+11, 1.7922e+11, 3.8706e+11, 3.1752e+11,
        1.2476e+11, 1.4746e+11, 1.8505e+11, 2.6727e+11, 6.4059e+11, 8.4331e+11,
        1.3093e+11, 1.9783e+11, 3.1158e+11, 6.0879e+11, 6.0595e+11, 4.5281e+11,
        1.3177e+12, 3.3283e+11, 1.9724e+11, 9.6805e+10, 4.7323e+11, 2.7131e+11,
        8.2866e+10, 1.5234e+11, 1.2339e+12, 2.6465e+11, 7.1465e+11, 2.6482e+12,
        1.6481e+11, 1.6354e+12, 9.9819e+10, 2.6636e+11, 4.4348e+11, 1.6675e+11,
        6.3542e+11, 2.4078e+13, 5.9953e+11, 9.4838e+11, 8.4968e+11, 2.5521e+11,
        3.4037e+11, 1.6007e+11, 1.0879e+12, 4.0578e+11, 1.8993e+11, 4.8095e+11,
        1.8956e+12, 2.5899e+11, 8.2225e+12, 2.4796e+11, 2.9268e+11, 2.2097e+12,
        1.4625e+11, 2.4382e+11, 1.9771e+11, 1.3696e+11, 1.0033e+11, 5.3891e+11,
        3.0254e+11, 2.0524e+11, 3.4779e+11, 2.7840e+11, 1.4423e+11, 9.5022e+11,
        6.4891e+11, 5.6965e+11, 2.6596e+11, 2.3975e+11, 2.3610e+11, 2.5607e+11,
        1.3408e+11, 3.6070e+11, 2.3637e+11, 2.2150e+12, 2.2562e+11, 1.2425e+11,
        1.3407e+12, 2.7751e+11, 2.2067e+11, 1.0237e+12, 6.9834e+11, 2.5760e+11,
        2.2227e+11, 2.3211e+11, 1.0762e+11, 5.2408e+11, 1.4698e+11, 3.8766e+11,
        1.3960e+12, 4.8594e+11, 2.4251e+12, 1.3996e+11, 1.8352e+11, 2.4253e+11,
        1.9223e+11, 9.5257e+10, 1.5976e+12, 5.3936e+11, 1.2452e+11, 1.6610e+11,
        2.1673e+11, 9.3528e+10, 6.3136e+11, 2.0085e+11, 2.2316e+11, 5.8026e+11,
        7.7560e+11, 1.3882e+11, 6.1020e+11, 1.7687e+11, 3.3012e+11, 2.7010e+11,
        1.9316e+11, 1.5516e+11, 1.4846e+11, 1.2739e+11, 1.3166e+12, 1.1712e+11,
        3.6466e+11, 1.6880e+12, 7.3732e+11, 2.0152e+11, 3.9563e+11, 2.3210e+12,
        1.2152e+11, 7.1365e+11, 2.7192e+11, 1.7411e+11, 1.2573e+11, 1.8326e+11,
        2.7914e+12, 1.5015e+12, 1.3095e+12, 1.9821e+11, 3.1249e+12, 3.7802e+11,
        1.4483e+11, 1.4004e+11, 5.0185e+11, 3.0648e+11, 1.4896e+12, 9.6669e+11,
        2.4156e+11, 1.1812e+11, 1.7184e+12, 1.2757e+12, 4.5728e+11, 4.4108e+12,
        5.8445e+11, 2.2186e+11, 2.9796e+11, 7.0782e+12, 1.4084e+12, 1.0596e+12,
        5.4228e+11, 1.4549e+11, 1.3427e+11, 6.8028e+11, 2.7401e+11, 2.7809e+11,
        9.2103e+11, 8.1407e+11, 4.5071e+11, 6.6958e+11, 2.5368e+11, 2.7427e+11,
        2.8288e+11, 1.9108e+11, 1.6494e+12, 2.9473e+11, 1.6280e+12, 3.8006e+11,
        2.1173e+11, 2.7599e+11, 1.6363e+11, 3.1243e+12, 1.8510e+11, 1.5768e+12,
        3.3036e+12, 3.7543e+11, 5.3629e+11, 5.2930e+11, 4.5620e+11, 1.9876e+11,
        1.9328e+11, 1.3466e+12, 2.9243e+11, 1.0004e+12, 2.5025e+11, 2.1901e+11,
        2.6624e+11, 3.8967e+11, 5.9741e+11, 3.0244e+11, 7.5214e+11, 5.6667e+11,
        1.0419e+11, 4.9329e+11, 1.6901e+11, 7.6942e+11, 1.5773e+11, 1.4718e+11,
        5.7886e+11, 9.9955e+11, 1.3506e+11, 9.2381e+11, 1.6630e+11, 4.3500e+11,
        7.1703e+11, 9.0316e+11, 2.0663e+11, 3.3602e+11, 5.4520e+11, 9.3332e+10,
        1.2319e+11, 1.7541e+11, 1.3428e+11, 7.5196e+10, 1.4003e+11, 2.6324e+11,
        2.1436e+11, 2.2173e+11, 8.2256e+11, 5.2392e+11, 1.1708e+12, 2.9152e+11,
        1.0532e+12, 9.8906e+11, 2.3780e+11, 2.4206e+11, 1.0970e+12, 8.6011e+11,
        4.1312e+11, 4.6677e+11, 1.8593e+11, 2.0981e+11, 1.0425e+12, 1.1790e+11,
        5.7516e+11, 5.0745e+11, 4.1533e+11, 7.5186e+11, 1.0310e+12, 1.2359e+11,
        5.3369e+11, 5.9770e+11, 2.6121e+11, 4.3139e+11, 2.2254e+12, 1.0928e+12,
        1.2645e+11, 1.3797e+11, 3.0524e+11, 5.7271e+11, 4.0052e+11, 3.4550e+11,
        3.1165e+11, 1.9212e+12, 2.6703e+11, 1.8075e+11, 1.8370e+11, 1.3634e+11,
        5.5384e+11, 3.0405e+11, 2.1714e+11, 1.4493e+11, 1.0848e+12, 2.1615e+11,
        1.5035e+11, 1.7535e+11, 2.6905e+12, 5.7415e+11, 2.5191e+11, 4.7055e+12,
        1.6453e+11, 3.5448e+11, 3.8912e+11, 1.0466e+11, 2.2162e+11, 8.1938e+11,
        2.2323e+11, 2.0058e+11, 1.0496e+11, 1.9796e+12, 2.9926e+11, 3.3777e+11,
        1.2059e+11, 1.7754e+11, 6.1149e+11, 4.6002e+11, 1.3669e+11, 2.3452e+11,
        3.6006e+11, 1.3266e+11, 3.3618e+11, 1.4161e+11, 2.0779e+11, 1.9570e+11,
        1.9032e+12, 3.1003e+11, 2.3480e+11, 1.0578e+11, 2.6208e+11, 1.1890e+11,
        1.9441e+11, 2.5890e+11, 8.8930e+11, 2.4288e+11, 4.5737e+11, 4.4547e+11,
        1.4676e+12, 2.0320e+11, 3.0149e+11, 7.3671e+11, 3.5564e+11, 1.1255e+12,
        9.1180e+11, 2.7983e+12, 1.3931e+11, 2.8718e+11, 1.8682e+12, 7.0348e+11,
        6.8775e+10, 8.4665e+11, 2.0215e+11, 1.2536e+12, 2.9193e+11, 5.1943e+10,
        1.6034e+11, 4.9508e+11, 1.1790e+11, 1.2867e+11, 1.8547e+11, 7.6355e+10,
        2.6005e+11, 2.5161e+11, 1.2452e+13, 5.0123e+11, 2.0832e+12, 1.5632e+12,
        5.0370e+11, 1.1218e+11, 3.3001e+11, 2.0422e+12, 2.5291e+11, 2.8004e+11,
        2.6868e+11, 1.6488e+11, 2.7756e+11, 1.6869e+12, 1.3794e+11, 1.9182e+12,
        3.2205e+11, 5.8537e+11, 1.3156e+11, 1.8319e+11, 2.5620e+12, 1.8916e+11,
        2.8094e+11, 3.2554e+11, 6.3617e+11, 3.4215e+11, 1.7458e+11, 1.4321e+12,
        7.4500e+11, 6.2299e+11, 5.7355e+11, 1.2647e+12, 5.7884e+11, 2.8523e+11,
        2.6827e+11, 5.4115e+11, 1.1651e+11, 1.2272e+11, 1.3807e+11, 7.9755e+11,
        2.7920e+11, 3.6432e+12, 5.4633e+11, 1.3286e+11, 1.5213e+12, 2.6131e+11,
        1.6475e+11, 4.1322e+11, 1.2946e+11, 1.3225e+12, 6.5686e+11, 3.1014e+11,
        1.4304e+11, 5.7019e+11, 1.3804e+11, 2.1600e+12, 4.0454e+11, 1.8675e+11,
        4.9621e+11, 7.7439e+11, 4.2291e+11, 8.8652e+11, 2.4765e+11, 1.6956e+11,
        2.5470e+11, 1.7986e+11])
Layer: encoder.5.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.8181e+11, 5.6917e+11, 4.8295e+11, 5.3163e+11, 3.1557e+11, 3.9653e+11,
        4.4608e+11, 3.7532e+11, 3.6710e+11, 4.4326e+11, 6.7367e+11, 3.5980e+11,
        2.8048e+11, 5.7162e+11, 6.3410e+11, 4.3721e+11, 3.7622e+11, 4.0729e+11,
        3.6639e+11, 2.3825e+11, 4.1474e+11, 4.6716e+11, 5.2581e+11, 3.3423e+11,
        3.4533e+11, 3.7641e+11, 3.3254e+11, 4.3799e+11, 4.5142e+11, 5.1730e+11,
        3.7669e+11, 2.8629e+11, 5.6113e+11, 2.6705e+11, 3.1020e+11, 4.3999e+11,
        3.7668e+11, 2.4270e+11, 4.9614e+11, 3.6875e+11, 3.7332e+11, 4.0092e+11,
        6.1451e+11, 3.9762e+11, 4.2115e+11, 4.0662e+11, 4.1500e+11, 4.3658e+11,
        2.7444e+11, 2.6536e+11, 3.2534e+11, 4.1509e+11, 4.1129e+11, 2.2851e+11,
        3.6697e+11, 3.5216e+11, 5.6296e+11, 4.5355e+11, 3.1556e+11, 4.1024e+11,
        3.3977e+11, 3.8904e+11, 5.3208e+11, 5.9985e+11, 3.7685e+11, 3.4815e+11,
        4.0616e+11, 3.8893e+11, 4.3503e+11, 4.8072e+11, 3.1782e+11, 4.9066e+11,
        4.1086e+11, 4.2658e+11, 5.6842e+11, 3.2642e+11, 4.1271e+11, 4.5043e+11,
        3.1576e+11, 2.4673e+11, 3.8184e+11, 3.8987e+11, 3.6348e+11, 4.2891e+11,
        3.8135e+11, 4.6125e+11, 3.6753e+11, 4.1966e+11, 3.1713e+11, 2.3851e+11,
        4.0134e+11, 3.3795e+11, 3.5168e+11, 2.8759e+11, 3.8799e+11, 5.4723e+11,
        3.4585e+11, 2.8586e+11, 3.9481e+11, 4.1451e+11, 3.6121e+11, 4.1689e+11,
        2.9537e+11, 2.2597e+11, 5.5305e+11, 3.9987e+11, 4.5476e+11, 4.1753e+11,
        5.2762e+11, 3.4710e+11, 2.9332e+11, 4.8325e+11, 4.6724e+11, 4.3743e+11,
        2.6254e+11, 2.6758e+11, 2.3573e+11, 3.2307e+11, 3.6918e+11, 2.5480e+11,
        3.8047e+11, 4.0387e+11, 3.2604e+11, 5.1447e+11, 5.6464e+11, 3.2883e+11,
        3.2803e+11, 2.8997e+11])
Layer: encoder.5.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.3048e+11, 6.3969e+11, 5.2176e+11, 9.3020e+11, 5.6539e+11, 6.2457e+11,
        5.1195e+11, 9.0884e+11, 6.8574e+11, 6.1456e+11, 5.3057e+11, 6.8686e+11,
        5.7634e+11, 7.1208e+11, 5.3839e+11, 7.3540e+11, 5.1478e+11, 7.6320e+11,
        7.5073e+11, 6.2601e+11, 9.6549e+11, 5.5555e+11, 5.2012e+11, 7.3048e+11,
        5.4698e+11, 6.3889e+11, 5.3455e+11, 7.5533e+11, 6.8523e+11, 5.8918e+11,
        5.3844e+11, 6.5678e+11, 6.9523e+11, 4.6399e+11, 8.3870e+11, 9.0997e+11,
        5.7407e+11, 6.3765e+11, 6.5379e+11, 5.6515e+11, 5.6028e+11, 6.4557e+11,
        7.9959e+11, 4.0370e+11, 8.0831e+11, 7.3248e+11, 9.5379e+11, 6.9908e+11,
        5.9266e+11, 5.3589e+11, 7.2112e+11, 5.4894e+11, 7.0236e+11, 5.1804e+11,
        5.9742e+11, 6.3187e+11, 3.9617e+11, 5.2940e+11, 3.9088e+11, 5.4524e+11,
        4.7531e+11, 6.0177e+11, 7.7141e+11, 6.7728e+11, 8.1362e+11, 6.0773e+11,
        6.6176e+11, 3.0546e+11, 5.2923e+11, 6.5800e+11, 9.5358e+11, 6.6039e+11,
        6.4964e+11, 5.6592e+11, 9.6138e+11, 6.7387e+11, 4.4110e+11, 6.9882e+11,
        7.9491e+11, 7.2597e+11, 4.0176e+11, 5.6303e+11, 7.0418e+11, 4.8958e+11,
        6.5471e+11, 7.1239e+11, 4.7710e+11, 6.8021e+11, 6.1866e+11, 9.5897e+11,
        6.1634e+11, 5.6608e+11, 8.4296e+11, 6.1687e+11, 6.6150e+11, 6.0402e+11,
        5.4629e+11, 4.4944e+11, 5.5076e+11, 9.1324e+11, 5.6673e+11, 7.3075e+11,
        7.0821e+11, 4.0075e+11, 6.8353e+11, 6.2251e+11, 5.8663e+11, 6.6302e+11,
        7.3468e+11, 4.5245e+11, 6.3918e+11, 5.5849e+11, 8.9452e+11, 5.7058e+11,
        5.5137e+11, 6.6546e+11, 9.5835e+11, 6.4017e+11, 7.4149e+11, 8.9658e+11,
        4.7074e+11, 7.3684e+11, 4.3336e+11, 4.7325e+11, 6.0494e+11, 8.5001e+11,
        6.1838e+11, 8.8309e+11])
Layer: encoder.5.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.1851e+10, 2.5853e+10, 3.1223e+10, 2.4200e+10, 4.8609e+10, 3.4393e+10,
        9.9843e+09, 5.1673e+10, 2.9580e+10, 2.3851e+09, 2.7734e+10, 4.8777e+09,
        5.1220e+10, 2.7390e+10, 1.6079e+10, 1.2482e+12, 1.9728e+10, 2.7979e+10,
        1.0526e+10, 4.0609e+10, 4.3324e+09, 2.7990e+10, 4.9053e+10, 2.9799e+10,
        4.0131e+10, 2.7499e+10, 1.1390e+10, 5.2378e+10, 3.9064e+10, 5.8126e+09,
        3.5242e+10, 2.6331e+10, 2.9283e+10, 3.9115e+10, 1.9854e+10, 1.6628e+11,
        3.4279e+10, 4.0056e+10, 5.1448e+09, 2.8773e+11, 1.4543e+11, 2.8220e+10,
        4.6478e+10, 3.5876e+10, 1.0499e+10, 1.2372e+10, 3.5110e+10, 7.6287e+10,
        2.6385e+10, 4.4911e+10, 1.6055e+11, 3.5530e+10, 2.0835e+10, 2.4464e+10,
        2.5030e+10, 4.1005e+10, 1.4901e+11, 3.9482e+10, 4.7695e+10, 5.1805e+09,
        3.2246e+10, 1.3075e+10, 2.7793e+10, 6.8230e+10, 2.5774e+10, 9.6805e+09,
        3.6476e+10, 7.8607e+10, 6.7311e+10, 5.7035e+10, 1.5881e+11, 5.9029e+10,
        2.1380e+10, 9.8514e+09, 4.5781e+09, 3.6435e+10, 2.4630e+10, 2.8037e+10,
        3.2441e+09, 2.2174e+10, 8.0688e+10, 1.7200e+10, 1.8801e+10, 3.5576e+10,
        5.9250e+10, 2.1032e+11, 2.9526e+10, 1.1304e+11, 4.2591e+10, 6.0220e+10,
        3.2557e+10, 1.3749e+10, 3.8466e+10, 1.5440e+10, 3.5566e+10, 4.1858e+10,
        6.3194e+09, 3.0502e+10, 3.1860e+10, 2.7168e+10, 2.6343e+09, 1.6742e+10,
        2.0856e+10, 3.3190e+10, 5.6993e+10, 2.2802e+10, 2.8562e+10, 4.3596e+10,
        9.5073e+10, 1.4027e+10, 1.7613e+10, 1.6996e+11, 1.5399e+11, 9.7925e+10,
        1.1377e+10, 4.5685e+10, 2.6305e+10, 3.5541e+10, 5.9033e+10, 4.4770e+10,
        4.4112e+09, 1.3122e+10, 1.0313e+11, 8.9483e+10, 2.7536e+10, 1.2266e+11,
        3.9030e+10, 1.3886e+11, 4.7154e+10, 5.2220e+10, 3.8969e+10, 5.5737e+09,
        9.4248e+09, 2.7670e+10, 6.1087e+10, 3.7850e+10, 4.6048e+10, 3.0153e+10,
        3.8247e+10, 3.4364e+10, 3.0290e+10, 1.0555e+10, 8.2138e+10, 2.9739e+10,
        1.0171e+10, 6.9380e+10, 3.9147e+10, 5.0478e+10, 4.3460e+10, 4.5003e+10,
        1.8633e+10, 7.1077e+09, 8.1136e+10, 3.1141e+10, 3.5974e+10, 3.6804e+10,
        2.9801e+10, 1.0811e+10, 2.4647e+10, 3.8037e+10, 1.1741e+10, 3.8217e+10,
        4.6123e+09, 5.1021e+10, 2.7331e+10, 4.1187e+10, 5.1040e+10, 1.1254e+10,
        1.6784e+10, 5.4500e+09, 1.8071e+10, 1.4159e+10, 4.6263e+10, 2.7702e+10,
        4.4615e+09, 1.3651e+10, 2.9043e+09, 3.8000e+10, 1.4299e+10, 8.7898e+10,
        3.0049e+10, 9.9733e+10, 4.1228e+10, 6.0597e+10, 5.5049e+10, 3.3161e+10,
        9.2449e+10, 5.2215e+10, 2.0412e+10, 5.8030e+10, 4.2075e+10, 3.7546e+10,
        4.2521e+09, 3.7214e+10, 7.1901e+09, 4.4381e+10, 9.0375e+09, 2.5407e+10,
        4.7284e+10, 3.0130e+10, 1.1554e+11, 7.7034e+09, 1.1537e+10, 5.3359e+09,
        1.8604e+11, 2.6359e+10, 2.5166e+10, 2.9419e+10, 3.0030e+10, 2.8929e+10,
        3.6255e+10, 6.0437e+09, 5.1154e+10, 6.7406e+09, 3.0757e+10, 2.0130e+10,
        3.9252e+10, 4.8983e+10, 4.1286e+09, 2.9830e+10, 1.1219e+11, 5.6739e+09,
        4.8611e+10, 4.7593e+10, 2.0764e+10, 2.6988e+10, 3.9996e+10, 1.2385e+09,
        1.6957e+10, 3.3859e+10, 4.3585e+10, 3.5368e+10, 3.8363e+10, 4.9376e+10,
        4.5588e+09, 4.5961e+10, 2.3396e+10, 6.8815e+09, 1.9392e+10, 4.5249e+10,
        8.7369e+10, 2.9534e+10, 9.9403e+10, 3.5016e+10, 2.5233e+10, 5.1968e+10,
        4.3722e+09, 3.1581e+10, 3.9829e+10, 3.7050e+10, 3.9403e+10, 2.7613e+10,
        1.7550e+10, 2.1486e+10, 3.5996e+10, 3.6702e+10, 7.0750e+10, 7.6869e+10,
        1.4638e+11, 2.8943e+10, 1.1117e+10, 7.4091e+10, 3.0257e+10, 1.3699e+10,
        4.0792e+10, 6.9627e+10, 4.2121e+10, 7.2321e+10, 4.0717e+10, 4.5951e+10,
        1.3951e+11, 2.3804e+11, 2.2159e+10, 2.9892e+10, 2.1701e+10, 2.0096e+10,
        4.9124e+10, 2.7838e+10, 5.1829e+10, 4.1616e+10, 2.9477e+10, 1.8095e+10,
        4.3245e+10, 3.6922e+10, 2.5735e+10, 1.6588e+10, 2.9229e+10, 4.3325e+10,
        5.6666e+11, 8.3180e+10, 3.2949e+10, 3.5311e+10, 8.9794e+10, 5.2592e+10,
        2.2464e+10, 2.3387e+10, 1.7441e+09, 3.1559e+10, 3.4709e+10, 3.0510e+10,
        1.3880e+10, 1.7288e+10, 4.3104e+10, 7.9309e+09, 1.5527e+10, 4.2568e+10,
        3.7461e+10, 1.0342e+10, 3.2458e+10, 2.3616e+10, 2.5567e+10, 5.4701e+09,
        1.6746e+10, 3.9687e+10, 5.3028e+10, 3.6118e+10, 4.1910e+10, 1.5879e+10,
        5.5801e+10, 4.4589e+10, 4.3393e+10, 3.1039e+10, 2.8942e+10, 2.9407e+09,
        4.1874e+10, 2.4353e+10, 1.1693e+10, 7.7753e+10, 5.7262e+09, 4.7622e+10,
        1.7611e+10, 3.7183e+10, 7.0798e+10, 1.1770e+11, 1.8822e+10, 7.9985e+10,
        2.1899e+11, 3.2087e+10, 1.0665e+10, 1.4903e+10, 9.8578e+10, 3.4775e+10,
        2.2509e+11, 2.9139e+10, 1.4237e+10, 8.9829e+09, 2.5808e+10, 2.7416e+10,
        3.4004e+10, 3.9230e+10, 2.9409e+10, 1.3117e+11, 5.6877e+10, 4.0877e+10,
        1.9848e+10, 2.4592e+10, 6.8097e+09, 4.0255e+10, 9.9343e+09, 1.8194e+10,
        2.9554e+10, 5.0347e+10, 1.8147e+10, 1.5580e+10, 3.3420e+09, 1.4030e+11,
        3.0511e+10, 4.8826e+11, 5.7701e+10, 1.6330e+10, 4.1961e+09, 2.2284e+10,
        6.0219e+10, 4.4859e+10, 4.1957e+10, 1.1933e+10, 4.2264e+10, 5.0414e+10,
        3.1711e+10, 2.7301e+10, 2.4024e+10, 2.5062e+10, 2.3458e+10, 2.6294e+10,
        1.7140e+10, 2.8583e+10, 3.4083e+10, 5.0394e+10, 4.4063e+10, 5.4772e+10,
        3.3660e+10, 4.4761e+09, 4.0308e+10, 4.5806e+10, 9.2166e+09, 2.3383e+10,
        2.0815e+10, 3.7352e+09, 2.5110e+10, 3.5421e+10, 8.3159e+09, 3.8023e+10,
        2.9084e+10, 6.0868e+09, 4.4784e+10, 3.6501e+10, 4.2015e+09, 3.6474e+10,
        7.7951e+10, 1.7073e+11, 1.2901e+10, 9.2360e+09, 5.3434e+10, 2.6652e+10,
        7.0521e+10, 2.3394e+10, 4.5309e+10, 4.8249e+10, 6.8116e+10, 1.1844e+11,
        4.4855e+10, 2.1198e+10, 3.6231e+10, 4.4347e+10, 2.8422e+10, 3.0411e+10,
        3.2683e+10, 3.0849e+10, 3.3276e+09, 3.1271e+10, 7.2333e+10, 3.6076e+10,
        4.1146e+10, 2.5565e+10, 3.0318e+10, 1.7520e+10, 2.9931e+10, 4.1090e+10,
        5.7687e+09, 2.0314e+10, 2.7916e+10, 4.1845e+09, 8.0564e+09, 4.7139e+10,
        2.6166e+10, 1.9448e+11, 3.8948e+10, 1.5097e+10, 3.5035e+10, 1.9665e+10,
        3.2063e+10, 1.7116e+10, 1.3289e+10, 4.4127e+10, 2.2553e+10, 1.1077e+11,
        2.2393e+10, 2.5647e+10, 1.5418e+10, 6.4015e+10, 5.2345e+09, 8.7932e+10,
        1.4843e+11, 2.7598e+10, 4.1884e+10, 4.6186e+09, 7.5287e+10, 9.0237e+10,
        1.2605e+10, 3.6327e+10, 3.4499e+10, 2.2659e+10, 7.9346e+09, 3.8407e+10,
        5.7143e+10, 7.1416e+10, 4.5646e+10, 3.4093e+10, 7.6106e+10, 3.5289e+10,
        5.7993e+10, 1.0814e+10, 1.8884e+10, 6.4082e+09, 6.7849e+09, 3.4557e+10,
        7.1913e+10, 2.9694e+10, 4.8193e+10, 4.0587e+10, 3.8368e+10, 3.8156e+10,
        7.4721e+09, 4.3739e+10, 2.5583e+10, 3.5182e+10, 1.0555e+12, 6.1434e+10,
        2.0686e+09, 2.1122e+10, 5.4786e+09, 6.9892e+10, 2.2368e+10, 6.7224e+09,
        2.9375e+10, 9.6929e+10, 3.5224e+10, 4.6468e+10, 1.0943e+10, 4.9891e+10,
        2.9685e+10, 2.7121e+10])
Layer: encoder.5.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([8.0921e+10, 7.5855e+10, 9.6985e+10, 1.0595e+11, 4.9958e+10, 1.0441e+11,
        6.5362e+10, 1.0502e+11, 6.8912e+10, 9.2078e+10, 9.0473e+10, 9.7224e+10,
        6.5762e+10, 8.0923e+10, 9.7134e+10, 7.6428e+10, 7.3530e+10, 8.4703e+10,
        6.0692e+10, 9.1350e+10, 9.3952e+10, 1.2565e+11, 5.7028e+10, 5.4410e+10,
        8.3974e+10, 7.3716e+10, 6.4272e+10, 9.2089e+10, 8.0990e+10, 7.0121e+10,
        8.7141e+10, 7.9997e+10, 6.6137e+10, 7.8311e+10, 9.9259e+10, 9.2721e+10,
        7.1864e+10, 1.0002e+11, 9.6484e+10, 9.1158e+10, 7.4887e+10, 7.7215e+10,
        5.7483e+10, 1.2006e+11, 7.3709e+10, 6.8041e+10, 9.6327e+10, 6.7977e+10,
        6.9743e+10, 6.1290e+10, 7.4087e+10, 6.6907e+10, 9.4424e+10, 4.5633e+10,
        6.8857e+10, 9.1086e+10, 8.6733e+10, 1.0974e+11, 7.0287e+10, 8.9107e+10,
        8.1678e+10, 9.1336e+10, 5.3654e+10, 5.3836e+10, 8.4508e+10, 6.0967e+10,
        7.9285e+10, 9.0900e+10, 8.8037e+10, 8.0255e+10, 8.6044e+10, 1.0946e+11,
        5.6157e+10, 1.0049e+11, 1.2673e+11, 5.7086e+10, 7.2264e+10, 1.2451e+11,
        9.5388e+10, 6.7374e+10, 6.9289e+10, 8.6108e+10, 6.4155e+10, 9.2281e+10,
        7.0220e+10, 9.5947e+10, 1.0125e+11, 1.4092e+11, 1.2648e+11, 7.2533e+10,
        7.0299e+10, 7.6049e+10, 1.0227e+11, 8.0819e+10, 1.0059e+11, 1.0121e+11,
        7.5435e+10, 8.7076e+10, 9.4094e+10, 7.1135e+10, 4.4120e+10, 5.4295e+10,
        5.4646e+10, 8.2561e+10, 9.8742e+10, 5.3371e+10, 9.2873e+10, 9.8901e+10,
        7.7928e+10, 7.6019e+10, 5.7508e+10, 6.5790e+10, 6.0976e+10, 5.5809e+10,
        7.1377e+10, 8.7413e+10, 4.5381e+10, 6.1177e+10, 6.2780e+10, 6.3456e+10,
        8.7954e+10, 7.5425e+10, 6.7602e+10, 5.8924e+10, 8.9923e+10, 6.4245e+10,
        1.0023e+11, 6.2235e+10])
Layer: encoder.5.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.0765e+11, 1.4446e+11, 1.2640e+11, 1.0136e+11, 1.0478e+11, 1.2356e+11,
        1.2239e+11, 7.8595e+10, 1.4542e+11, 1.0385e+11, 1.0063e+11, 1.3145e+11,
        8.4159e+10, 1.1720e+11, 1.4205e+11, 1.7009e+11, 1.5726e+11, 9.6975e+10,
        1.0074e+11, 1.0909e+11, 8.6645e+10, 1.2539e+11, 1.3965e+11, 8.1618e+10,
        1.2128e+11, 1.5231e+11, 1.1403e+11, 8.5117e+10, 1.2988e+11, 1.6964e+11,
        1.2012e+11, 8.2044e+10, 1.1299e+11, 9.8891e+10, 1.7201e+11, 1.2186e+11,
        1.3835e+11, 1.2114e+11, 1.2685e+11, 1.6159e+11, 1.4883e+11, 1.1741e+11,
        1.2862e+11, 1.3296e+11, 1.1534e+11, 1.2462e+11, 1.0085e+11, 1.4676e+11,
        9.5662e+10, 1.2183e+11, 8.9355e+10, 9.7797e+10, 1.5864e+11, 1.4119e+11,
        1.1187e+11, 6.4707e+10, 1.2503e+11, 1.3086e+11, 1.3672e+11, 1.1066e+11,
        1.7818e+11, 1.4743e+11, 1.4281e+11, 1.0592e+11, 1.1314e+11, 8.8151e+10,
        9.6480e+10, 1.0577e+11, 8.6911e+10, 1.1539e+11, 1.2364e+11, 1.5275e+11,
        1.3333e+11, 1.4959e+11, 9.4077e+10, 1.3259e+11, 9.6717e+10, 9.1149e+10,
        9.2833e+10, 9.9411e+10, 1.6750e+11, 9.7606e+10, 1.8770e+11, 1.3373e+11,
        7.3505e+10, 1.4022e+11, 1.3302e+11, 1.6033e+11, 7.9790e+10, 1.3878e+11,
        1.6229e+11, 1.0333e+11, 1.4857e+11, 1.3022e+11, 1.2613e+11, 1.1942e+11,
        1.4473e+11, 1.5802e+11, 7.8644e+10, 9.9369e+10, 1.5873e+11, 1.1344e+11,
        1.7048e+11, 1.2592e+11, 8.9677e+10, 1.1765e+11, 1.1418e+11, 1.3048e+11,
        8.5150e+10, 1.3078e+11, 1.3265e+11, 1.1506e+11, 1.9479e+11, 1.1846e+11,
        9.7958e+10, 8.0801e+10, 1.7273e+11, 7.2854e+10, 1.1845e+11, 1.0769e+11,
        1.3563e+11, 1.2954e+11, 1.3569e+11, 1.6655e+11, 1.2551e+11, 1.0273e+11,
        1.5929e+11, 1.1791e+11])
Layer: encoder.5.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.8400e+09, 3.5323e+09, 5.4753e+09, 1.2906e+09, 3.4570e+09, 7.5309e+09,
        2.2495e+08, 1.1924e+10, 1.5996e+10, 7.1942e+08, 1.5467e+09, 5.0251e+09,
        2.1866e+10, 5.7101e+09, 2.9468e+09, 4.0083e+09, 2.0845e+09, 2.6102e+09,
        1.1352e+09, 3.0181e+09, 2.8594e+09, 4.1162e+09, 2.8382e+10, 1.1548e+10,
        4.2227e+09, 4.5022e+09, 7.9029e+08, 4.8436e+09, 2.0535e+09, 9.7560e+08,
        1.2177e+09, 1.1191e+09, 9.6833e+09, 2.2241e+09, 1.1499e+09, 2.0579e+09,
        4.3702e+10, 6.3344e+09, 5.1346e+08, 1.1803e+09, 1.4983e+09, 2.2487e+09,
        5.2246e+10, 1.8359e+09, 9.4278e+08, 2.0923e+09, 5.4262e+09, 6.2880e+09,
        7.5146e+09, 6.8670e+09, 1.6482e+11, 3.9733e+09, 1.9462e+09, 5.5784e+09,
        6.7695e+08, 6.4465e+10, 7.9362e+09, 2.8317e+09, 1.3658e+09, 1.6429e+09,
        3.2221e+09, 2.5150e+09, 2.0431e+09, 4.1959e+09, 8.7470e+09, 1.8383e+09,
        6.3177e+09, 2.0326e+10, 6.9529e+09, 1.4820e+10, 7.0034e+09, 6.4894e+09,
        8.3617e+09, 3.7417e+08, 6.2032e+08, 6.2783e+09, 3.7977e+09, 5.5396e+09,
        4.0128e+08, 3.0753e+09, 1.2726e+09, 3.8908e+09, 3.6344e+09, 6.4625e+09,
        4.3516e+09, 1.4697e+09, 2.0343e+09, 6.8228e+09, 3.7553e+09, 2.5460e+09,
        3.9520e+09, 2.6844e+08, 5.7317e+09, 6.7624e+09, 1.0100e+10, 5.8491e+09,
        3.3231e+08, 6.8228e+09, 6.6291e+09, 6.3517e+09, 1.0460e+09, 2.3283e+09,
        3.4944e+09, 3.0129e+09, 3.5158e+09, 1.2001e+09, 2.1617e+09, 3.9850e+10,
        3.5450e+09, 3.7735e+09, 3.0419e+09, 1.4426e+11, 1.1298e+10, 4.2731e+09,
        1.5852e+09, 1.4117e+09, 4.7077e+09, 3.0713e+09, 2.8020e+09, 3.4116e+09,
        8.4304e+08, 1.0861e+09, 9.0272e+09, 4.0156e+09, 5.7408e+09, 6.2148e+09,
        3.1835e+09, 3.5837e+09, 5.7289e+09, 3.7498e+09, 3.8368e+09, 8.2685e+08,
        4.8572e+08, 5.3924e+09, 4.5043e+09, 5.4475e+09, 4.7077e+09, 2.6364e+09,
        7.3992e+09, 1.5642e+09, 7.1472e+09, 1.9345e+09, 1.4882e+10, 2.8942e+09,
        3.7713e+09, 1.0183e+10, 3.3321e+09, 5.9520e+09, 3.2313e+09, 2.9344e+10,
        2.9053e+09, 6.5324e+08, 8.3283e+09, 5.3252e+09, 5.4083e+09, 3.0383e+09,
        3.4026e+10, 4.4525e+08, 2.7521e+09, 2.6145e+09, 8.6643e+08, 6.3046e+09,
        6.1000e+08, 2.6287e+09, 7.3481e+09, 2.0454e+10, 1.1538e+10, 1.9320e+09,
        1.9759e+09, 4.4080e+08, 2.7831e+09, 5.4695e+08, 1.8517e+10, 6.4073e+08,
        3.7786e+09, 4.5602e+09, 2.1469e+09, 7.2882e+09, 5.7422e+08, 1.1362e+10,
        1.1632e+09, 3.3400e+09, 1.3973e+09, 7.7464e+09, 2.3288e+10, 1.1388e+10,
        4.4732e+09, 4.6088e+09, 1.2512e+09, 6.0670e+09, 2.0511e+10, 7.2003e+09,
        5.2889e+08, 2.3048e+10, 7.6832e+08, 3.1411e+09, 4.6189e+09, 4.2791e+09,
        1.9984e+10, 4.2063e+09, 1.1719e+11, 7.9530e+08, 1.2951e+09, 9.9819e+08,
        1.6175e+11, 8.6091e+09, 3.3192e+09, 4.6498e+09, 4.8649e+09, 7.7686e+09,
        3.1952e+09, 9.1147e+08, 4.9121e+09, 9.2457e+08, 8.9438e+09, 6.8730e+09,
        3.5709e+09, 7.3612e+09, 5.3210e+08, 9.7173e+09, 7.0052e+10, 1.5644e+09,
        7.8185e+09, 4.0687e+10, 1.0358e+10, 5.4071e+09, 1.3906e+10, 3.3861e+08,
        2.0985e+09, 3.2132e+09, 1.1348e+10, 4.7522e+09, 2.1247e+09, 4.4095e+09,
        6.5980e+08, 6.9103e+09, 3.5921e+09, 3.7245e+08, 3.1012e+09, 3.0046e+10,
        3.2402e+10, 1.1368e+10, 5.4102e+09, 7.6873e+09, 1.7944e+09, 4.9023e+09,
        6.3524e+08, 9.9130e+09, 1.1488e+10, 8.9093e+09, 4.0089e+09, 4.5482e+09,
        1.0723e+10, 4.3582e+09, 5.5935e+09, 4.3347e+09, 2.4660e+09, 3.8124e+10,
        6.3585e+09, 7.7641e+09, 3.9895e+08, 8.1370e+09, 4.3085e+09, 3.7643e+09,
        1.9446e+09, 1.5878e+09, 2.0465e+10, 5.7284e+10, 5.8697e+09, 7.0592e+09,
        1.0852e+10, 5.7711e+09, 1.3558e+10, 3.4356e+09, 1.7074e+09, 7.0519e+09,
        8.7473e+09, 1.8819e+09, 5.2142e+09, 2.8059e+09, 1.2133e+10, 5.8428e+09,
        1.3719e+10, 5.8132e+09, 4.7484e+09, 3.6556e+09, 4.0103e+09, 2.5137e+10,
        4.1572e+09, 2.7437e+09, 2.9810e+09, 5.0689e+09, 9.6635e+09, 2.8285e+10,
        6.4320e+09, 8.0533e+09, 6.7820e+08, 7.5471e+09, 1.1586e+10, 3.0528e+09,
        2.5735e+09, 4.6514e+09, 2.4416e+09, 2.2312e+08, 4.9685e+09, 2.3416e+10,
        6.9046e+09, 6.2328e+08, 5.3494e+09, 1.0571e+10, 2.5723e+09, 1.7986e+09,
        1.0501e+09, 6.1044e+09, 3.2157e+10, 1.2452e+10, 5.9210e+09, 7.5812e+09,
        3.3969e+09, 1.1768e+10, 4.8678e+09, 9.7019e+09, 3.1338e+09, 1.8480e+09,
        1.8561e+10, 6.7805e+09, 6.8989e+08, 6.2478e+10, 1.0108e+10, 4.7536e+09,
        7.5202e+09, 1.2679e+10, 3.6113e+09, 2.3422e+10, 9.8067e+09, 2.3187e+09,
        1.4520e+11, 1.0004e+10, 1.1939e+09, 9.4410e+08, 8.6063e+09, 2.2756e+09,
        2.3842e+09, 5.1868e+09, 5.1624e+08, 1.4152e+09, 2.9186e+09, 3.1414e+09,
        3.7079e+09, 6.3473e+10, 1.8880e+09, 3.6072e+09, 3.2376e+09, 6.9823e+09,
        2.6469e+10, 5.0843e+10, 1.0039e+09, 2.1955e+09, 2.3574e+09, 3.3804e+09,
        4.4380e+09, 2.1063e+10, 3.9418e+09, 2.9145e+09, 2.2139e+08, 5.5367e+09,
        2.0809e+09, 2.2383e+10, 1.6436e+10, 1.1701e+09, 1.4120e+08, 4.7855e+09,
        1.5711e+10, 1.0923e+10, 2.6455e+10, 3.2102e+09, 1.8271e+10, 2.2146e+10,
        2.5747e+09, 2.6027e+09, 4.4105e+09, 4.0512e+10, 5.0535e+09, 3.2274e+09,
        1.9028e+10, 4.3949e+09, 8.8106e+09, 4.1925e+09, 3.6669e+09, 5.2870e+09,
        9.3267e+09, 1.3576e+09, 5.9705e+09, 1.5466e+10, 9.9814e+08, 3.2602e+09,
        7.1404e+09, 1.2814e+09, 4.3239e+09, 2.8109e+09, 8.7475e+08, 5.5496e+09,
        8.7801e+09, 1.7928e+10, 8.5314e+09, 9.3830e+09, 4.7780e+08, 6.0355e+09,
        7.7386e+09, 2.5461e+09, 2.7760e+09, 6.3439e+08, 5.5692e+09, 4.8644e+09,
        5.1808e+09, 3.4911e+09, 5.4501e+09, 7.7673e+09, 6.9394e+09, 4.5649e+09,
        5.1968e+09, 3.0200e+10, 4.2100e+09, 6.3737e+09, 4.6164e+10, 3.6530e+09,
        4.1638e+09, 5.8125e+09, 9.1580e+08, 3.8583e+09, 1.0312e+10, 3.2092e+09,
        3.0393e+09, 4.2520e+09, 2.5164e+09, 1.6080e+09, 5.5782e+09, 5.0027e+09,
        1.0736e+09, 5.4522e+09, 4.4562e+09, 5.3849e+08, 1.6910e+09, 1.8366e+10,
        9.7414e+09, 2.3365e+09, 2.7411e+09, 1.6869e+09, 2.1828e+09, 3.2286e+09,
        5.1571e+09, 7.0078e+09, 4.1222e+09, 1.3573e+10, 3.3383e+09, 4.6528e+09,
        5.1446e+09, 5.2054e+09, 1.0623e+10, 1.1203e+10, 2.5784e+09, 2.0083e+09,
        2.4563e+09, 1.1997e+10, 1.8881e+10, 2.6298e+08, 2.8104e+09, 1.6230e+10,
        7.8864e+08, 5.0730e+09, 2.6189e+09, 1.7044e+09, 9.7311e+08, 7.0816e+09,
        2.6641e+10, 4.7276e+10, 5.7819e+09, 2.1691e+09, 7.9616e+09, 1.3304e+09,
        2.9732e+09, 1.7356e+09, 5.6820e+08, 4.8097e+08, 1.8187e+09, 2.8340e+09,
        1.5378e+09, 5.8049e+09, 2.7414e+10, 3.3299e+09, 3.4266e+09, 7.2784e+09,
        1.6515e+08, 1.3176e+10, 1.7965e+09, 7.9345e+09, 9.1842e+09, 6.5352e+09,
        6.0992e+08, 1.6030e+09, 1.2158e+09, 4.4056e+09, 1.5776e+09, 1.1330e+09,
        6.9878e+09, 3.1578e+09, 5.8256e+09, 1.3980e+09, 1.5902e+09, 1.4890e+10,
        6.1730e+09, 3.6937e+09])
Layer: encoder.5.3.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.6662e+10, 2.5053e+10, 1.2511e+10, 1.7780e+10, 8.9631e+09, 2.2818e+10,
        9.2220e+09, 1.8094e+10, 1.7750e+10, 1.8126e+10, 1.4678e+10, 7.7388e+09,
        7.3738e+09, 2.5740e+10, 1.7263e+10, 1.6112e+10, 1.8010e+10, 7.8929e+09,
        9.7023e+09, 1.5013e+10, 9.6474e+09, 9.1332e+09, 1.3441e+10, 1.1482e+10,
        2.1254e+10, 1.6409e+10, 1.2783e+10, 1.3797e+10, 2.2447e+10, 8.2273e+09,
        1.7695e+10, 1.6320e+10, 1.6077e+10, 1.4634e+10, 1.3439e+10, 1.8396e+10,
        1.3087e+10, 6.0191e+09, 1.7208e+10, 2.1332e+10, 9.6617e+09, 1.7745e+10,
        1.4125e+10, 2.0980e+10, 1.5950e+10, 9.1221e+09, 1.1263e+10, 1.1478e+10,
        2.1464e+10, 1.8772e+10, 1.4491e+10, 6.7451e+09, 1.3647e+10, 1.4027e+10,
        8.8575e+09, 1.3804e+10, 1.5048e+10, 1.3629e+10, 1.5665e+10, 2.1278e+10,
        2.5638e+10, 2.2746e+10, 5.9094e+09, 1.1264e+10, 8.0132e+09, 9.5770e+09,
        1.4501e+10, 1.9652e+10, 1.6194e+10, 1.1309e+10, 1.7698e+10, 1.8092e+10,
        2.2467e+10, 1.4203e+10, 2.3060e+10, 1.9434e+10, 2.1448e+10, 1.2207e+10,
        1.5356e+10, 8.5893e+09, 1.0093e+10, 1.0955e+10, 1.3531e+10, 2.1545e+10,
        1.5669e+10, 1.1579e+10, 1.3738e+10, 8.1286e+09, 7.6199e+09, 2.6116e+10,
        1.7276e+10, 6.2880e+09, 1.1229e+10, 1.4486e+10, 1.6133e+10, 1.2544e+10,
        1.1025e+10, 1.3870e+10, 1.6914e+10, 1.1622e+10, 1.8299e+10, 1.6814e+10,
        1.1744e+10, 9.1575e+09, 9.1278e+09, 1.3322e+10, 2.3627e+10, 1.9218e+10,
        7.1566e+09, 1.5554e+10, 2.2919e+10, 9.0999e+09, 1.1527e+10, 1.0627e+10,
        9.7768e+09, 9.5330e+09, 2.8071e+10, 1.6040e+10, 1.6824e+10, 1.5291e+10,
        1.6984e+10, 2.3001e+10, 6.8511e+09, 1.2015e+10, 1.4317e+10, 1.3120e+10,
        1.0044e+10, 1.7643e+10])
Layer: encoder.5.3.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.0622e+10, 3.9151e+10, 1.9318e+10, 2.2281e+10, 1.9195e+10, 4.4159e+10,
        9.2559e+09, 1.4475e+10, 2.1036e+10, 4.1308e+10, 2.4305e+10, 3.4193e+10,
        2.3058e+10, 2.4957e+10, 2.1528e+10, 1.4508e+10, 1.9346e+10, 1.3876e+10,
        4.6395e+10, 1.3599e+10, 3.5189e+10, 2.6701e+10, 1.6109e+10, 2.3719e+10,
        2.9977e+10, 2.5404e+10, 2.3073e+10, 1.4217e+10, 2.5067e+10, 1.2599e+10,
        1.2335e+10, 2.4331e+10, 2.2052e+10, 2.0595e+10, 1.2699e+10, 2.0752e+10,
        2.6865e+10, 3.3551e+10, 2.3371e+10, 2.8231e+10, 1.8879e+10, 1.6895e+10,
        2.7292e+10, 1.5901e+10, 1.8731e+10, 2.6065e+10, 2.2539e+10, 2.1112e+10,
        2.8849e+10, 1.8683e+10, 2.4867e+10, 1.1305e+10, 3.0877e+10, 2.6489e+10,
        1.1690e+10, 1.4380e+10, 2.1385e+10, 1.6863e+10, 2.1700e+10, 1.8699e+10,
        1.8551e+10, 8.8774e+09, 2.3902e+10, 1.5409e+10, 2.8469e+10, 1.2873e+10,
        1.7518e+10, 1.8218e+10, 2.2427e+10, 1.6792e+10, 2.4443e+10, 3.3208e+10,
        1.6725e+10, 3.2278e+10, 2.8404e+10, 3.6402e+10, 1.8994e+10, 3.2033e+10,
        3.6290e+10, 3.3075e+10, 1.5277e+10, 2.6893e+10, 1.9749e+10, 1.8395e+10,
        1.7012e+10, 1.1843e+10, 1.5773e+10, 2.6675e+10, 2.8667e+10, 1.4172e+10,
        1.9522e+10, 1.4554e+10, 1.1986e+10, 2.0121e+10, 2.7197e+10, 1.3569e+10,
        1.6656e+10, 2.3997e+10, 1.5830e+10, 2.7671e+10, 1.4585e+10, 1.8463e+10,
        1.3293e+10, 3.5994e+10, 2.2213e+10, 1.5955e+10, 2.2038e+10, 1.6070e+10,
        2.2531e+10, 1.7388e+10, 1.8355e+10, 3.1011e+10, 2.9853e+10, 1.0985e+10,
        1.9460e+10, 2.5988e+10, 2.1339e+10, 2.0312e+10, 1.9562e+10, 2.5187e+10,
        2.7744e+10, 1.8927e+10, 2.0181e+10, 3.1302e+10, 1.2652e+10, 2.0650e+10,
        1.9550e+10, 3.5069e+10])
Layer: encoder.5.3.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.3909e+08, 2.2699e+07, 6.7965e+07, 1.1604e+08, 2.2885e+08, 8.2309e+08,
        2.4642e+07, 3.0910e+08, 1.2523e+09, 5.1327e+07, 8.1937e+07, 6.8879e+07,
        2.2127e+08, 4.4977e+08, 6.7436e+08, 4.7068e+08, 2.2331e+07, 8.5712e+08,
        3.7656e+08, 2.8059e+08, 3.3120e+08, 2.4120e+09, 2.6747e+08, 1.5826e+08,
        1.8343e+08, 1.6591e+08, 4.5861e+07, 8.0281e+08, 9.7153e+07, 1.9797e+08,
        5.1968e+07, 2.1046e+08, 3.1418e+08, 1.2229e+08, 5.5979e+08, 2.5169e+07,
        5.0285e+08, 2.8660e+08, 1.8087e+07, 1.2352e+08, 2.5837e+08, 2.5986e+08,
        1.6657e+08, 8.6740e+07, 5.0682e+07, 4.5194e+07, 3.0421e+08, 1.4410e+08,
        2.9917e+09, 1.7162e+08, 2.4389e+08, 1.8162e+08, 2.7322e+07, 4.9034e+08,
        7.9258e+07, 1.7698e+08, 2.2204e+09, 4.8690e+08, 3.3185e+08, 3.0121e+07,
        1.7288e+08, 9.9838e+07, 2.5186e+08, 1.1908e+09, 4.0058e+08, 3.3514e+08,
        9.0412e+08, 4.6246e+08, 2.1431e+08, 4.5591e+08, 3.6675e+08, 3.4840e+08,
        2.8168e+08, 2.8329e+07, 2.5801e+07, 1.3812e+09, 1.9236e+09, 9.0323e+08,
        1.4611e+07, 5.0529e+07, 6.6721e+07, 3.2068e+08, 8.2417e+08, 4.0209e+08,
        7.6066e+07, 5.6119e+08, 1.0311e+08, 1.6864e+09, 2.7559e+08, 9.9636e+07,
        3.2302e+08, 1.8365e+07, 4.9506e+09, 1.9246e+08, 2.2435e+08, 1.2401e+08,
        6.7303e+07, 1.3941e+08, 1.8854e+09, 2.4884e+08, 1.4531e+07, 6.0093e+07,
        3.5139e+08, 4.4222e+08, 1.8696e+08, 1.9068e+07, 6.7374e+08, 1.5527e+09,
        1.9375e+08, 4.1364e+08, 6.2771e+08, 3.1775e+08, 3.0681e+08, 1.2197e+08,
        2.9747e+07, 4.6439e+07, 1.0331e+08, 1.5303e+08, 6.4092e+08, 1.6752e+09,
        1.1836e+07, 9.9555e+07, 3.1138e+08, 1.2504e+08, 4.3647e+09, 1.2137e+08,
        3.0550e+08, 9.9003e+07, 3.0999e+08, 3.4649e+10, 5.2958e+08, 9.1867e+07,
        2.5323e+07, 6.5572e+08, 2.7376e+08, 6.5342e+09, 4.3184e+08, 8.1832e+08,
        1.2668e+08, 5.1515e+08, 2.9078e+08, 7.7324e+08, 9.5469e+08, 1.9680e+08,
        4.9024e+07, 4.9686e+08, 2.2414e+08, 2.9318e+08, 4.8547e+08, 3.9550e+08,
        1.5655e+08, 4.4073e+07, 2.8002e+08, 2.3113e+07, 2.8438e+08, 1.9364e+08,
        3.2934e+10, 1.8452e+08, 7.8414e+07, 3.5400e+08, 2.4628e+08, 5.2833e+08,
        2.1702e+07, 1.7747e+08, 3.8732e+08, 3.8072e+08, 2.9565e+08, 1.0409e+08,
        6.6804e+07, 1.8114e+07, 1.0342e+08, 2.9496e+07, 1.6936e+09, 8.7433e+07,
        6.2976e+07, 4.9896e+07, 2.1511e+08, 2.2190e+08, 3.6892e+08, 3.2059e+08,
        3.3675e+07, 8.2989e+08, 1.2618e+08, 2.4328e+08, 3.5371e+09, 1.3805e+08,
        1.8515e+09, 2.9030e+08, 1.1941e+08, 4.9458e+08, 5.2838e+08, 6.6006e+08,
        5.9264e+07, 2.8628e+08, 2.3501e+07, 1.3381e+08, 7.9797e+07, 4.5026e+09,
        3.1356e+08, 1.4265e+08, 5.2802e+08, 1.9953e+07, 1.0330e+08, 1.0486e+08,
        2.6987e+08, 3.3861e+08, 1.4496e+08, 1.4933e+08, 9.4972e+08, 3.3625e+08,
        2.9570e+08, 3.3335e+08, 1.3514e+09, 1.0337e+08, 1.8759e+08, 7.6737e+07,
        2.8574e+08, 3.7481e+08, 2.3483e+07, 2.7951e+08, 1.1279e+08, 2.7190e+07,
        5.3773e+08, 1.8853e+08, 2.4218e+08, 4.9507e+09, 3.0616e+08, 9.6912e+06,
        3.0817e+07, 2.0872e+09, 6.6414e+08, 2.9548e+08, 5.6411e+08, 6.1028e+08,
        6.4834e+06, 1.5041e+09, 8.1596e+08, 3.0160e+07, 3.6423e+08, 3.5643e+08,
        2.1944e+08, 2.9634e+08, 2.5993e+08, 1.9532e+08, 5.6090e+08, 2.4132e+09,
        3.9005e+07, 5.0964e+09, 5.0900e+08, 2.9178e+08, 6.7265e+08, 6.1966e+08,
        1.1902e+08, 6.1157e+08, 1.2138e+08, 5.5935e+08, 1.8701e+08, 2.0912e+08,
        1.0047e+08, 1.1555e+08, 7.6928e+06, 3.1810e+08, 3.0655e+09, 2.7431e+07,
        1.6418e+09, 1.3134e+09, 1.0362e+09, 2.3851e+08, 2.0092e+08, 2.0757e+08,
        2.1467e+08, 1.7286e+08, 8.2244e+08, 4.0764e+07, 5.0383e+07, 1.5351e+08,
        2.4397e+08, 7.1295e+07, 3.2727e+07, 3.9578e+08, 9.6067e+09, 2.1479e+08,
        9.2976e+07, 2.7889e+08, 2.5830e+08, 1.2487e+08, 1.0345e+08, 8.0316e+07,
        3.9075e+08, 9.4195e+08, 4.5642e+08, 2.6029e+09, 1.1532e+08, 1.2570e+08,
        5.0330e+08, 6.4318e+07, 2.8460e+07, 4.6817e+08, 2.2882e+08, 2.5065e+08,
        1.0809e+08, 9.2786e+07, 2.4372e+08, 2.8833e+07, 2.3469e+08, 1.1467e+08,
        1.6809e+09, 3.1053e+07, 1.1124e+08, 1.2348e+09, 1.1708e+08, 3.8745e+07,
        7.5002e+07, 1.0057e+09, 5.0949e+08, 1.4151e+08, 3.8223e+08, 3.2226e+08,
        2.4217e+08, 4.4166e+08, 1.0250e+09, 5.1274e+08, 8.7425e+07, 4.9457e+07,
        3.7793e+08, 6.7959e+07, 6.3895e+07, 5.5024e+08, 2.0705e+08, 5.4205e+08,
        6.2240e+08, 6.4032e+08, 1.0812e+08, 2.2345e+08, 5.3232e+08, 2.1345e+08,
        1.8029e+08, 2.2865e+08, 5.0468e+07, 7.8497e+07, 1.3673e+08, 7.3502e+08,
        6.8776e+07, 1.6558e+08, 9.7049e+07, 1.1113e+08, 1.4734e+08, 2.0621e+08,
        2.1376e+08, 2.2409e+08, 1.2421e+08, 1.6891e+08, 6.1498e+08, 2.1000e+08,
        1.1683e+09, 4.2377e+10, 5.4528e+07, 8.6337e+07, 5.0094e+07, 1.3942e+08,
        4.4651e+08, 4.6381e+08, 4.5316e+07, 6.0308e+07, 4.7303e+07, 1.8897e+08,
        2.5647e+08, 7.2119e+10, 3.9989e+08, 3.2391e+07, 4.4534e+07, 1.9855e+08,
        4.9011e+08, 4.2379e+08, 2.3845e+08, 1.2056e+09, 1.1406e+09, 1.1121e+09,
        2.7643e+08, 8.2328e+07, 1.6421e+09, 3.8156e+08, 1.6906e+09, 5.6582e+07,
        1.5165e+08, 3.0724e+09, 6.8082e+07, 7.3193e+08, 1.2777e+08, 2.2220e+08,
        2.0180e+08, 1.0868e+08, 7.5842e+08, 1.2515e+09, 9.2696e+07, 6.8727e+08,
        7.2475e+08, 6.2191e+06, 7.1798e+07, 2.1943e+08, 4.5507e+07, 5.5391e+07,
        8.3726e+07, 1.2412e+09, 3.2123e+08, 4.2182e+08, 1.4670e+07, 2.9037e+08,
        2.1008e+08, 1.0960e+08, 2.3205e+08, 3.1546e+07, 1.8446e+08, 3.7788e+08,
        1.2867e+08, 1.0903e+09, 6.3580e+08, 2.2882e+08, 2.5011e+08, 7.1854e+07,
        3.1734e+08, 1.6042e+08, 2.0650e+08, 2.5896e+08, 2.4136e+08, 1.8067e+09,
        2.1394e+08, 4.2993e+09, 1.4518e+08, 3.7165e+09, 2.2481e+08, 2.0207e+08,
        5.2458e+08, 1.7184e+09, 8.6764e+07, 6.6392e+07, 2.6691e+09, 3.3057e+08,
        3.4920e+07, 2.0656e+08, 1.1634e+08, 1.4547e+08, 5.4445e+08, 2.2907e+08,
        2.5601e+08, 1.5247e+09, 3.4165e+08, 6.0214e+07, 1.8998e+08, 1.2642e+09,
        5.1353e+08, 9.9156e+07, 4.3739e+08, 1.1934e+09, 1.6294e+08, 3.5173e+08,
        7.9099e+08, 2.8767e+08, 8.2738e+08, 2.9211e+08, 1.6579e+07, 1.1435e+08,
        1.0940e+08, 2.7020e+09, 3.7009e+08, 3.3708e+07, 3.1935e+08, 2.2816e+08,
        1.4600e+07, 1.7062e+09, 3.2395e+08, 6.3803e+07, 3.2949e+07, 2.1893e+08,
        3.3208e+08, 3.8933e+08, 2.2489e+08, 1.6655e+09, 3.9768e+08, 1.7285e+08,
        3.1304e+08, 4.2670e+07, 4.3145e+07, 1.6401e+07, 3.4097e+07, 1.2889e+08,
        1.1168e+08, 2.9761e+08, 5.8392e+08, 2.0211e+08, 1.6017e+08, 9.3462e+08,
        1.7681e+08, 1.1445e+08, 2.1526e+08, 4.6499e+08, 4.7211e+08, 1.0535e+09,
        7.5650e+07, 2.3277e+08, 1.1545e+08, 1.3858e+08, 7.7350e+07, 5.4652e+07,
        2.2525e+08, 2.1534e+08, 3.4097e+08, 1.0245e+08, 3.6355e+07, 2.0909e+08,
        3.8178e+08, 2.0369e+08])
Layer: encoder.6.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.7848e+08, 4.8718e+08, 2.2616e+08, 2.6483e+08, 4.0104e+08, 4.9201e+08,
        1.7234e+08, 2.2092e+08, 3.1430e+08, 4.4999e+08, 4.9076e+08, 5.9797e+08,
        4.0687e+08, 4.1836e+08, 4.8425e+08, 4.3219e+08, 2.9124e+08, 3.7126e+08,
        2.8142e+08, 4.4152e+08, 4.4814e+08, 3.2090e+08, 2.7658e+08, 4.2926e+08,
        5.5779e+08, 4.4727e+08, 4.7745e+08, 3.2074e+08, 5.8727e+08, 5.3957e+08,
        4.2024e+08, 6.1071e+08, 4.1573e+08, 5.6093e+08, 3.5483e+08, 2.6794e+08,
        6.5605e+08, 2.8835e+08, 6.0832e+08, 5.2640e+08, 3.0009e+08, 5.7834e+08,
        4.0622e+08, 3.6907e+08, 4.8825e+08, 3.0319e+08, 4.6147e+08, 7.6985e+08,
        4.5892e+08, 3.3763e+08, 4.2679e+08, 5.0910e+08, 4.0677e+08, 3.3924e+08,
        2.9220e+08, 2.5116e+08, 3.7992e+08, 4.3492e+08, 3.9886e+08, 5.9778e+08,
        6.7481e+08, 3.4290e+08, 2.3069e+08, 3.2710e+08, 2.4301e+08, 3.5110e+08,
        3.0081e+08, 4.8929e+08, 5.2559e+08, 2.6380e+08, 3.9010e+08, 4.0836e+08,
        5.2735e+08, 5.7362e+08, 4.3041e+08, 3.0770e+08, 4.4906e+08, 4.7968e+08,
        2.8973e+08, 4.4526e+08, 2.8209e+08, 5.1851e+08, 4.3463e+08, 4.5346e+08,
        3.8226e+08, 4.1095e+08, 5.5583e+08, 4.9100e+08, 4.9397e+08, 2.8013e+08,
        2.4327e+08, 3.4293e+08, 5.6048e+08, 7.8068e+08, 2.5043e+08, 4.4938e+08,
        2.4755e+08, 8.7367e+08, 5.1564e+08, 5.8367e+08, 3.8659e+08, 4.5903e+08,
        3.8641e+08, 5.0098e+08, 7.8982e+08, 5.1287e+08, 4.8715e+08, 5.0485e+08,
        7.1636e+08, 4.1267e+08, 3.2276e+08, 3.5694e+08, 1.8551e+08, 5.6088e+08,
        3.5521e+08, 4.5634e+08, 4.2907e+08, 2.7025e+08, 2.8802e+08, 3.2997e+08,
        4.2628e+08, 3.0220e+08, 4.4162e+08, 3.7604e+08, 3.6700e+08, 2.4062e+08,
        5.6736e+08, 3.6159e+08, 5.4335e+08, 3.9273e+08, 3.9693e+08, 6.0292e+08,
        5.6479e+08, 3.8615e+08, 3.6804e+08, 4.2601e+08, 4.7019e+08, 4.0823e+08,
        4.2925e+08, 5.0517e+08, 2.7851e+08, 3.3767e+08, 7.5397e+08, 7.0007e+08,
        6.0442e+08, 3.3367e+08, 4.8900e+08, 5.2858e+08, 3.7689e+08, 2.4692e+08,
        3.5797e+08, 3.7123e+08, 5.1169e+08, 2.0868e+08, 4.1415e+08, 4.4995e+08,
        4.3581e+08, 4.4307e+08, 5.6368e+08, 3.1753e+08, 5.4827e+08, 3.2987e+08,
        2.6177e+08, 4.7914e+08, 4.0116e+08, 5.3084e+08, 2.2984e+08, 2.3453e+08,
        2.2298e+08, 3.4297e+08, 4.2426e+08, 4.5299e+08, 5.6361e+08, 3.5792e+08,
        3.2338e+08, 2.6151e+08, 3.2880e+08, 5.8548e+08, 3.8499e+08, 5.4578e+08,
        2.9901e+08, 5.2124e+08, 5.5176e+08, 3.4733e+08, 4.9407e+08, 3.4706e+08,
        2.5321e+08, 4.2253e+08, 2.6575e+08, 5.5771e+08, 3.4212e+08, 4.1199e+08,
        2.0432e+08, 7.6700e+08, 2.9038e+08, 4.6309e+08, 4.5015e+08, 6.4413e+08,
        3.8329e+08, 3.1706e+08, 4.9844e+08, 3.4295e+08, 5.3976e+08, 6.1945e+08,
        3.6791e+08, 3.4566e+08, 3.3171e+08, 2.3358e+08, 3.3117e+08, 4.1736e+08,
        3.7127e+08, 3.7757e+08, 5.5569e+08, 3.4460e+08, 3.4564e+08, 3.9833e+08,
        4.2547e+08, 4.4834e+08, 3.8116e+08, 2.3495e+08, 4.6452e+08, 3.3175e+08,
        4.7163e+08, 3.2619e+08, 3.7886e+08, 4.6268e+08, 4.3288e+08, 5.5045e+08,
        2.8476e+08, 4.8067e+08, 4.2468e+08, 4.3642e+08, 6.0875e+08, 6.5695e+08,
        6.4924e+08, 2.6818e+08, 3.5656e+08, 2.5478e+08, 2.3162e+08, 5.9700e+08,
        3.6485e+08, 3.1516e+08, 3.6192e+08, 7.1415e+08, 4.3094e+08, 3.3469e+08,
        4.9955e+08, 3.3621e+08, 3.4601e+08, 4.3091e+08, 2.2965e+08, 2.9545e+08,
        4.1567e+08, 4.5766e+08, 4.8861e+08, 3.3193e+08])
Layer: encoder.6.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([9.3638e+08, 9.6244e+08, 6.2275e+08, 6.5622e+08, 1.0842e+09, 5.4590e+08,
        7.6086e+08, 7.2058e+08, 6.9251e+08, 5.7092e+08, 9.9427e+08, 5.0850e+08,
        1.0069e+09, 1.1571e+09, 9.1870e+08, 9.7057e+08, 9.4786e+08, 8.1718e+08,
        8.5388e+08, 6.5180e+08, 8.1081e+08, 9.6099e+08, 7.2276e+08, 6.6817e+08,
        5.4632e+08, 1.1085e+09, 7.6966e+08, 9.3162e+08, 5.8301e+08, 1.3234e+09,
        6.7081e+08, 6.8533e+08, 6.6450e+08, 6.6839e+08, 5.6562e+08, 8.1105e+08,
        9.8303e+08, 9.2660e+08, 7.6851e+08, 1.1143e+09, 4.1907e+08, 5.1367e+08,
        6.5945e+08, 3.0976e+08, 1.1759e+09, 7.2762e+08, 1.0437e+09, 1.1153e+09,
        9.6963e+08, 9.1415e+08, 4.4854e+08, 8.1279e+08, 1.5665e+09, 9.4080e+08,
        7.5598e+08, 1.1442e+09, 6.8483e+08, 1.3665e+09, 5.5917e+08, 1.0416e+09,
        1.1329e+09, 9.5846e+08, 9.5125e+08, 8.9809e+08, 7.7681e+08, 7.9510e+08,
        7.2035e+08, 1.1021e+09, 4.9477e+08, 7.2932e+08, 9.4290e+08, 6.4190e+08,
        8.3443e+08, 1.4604e+09, 1.0731e+09, 1.0468e+09, 1.2317e+09, 7.8228e+08,
        8.8927e+08, 9.2866e+08, 8.7906e+08, 4.4358e+08, 9.1106e+08, 1.3541e+09,
        9.1373e+08, 8.8162e+08, 7.2081e+08, 1.1722e+09, 8.7106e+08, 5.5566e+08,
        8.7099e+08, 5.9305e+08, 8.7830e+08, 4.9239e+08, 7.1763e+08, 1.0827e+09,
        1.2832e+09, 1.4298e+09, 1.1343e+09, 1.0120e+09, 9.9607e+08, 7.9375e+08,
        8.9669e+08, 1.0583e+09, 5.9324e+08, 8.7145e+08, 4.9426e+08, 1.4926e+09,
        3.9482e+08, 5.6176e+08, 1.0128e+09, 9.2870e+08, 1.2962e+09, 7.7554e+08,
        7.2873e+08, 7.7897e+08, 5.4432e+08, 1.0101e+09, 4.9717e+08, 1.0432e+09,
        5.6194e+08, 1.3517e+09, 4.8633e+08, 7.4132e+08, 3.9919e+08, 9.6707e+08,
        4.3818e+08, 1.0836e+09, 6.0460e+08, 1.0520e+09, 6.8688e+08, 9.2435e+08,
        4.1721e+08, 5.0728e+08, 1.2195e+09, 7.2558e+08, 5.3115e+08, 8.9512e+08,
        1.1390e+09, 7.6477e+08, 8.6647e+08, 5.7598e+08, 5.8495e+08, 7.5837e+08,
        1.1206e+09, 1.4385e+09, 1.2694e+09, 6.9597e+08, 1.0586e+09, 7.3714e+08,
        7.8497e+08, 1.3271e+09, 1.0627e+09, 8.3447e+08, 1.1504e+09, 7.6289e+08,
        8.8542e+08, 6.7762e+08, 7.9702e+08, 6.1666e+08, 1.1714e+09, 6.1327e+08,
        1.0775e+09, 1.1621e+09, 7.4405e+08, 4.9411e+08, 7.5477e+08, 9.4983e+08,
        5.5489e+08, 1.2205e+09, 1.0385e+09, 1.0086e+09, 6.2992e+08, 9.8127e+08,
        7.7895e+08, 7.7866e+08, 8.9393e+08, 6.3397e+08, 5.2495e+08, 9.5788e+08,
        7.2630e+08, 1.1017e+09, 9.5580e+08, 9.3143e+08, 8.3588e+08, 4.2801e+08,
        8.6507e+08, 3.9601e+08, 7.3870e+08, 9.3137e+08, 7.2000e+08, 8.7634e+08,
        9.2493e+08, 1.1062e+09, 1.1260e+09, 8.1067e+08, 5.9360e+08, 5.2431e+08,
        5.9959e+08, 6.9939e+08, 3.4178e+08, 1.3564e+09, 7.9760e+08, 6.9041e+08,
        7.0379e+08, 6.9214e+08, 6.7222e+08, 9.8032e+08, 9.2881e+08, 6.3685e+08,
        1.0392e+09, 4.9967e+08, 8.0275e+08, 7.9295e+08, 1.0155e+09, 5.9059e+08,
        5.3192e+08, 1.1961e+09, 6.4508e+08, 8.2840e+08, 7.9101e+08, 8.3029e+08,
        1.5039e+09, 6.7090e+08, 1.0444e+09, 8.1652e+08, 9.2791e+08, 8.9182e+08,
        5.9196e+08, 5.7189e+08, 6.0808e+08, 1.1490e+09, 7.5418e+08, 1.0725e+09,
        6.0414e+08, 8.4663e+08, 8.6074e+08, 1.0293e+09, 9.4520e+08, 1.0625e+09,
        8.5598e+08, 5.6627e+08, 1.3614e+09, 6.0781e+08, 6.9599e+08, 1.2545e+09,
        8.5123e+08, 8.1225e+08, 5.9286e+08, 8.4380e+08, 7.2511e+08, 8.4266e+08,
        9.6115e+08, 1.0891e+09, 8.1310e+08, 5.6882e+08])
Layer: encoder.6.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5.9165e+06, 8.3748e+06, 1.7750e+06,  ..., 2.3719e+07, 9.2168e+08,
        7.5718e+07])
Layer: encoder.6.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.0362e+07, 1.7124e+07, 6.7836e+06,  ..., 6.3487e+07, 5.2473e+08,
        9.9979e+07])
Layer: encoder.6.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.7145e+07, 5.7890e+07, 4.2547e+07, 1.3616e+08, 6.6050e+07, 3.1718e+07,
        6.7510e+07, 3.4049e+07, 8.6229e+07, 4.6763e+07, 2.6623e+07, 5.3132e+07,
        4.5851e+07, 4.2242e+07, 9.1620e+07, 3.1428e+07, 7.0205e+07, 8.4985e+07,
        6.4830e+07, 6.7935e+07, 7.2036e+07, 3.4000e+07, 1.2483e+08, 6.5012e+07,
        7.6512e+07, 6.2331e+07, 7.7011e+07, 7.3464e+07, 5.6892e+07, 7.8130e+07,
        4.9723e+07, 4.1458e+07, 4.8753e+07, 1.1779e+08, 7.9710e+07, 8.1079e+07,
        3.3527e+07, 4.2663e+07, 1.2154e+08, 1.3548e+08, 6.4143e+07, 7.0440e+07,
        3.0775e+07, 4.1102e+07, 1.1669e+08, 4.9937e+07, 4.4179e+07, 6.5865e+07,
        4.3562e+07, 7.9468e+07, 8.1675e+07, 1.2219e+08, 3.0238e+07, 2.9877e+07,
        4.0710e+07, 1.1079e+08, 2.1856e+07, 4.3621e+07, 7.4571e+07, 1.0813e+08,
        1.2084e+08, 5.2214e+07, 5.1615e+07, 5.3239e+07, 1.2108e+08, 7.1204e+07,
        3.4807e+07, 7.5918e+07, 4.2662e+07, 4.6689e+07, 6.8111e+07, 4.8813e+07,
        4.0663e+07, 4.7197e+07, 4.5787e+07, 4.0465e+07, 6.6768e+07, 7.4745e+07,
        5.1414e+07, 4.3351e+07, 6.8632e+07, 1.1049e+08, 8.9398e+07, 5.5905e+07,
        6.8925e+07, 3.3500e+07, 8.6832e+07, 5.1201e+07, 8.6948e+07, 8.9012e+07,
        2.2129e+07, 4.2730e+07, 4.6609e+07, 5.8857e+07, 1.0469e+08, 3.2760e+07,
        7.8237e+07, 1.5935e+07, 1.5238e+08, 2.5964e+07, 4.4641e+07, 8.9099e+07,
        9.8729e+07, 4.2804e+07, 1.7192e+07, 6.5259e+07, 2.5294e+07, 9.4330e+07,
        3.2971e+07, 3.5486e+07, 7.0545e+07, 9.4542e+07, 7.0040e+07, 6.0339e+07,
        4.0554e+07, 2.6035e+07, 5.9175e+07, 6.8505e+07, 1.8077e+07, 3.1913e+07,
        3.3038e+07, 4.7445e+07, 6.2652e+07, 1.0328e+08, 9.1799e+07, 8.6818e+07,
        5.0531e+07, 3.2977e+07, 2.8793e+07, 7.5822e+07, 6.4242e+07, 4.9721e+07,
        1.0676e+08, 3.7304e+07, 2.5122e+07, 6.5446e+07, 1.1406e+08, 2.2266e+07,
        6.2132e+07, 9.8710e+07, 5.1661e+07, 6.7851e+07, 6.2787e+07, 7.1294e+07,
        8.7533e+07, 1.1673e+08, 3.4750e+07, 1.0818e+08, 9.4162e+07, 5.8081e+07,
        1.3302e+08, 2.9559e+07, 5.5304e+07, 5.0986e+07, 9.9857e+07, 1.6822e+07,
        9.2204e+07, 8.3062e+07, 8.7403e+07, 1.5579e+07, 8.5463e+07, 8.1167e+07,
        7.1424e+07, 2.9767e+07, 4.3877e+07, 4.1745e+07, 4.5609e+07, 5.5962e+07,
        1.4619e+07, 1.3687e+08, 4.4283e+07, 1.1041e+08, 8.2345e+07, 5.8830e+07,
        4.1683e+07, 6.4272e+07, 1.4687e+08, 6.4544e+07, 2.2924e+07, 6.2404e+07,
        5.5365e+07, 3.7981e+07, 8.3690e+07, 9.2169e+07, 3.8674e+07, 6.3289e+07,
        5.3923e+07, 4.5919e+07, 9.7136e+07, 6.1508e+07, 8.3933e+07, 4.1283e+07,
        1.1109e+08, 8.1041e+07, 1.2058e+08, 5.4745e+07, 7.8679e+07, 1.7091e+07,
        3.8618e+07, 6.7398e+07, 2.7948e+07, 2.6806e+07, 4.5580e+07, 1.0028e+08,
        3.6166e+07, 7.1539e+07, 6.1545e+07, 2.7193e+07, 8.4786e+07, 4.2795e+07,
        5.7032e+07, 9.4637e+07, 1.4052e+08, 5.8614e+07, 4.5785e+07, 4.1894e+07,
        3.1295e+07, 1.0946e+08, 7.7480e+07, 2.7511e+07, 3.5923e+07, 7.7031e+07,
        6.9592e+07, 4.7090e+07, 6.7015e+07, 2.4805e+07, 4.4463e+07, 4.7649e+07,
        5.9493e+07, 2.6175e+07, 1.2409e+08, 7.9367e+07, 4.2441e+07, 3.5184e+07,
        9.3195e+07, 7.3346e+07, 1.0441e+08, 5.2671e+07, 3.7765e+07, 1.2680e+08,
        1.0015e+08, 1.6558e+07, 7.7704e+07, 5.6730e+07, 8.9300e+07, 9.4989e+07,
        9.3055e+07, 6.5038e+07, 6.4071e+07, 4.7062e+07, 4.1332e+07, 3.8867e+07,
        4.4937e+07, 2.3440e+07, 4.8501e+07, 4.9501e+07])
Layer: encoder.6.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.2455e+08, 1.0378e+08, 5.0031e+07, 2.5952e+08, 3.1157e+08, 1.8711e+08,
        2.3546e+08, 1.8236e+08, 1.1604e+08, 7.7407e+07, 1.6234e+08, 2.7743e+08,
        8.4760e+07, 9.8763e+07, 2.0235e+08, 2.3360e+08, 2.4316e+08, 2.5797e+08,
        1.5358e+08, 1.8220e+08, 4.4990e+07, 1.4438e+08, 1.3755e+08, 1.6794e+08,
        1.2340e+08, 5.8300e+07, 1.5340e+08, 1.9279e+08, 1.1771e+08, 9.4744e+07,
        2.6876e+08, 1.6980e+08, 1.6631e+08, 2.2028e+08, 2.0622e+08, 1.2557e+08,
        8.7356e+07, 2.0289e+08, 3.2475e+08, 2.6375e+08, 9.9210e+07, 8.6384e+07,
        2.4982e+08, 2.8455e+08, 2.3244e+08, 5.9900e+07, 8.9511e+07, 2.7660e+08,
        8.9220e+07, 1.8083e+08, 1.1728e+08, 3.4938e+08, 3.9947e+08, 1.0511e+08,
        5.1063e+07, 1.1048e+08, 1.3973e+08, 2.2726e+08, 3.1698e+08, 6.8322e+07,
        2.1148e+08, 1.8608e+08, 5.0100e+08, 9.9288e+07, 2.2245e+08, 3.3569e+08,
        8.7915e+07, 8.3444e+07, 1.7601e+08, 1.1397e+08, 1.3657e+08, 7.2917e+07,
        1.5298e+08, 8.5949e+07, 1.8302e+08, 9.2522e+07, 1.0327e+08, 8.9523e+07,
        3.4025e+08, 2.5179e+08, 3.0914e+08, 1.1849e+08, 2.4069e+08, 1.2410e+08,
        1.3225e+08, 8.5527e+07, 1.0802e+08, 5.8496e+07, 1.4670e+08, 1.5383e+08,
        1.5151e+08, 3.5205e+08, 2.3487e+08, 2.1405e+08, 9.0481e+07, 8.9486e+07,
        2.5875e+08, 1.9435e+08, 2.4852e+08, 3.8383e+08, 1.3249e+08, 4.4066e+07,
        1.9477e+08, 1.8887e+08, 1.0112e+08, 7.7533e+07, 2.3155e+08, 3.0340e+08,
        8.6298e+07, 1.3780e+08, 1.1568e+08, 6.5371e+07, 1.1150e+08, 9.1416e+07,
        1.2384e+08, 2.5987e+08, 1.1907e+08, 1.1938e+08, 1.6108e+08, 5.8348e+07,
        2.7794e+08, 2.8060e+08, 2.9140e+08, 1.4072e+08, 5.7443e+07, 2.0401e+08,
        3.4916e+08, 3.5711e+08, 4.9957e+07, 1.6223e+08, 1.9208e+08, 7.6749e+07,
        8.4557e+07, 1.4910e+08, 1.8703e+08, 4.4816e+08, 1.8777e+08, 2.2589e+08,
        9.3695e+07, 1.7216e+08, 1.1672e+08, 1.0821e+08, 2.7661e+08, 1.5157e+08,
        1.3217e+08, 2.0500e+08, 1.7203e+08, 1.6357e+08, 1.8606e+08, 1.0638e+08,
        3.1782e+08, 1.2232e+08, 2.0897e+08, 7.8151e+07, 2.2421e+08, 3.6649e+08,
        1.3760e+08, 2.9210e+08, 2.9692e+07, 1.2868e+08, 7.4160e+07, 6.9120e+07,
        3.0904e+08, 2.4979e+08, 1.0914e+08, 6.1208e+07, 2.9434e+08, 6.3260e+07,
        5.7993e+07, 7.1854e+07, 1.3829e+08, 3.1864e+08, 4.1833e+08, 2.9094e+08,
        1.4630e+08, 1.3752e+08, 1.0547e+08, 1.7048e+08, 1.3239e+08, 1.7063e+08,
        8.6890e+07, 1.3713e+08, 6.0663e+07, 1.0173e+08, 1.8955e+08, 1.5447e+08,
        9.8369e+07, 2.4866e+08, 2.2911e+08, 2.9702e+08, 1.8112e+08, 1.0104e+08,
        2.5574e+08, 2.2508e+08, 2.3278e+08, 2.0460e+08, 1.2814e+08, 1.1481e+08,
        4.6141e+07, 1.7870e+08, 1.0604e+08, 8.7059e+07, 2.0112e+08, 1.1825e+08,
        2.4957e+08, 6.8308e+07, 8.7096e+07, 2.0549e+08, 1.1421e+08, 6.7327e+07,
        6.0640e+07, 2.2967e+08, 3.6714e+08, 2.1781e+08, 1.1737e+08, 5.7471e+08,
        2.2776e+08, 1.0461e+08, 4.2300e+08, 1.7290e+08, 1.5002e+08, 1.2318e+08,
        3.7066e+08, 7.2844e+07, 1.4627e+08, 1.3162e+08, 2.9913e+08, 1.9621e+08,
        2.1066e+08, 1.7375e+08, 6.0772e+07, 2.6865e+08, 1.9609e+08, 1.4069e+08,
        3.2712e+08, 2.0841e+08, 6.2876e+07, 1.3863e+08, 1.6018e+08, 2.6799e+08,
        1.8650e+08, 2.4497e+08, 5.8138e+07, 8.6074e+07, 1.7200e+08, 1.5823e+08,
        1.0472e+08, 1.4596e+08, 1.2192e+08, 1.3907e+08, 9.9024e+07, 4.3032e+08,
        2.1182e+08, 2.7006e+08, 1.6303e+08, 1.4475e+08])
Layer: encoder.6.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.4060e+05, 1.4492e+06, 3.6828e+05,  ..., 1.0035e+06, 1.4342e+09,
        2.5735e+06])
Layer: encoder.6.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 4103990.5000,  5522042.0000,  9114208.0000,  5317206.0000,
         6508066.5000,  7036832.5000,  4466906.5000,  3358105.5000,
         3237821.0000,  4854943.5000,  3387765.2500,  4871235.5000,
         3913695.5000,  3926346.5000,  6351339.5000,  4511343.0000,
         4441346.0000,  4301351.0000,  8675085.0000,  4349112.0000,
         3144023.5000,  4935450.0000,  3580460.5000,  4677614.0000,
         4565662.5000,  6321384.5000,  7151907.0000,  6600408.0000,
         4436232.5000,  4299721.0000,  5468405.0000,  4693409.5000,
         4936895.5000,  7201753.0000,  5465489.0000,  5460360.0000,
         5473272.5000,  4488424.0000,  7729414.5000,  4550678.0000,
         3423982.5000,  6724309.0000,  6779795.0000,  5877254.5000,
         4794553.0000,  6033463.5000,  9144092.0000,  4681167.5000,
         4998377.0000,  5608057.5000,  4510854.5000,  5772108.5000,
         3722217.5000,  3577618.2500,  6295208.0000,  3530938.2500,
         5837467.0000,  5398664.5000,  5784915.0000,  6806809.0000,
         5018723.0000,  4393937.5000,  3564978.0000,  5797035.5000,
         4387868.0000,  3399060.5000,  7422809.0000,  4298194.5000,
         4845527.0000,  4935331.5000,  4100393.0000,  5398156.0000,
         5056974.5000,  4200098.0000,  9723272.0000,  8237522.0000,
         3648087.0000,  4436746.0000,  4382314.0000,  7504598.5000,
         3529021.0000,  3290260.5000,  4583648.0000,  6228170.5000,
         4239263.5000,  7687705.5000,  5213543.5000,  4604672.5000,
         4006634.0000,  6518590.5000,  4221532.0000,  3712555.7500,
         7271452.5000,  6500170.0000,  6599524.5000,  4993726.5000,
         8287371.0000,  8050198.0000,  5542529.0000,  4203840.5000,
        10357847.0000,  3829446.0000,  4667971.0000,  5690492.5000,
         3449725.0000,  3623469.7500,  3768693.5000,  4879178.0000,
         8746835.0000,  4150536.5000,  3770806.5000,  4320290.0000,
         6830994.0000,  3770004.7500,  3788583.5000,  3785486.2500,
         3571132.5000,  8552058.0000,  9091479.0000,  6297563.5000,
         8094062.5000,  4416794.0000,  8227514.0000,  3795083.5000,
         5040299.5000,  6606975.0000,  5017404.0000,  3851715.2500,
         4913240.5000,  3563472.2500,  3196420.2500,  3107785.5000,
        10263578.0000,  5758960.0000,  6334984.0000,  2861702.0000,
         5751357.5000,  4147027.7500,  5178569.0000,  5713631.0000,
         4707483.0000,  5294025.5000,  5640675.5000,  5755656.0000,
         4263338.5000,  4937619.0000,  3463248.7500, 11103081.0000,
         7510452.0000,  4134335.2500,  7519442.5000,  7645286.0000,
         6958975.0000,  9224271.0000,  3407779.7500,  2761609.7500,
         5394904.5000,  3206192.7500,  4389321.5000,  4097333.2500,
         4321548.0000,  6208800.5000,  7553202.0000,  8141269.0000,
         4888960.5000,  3861399.5000,  5980599.5000,  4120446.2500,
         6408956.0000,  6921528.5000,  4308792.5000,  6748415.0000,
         7078681.0000,  6651741.5000,  8759813.0000,  5658282.5000,
         4322154.5000,  5782342.5000,  4269393.5000,  5405492.5000,
         6714915.5000,  4626129.0000,  3795022.2500,  4039438.2500,
         5426817.0000,  4886261.0000,  4051512.0000,  6779569.0000,
         4008472.7500,  2827067.5000,  2947546.7500,  3694338.0000,
         5458503.5000,  6932377.0000,  8773554.0000,  5256374.0000,
         3074014.2500,  6998008.5000,  6545662.5000,  4186773.5000,
         5769359.0000,  6337395.5000,  6233799.5000,  4447680.5000,
        11677098.0000,  2519310.5000,  4767296.0000,  6222978.0000,
         4999004.5000,  5677573.0000,  7870081.5000,  3720157.2500,
         7041863.5000,  5159953.5000,  8648547.0000,  5314997.5000,
         4921129.5000,  7377019.0000,  3092907.5000,  6346622.0000,
         4753840.5000,  5397258.5000,  5009560.5000,  9206319.0000,
         3205552.7500,  5370468.0000,  5357047.5000,  6212130.0000,
         5957281.5000,  3982288.5000,  7545535.0000,  6543640.0000,
         4365049.0000,  5337460.0000,  5837956.5000,  7874513.5000,
         3276225.0000,  3474441.2500,  4231299.0000,  4865009.0000,
         6235404.5000,  4010850.0000,  4599005.5000,  3508073.7500,
         3657098.7500,  5005435.0000,  5019419.0000,  5133740.0000,
         6240743.5000,  3911509.2500,  5154633.5000,  5161700.0000,
         4911046.0000,  5076102.0000,  4467353.0000,  5442271.0000])
Layer: encoder.6.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([15013719.0000, 17985532.0000, 12591606.0000, 13125201.0000,
        17523786.0000, 17285034.0000, 12302228.0000, 26198854.0000,
        12479958.0000, 18721578.0000, 11012084.0000, 14229614.0000,
        19080684.0000, 16177884.0000, 18273190.0000,  8866394.0000,
        17053044.0000, 11600303.0000, 15468681.0000, 19081844.0000,
        15902802.0000, 19938256.0000, 11040861.0000, 11225276.0000,
        24800264.0000, 12581934.0000,  9122387.0000, 24702838.0000,
        13986587.0000,  9305095.0000, 18767990.0000, 16962414.0000,
        16300893.0000, 16007350.0000, 17216820.0000, 10254627.0000,
        21946896.0000,  9934743.0000, 26165594.0000, 20335414.0000,
        20391556.0000, 15509104.0000, 20644854.0000, 24936598.0000,
        22424518.0000,  8177167.5000, 12206475.0000, 20224030.0000,
        19352858.0000, 27996386.0000, 11055692.0000, 10711970.0000,
        17581460.0000,  8885459.0000, 21485564.0000, 14897278.0000,
        18513466.0000, 14321783.0000, 12572544.0000, 13533856.0000,
        15106568.0000, 15808466.0000, 11714302.0000,  9029265.0000,
        13405593.0000, 15477935.0000, 17250430.0000, 15090156.0000,
        13132528.0000, 11783333.0000, 14790251.0000, 12310637.0000,
        12534232.0000, 10927586.0000, 18081208.0000, 24741188.0000,
        12963696.0000, 13640809.0000, 13436400.0000, 14248649.0000,
        14868885.0000, 21854362.0000,  8311019.5000, 17780038.0000,
        17717434.0000, 31788284.0000, 29883446.0000, 22244242.0000,
        12468352.0000,  9118532.0000, 17790066.0000, 16524216.0000,
        17368722.0000, 32577372.0000, 13084668.0000, 15297538.0000,
        10586199.0000, 13316001.0000, 10518636.0000, 10563119.0000,
        16250570.0000, 18984050.0000,  9608875.0000, 15295938.0000,
        11587302.0000, 17375676.0000, 18987896.0000, 23995448.0000,
         9918997.0000, 13615383.0000, 19496484.0000, 10050808.0000,
        12826875.0000, 12202764.0000, 19334038.0000, 15830917.0000,
        12110758.0000, 19019796.0000, 17877846.0000, 20891218.0000,
        12739304.0000, 25824766.0000, 14165868.0000, 11780606.0000,
        23547922.0000, 28332612.0000, 13918560.0000, 24778370.0000,
        24414542.0000, 19473740.0000, 12666623.0000, 15183199.0000,
        13104134.0000, 24312090.0000, 10847875.0000, 10147676.0000,
         8615461.0000,  8906253.0000, 19593962.0000, 15642101.0000,
        21950438.0000, 19992854.0000, 17114230.0000, 19100230.0000,
        18287630.0000, 18432960.0000, 11378830.0000, 13390936.0000,
        11642849.0000, 11600637.0000, 15217019.0000, 20798344.0000,
        12007074.0000, 15815599.0000, 12065647.0000, 15884206.0000,
        17853726.0000, 13655202.0000, 28069332.0000, 20096542.0000,
        24264296.0000, 30391922.0000, 21089886.0000, 16918150.0000,
        26302792.0000, 15694540.0000, 17248610.0000, 28945614.0000,
        22795052.0000, 14392839.0000, 14569452.0000, 14039842.0000,
        11886059.0000, 10371292.0000, 13697849.0000, 36673100.0000,
        26702058.0000, 13953707.0000, 27955034.0000, 18203578.0000,
        20107504.0000,  9084319.0000, 14281262.0000, 12478453.0000,
        22372900.0000, 17820778.0000, 13658445.0000, 12466195.0000,
        10170106.0000, 10647315.0000, 10984429.0000, 18444518.0000,
         9181375.0000, 27128122.0000, 22621902.0000, 33553614.0000,
        25313652.0000, 13332986.0000, 12513226.0000,  9585363.0000,
        19869068.0000, 14903957.0000, 10020191.0000, 18703554.0000,
        13696864.0000, 24930312.0000, 11708646.0000, 19464848.0000,
        14643507.0000, 11468789.0000, 25721388.0000, 10545091.0000,
        24319660.0000, 12561454.0000, 15935466.0000, 20101736.0000,
        15564643.0000, 10788805.0000, 18825364.0000, 19755162.0000,
        16159602.0000, 18683530.0000, 12061857.0000, 21411798.0000,
        13686116.0000,  9500363.0000, 14311734.0000, 15906829.0000,
        14186681.0000, 19715848.0000,  9105374.0000, 19600446.0000,
        12473678.0000, 11044378.0000,  9583597.0000, 26601626.0000,
        15148269.0000,  8345164.0000, 13118531.0000, 12279183.0000,
        21456080.0000, 11119090.0000, 17382298.0000, 22737806.0000,
        12942962.0000, 10985235.0000, 11491561.0000, 10951607.0000,
        18933124.0000,  9709167.0000, 10482782.0000, 15982476.0000,
        11477143.0000, 17828906.0000, 11025480.0000, 12926609.0000])
Layer: encoder.6.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 60953.0664, 675598.7500,  33293.7930,  ...,  32279.0254,
         87874.1875, 203636.6406])
Layer: encoder.6.3.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 570955.8125,  852632.5000,  589217.3125,  631349.5625,  646092.8125,
         718639.5000,  725625.2500,  909591.0625,  637537.9375,  575013.0000,
         568303.1250,  626850.8750,  483068.4688,  774377.8750,  742239.7500,
         614223.6875,  761048.6875,  484660.5625,  733980.4375,  734151.3125,
         722891.3125,  554126.3750,  554620.4375,  817113.6875,  568197.1250,
         520358.3438,  605107.1875,  858964.5000,  476883.0000,  734322.5000,
         466244.3750,  668984.6875,  596583.6250,  750988.1250,  608589.0000,
         790342.6875,  633740.1875,  609132.3750,  511389.9688,  673764.0000,
         570648.5000,  490825.1562,  498057.6250,  806229.9375,  609295.6250,
         778794.1250,  717940.5625,  549499.6875,  670785.1250,  609006.0625,
         490834.7812,  662354.9375,  641051.5625,  366899.7188,  510513.2188,
         621702.6875,  667484.0625,  476525.3125,  737726.7500,  505422.3750,
         585236.8125,  605447.8125,  485532.4062,  689659.6875,  591980.3750,
         619383.4375,  505261.7188,  662587.3125,  627986.1875,  515670.1250,
         682128.6875,  675837.3125,  664033.4375,  597275.5625,  562375.2500,
         722103.8125,  551050.4375,  872036.1875,  672875.0000,  699411.3125,
         643972.6250,  542989.7500,  575428.7500,  481671.5625, 1079094.0000,
         555698.6875,  458581.1562,  500066.4062,  667772.3125,  770285.4375,
         618874.2500,  686596.6875,  532574.2500,  623086.2500,  604590.8125,
         587222.8750,  467696.8125,  605862.9375,  566451.0000,  429407.5312,
         580342.6875,  605717.8125,  438455.4688,  577244.8750,  912591.1250,
         462514.5938,  724719.9375,  463321.6250,  815349.3125,  624410.2500,
         683780.3125,  788539.1875,  608657.3750,  664120.5000,  631998.2500,
         826893.0625,  807518.0625,  730096.9375,  778143.1875,  583342.2500,
         701504.4375,  497924.2188,  691017.7500,  787642.3750,  747063.2500,
         709552.7500,  530042.2500,  585472.1875,  496104.0625,  730272.8750,
         620117.6250, 1032115.5625,  623220.0000,  489130.7812,  547627.0625,
         639600.4375,  608304.5625,  572107.3750,  496574.3125,  696850.4375,
         587536.4375,  693049.6875,  701846.3750,  863902.9375,  602311.1250,
         603797.2500,  500596.6250,  634166.9375,  507522.1250,  603161.1250,
         710101.6250,  636208.0000,  600620.1250,  510411.7188,  651417.1875,
         676085.0000,  581370.9375,  812466.8125,  395794.7188,  395820.6875,
         569371.2500,  859263.6875,  664464.6875,  696826.6250,  464105.9062,
         493581.2500,  646238.9375,  457152.6875,  565859.7500,  555943.8125,
         693463.4375,  693421.5625,  527382.4375,  598780.3750,  531174.5625,
         470813.6562,  710486.9375,  651957.4375,  577617.1875,  686198.0000,
         836902.9375,  630876.5625,  820386.2500,  552071.3125,  787280.1250,
         584382.3125,  724147.0625,  646880.0625,  574708.6875,  623222.3750,
         564411.3125,  667301.0625,  814618.6875,  581516.7500,  694098.3125,
         605933.5625,  489726.2812,  659138.4375,  704723.1875,  712835.1250,
         573349.0625,  663547.0625,  581619.5625,  690912.8125,  571605.5625,
         719000.6875,  631896.0625,  657874.9375,  675580.6250,  818906.0625,
         648957.3125,  618111.6250,  670060.5625,  621604.1250,  676615.5000,
         446579.6562,  504381.5625,  984829.3750,  592753.6250,  477948.0312,
         557779.0625,  523966.1562,  609664.5625,  737431.6875,  639919.3750,
         683400.3125,  704691.7500,  462903.7500,  711635.9375,  672866.4375,
         615784.9375,  577900.7500,  672329.9375,  473685.7188,  599015.1875,
         687025.8750,  766733.3750,  523467.6875,  704025.1875,  726228.9375,
         668721.5000,  759240.8750,  614027.5625,  532785.3750,  503132.5625,
         603393.6250,  636307.5000,  480226.0938,  517446.7188,  676840.6875,
         614840.7500,  800486.0000,  477692.5938,  591021.9375,  762647.0625,
         697902.6875])
Layer: encoder.6.3.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3028474.7500, 2188648.2500, 2087101.2500, 1447505.3750, 1729796.7500,
        2006639.7500, 2141195.0000, 1894045.1250, 2106042.7500, 2213691.0000,
        2209101.5000, 1967466.2500, 2968312.2500, 2367236.2500, 1694766.0000,
        2581435.7500, 2242488.2500, 2683305.7500, 1786531.6250, 1779556.6250,
        2488134.5000, 2262515.0000, 1924336.5000, 2276263.0000, 2127250.7500,
        2050157.6250, 2407591.5000, 2377828.2500, 1911187.0000, 3266441.2500,
        2476725.7500, 2381233.0000, 3105886.7500, 1910520.0000, 2315497.2500,
        2015853.0000, 1985072.3750, 2163933.2500, 2623530.5000, 2848767.2500,
        2234384.7500, 2340588.7500, 2463950.7500, 1800102.6250, 1741025.0000,
        2793200.5000, 1780459.6250, 2419573.7500, 2159681.7500, 2352419.2500,
        3119442.0000, 2614011.7500, 2465059.5000, 2546155.0000, 1289036.8750,
        2983236.2500, 1675208.0000, 1794419.2500, 2096145.3750, 2227014.0000,
        1893324.6250, 1685748.0000, 2739799.2500, 1608526.0000, 1951426.3750,
        2577264.0000, 1922264.0000, 2891904.0000, 1985958.2500, 2139746.2500,
        2871593.2500, 2718355.0000, 2377108.7500, 2471929.7500, 2544803.7500,
        2464276.0000, 1560138.6250, 2073729.6250, 1762662.2500, 2769526.7500,
        2248278.2500, 2308971.5000, 1986645.7500, 1853439.8750, 2699053.7500,
        2830239.7500, 2557467.7500, 2561428.5000, 2529895.7500, 1556323.0000,
        2311921.5000, 2477162.2500, 2080339.0000, 1827765.1250, 2442282.2500,
        2069009.6250, 2721219.2500, 2513284.0000, 1975711.3750, 3481030.5000,
        2220473.7500, 1802327.8750, 1756373.5000, 2321676.0000, 2483863.7500,
        1903888.3750, 2191627.5000, 2280492.7500, 2949686.2500, 2299998.5000,
        2719371.0000, 2319655.2500, 3121954.0000, 2310512.0000, 2217665.2500,
        1404479.8750, 1616299.6250, 1665312.0000, 2032639.3750, 2037466.2500,
        2583256.0000, 2167711.0000, 1959556.7500, 1904915.2500, 2450604.5000,
        1971069.0000, 2247424.2500, 2272258.0000, 1995101.0000, 2580854.5000,
        2209018.5000, 1858576.1250, 2121079.7500, 1701686.6250, 1975925.0000,
        2710738.7500, 2017539.5000, 1989230.6250, 2421420.7500, 2236134.7500,
        2531971.5000, 2074802.3750, 2318287.2500, 1875085.7500, 2064040.3750,
        3139195.2500, 3274495.5000, 2469088.0000, 2311717.0000, 2036438.3750,
        2068998.5000, 2355282.2500, 3618237.2500, 1840087.3750, 2609876.0000,
        2799907.2500, 2169436.5000, 2514913.5000, 2458898.7500, 2056746.2500,
        2137033.7500, 2014932.0000, 2008571.5000, 2508331.5000, 2189742.0000,
        2080038.3750, 2566259.7500, 2057143.3750, 1849499.2500, 2534630.2500,
        2195111.0000, 2124748.7500, 2744495.2500, 2448491.0000, 1943599.7500,
        1988993.2500, 2081882.0000, 1937160.6250, 2569195.5000, 1603468.2500,
        2022325.8750, 2287402.2500, 3400335.5000, 2252434.7500, 2276923.0000,
        3225858.7500, 2400822.7500, 2195637.2500, 2321258.5000, 2331808.0000,
        1889469.3750, 2858936.5000, 2158045.5000, 2631878.7500, 2603699.7500,
        2831771.0000, 1736887.3750, 2746588.7500, 1905939.2500, 1942258.2500,
        2629281.2500, 1940330.1250, 1985416.6250, 1902010.6250, 2248656.5000,
        1755256.7500, 2301053.5000, 2888938.0000, 1773223.7500, 2325173.5000,
        2949294.0000, 1751461.3750, 1816557.0000, 3570882.5000, 2052860.2500,
        2511700.2500, 2116820.7500, 2300003.7500, 2079506.3750, 2166590.2500,
        2270208.7500, 2062407.3750, 2159801.7500, 2510686.2500, 2735339.2500,
        2527609.0000, 1499655.3750, 1652393.6250, 2289842.7500, 2331011.2500,
        2214625.0000, 2406835.5000, 2082797.0000, 1945741.5000, 1813599.3750,
        2223488.0000, 2569798.0000, 2248203.5000, 2698443.7500, 2512251.0000,
        2277093.7500, 2377882.2500, 2215700.0000, 2426661.2500, 2519903.2500,
        1918499.8750, 1382975.2500, 1651079.2500, 1747049.7500, 1861162.3750,
        1500627.7500, 2350740.2500, 2757966.0000, 2299265.7500, 2618925.7500,
        1755166.2500])
Layer: encoder.6.3.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 12289.7285, 162913.1719,   1146.8730,  ...,  15397.2109,
         64863.6797,  11910.0420])
Layer: encoder.6.4.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([207973.4844, 130524.0234, 177440.5625, 184863.8594, 192972.9375,
        113909.2891, 154984.4531, 103763.8672, 174953.7188, 210290.4844,
        125940.9766, 137150.1406, 129035.4922, 131629.5000, 179209.6406,
        154182.1250, 164274.4375, 201336.3594, 198278.9531, 213468.6406,
        185412.2500, 162969.3438, 139433.6094, 194962.9688, 170304.1250,
        172074.9062, 163990.3125, 255599.3906, 148210.2500, 135836.3906,
        169268.1875, 161553.7344, 209471.6875, 137203.6562, 110656.0938,
        153857.2812, 171484.9844, 120899.2891, 161499.8438, 133827.1250,
        140615.9531, 137963.6875, 202312.7031, 207514.6094, 186727.9688,
        161598.4531, 209578.6875, 143451.9688, 185491.4062, 182661.7188,
        202074.1250, 196314.7031, 140764.5781, 189576.0938, 123392.3516,
        169864.5156, 175646.7812, 171506.2188, 165072.5469, 146622.1250,
        142349.4688, 222352.0156, 207241.8438, 177526.6250, 213487.6875,
        147444.7031, 180648.5000, 179763.6094, 169636.6875, 154954.0000,
        150969.0625, 137819.8438, 135962.5312, 145533.9062, 163307.0625,
        171907.7031, 207622.0938, 195970.4688, 195115.4375, 153793.0938,
        160881.1250, 158358.0312, 188090.7344, 145964.6562, 137978.4688,
        139725.7500, 140453.3125, 177426.2656, 126262.2812, 176871.5781,
        160473.2188, 213152.1250, 137703.2188, 155268.8594, 241330.1406,
        125460.3359, 134475.8594, 206238.7031, 131852.7969, 219282.5781,
        164233.8125, 114727.7031, 183666.7500, 152894.7969, 143028.9062,
        129946.2891, 133441.5312, 154172.4688, 110077.4688, 128282.2891,
        224841.9844, 165923.3906, 124073.0234, 106425.5234, 134199.8125,
        181511.6562, 166775.4844, 144300.9688, 144207.7188, 134063.5000,
        163234.7344, 143042.6562, 137454.6406, 223750.1406, 139132.8906,
        181378.9062, 147008.8125, 138662.6562, 129585.9688, 205453.3281,
        172650.8438, 185229.5781, 144486.5625, 168358.6094, 121920.8906,
        123354.3906, 121795.6250, 131654.6562, 163060.8750, 162761.9062,
        109227.6484, 153619.8281, 137553.2812, 161646.3750, 166641.5000,
        129255.6953, 147452.1406, 169630.1875, 201328.2969, 145136.5625,
        139698.5938, 156211.9844, 158213.0781, 135636.0938, 168454.1875,
        128461.1094, 151895.9688, 126211.4922, 110913.1094, 143876.2344,
        209202.8438, 208093.4062, 146252.9844, 162870.6094, 145038.3125,
        159725.3594, 183971.6094, 168958.0938, 138656.5000, 131750.8750,
        149883.1719, 177787.6562, 229232.3750, 184605.2344, 162400.6719,
        173922.5781, 126863.5859, 190750.5938, 206587.4062, 232784.5000,
        143580.2344, 194752.0938, 116707.2109, 130987.6719, 164367.6094,
        149595.5469, 181175.7031, 119910.4453, 147907.2188, 194059.1875,
        170373.6719, 131740.4688, 130700.6016, 186539.6875, 152964.4219,
        192138.4531, 202716.3281, 132882.3594, 196872.2188, 152318.6875,
        136002.3125, 203486.3281, 193009.4062, 178897.3281, 219534.0312,
        168890.0469, 173004.2031, 128110.4609, 198262.8125, 164832.1719,
        150409.4062, 117918.1016, 139420.5156, 170159.1875, 177845.7500,
        173424.8281, 170280.6719, 213862.9219, 131714.1875, 175788.2031,
        136629.0312, 191894.5938, 207708.9375, 208141.7188, 174821.0312,
        172039.9219, 159143.8125, 140569.8594, 150184.5312, 118285.4141,
        173711.9375, 183981.2344, 147172.1094, 165986.1250, 148490.7500,
        122011.8125, 164176.3281, 134086.2500, 170675.7031, 124794.7031,
        112604.4922, 177415.3906, 169940.3438, 176619.5156, 158750.5781,
        133416.3125, 120884.1719, 111027.3750, 139407.4375, 151513.4375,
        141827.4219, 141972.9375, 184531.7969, 184104.7656, 202135.1719,
        100260.3125])
Layer: encoder.6.4.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([627629.1875, 663750.3750, 897197.8750, 468014.8438, 624205.5625,
        632656.4375, 875459.8125, 778495.7500, 490441.9688, 561591.1875,
        605966.6875, 695540.5625, 674438.8125, 705208.8750, 597140.3750,
        537249.5000, 916893.4375, 596887.0625, 520007.6875, 573306.0000,
        514484.5938, 353896.4062, 483780.3125, 602076.2500, 744699.8750,
        559405.1875, 733378.5625, 517648.4375, 647434.2500, 562005.1250,
        713957.0625, 644094.5625, 476685.6875, 481499.4375, 811057.1250,
        819816.8750, 563332.5000, 596208.3125, 760883.5625, 679302.6250,
        508649.1250, 500043.9375, 556241.8125, 750583.1250, 557496.0625,
        883758.6875, 881043.4375, 538302.6875, 714977.2500, 511589.5312,
        577646.8750, 631338.4375, 591862.7500, 629809.5625, 577423.3125,
        740448.7500, 648306.8125, 534433.5625, 743229.8125, 520429.9688,
        783899.6875, 720315.8125, 505827.3750, 611032.9375, 530423.5000,
        564875.7500, 737548.2500, 671716.8125, 579864.6875, 661052.3750,
        752729.0625, 560475.1875, 569944.2500, 631215.5625, 634701.9375,
        634003.6250, 820996.5625, 662279.1875, 735614.3125, 642234.1875,
        559785.1250, 434832.3125, 525312.4375, 600842.9375, 345171.7812,
        661391.4375, 610729.6250, 666634.2500, 735197.5000, 613141.3125,
        599526.5625, 511902.2500, 733652.9375, 610179.6250, 653061.2500,
        642340.0000, 821107.6875, 664010.0000, 558628.5000, 422976.9062,
        587145.1875, 448631.0938, 376557.1250, 774070.0625, 515095.9688,
        718254.6875, 479383.6250, 460895.3438, 518364.8438, 613802.5000,
        625834.7500, 554947.1875, 698959.8750, 517664.0312, 523714.1250,
        507677.7500, 701255.8750, 631125.3125, 479214.0938, 624209.0625,
        592359.9375, 611061.5000, 498228.8438, 677063.6875, 922267.8750,
        708987.2500, 802295.6875, 509942.7188, 642271.0000, 715530.6875,
        681556.0000, 555949.0000, 605662.6875, 523585.2188, 709428.1250,
        501381.2188, 527927.5000, 592623.5625, 729232.8125, 588484.5000,
        718820.8125, 485839.7812, 833708.6250, 615164.0000, 773781.2500,
        548744.0000, 549938.5000, 712154.4375, 650068.3125, 472210.4688,
        606016.0625, 476370.1562, 632979.0625, 448843.3125, 801751.1250,
        727673.2500, 475329.9062, 630587.9375, 762533.2500, 808201.9375,
        712254.3125, 699647.0625, 533367.5625, 578194.2500, 639739.1250,
        798947.3750, 585017.6875, 747500.1250, 572292.0625, 538684.5000,
        643954.3125, 673924.5625, 798700.3125, 675903.7500, 762171.5000,
        701783.0625, 669832.5000, 657762.3750, 717333.1875, 587896.6875,
        877911.6875, 564925.8750, 558098.4375, 662747.3750, 590970.5625,
        725643.5625, 571603.6250, 692008.8750, 609539.6250, 583044.1250,
        521616.4688, 604823.4375, 536639.7500, 543788.5000, 483493.0625,
        707251.5000, 699095.0625, 627697.8125, 591287.9375, 806815.8125,
        547783.0625, 584009.6250, 792930.6250, 455214.6562, 675139.6250,
        723807.1250, 493870.5000, 644941.1875, 802660.5625, 747260.6250,
        562347.5625, 444760.6875, 747323.9375, 700304.3125, 549072.7500,
        715450.5000, 653505.8125, 742631.6875, 729720.7500, 587234.6875,
        667299.5000, 516812.5938, 863759.9375, 479279.5000, 866227.7500,
        714293.8125, 515820.7812, 484254.1562, 575743.1250, 788530.1250,
        569011.4375, 826374.3750, 489346.0000, 778165.6250, 497250.3438,
        753239.8750, 517937.5312, 569799.7500, 570433.5000, 447634.1250,
        637970.3750, 567968.5625, 584998.2500, 806564.6250, 654233.4375,
        669882.4375, 406756.7500, 706708.1250, 503190.0625, 770039.9375,
        515678.5000, 650965.5625, 673572.7500, 693418.1875, 594986.4375,
        709121.1250])
Layer: encoder.6.4.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([   953.8790, 134125.5000,   1261.3462,  ...,   4182.9106,
        136495.0000,   7864.6343])
Layer: encoder.6.5.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 73591.3828,  53179.7578,  46255.7969,  46852.6797,  78496.7891,
         96191.1641,  78635.4844,  72225.8203,  88122.9375,  65842.3203,
         74105.1406,  74539.7500,  73291.8516,  78042.1094,  71444.8516,
         56409.2031,  49003.3555,  63773.4570,  61690.8086,  75695.3516,
         78971.7344,  82733.8516,  64346.3320,  72363.6797,  83529.1094,
         86378.2891,  63290.8711,  89074.2188, 104523.7656,  88954.7656,
         57419.0625, 120961.1328,  80618.1641,  64474.3594,  55239.2070,
         73642.9766,  42351.8984,  46978.7109,  70122.9531,  92086.3594,
         59481.1602,  70315.6016,  70135.5078,  76372.0781,  78650.5859,
         50422.5000,  56737.5000,  91541.9062,  72077.0859,  80106.2109,
         66482.0703,  62973.9961,  70128.3047,  64273.8906,  50171.1953,
         77501.1250,  65239.2266,  66067.1094,  84901.4453,  89050.4453,
         61170.1250,  65861.0859,  70738.0156,  95253.8594,  84100.4219,
         65740.8359,  73533.5078,  83219.2656,  59667.8320,  72845.3203,
         45938.5977,  54752.7969,  96037.4609,  72466.1016,  74666.3672,
         54237.8320,  77299.4766,  68957.6016,  51195.3281,  68433.0547,
         76712.6016,  64905.7383,  63148.7188,  80417.0000,  55757.5312,
         68980.2891,  65894.6641,  74603.3281,  60585.1094,  76662.3594,
         49215.0156,  77281.9609,  79804.8359,  75483.8516,  64011.0117,
         67008.6016, 100731.5625,  86130.1797,  69259.6641, 102966.1875,
         54296.8828,  69959.3125, 102757.4297,  88596.0469,  45518.2930,
         58488.4141,  47853.7773,  65567.6016,  75221.4688,  61949.1328,
         35650.1211,  74530.2578,  62971.8750,  61167.3320,  71861.4688,
         65563.7266,  98454.4844,  60857.5508,  88576.7344,  67908.5781,
         61948.0469,  82317.9219,  82793.0391,  75171.7188,  60978.8555,
         61675.2031,  54081.4883,  61663.9648,  59440.9102,  74378.2500,
         75807.9531,  90448.0156,  87361.6094,  96169.8125,  59945.9688,
         80306.7031,  92205.2734,  70822.4297,  87867.6641,  57970.1875,
        100848.6094,  64998.0664,  67043.5000,  68878.8906,  76687.2734,
         72621.8125,  83331.5703,  73596.9531,  95298.7734,  85641.2578,
         61082.8789,  78090.0312,  65647.5234,  61919.1055,  62651.3945,
         82294.4141,  62839.8984,  59773.1758,  60932.3945,  93355.9062,
         65158.6406,  62734.5547,  84984.7969,  60758.8125,  82775.3906,
         45029.1016,  60298.6406,  73334.5391,  63815.0156,  53286.0586,
         81116.4688,  71509.0469, 100464.6250,  84447.0156,  93536.6172,
         71369.1250,  98093.4922,  72198.6719,  84958.2109,  46910.7578,
         88728.1797,  62131.2734,  50700.8711,  86308.3984,  59401.2031,
         70177.9922,  75933.5000,  71528.8203,  76055.5703,  39319.6094,
         59742.1641,  74573.8672,  64409.1445,  54349.2500,  53216.1953,
         76730.8984,  52591.0039,  68997.3828,  58984.8125, 100752.7578,
         56173.2891,  62888.8984,  38308.1289, 104435.5000,  61594.3672,
         83065.9062,  59614.6602, 128077.7969,  83585.7734,  70001.9844,
         88689.5156,  57306.8555, 124343.1406,  69824.1719,  57143.7812,
         84729.4531,  58161.3555,  83573.5859,  71222.6406,  52085.6797,
         85351.4688,  95285.4609,  76627.6016,  63056.2461,  50696.6016,
        111525.3594,  64475.8008,  78124.9297,  71527.5547,  72689.5000,
         42064.7500,  89578.8359,  74300.5234,  59102.1758,  58474.0664,
         57993.4062,  64537.0547,  80174.1562,  66507.3750, 103856.7344,
         57176.7734,  68579.2109,  85309.0703,  58557.8203,  57919.8633,
         86066.2578,  53498.0469,  78211.9219,  76951.6484,  86548.0078,
         72465.6094,  61500.1914,  48550.3164,  60190.4453,  88905.9766,
         88028.0391])
Layer: encoder.6.5.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([291721.0625, 454188.7188, 357476.9688, 458962.5000, 319350.2188,
        297804.3750, 411148.4062, 318243.0312, 277204.1875, 340838.7500,
        330244.7500, 354830.7188, 400707.0938, 182830.2812, 349161.7500,
        367732.5625, 389981.4688, 347449.0625, 277093.0938, 271551.0312,
        214656.3750, 354405.2812, 394356.0938, 219252.3594, 328267.7812,
        371337.5000, 333797.8750, 330656.6250, 216215.2656, 448646.5625,
        305410.4062, 280092.5625, 288199.6562, 430104.6562, 281246.4688,
        399822.0938, 447390.4375, 254825.7188, 359382.6875, 240648.9375,
        326588.9062, 236659.1094, 482649.0625, 264750.0312, 248924.4844,
        332668.6875, 327456.2188, 215460.0469, 322096.6875, 355040.6875,
        389862.3125, 333034.6562, 316436.0000, 248304.2500, 342135.2500,
        388864.7188, 283841.0938, 299043.4062, 307929.6875, 254081.4375,
        375870.7812, 303712.3750, 355229.6250, 328686.2812, 356171.6250,
        348126.2188, 394866.8438, 401520.8125, 383798.0938, 281922.8125,
        238144.7812, 287744.9062, 304707.5625, 296989.6562, 352492.9375,
        303027.0312, 367995.6250, 276132.9062, 417049.6250, 308403.8750,
        360013.0938, 408664.2500, 288910.4062, 375151.7188, 282220.1875,
        197886.1250, 222029.1562, 242787.2812, 254870.2500, 299216.6562,
        276714.4375, 190052.8906, 285348.1562, 330139.6250, 391071.8438,
        300888.2812, 350504.5000, 306172.0312, 308892.2500, 277358.5000,
        271131.0938, 274917.6250, 243886.7656, 256396.7656, 214041.9375,
        287013.3438, 317417.0000, 244066.0312, 341717.4688, 397260.1250,
        415535.9062, 298813.7812, 359799.8125, 307311.3750, 214419.8281,
        322674.0000, 233925.8281, 284684.0312, 353909.2500, 377186.4062,
        352137.5000, 329082.0312, 281530.9062, 271316.5625, 347787.1250,
        192307.3438, 233136.3750, 237510.2812, 260571.5156, 284145.5000,
        466320.3438, 232020.8438, 206679.7031, 494836.3125, 305899.0000,
        250352.8906, 365350.4062, 338311.6875, 224788.3125, 260790.2500,
        234799.8906, 332544.4062, 316264.8438, 500503.5000, 207351.8594,
        288146.6875, 449605.5625, 361341.6562, 335475.8125, 459600.7188,
        270445.0312, 186058.8906, 356839.4688, 279993.5000, 382524.7812,
        232171.2812, 196675.3281, 295432.1875, 398235.9375, 278603.2500,
        317236.0625, 427559.0938, 329677.1875, 411141.6875, 344417.4375,
        297749.9688, 273180.0000, 397427.6562, 253027.7188, 293590.2812,
        336558.7812, 312561.7188, 425254.4375, 279281.8750, 378625.1562,
        416146.5000, 352626.8125, 376745.7812, 391654.0312, 376944.5938,
        275253.5312, 365349.6875, 357087.0000, 195807.9219, 503069.1875,
        310960.0625, 376188.2500, 318828.6250, 314176.5312, 326663.2812,
        339682.0938, 241180.2188, 196894.7188, 367187.1875, 441456.6875,
        250672.5625, 308518.4375, 285338.5938, 225948.1094, 466999.8750,
        258627.4531, 263278.5938, 285510.2812, 191659.5156, 253801.2969,
        478714.4375, 293501.1250, 334868.5000, 341229.9375, 352000.3750,
        324962.2188, 373489.0625, 375896.7188, 210947.7344, 290077.2188,
        394963.6250, 456533.9062, 330842.1562, 363098.4375, 310185.2812,
        233199.1719, 260356.8125, 240924.4688, 287304.6250, 326281.8125,
        324503.0625, 403745.2188, 330645.5000, 360475.5000, 284150.0938,
        302985.8125, 260385.9219, 348394.3125, 243341.5000, 357599.9375,
        151285.6562, 315157.5625, 500639.1250, 199207.9219, 279837.0938,
        491594.3750, 188937.7500, 313289.4375, 369396.8125, 392223.6875,
        325105.8750, 295911.4688, 286645.9062, 328072.7188, 334600.3750,
        252926.0156, 215877.5469, 206627.7812, 352973.6562, 422177.5000,
        412229.8125])
Layer: encoder.6.5.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1448.9547, 6170.9194,  814.4988,  ...,  644.7186, 3796.6877,
        1282.1833])
Layer: encoder.7.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3470.0078, 3979.3513, 2965.8152, 3107.5000, 3575.7424, 3712.8613,
        3998.3926, 2830.7695, 3592.9998, 4018.4736, 4532.9541, 2710.2271,
        3224.4067, 4464.0581, 4325.3179, 4687.0508, 3644.8208, 4309.9653,
        3973.3413, 3910.3835, 4422.2505, 4571.0210, 3732.5273, 3000.5522,
        3373.3311, 3964.9990, 3462.4851, 3597.3918, 3812.4985, 3329.4773,
        4098.7485, 3156.3511, 3584.2014, 3237.4963, 4452.0737, 3662.2683,
        3146.1887, 4283.5371, 4104.9302, 3398.5227, 2676.3069, 2916.7419,
        4078.2744, 3506.7900, 3070.1914, 3597.2542, 3917.6260, 3280.2197,
        3605.0879, 3308.6047, 3015.1826, 3333.6858, 3625.5215, 2842.1157,
        4434.3472, 3007.0391, 3131.8730, 4046.6323, 2855.8989, 2934.8071,
        3433.6353, 3515.4724, 4539.0996, 4097.3320, 3686.0908, 3867.6821,
        4301.5264, 4206.3394, 3625.9287, 3140.0129, 4970.4126, 4352.9395,
        3683.8230, 4217.9375, 3589.6748, 3425.9556, 3861.0833, 4810.4722,
        4316.2739, 3680.7046, 3650.0415, 3384.9873, 4401.3872, 3462.7642,
        4069.4812, 3650.3152, 3152.4941, 2853.8755, 4078.8665, 3487.8521,
        3757.0513, 3765.4514, 3803.9331, 4721.9517, 5255.4746, 3947.3689,
        4623.7271, 3107.7439, 3813.4597, 3978.3904, 5151.4321, 3361.7178,
        5592.1646, 3602.0461, 4109.6245, 3305.1174, 3037.4395, 3916.7239,
        4651.9966, 2191.5349, 3614.8201, 4098.9448, 3039.3928, 2989.6892,
        4058.2605, 3410.8062, 4524.4668, 4038.2815, 3693.9304, 4193.4253,
        2987.2366, 2802.8076, 3407.6450, 2436.7856, 4626.3555, 3312.6023,
        4399.2188, 4905.7397, 3861.3550, 3219.2236, 4116.3979, 3421.9131,
        3388.6877, 3907.9834, 3638.2031, 4476.3921, 3757.5010, 4173.1875,
        2931.2185, 3374.6804, 3252.9778, 3253.1323, 2593.8569, 3647.4927,
        4887.8672, 4929.9019, 4339.6069, 4657.1597, 4602.5332, 4200.4971,
        4350.4419, 5091.0005, 3506.5142, 3299.1484, 4525.3267, 4535.2559,
        3128.8674, 4636.5562, 3494.3445, 3701.9036, 3198.2764, 3995.2705,
        3037.3955, 3903.2959, 3963.1877, 3635.0310, 2937.9375, 5302.5596,
        5049.8433, 3047.7949, 3803.0964, 4408.4126, 2951.3135, 3292.8501,
        3171.8511, 3008.4041, 4016.0542, 4518.5791, 4606.2598, 3166.1248,
        2923.1785, 3472.8108, 4425.0298, 3619.1897, 4389.0288, 3382.8594,
        3638.5913, 3320.2700, 3865.1404, 3864.2373, 3818.1162, 4305.9683,
        3750.5334, 3358.8457, 2920.9851, 4152.6265, 3577.5527, 3843.8340,
        4141.7051, 3929.9463, 3714.8525, 4576.5430, 3285.0300, 4788.0718,
        3627.7124, 3547.8181, 3551.2239, 2882.4314, 2942.7253, 3310.1597,
        5435.0562, 4287.3145, 3168.0920, 3281.8721, 3792.7009, 3082.3218,
        4354.3525, 2722.4426, 3645.2246, 3251.1670, 4044.8572, 3783.4963,
        4500.0625, 4163.7954, 4293.0679, 2544.7266, 4405.9336, 2915.1921,
        3425.0005, 4184.7681, 4883.5435, 4686.1245, 2712.6306, 3651.5623,
        4558.3740, 3896.8186, 5457.1025, 3319.0142, 4970.6060, 3746.9092,
        3910.9819, 2762.2197, 3664.8518, 3255.0095, 3616.0015, 3327.0588,
        2936.2781, 3209.5398, 3557.2617, 3628.0562, 3256.4351, 4795.6401,
        3285.9746, 5566.9771, 4151.7305, 3376.7102, 4032.8479, 3482.1243,
        3202.7637, 3791.7534, 2834.6284, 3162.8423, 4152.2715, 2980.9282,
        2997.5852, 4355.6123, 3063.6602, 4215.4038, 3609.1826, 3397.0439,
        4633.8350, 3034.6492, 3352.9841, 3978.9282, 4364.2139, 4017.9297,
        3969.0093, 4545.9395, 3351.8313, 2674.5615, 3389.3389, 3036.2688,
        3799.5557, 3130.1694, 3991.7639, 3133.7915, 3609.6282, 4590.0010,
        2708.0098, 3431.0813, 3603.8965, 3517.7295, 2908.8840, 3005.2690,
        3509.6050, 3630.4580, 4548.1787, 3616.1599, 3668.2476, 4269.5474,
        3501.9868, 4067.1960, 4244.3545, 3422.5664, 4254.0991, 3355.1550,
        4023.9167, 3602.9626, 4199.2441, 4341.2896, 3943.3525, 3643.9395,
        2934.4365, 4408.8120, 2884.0876, 3690.5608, 3148.9209, 5278.1514,
        5366.6401, 3658.5510, 3165.4617, 4074.2612, 3923.4600, 4016.8328,
        4300.5381, 4029.3918, 3398.0015, 4036.6460, 3282.7031, 3233.5828,
        3620.5803, 3822.3596, 3123.2207, 4156.3066, 2760.6406, 4353.3545,
        3644.8997, 3651.9961, 2949.8965, 4225.6479, 4078.2629, 3575.9675,
        3188.4155, 3093.8892, 3695.8599, 2920.9487, 3511.3777, 2915.5623,
        3536.9734, 3680.0459, 3359.2375, 3668.8582, 3292.1438, 3462.4934,
        4205.6958, 4472.7607, 3108.0420, 3405.7888, 3865.0266, 3121.7263,
        4004.8179, 5509.0376, 3778.5996, 4499.4556, 5141.6216, 2936.7844,
        3957.5610, 3142.8789, 2802.3525, 3613.9080, 3126.1660, 4372.9551,
        3621.2410, 3661.2437, 3533.8359, 3415.4575, 4299.2114, 2561.7842,
        2747.7153, 3202.6428, 3256.3870, 3861.0723, 2979.3008, 3454.2493,
        3013.3159, 3350.5657, 2962.2676, 3612.8853, 3571.7671, 3824.0303,
        3669.3145, 3842.1714, 3868.1543, 3467.0867, 3898.5720, 4188.1567,
        3322.6423, 3938.2849, 3067.6948, 5455.6660, 3756.6938, 3098.8352,
        3073.7466, 3826.0349, 3136.1548, 5098.6792, 3113.3306, 4625.6606,
        3449.1819, 3290.0588, 3494.7202, 3681.4277, 3808.7437, 4116.5088,
        3507.5811, 3533.2454, 3567.3120, 4344.1206, 3780.7786, 3871.1614,
        3132.8833, 4180.9404, 4232.9409, 3911.0725, 4104.7119, 4180.2881,
        4041.8218, 4542.2075, 3603.8657, 3798.6914, 3274.1838, 4372.7578,
        3151.9661, 2677.1458, 6070.5742, 2862.0791, 4562.0728, 3268.2363,
        3160.1406, 3146.7104, 2977.5103, 2932.0400, 4019.5928, 4541.9448,
        4058.1965, 3031.5632, 3135.8015, 3085.9819, 3425.2224, 2992.8887,
        2936.4695, 5198.9287, 5635.2397, 3024.8328, 4549.9307, 2904.3271,
        4234.2295, 3950.3633, 3766.2490, 3240.7537, 3453.8245, 3503.5623,
        3100.0859, 3759.1326, 3684.1794, 4096.3140, 4175.0005, 3837.1482,
        3507.5000, 3008.8733, 3482.8130, 3875.3855, 4657.4185, 3787.2468,
        3259.2881, 4230.1245, 4527.1621, 3916.3467, 3080.8569, 3963.8438,
        4663.1509, 4050.4751, 3758.3188, 4290.4707, 4396.6147, 5312.9067,
        2774.5591, 3430.3035, 3630.0315, 4069.6567, 4663.6987, 3190.1931,
        4856.9663, 4844.9136, 3895.5671, 3401.2922, 5982.6528, 3828.7097,
        2922.9001, 4513.5454, 4271.2715, 2904.0413, 3656.1409, 3511.2166,
        4333.4775, 4486.3994, 3735.7695, 3691.8501, 3073.6313, 3468.1199,
        3361.5923, 3810.0640])
Layer: encoder.7.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([20234.8926, 30572.0078, 35175.2617, 35850.2266, 27747.2676, 37270.2617,
        29805.5371, 35891.5352, 26112.6699, 28931.1934, 32915.3750, 43365.8516,
        34789.5703, 25977.9590, 32180.1016, 32983.6367, 29637.6582, 32312.2852,
        24038.2793, 28106.2695, 33155.1367, 28995.6113, 34938.9727, 44672.2109,
        34590.6445, 39774.5547, 30303.8008, 35578.8125, 36790.1484, 38379.4453,
        39418.2031, 27029.2324, 32241.4941, 26555.9688, 32544.4355, 29220.8750,
        30623.7520, 45603.7812, 25365.1816, 26057.0898, 25942.5664, 28142.0156,
        33866.1641, 30800.5801, 24265.6387, 36018.7891, 28297.8457, 43005.1367,
        31615.0059, 23927.5430, 29112.8301, 40404.1133, 36679.9023, 29415.0156,
        33016.1797, 41922.8711, 38431.6172, 28402.2793, 34151.3633, 38546.2695,
        27077.0762, 23028.5820, 35702.8398, 42003.7031, 34868.5586, 27883.0742,
        31915.2656, 36228.1016, 34326.6797, 27914.0449, 37799.9531, 37487.4648,
        38743.9102, 32147.3301, 33036.3516, 32671.2871, 39855.0898, 36986.9570,
        44858.3359, 34719.5117, 47389.9219, 24910.5254, 25401.8398, 34855.1133,
        34644.3320, 43999.5703, 38582.9375, 36078.7734, 38154.3398, 27761.3945,
        27517.2441, 41161.0820, 42192.9414, 30132.5996, 28900.3887, 27876.2930,
        30668.5977, 31727.5488, 35169.4844, 23928.4551, 42724.7539, 33526.7734,
        26029.2832, 25597.9707, 40028.1016, 35648.9805, 34631.0117, 29893.5098,
        42653.7734, 38079.2227, 38787.8555, 28510.6426, 30506.5234, 31243.4863,
        29943.8184, 36975.6523, 42316.3516, 23683.0508, 30465.2344, 37074.5078,
        27490.2090, 30346.3672, 30783.2402, 44443.0352, 29507.0273, 35448.5273,
        35285.8398, 30377.4336, 30560.4473, 36617.4531, 25077.9746, 30046.4824,
        27564.4512, 23025.1523, 30390.9746, 41809.8594, 29611.5605, 38730.5938,
        37372.8242, 37355.0898, 50237.6289, 35603.8008, 25564.8047, 28302.6973,
        36961.8164, 35019.1680, 29613.8125, 29483.5879, 33271.4258, 48434.5508,
        36028.9336, 34337.5781, 31683.5195, 33261.4570, 36138.0195, 34373.0859,
        31385.7969, 34937.3828, 26026.2832, 30330.8438, 21689.6816, 43041.7773,
        28425.2109, 24839.3594, 38735.0000, 31074.6465, 33995.9570, 31422.7051,
        27787.1328, 33069.7578, 33621.6328, 38136.0078, 30455.3926, 27564.7402,
        38591.0703, 27606.3164, 28788.3477, 34533.3711, 28963.5391, 28926.5547,
        33139.1289, 38237.5195, 26523.5664, 37592.7070, 31932.2285, 38000.3164,
        36929.2461, 44061.9297, 47152.8594, 31143.1992, 46402.3320, 27664.7402,
        30282.1230, 28611.3379, 29146.5840, 29845.6953, 33837.1367, 28509.5684,
        26086.7656, 26256.5488, 30456.0039, 34975.5508, 26428.2578, 30010.6992,
        38540.1914, 23583.1152, 46262.1016, 46673.6367, 26004.9355, 27416.1992,
        32447.8828, 31915.3496, 27326.4707, 33309.0938, 34051.8711, 50215.6875,
        37325.9102, 38873.4492, 39637.6055, 32790.1602, 27848.4766, 29489.0469,
        30756.0664, 33740.8516, 27529.9512, 29223.9316, 30221.6855, 29737.9844,
        39550.1367, 29397.8730, 46427.7539, 33684.3086, 36760.8203, 24906.3750,
        32073.0723, 34000.0547, 34742.0156, 29893.0371, 29805.8711, 33541.4844,
        34099.1758, 38446.2305, 23657.3613, 41081.2812, 39232.3203, 43340.8711,
        33124.8945, 24782.2930, 32096.8809, 34807.1797, 26474.9238, 26493.3086,
        32871.0000, 45016.5508, 32506.7852, 35951.7109, 26810.9863, 31513.3242,
        35720.5117, 32282.6270, 34463.4492, 37186.6992, 28789.3906, 50140.0234,
        40462.2930, 26304.5898, 27319.4043, 29756.4785, 30288.9922, 35104.8008,
        35084.1680, 29918.2461, 27866.7012, 40294.6680, 41059.3047, 26557.0996,
        31043.7168, 32297.3281, 25772.7402, 33464.2422, 44329.1016, 27080.6953,
        38368.9883, 30863.8242, 29293.9160, 34353.8633, 32018.5488, 33093.5352,
        35226.5938, 35789.2695, 31877.4922, 31033.5684, 36848.4883, 40575.3594,
        31254.0664, 29511.4883, 28586.6973, 46738.6484, 41501.3594, 38282.7344,
        31156.6934, 23526.4062, 27919.2129, 34179.6992, 35829.2148, 37198.6836,
        41112.9648, 38559.8945, 32710.6074, 33990.9805, 35365.2383, 27963.3535,
        31814.7441, 30696.6289, 41261.1641, 38231.4609, 32292.1309, 28232.7891,
        42470.3086, 32484.0137, 36760.9141, 34890.7266, 32752.3672, 36619.9023,
        33371.0234, 33790.9023, 48287.2227, 28272.5703, 32389.0781, 27079.1348,
        32537.7207, 42727.7656, 30718.0820, 37076.9961, 39674.7500, 32419.3145,
        33699.4102, 35629.5859, 31923.5059, 31205.8965, 48817.6484, 31104.1602,
        41707.9805, 26331.9844, 36511.8633, 42932.1797, 36271.9219, 41072.2227,
        33988.2383, 28902.4609, 24942.2363, 31114.6191, 29146.6797, 30502.1191,
        30170.2617, 34217.1875, 31481.3750, 36752.6719, 29846.0312, 42051.2500,
        32401.9766, 30845.5605, 36966.4609, 32374.2852, 35113.8516, 44501.7539,
        29333.5977, 37526.1328, 48266.5938, 40821.8086, 26247.1621, 31064.9316,
        30978.8945, 36058.7656, 43595.2500, 29210.4707, 31143.7012, 32870.9453,
        25145.2422, 26408.3984, 43131.9492, 29175.3438, 30355.0137, 29733.5508,
        38004.9688, 31316.4551, 37827.4727, 33387.2695, 23298.6621, 29021.4805,
        28602.1934, 22339.7500, 38936.6133, 33350.9805, 41094.9805, 36548.7227,
        36743.0234, 26583.1914, 28943.0977, 30648.4238, 23548.5977, 40285.3789,
        48022.8320, 29875.4121, 34690.8477, 26653.7266, 33744.2266, 31819.8965,
        38627.5859, 35993.8281, 30628.1055, 27529.0664, 43245.0508, 26742.5977,
        29408.7871, 42894.8047, 34448.7227, 39844.9844, 46166.5430, 49228.9297,
        42090.1094, 28300.1445, 31042.8086, 27612.8086, 30203.4883, 36755.5000,
        33788.9219, 28972.0508, 29258.4746, 29821.6895, 38928.2070, 39036.1133,
        33926.8086, 49590.4297, 25232.3984, 29028.9180, 24669.3203, 28545.8359,
        32057.7305, 27406.7852, 32754.9492, 30468.9512, 26925.8535, 25339.7734,
        37444.5195, 37120.1406, 32423.8086, 37470.0430, 47920.1328, 33055.5117,
        31279.6133, 32498.4492, 38456.1367, 30704.1094, 23972.9316, 50280.7500,
        43430.9453, 26126.2051, 32131.7012, 25750.5742, 31038.4648, 37121.3516,
        36498.4258, 29757.6113, 28029.7949, 33908.3789, 31632.1484, 46681.9883,
        31472.6895, 45495.5000, 36876.1680, 29624.1582, 33025.9883, 45573.4766,
        33707.0859, 31219.1074, 25778.9258, 24331.8965, 27236.7422, 32529.3750,
        35244.9336, 33455.5898, 27949.8281, 33463.8906, 34955.8477, 27604.7637,
        27604.8516, 38789.2812, 33306.5547, 32438.2461, 31256.3164, 37982.8320,
        48326.7344, 36452.6758, 27795.3203, 43558.8906, 35957.9531, 27880.3848,
        31182.4707, 28114.4980, 24231.5215, 28974.4844, 26545.1699, 31241.1699,
        27201.8848, 35197.4258, 33357.3945, 34910.0273, 42503.5664, 37095.9570,
        35152.9805, 25853.6973])
Layer: encoder.7.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([  29.2363,  240.8329,  140.8889,  ...,  389.5469, 1286.1428,
           9.4671])
Layer: encoder.7.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 282.7633,  111.4872,  430.7698,  ...,  497.1896, 1353.4937,
         221.5560])
Layer: encoder.7.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 872.6945,  645.9775,  912.6101,  779.5250,  959.7505, 1320.3458,
        1028.6931,  848.6915, 1318.8004,  887.0536, 1016.9958, 1078.2338,
         966.6057, 1046.9779,  959.7427,  814.8825, 1119.4979,  744.6669,
        1035.9771,  963.1038, 1016.3845, 1068.2264,  860.7441,  985.0238,
         780.4682, 1198.2661,  895.0288,  677.4076,  833.8969,  839.8696,
        1127.9994,  946.0865,  829.6254,  796.4984,  788.6298, 1164.0024,
         928.4497,  765.7113, 1113.8127, 1226.1974,  864.8265,  891.9740,
         962.9457,  960.3058, 1114.2180, 1093.1183,  831.1483, 1040.8910,
         988.6702,  988.8597,  914.3942,  950.6164, 1010.4816,  831.1646,
         923.5142, 1228.5745,  815.5052, 1008.3406, 1248.1169,  995.6456,
         832.5772,  794.7941, 1226.3109, 1092.8496,  902.3419,  959.0403,
         918.4854,  725.7086,  944.6725,  775.4247,  783.2886,  693.7755,
        1307.0216,  709.9727,  977.6996, 1064.7422, 1023.5214,  730.4698,
        1057.4603,  953.0677,  787.0865,  812.2820,  824.2089,  919.6273,
         887.5670,  905.3362,  685.9217,  999.3755,  973.8198,  900.5016,
        1048.6669, 1036.4349,  721.0375, 1202.9873, 1073.3711,  722.2552,
        1136.3423,  657.5906,  899.2937,  881.4169, 1075.3878,  991.6195,
         788.1971,  811.9533,  962.8138,  998.5797,  825.5235,  972.7738,
         933.1482,  980.7130,  832.6260, 1335.3171,  841.1190, 1005.8996,
         830.2213,  926.1640,  795.4417, 1135.6997,  943.4708, 1158.3400,
         852.7640, 1079.9484,  751.4806,  964.7802, 1017.2097,  732.0872,
         907.6981, 1038.9430,  985.3743,  728.9546, 1158.4672, 1117.2760,
         941.4210,  934.1005, 1251.9697,  950.2866,  995.8749,  675.6530,
         824.9726,  995.0734,  827.6436, 1083.6307,  772.5705, 1221.1890,
        1296.9321, 1024.7566,  827.8637, 1001.2255, 1173.2496,  957.5568,
        1019.3146, 1062.4513,  820.6750,  802.0977,  896.0538, 1367.8734,
         847.5829,  789.6082,  855.6071,  812.5647,  760.3998,  916.5932,
        1096.7802,  906.0672,  666.0294,  950.0464,  719.0101,  772.5840,
         979.0128,  900.7564,  937.9861,  979.3963, 1012.3591,  813.6433,
         747.8408,  709.3192,  844.5699,  922.2867,  751.5380,  690.9821,
        1167.3860,  722.3112, 1108.0270,  803.3981,  939.9431,  839.4500,
         827.8091,  750.6865, 1037.4734,  812.6279,  849.9318,  948.9229,
        1163.5453,  817.4786, 1028.5525,  881.3615,  737.7479, 1021.7117,
        1116.9357,  997.6140,  793.1685, 1130.4650,  842.7489,  911.1122,
         946.6851,  801.7896,  710.7869,  897.8973,  882.1220,  841.5015,
         815.6717, 1328.3320, 1073.7062,  698.7040,  905.5513, 1188.3989,
         827.5714,  748.1782,  864.0707,  928.6615, 1124.6719, 1041.8181,
         770.1318, 1254.3521,  985.9082,  876.2869, 1229.4600, 1041.8837,
         724.6989,  805.5565,  950.3029,  909.7023,  833.1653, 1085.5931,
        1233.7135, 1081.2122,  961.4635,  980.7219, 1077.4225,  793.5851,
         803.4440, 1100.9088, 1007.7961,  964.9681,  782.1583,  875.8571,
         899.0494,  982.1013,  902.0811, 1065.0391,  997.6821,  924.9932,
         781.8735,  839.5201,  659.3618, 1196.6683, 1022.8860, 1026.8547,
        1179.0519,  732.2197,  945.0770,  901.2046, 1169.6072,  871.7159,
         941.7252,  723.9949,  900.0689,  821.8329,  984.8781,  786.2676,
        1029.8080,  814.4755, 1239.4585, 1124.3073,  925.4155,  913.8765,
         989.2371, 1261.6274,  862.1620,  820.8887,  865.4992,  910.9597,
         934.2932,  929.7610, 1140.5996,  825.4054,  806.8556,  692.9695,
         888.4763,  873.2265,  943.4816,  817.7034,  768.1710, 1094.9792,
         780.9429, 1326.0197,  936.4398, 1156.1921,  917.0667,  737.2723,
        1006.2509,  861.0289,  957.0473,  786.4657,  924.3224,  835.4761,
        1230.1398,  941.4656,  741.0657,  826.5666,  836.5977, 1029.5280,
         817.8804,  836.8019,  911.1226,  778.6097,  810.8506, 1013.1404,
         863.8918,  788.8359,  970.2211,  786.4537, 1033.3022,  759.4709,
        1299.5023, 1213.0781, 1050.0547,  951.8568, 1225.0145, 1101.4943,
        1168.2601,  801.7650,  792.4137,  906.5102,  902.9240, 1091.9713,
        1073.1815,  976.8712, 1127.3007,  855.2764, 1009.3856,  946.5153,
         740.6107,  690.7720,  869.7625,  798.7390, 1010.0940, 1063.1998,
         814.4525, 1031.2793,  903.5739,  897.8914,  888.6167,  944.0070,
         930.7183,  920.2987,  686.6661,  783.3989,  889.2332,  654.6193,
         880.6908,  984.3516,  852.2706, 1068.2809, 1077.2518, 1020.3449,
        1046.0525, 1221.2847,  910.3034,  819.9095,  941.8585,  799.0345,
         795.5563, 1151.7734, 1075.6500,  873.9675,  788.6769, 1041.4031,
        1129.1012,  892.7860,  781.4339,  780.1746,  839.0999,  743.1793,
         976.4324,  788.5982, 1164.9764,  791.9156,  837.8677, 1095.2057,
         865.7433,  822.2487,  828.3461,  859.6390, 1011.5152,  791.5400,
         828.8615,  733.4118,  677.8040,  746.3347,  697.8250,  700.7526,
         789.0173, 1083.7395, 1077.6854, 1306.9485,  811.8737,  772.3314,
         720.5856,  873.3372,  884.3650,  927.4521,  926.6605, 1167.4323,
         937.3185,  936.8854,  867.5662,  778.1900, 1042.1102,  938.8931,
        1057.0356,  906.3972, 1176.1753,  948.1027,  827.6169, 1204.8121,
         848.2949,  958.1824,  771.7387,  906.5857,  906.6685,  869.6214,
         992.4874, 1002.9290,  993.6365, 1014.3952, 1077.5773,  868.5431,
         952.3141,  708.4885, 1272.9731, 1041.5776,  696.4507,  830.7090,
         831.6888,  786.8708,  866.4905,  922.6278,  893.0774,  753.9348,
         815.3454,  714.3716,  945.1865,  995.3091,  993.6182,  758.0295,
        1090.4121,  677.3804,  711.2347,  889.0437,  890.7511,  979.5101,
         822.6677, 1039.6304, 1222.3346, 1015.5691, 1102.7573,  707.4916,
         940.5937,  786.8254, 1241.8940, 1078.7456, 1272.7832,  852.7166,
        1188.7134, 1061.9369, 1126.3169,  971.0359,  881.8785, 1164.9114,
         727.6863,  958.2653,  733.4215, 1144.5411, 1014.3015, 1215.3857,
         849.9094,  686.9132, 1244.2662,  998.0245, 1076.2135, 1125.6898,
         883.9669,  972.2963, 1113.9104,  757.9030,  733.5112,  910.0078,
         892.0408, 1096.4441,  881.8672,  768.9330,  985.4720,  991.6150,
         975.0635, 1028.7341,  935.7817,  926.9579,  721.1335, 1055.7812,
        1101.6573,  905.6153])
Layer: encoder.7.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 7678.9941,  8102.4229,  8490.7178,  7834.4624,  7946.4858,  7398.5312,
         9793.2695,  6626.1782,  6953.6235,  7719.3809,  7065.2183,  7994.7773,
         9093.3457,  7326.4795,  9472.2295,  8628.9268,  5798.2910,  6140.8955,
         6150.3042,  7026.9526,  8908.6758,  7741.9624,  8767.3047,  7063.2529,
         7655.0454,  8175.2432,  8275.3740, 10366.5645,  8817.0020,  8055.4292,
         7162.7852,  7275.6313,  6713.6582, 10228.2510,  7778.6650,  7521.6611,
         8598.0576,  9182.0625,  7732.3164,  8642.0703,  7985.0542,  7215.3374,
         7704.0840,  8876.6543,  9650.6279,  8257.6172,  6021.9028,  7413.3433,
         6881.8159,  7285.8354,  9193.6045,  7954.5786,  8688.7051,  8122.0371,
         6805.5874,  6183.0757, 11224.0352,  8935.2793,  5678.8242,  8170.7715,
         8962.3496,  7198.8960,  7159.8887,  6108.9751,  8111.0693,  9508.3105,
         7298.8584,  8630.6299,  9195.7432,  5928.5718,  7903.0029,  7335.5801,
         8573.5977,  7644.4111,  7714.8701,  7572.8799,  7269.5386,  7193.1016,
         7464.0601,  7556.5312,  7943.3149,  6567.4658,  7961.9229,  8510.3018,
         8380.8193,  7671.6357,  8821.1172,  7703.8716,  8652.9756,  9367.5947,
         8548.3057,  6392.3574,  9025.1426,  8114.0669,  6535.4517,  9118.1650,
         8282.9785,  7103.4082,  6890.7437,  7429.6934,  6754.7261,  8253.7217,
         5967.4849,  9094.6660,  7114.6704,  7177.6567,  9961.4746,  8994.0254,
         8133.1455,  8477.3105,  7428.3271,  7983.2881,  6910.0229,  8073.9590,
        11295.0771,  7947.2373, 10725.7959, 10405.1377,  8046.1543,  6710.2544,
        11509.9746,  6783.5825,  8217.1270, 10917.5146,  6994.9111,  8769.0889,
         5514.8535,  9041.7832,  8884.2637,  8232.0176,  7832.3403,  4897.2788,
         7671.9434,  7672.2515,  6766.5049,  7048.1143,  7517.9736, 10184.2588,
         6920.4175,  6506.8774,  8634.5449,  7001.2310,  8158.2979,  7213.7021,
         6752.7573,  6835.7021,  8392.4189,  7046.2822,  8055.4077,  8154.2144,
         6828.0938,  9497.1270,  6234.7856,  7283.1621, 11256.5410,  9900.0020,
         6486.8687,  6017.0127,  6420.8354,  7328.7017,  9989.9023,  7121.5889,
         6393.2676,  8213.5752,  7299.5918,  7380.7944,  9557.1748,  6972.4434,
         7688.1411,  7909.5493,  7091.6514,  8124.4053,  9894.5576,  7190.8843,
        10758.1387,  9024.6475,  7479.9390,  8250.8604,  8028.4688,  7976.3164,
         8292.9619,  8667.8955,  8274.8262,  7548.9922,  9423.9922,  6042.8555,
         8241.5078,  7031.2998,  8540.7627,  6443.9624,  7329.1270,  7813.9858,
         6817.6899,  6989.0845,  7328.4561,  8195.0928,  7908.1924,  8595.3506,
         6811.6714,  9316.6357,  6932.7852,  6709.5854,  9239.3447,  8439.2393,
         8809.2646,  7530.7646,  9215.7451,  7141.9746, 11291.0254,  8024.8398,
         7717.1162,  7213.8823,  6790.7349,  6838.8975,  7331.4409,  8391.9863,
         9186.2939,  6583.1523,  8957.9346,  7133.1899,  6647.9077,  8089.8203,
         7595.9199,  7080.8472,  7719.0640,  7977.4897, 10456.6895,  9115.3750,
         6848.1177,  6235.5049,  7477.8530,  7969.7871,  8015.7646,  8614.8271,
         5536.1362,  7960.7319,  8558.9131,  8797.4375, 10902.6934,  7958.0835,
         6853.6431,  7931.7510,  7930.7061,  9419.3916,  6786.8804,  8238.3955,
         7384.0098,  8661.9229,  6647.0713,  7614.4736,  7924.6958,  8460.7520,
         7096.0391,  9489.1523,  7331.0762,  8717.3252,  8994.5791,  6703.0557,
         8272.7207,  5952.5176,  9894.4756,  6812.5366,  7426.4932,  7481.6577,
         7234.9751,  7369.9883,  7148.2407,  6511.0771,  9290.0527,  7863.0317,
         9297.8447, 10285.5156,  8521.2842,  8493.0947,  6396.8145,  8604.0430,
         8761.8271, 10788.0420,  9350.6113,  7716.0913,  7991.2539,  9731.5020,
         8263.7754,  5639.9004,  7891.4893,  8606.3447,  8764.8398,  9241.7949,
         7327.8706, 10434.6230,  9154.6543,  6184.6885,  6520.9941,  8002.2817,
         9301.1953,  6689.3423,  8281.0000,  6474.4844,  6805.3433,  7090.3823,
         7924.1245,  6962.0938,  8649.7812,  6385.1680,  6777.3804,  6901.9800,
         6565.1743,  8536.5029,  8189.2847,  7500.3940,  8067.6206,  7290.9600,
        10208.9092,  6013.7603,  8575.5371,  9617.4014,  6800.7686,  7441.2095,
         7174.5400,  6803.7158,  8000.8833,  8123.4341,  8492.0771,  8375.6992,
         6811.4072,  7987.0605,  7530.2104,  7477.6333,  9016.9248,  6309.5806,
         7396.3198,  6507.8682,  8558.3887,  7150.4131,  9506.1152,  7569.6157,
         9655.8096,  7725.3477,  9543.7021,  7321.9980,  7404.3862,  7271.2383,
         8874.7461,  8099.2617,  7426.3721,  6396.8525, 10345.5684,  6227.0718,
        10179.2324,  7873.3057,  6499.9985,  8964.5586,  6609.0752,  5621.2935,
         5727.9014,  8789.2480,  7132.1299,  6446.1631,  7697.5454,  8222.7275,
         8284.3857,  6838.8843,  9148.5791,  7768.3159,  9405.8398,  8056.0225,
        10211.4238,  7388.4980,  7446.4600,  6557.7476,  7919.1230,  6417.7441,
         9580.4258,  6905.2671,  9842.7842,  8154.6157,  7647.7612,  6929.0571,
         6647.1489,  9992.4102,  5550.2393,  9136.3945,  8152.6333,  6658.8589,
         9888.8809,  9069.5996, 10211.3604,  7863.0327,  9807.9814,  9552.9893,
         6905.2705,  7536.7622,  7424.0757,  9508.4004,  9062.2803,  7467.9722,
         8094.4688,  7727.2065,  7378.7905, 11003.3574,  5864.6797,  8159.3711,
         7241.2363,  9044.0850,  9145.0742,  9603.6074,  6448.0239,  7978.6211,
         7964.6680,  7355.4561,  7505.3584,  6506.5791,  9694.0146,  7340.7632,
         7364.5425,  7273.8057,  9296.9854,  6762.7876,  9565.8223,  6557.2681,
         9730.3369,  7177.3716,  9224.3457,  7772.8706,  9330.4688, 10070.7451,
         7300.9033,  5873.8872,  8510.3867,  8566.8057,  8875.6211,  6494.3745,
         6305.1128,  7595.6577,  9582.1533,  7378.0439,  7199.3286, 10029.0381,
         8407.0469,  7661.7598,  8613.9316,  8943.8115,  7102.7861,  9111.0820,
         6278.5913,  6237.0762,  6367.9932,  7845.5039,  8347.5342,  7386.9204,
         9654.4336,  9147.8008,  9260.2891,  9033.6279,  9019.6191,  8709.4463,
         7684.4697,  6810.0513,  8551.6631,  6949.6284,  7127.1167,  9171.8408,
         6357.8857,  8493.2344,  7723.0967,  7765.5332,  8926.7646,  8083.1724,
         7122.6201,  8967.5986,  6664.5356,  7105.0425,  9920.3926,  6908.8467,
         5956.3110,  6347.4966,  8197.6416,  7392.7295,  7229.2632,  7929.6294,
         8313.7871,  8843.4424,  6564.7080,  6853.8354,  6956.7285,  8725.1455,
         9132.2021,  7461.4746,  4953.2197,  7370.8320,  8534.1182,  7791.5845,
         6496.2866,  6982.4980,  8114.0532,  9452.4697,  6600.3120,  9220.0654,
         6862.3770,  8070.7876,  9619.0967,  8127.8320,  8826.5938,  9987.5381,
         6242.9292,  9009.6162,  6913.8511,  7471.0518,  7684.0996,  7653.7969,
         8315.7666, 10444.2158])
Layer: encoder.7.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([9.8209e+01, 1.8532e-01, 9.9103e+01,  ..., 7.7420e+01, 3.3164e+02,
        7.9326e+01])
Layer: encoder.7.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 579.5654,  611.3971,  835.2222,  569.9508,  495.0396,  608.0706,
         603.4193, 1014.2875,  658.1649,  711.8440,  696.9443,  724.1306,
         620.1960,  674.0302,  534.8214,  719.1686,  653.6051,  516.3823,
         563.6973,  618.5593,  838.4731,  800.9272,  668.7463,  696.1617,
         768.3468,  586.0500,  940.1758,  729.9348,  752.0765,  526.8712,
         825.2971,  528.9560,  604.7378,  773.3073,  749.6513,  982.0820,
         815.7692,  643.4368,  539.5980,  539.9470,  689.1939,  527.6205,
         646.6439,  714.3518,  565.0241,  499.6736,  605.4994,  936.0905,
         669.4536,  486.7242,  828.9022,  775.1362,  670.4572,  683.2852,
         613.3799,  521.8926,  556.1150,  702.7793,  604.7858,  737.4435,
         746.4154,  590.3743,  642.4161,  781.9359,  491.9530,  493.3166,
         615.4554,  459.7727,  661.2433,  749.3222,  606.5990,  680.3621,
         659.6219,  502.6818,  731.8232,  791.9792,  526.8204,  524.2520,
         513.0674,  611.5776,  815.3876,  604.1668,  608.4316,  575.5717,
         920.1807,  702.3024,  646.1417,  648.3508,  851.2202,  746.2975,
         508.1607,  680.4034,  568.6066,  620.7118,  466.2167,  917.9505,
         915.8127,  980.3346,  711.2147,  579.6782,  657.7236,  798.6617,
         534.6398,  443.1276,  819.1923,  725.8422,  626.1777,  631.4387,
         652.5560,  796.4088,  618.8728,  642.7244,  489.5428,  597.8169,
         685.4189,  770.7005,  766.9728,  688.7361,  430.0663,  785.7668,
         564.8875,  636.0505,  678.1042,  938.3914,  419.0750,  513.0531,
         598.2061,  624.0204,  794.7262,  600.2101,  723.6674,  625.0489,
         746.1573,  619.7598,  809.2772,  611.4639,  510.4555,  701.7677,
         697.0052,  532.9100,  556.7649,  552.7764,  498.9412,  762.6569,
         657.3008,  702.2120,  724.6957,  711.5365,  725.5673,  718.4313,
         715.3917,  648.9272,  610.4180,  641.1332,  662.3575,  702.8452,
         547.8250,  588.7928,  699.7341,  725.6901,  651.8523,  695.9321,
         623.2017,  539.3814,  843.3784,  771.7839,  672.3140,  517.5852,
         630.2812,  544.6006,  636.6313,  879.5049,  907.8275,  734.3841,
         849.0553,  799.3023,  761.6784,  652.2600,  497.8686,  590.9836,
         808.4011,  809.2518,  828.0764,  732.0881,  568.1757,  825.1685,
         777.2808,  814.6318,  648.0234,  607.2050,  686.4361,  614.1788,
         904.2578,  745.0960,  524.6833,  695.4628,  651.3319,  674.8191,
         577.3075,  637.6055,  758.7686,  730.4241,  550.5825,  521.1089,
         776.5287,  725.6016,  742.6788,  529.4802,  454.8686,  572.9567,
         702.5410,  461.7656,  523.2521,  623.8085,  634.7818,  649.6755,
         599.2131,  650.2543,  604.6121,  818.5817,  518.5861,  662.4291,
         574.5178,  693.0385,  772.1752,  861.3786,  595.0852,  705.6104,
         736.7693,  792.9234,  675.6849,  606.2860,  707.8294,  878.2264,
         462.9863,  858.0754,  667.1525,  704.6556,  869.1025,  525.7761,
         692.8231,  752.9886,  735.4764,  659.0373,  549.0807,  807.2290,
         672.7106,  801.3895,  573.4672,  573.0977,  637.3943,  572.2726,
         726.5621,  646.2889,  572.4055,  705.3374,  789.3350,  684.3563,
         672.3029,  517.8871,  960.2375,  616.1903,  589.3658,  512.6948,
         750.5387,  498.0258,  692.2444,  643.2123,  660.7344,  545.0350,
         830.6172,  839.3565,  628.5801,  745.6790,  579.8046,  550.6797,
         637.9958,  656.0916,  635.1147,  631.7249,  639.6771,  506.0017,
         810.1213,  733.1487,  640.7337,  589.6647, 1002.9805,  530.7891,
         622.8033,  605.8990,  496.1802,  513.3377,  524.3338,  706.5110,
         784.7526,  727.2693,  694.4541,  596.6361,  557.8538,  574.3970,
         653.7910,  575.4573,  553.2182,  648.9551,  549.1985,  773.3315,
         571.7827,  610.3210,  858.1239,  679.7958,  654.4835,  422.2372,
         883.5485,  580.9976,  644.9961,  650.4095,  510.2797,  494.4548,
         667.9453,  597.9314,  779.4454,  621.4113,  449.6409,  644.4818,
         848.6082,  550.3740,  658.5174,  569.5887,  660.1580,  748.6037,
         579.5839,  422.7591,  538.1295,  540.1188,  712.1799,  944.6625,
         592.1435,  683.1566,  769.4318,  576.7874,  694.7819,  492.5126,
         750.8190,  580.6321,  859.1296,  657.0265,  629.9930,  719.7943,
         766.6302,  708.3140,  614.8317,  618.3013,  707.8013,  688.4557,
         618.0795,  883.2542,  626.3972,  756.7416,  456.2043,  918.4076,
         657.2948,  565.0750,  543.2939,  538.2273,  780.4373,  446.2573,
         536.0844,  826.5588,  625.7292,  624.4389,  841.4230,  554.5036,
         576.3881,  442.6611,  599.0104,  637.2673,  800.7221,  580.2812,
         688.4337,  666.8441,  551.6830,  595.9328,  456.1870,  738.4267,
         736.2182,  631.5987,  520.5939,  618.8983,  872.0382,  658.9182,
         868.2893,  593.8135,  737.3116,  622.1146,  869.3798,  833.1258,
         727.2333,  715.5060,  663.8476,  573.5869,  819.3538,  626.3981,
         722.4224,  778.0710,  668.5834,  707.1165,  759.8517,  614.1909,
         645.3575,  542.5474,  687.6426,  555.0412,  573.4663,  671.5984,
         658.4745,  859.2281,  689.2467,  628.3091,  586.1627,  674.1226,
         584.0848,  689.6426,  633.0548,  536.6437,  615.1390,  850.8778,
         530.6803,  904.2072,  520.2378,  730.9360,  733.3706,  790.1843,
         736.6840,  615.1477,  652.4142,  539.3771,  475.0145,  532.5956,
         831.8262,  999.3375,  625.8503,  589.3396,  583.5172,  526.0618,
         583.1284,  700.0061,  559.8459,  731.4603,  553.6367,  682.5376,
         592.8865,  849.5828,  642.6266,  613.4612,  545.4867,  592.5905,
         680.2188,  641.3310,  633.4534,  846.7643,  815.2961,  554.7161,
         712.2285,  666.7039,  552.4454,  590.6263,  783.7451,  692.9141,
         561.6920,  544.2741,  771.5614,  757.9897,  587.6291,  597.1660,
         865.0275,  737.3882,  528.3757,  848.2621,  840.5219,  621.1570,
         568.0401,  550.6317,  666.7989,  692.5038,  382.8994,  650.1965,
         632.2215,  597.1956,  632.4898,  645.2249,  860.8333,  609.6298,
         595.0006,  624.4990,  731.7661,  706.3859,  568.5523,  747.9968,
         601.7599,  437.9341,  643.0694,  680.5054,  467.2876,  635.3131,
         643.4323,  533.7929,  594.6455,  609.7187,  704.0710,  836.1876,
         487.9631,  631.4500])
Layer: encoder.7.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 7841.4229,  5907.9810,  6014.3833,  5945.8882,  7111.1421,  6772.7837,
         6391.3267,  5951.0552,  8529.2207,  5076.2256,  5264.7852,  6033.3857,
         6149.8521,  6177.2812,  5580.0732,  5796.7344,  6340.1357,  8645.6787,
         7202.5449,  6332.4443,  7232.8994,  8531.0029,  6362.8418,  6077.7671,
         5620.2075,  6899.6099,  7051.8042,  5457.0889,  5282.8384,  7479.4688,
         5165.2002,  8024.1704,  6348.3545, 10020.6357,  5964.6289,  8814.5762,
         6789.7354,  5796.6313,  8279.1426,  7385.2139,  6638.8877,  7173.6431,
         6685.0083,  6300.7979,  7414.4248,  5566.5435,  4737.5410,  6812.4751,
         5650.0801,  6767.4321,  7312.8062,  6689.0264,  6490.5337,  7005.8457,
         6365.5806,  7164.8169,  6586.7979,  8076.1938,  7563.8945,  5537.7339,
         7107.4561,  7189.3687,  8993.5898,  7027.1445,  6388.9897,  9358.9541,
         5094.9028,  5401.9478,  6921.1309,  7441.3042,  7307.5122,  8326.5166,
         6968.0479,  5662.0176,  6287.3838,  7591.7119,  6653.7798,  5050.4697,
         6551.1504,  6886.7227,  5578.1675,  6519.3584,  5008.6304,  6614.5210,
         5483.1499,  8479.0186,  6952.2793,  9369.1787,  6183.2012,  9552.4229,
         7054.1055,  5604.4355,  6651.3818,  5234.1104,  5991.5317,  7443.8398,
         6566.0654,  6995.4155,  5905.1738,  8019.3994,  7728.5879,  5606.1821,
         9068.4150,  6398.9121,  6882.5557,  7824.0142,  7273.7559,  7062.9053,
         8810.1318,  7829.0869,  5734.4995,  7618.0166,  7676.6113,  9415.6025,
         7129.5205,  8192.8594,  7197.3130,  5641.7871,  7213.2056,  9635.3447,
         6810.8262,  8022.0239,  5908.9321,  6253.8843,  6919.9585,  7291.2207,
         5716.8027,  5646.3799, 11925.1123,  5210.2261,  7889.1362,  5744.4424,
         5405.0498,  5623.5815,  6855.6230,  6297.6558,  6333.4307,  5105.6177,
         5245.2549,  7250.1499,  7502.7646,  8486.0254,  6985.4102,  7786.2520,
         8307.0410,  7827.2124,  6096.3604,  5333.9639,  7392.4814,  6393.0293,
         8190.2051, 10475.1357,  7208.2788,  9533.1973,  5899.1021,  5772.2368,
         5675.8545,  8154.9053,  5745.0493,  7912.7422,  8179.8423,  6923.8374,
         7364.3931,  6676.0903,  6850.9565,  6830.3076,  6860.3398,  6766.8789,
         6853.8193,  6525.8955,  5979.9429,  7333.8853,  6811.0015,  7111.3691,
         6352.7134,  8564.1016,  5960.5752,  9260.9102,  8240.3340,  9800.1084,
         7319.6743,  7133.7256,  7066.2363,  6266.6899,  5743.5698,  5104.0698,
         7872.4453,  5468.9595,  7627.8301,  8569.9062,  5781.3755,  6739.4751,
         5977.3027,  6364.3887,  6093.3135,  6626.4380,  7275.4795,  5189.9072,
         6022.0034,  5030.5322,  7134.9883,  7016.8374,  6636.2163,  8519.7842,
         5923.8228,  9503.8057,  7068.2563,  6127.5244,  6650.6807,  8424.4971,
         5129.5889,  5375.5811,  6383.5972,  7722.7085,  7057.8608,  7715.3379,
         6531.9668,  6477.0464,  7704.7173,  5673.9473,  6946.5737,  8214.4180,
         6622.8325,  6744.7827,  7631.4028,  6271.6777,  4875.4678,  7408.3716,
         6588.4897,  6723.3672,  7570.4629,  7567.7788,  6631.8970,  5828.1704,
         5997.0454,  5496.4663,  5686.0586,  6673.3784,  6581.2056,  7189.5664,
         4516.3511,  7688.9614,  7509.0874,  6171.7822,  6608.2495,  8091.2427,
         8733.8740,  8785.2412,  8560.6299,  5466.5107,  5420.8984,  6671.2466,
         6687.6611,  6480.4097,  6125.6138,  5809.8843,  5669.3833,  6005.3418,
         9726.8408,  8008.0029,  7457.2773,  4981.1763,  6283.3794,  7274.4927,
         5665.4429,  7357.5078,  5757.9062,  8183.8574,  6678.0742,  7410.5811,
         7475.1270,  5729.0376,  6167.8706,  5143.3560,  8432.9688,  7220.9282,
         7385.8120,  5515.1509,  5205.5400,  6647.9395,  6812.6934,  7967.3545,
         7102.2251,  7174.2769,  5647.2554,  7169.5059,  6503.1421,  6182.7529,
         6262.1021,  7232.8848,  5237.7993,  7831.1416,  5888.4985,  8521.8193,
         8156.9541,  9155.6943,  5485.2002,  6447.3472,  7306.5732,  5980.4785,
         4765.5762,  6478.0483,  8318.3906,  7183.9648,  7734.3828,  7405.7549,
         7454.6538,  6998.5464,  5045.5195,  5885.0581,  5435.5537,  5865.8530,
         6680.2290,  5719.2314,  4999.1846,  5560.9224,  6266.2153,  5434.9224,
         6792.7734,  4917.5137,  8732.0518,  6070.3672,  8428.9121,  7320.4004,
         8793.1885,  6692.7285,  7091.6069,  7990.5845,  6283.9873,  6552.6812,
         6157.6812,  7338.8853,  5845.9868,  6847.6182,  4648.2725,  7469.3022,
         6202.7871,  4886.6484,  5535.3970,  7969.4351,  6254.8145,  4881.5371,
         6717.5879,  8739.7188,  5873.9805,  5349.0894,  7584.2603,  8160.7539,
         5505.5801,  5238.5781,  6384.6348,  6470.5757,  5207.9409,  6053.0063,
         5635.1631,  7217.5688,  5911.2065,  5407.5747,  5767.5264,  5501.8706,
         7771.2939,  8623.9961,  8028.0840,  6995.1890,  6433.0312,  6580.2808,
         5370.8535,  6214.8682,  7278.6470,  6124.3706,  6669.5625,  7192.0459,
         6209.1382,  6743.6162,  6836.1909,  9160.7383,  6328.7505,  7135.9160,
         6610.9546,  5763.8789,  7888.4126,  6012.5479,  5947.4365,  7584.6558,
         6910.2627,  6979.8965,  5820.2686,  5158.8794,  8393.7002,  5936.2959,
         4615.1543,  8995.3809,  7470.4941,  6814.5576,  7781.1450,  6730.8638,
        11777.2520,  4909.4824,  7447.5693,  6110.5615,  5933.5088,  5278.0166,
         8462.4219,  6097.7856,  7641.3545,  6293.3760,  8994.7822,  4810.7261,
         6659.3228,  6666.9141,  6354.0693,  7595.8608,  5947.0503,  6848.1372,
         7486.2983,  4722.1665,  5414.4219,  6722.6421,  5325.1914,  7714.4370,
         7243.4795,  5259.2827,  6591.6240,  5354.6982,  7597.3896,  4731.3389,
         5358.8271,  6462.0171,  7239.1567,  8628.9277,  5893.2163,  6080.0908,
         5617.3979,  7137.6235,  6985.9736,  6155.7173,  7493.2300,  7205.4893,
         5757.6572,  7147.5708,  5200.6304,  6427.7300,  7735.3140,  7002.6938,
         6483.2876,  7482.2261,  6035.6519,  6804.6836,  6788.3491,  7128.3096,
         8516.4570,  7269.1924,  7606.4463,  6961.5415,  8656.1016,  6616.9971,
         7026.5591,  8139.9155,  9266.7861,  6380.2339,  6422.7539,  7710.6611,
         6177.4043,  8307.7852,  7055.2729,  5778.4209,  7648.2651,  6365.3457,
         6269.3945,  6576.0576,  8272.2764,  6524.0654,  7745.0576,  6701.1030,
         6734.1758,  5202.7178,  7564.5996, 10584.8809,  7121.8257,  6076.6172,
         5125.2119,  6141.6138,  8393.4971,  6122.3047,  7434.1865,  7147.6641,
         7091.5649,  6139.1323,  7559.7109,  4559.8413,  8262.1553,  6959.9048,
         6408.8208,  5286.0439,  6532.6240,  8847.6816,  7002.7310,  5800.7280,
         7582.3779,  7788.3657,  7780.3013,  5312.9106,  5687.1113,  8145.5576,
         6840.4775,  6005.1099,  6130.9736,  9812.4258,  5895.7144,  5858.0391,
         9453.2383,  5740.3633])
Layer: encoder.7.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([  0.0000,  15.0245,  49.3432,  ..., 134.5076, 343.9723, 217.2310])
[DEBUG] Global concept maps computed with 53 layers.
Layer: conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.4.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.4.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.4.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.4.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.4.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.4.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0')}}
Layer: encoder.5.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.5.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.5.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0.], device='cuda:0')}}
Layer: encoder.5.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.3.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0')}}
Layer: encoder.5.3.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.3.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.6.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.3.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.3.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.3.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.4.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.4.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.4.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.7.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.7.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.7.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.7.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.7.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.7.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.7.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}}
[DEBUG] Global pruning mask: OrderedDict([('conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}}), ('encoder.4.0.conv1', {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0')}}), ('encoder.4.0.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.0.conv3', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 0., 0., 1.], device='cuda:0')}}), ('encoder.4.0.downsample.0', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1.], device='cuda:0')}}), ('encoder.4.1.conv1', {'Conv2d': {'weight': tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.1.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0')}}), ('encoder.4.1.conv3', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.2.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0')}}), ('encoder.4.2.conv2', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.2.conv3', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.0.conv1', {'Conv2d': {'weight': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0')}}), ('encoder.5.0.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0')}}), ('encoder.5.0.conv3', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}}), ('encoder.5.0.downsample.0', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0')}}), ('encoder.5.1.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0.], device='cuda:0')}}), ('encoder.5.1.conv2', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0')}}), ('encoder.5.1.conv3', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.2.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0.], device='cuda:0')}}), ('encoder.5.2.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1.], device='cuda:0')}}), ('encoder.5.2.conv3', {'Conv2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.3.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1.], device='cuda:0')}}), ('encoder.5.3.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}}), ('encoder.5.3.conv3', {'Conv2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.0.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.0.conv2', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.0.conv3', {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.0.downsample.0', {'Conv2d': {'weight': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.1.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.1.conv2', {'Conv2d': {'weight': tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.1.conv3', {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.2.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.2.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1.], device='cuda:0')}}), ('encoder.6.2.conv3', {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.3.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.3.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.3.conv3', {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.4.conv1', {'Conv2d': {'weight': tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.4.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.4.conv3', {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.5.conv1', {'Conv2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.5.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.5.conv3', {'Conv2d': {'weight': tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 0., 1., 1.], device='cuda:0')}}), ('encoder.7.0.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.0.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0')}}), ('encoder.7.0.conv3', {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:0')}}), ('encoder.7.0.downsample.0', {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')}}), ('encoder.7.1.conv1', {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.1.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.1.conv3', {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 0., 1., 0.], device='cuda:0')}}), ('encoder.7.2.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0')}}), ('encoder.7.2.conv2', {'Conv2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0')}}), ('encoder.7.2.conv3', {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}})])
Full profiling results saved to /home/paul/projects/CV4RS-main/pruning_callgraph.txt
=== Round 2/3 ===
Applying pruning mask for Round 2...
[DEBUG] Validating mask for layer: conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 10, 7, 7])
[INFO] Successfully applied mask to weight in layer: conv1
[DEBUG] Layer conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 10, 7, 7])
[INFO] Successfully applied mask to weight in layer: conv1
[DEBUG] Layer conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: conv1
[DEBUG] Validating mask for layer: encoder.4.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv1
[DEBUG] Layer encoder.4.0.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv1
[DEBUG] Layer encoder.4.0.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv1
[DEBUG] Validating mask for layer: encoder.4.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv2
[DEBUG] Layer encoder.4.0.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv2
[DEBUG] Layer encoder.4.0.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv2
[DEBUG] Validating mask for layer: encoder.4.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv3
[DEBUG] Layer encoder.4.0.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv3
[DEBUG] Layer encoder.4.0.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv3
[DEBUG] Validating mask for layer: encoder.4.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.downsample.0
[DEBUG] Layer encoder.4.0.downsample.0 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.downsample.0
[DEBUG] Layer encoder.4.0.downsample.0 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.downsample.0
[DEBUG] Validating mask for layer: encoder.4.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv1
[DEBUG] Layer encoder.4.1.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv1
[DEBUG] Layer encoder.4.1.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv1
[DEBUG] Validating mask for layer: encoder.4.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv2
[DEBUG] Layer encoder.4.1.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv2
[DEBUG] Layer encoder.4.1.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv2
[DEBUG] Validating mask for layer: encoder.4.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv3
[DEBUG] Layer encoder.4.1.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv3
[DEBUG] Layer encoder.4.1.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv3
[DEBUG] Validating mask for layer: encoder.4.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv1
[DEBUG] Layer encoder.4.2.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv1
[DEBUG] Layer encoder.4.2.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv1
[DEBUG] Validating mask for layer: encoder.4.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv2
[DEBUG] Layer encoder.4.2.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv2
[DEBUG] Layer encoder.4.2.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv2
[DEBUG] Validating mask for layer: encoder.4.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv3
[DEBUG] Layer encoder.4.2.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv3
[DEBUG] Layer encoder.4.2.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv3
[DEBUG] Validating mask for layer: encoder.5.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv1
[DEBUG] Layer encoder.5.0.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv1
[DEBUG] Layer encoder.5.0.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv1
[DEBUG] Validating mask for layer: encoder.5.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv2
[DEBUG] Layer encoder.5.0.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv2
[DEBUG] Layer encoder.5.0.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv2
[DEBUG] Validating mask for layer: encoder.5.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv3
[DEBUG] Layer encoder.5.0.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv3
[DEBUG] Layer encoder.5.0.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv3
[DEBUG] Validating mask for layer: encoder.5.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.downsample.0
[DEBUG] Layer encoder.5.0.downsample.0 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.downsample.0
[DEBUG] Layer encoder.5.0.downsample.0 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.downsample.0
[DEBUG] Validating mask for layer: encoder.5.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv1
[DEBUG] Layer encoder.5.1.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv1
[DEBUG] Layer encoder.5.1.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv1
[DEBUG] Validating mask for layer: encoder.5.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv2
[DEBUG] Layer encoder.5.1.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv2
[DEBUG] Layer encoder.5.1.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv2
[DEBUG] Validating mask for layer: encoder.5.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv3
[DEBUG] Layer encoder.5.1.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv3
[DEBUG] Layer encoder.5.1.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv3
[DEBUG] Validating mask for layer: encoder.5.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv1
[DEBUG] Layer encoder.5.2.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv1
[DEBUG] Layer encoder.5.2.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv1
[DEBUG] Validating mask for layer: encoder.5.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv2
[DEBUG] Layer encoder.5.2.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv2
[DEBUG] Layer encoder.5.2.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv2
[DEBUG] Validating mask for layer: encoder.5.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv3
[DEBUG] Layer encoder.5.2.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv3
[DEBUG] Layer encoder.5.2.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv3
[DEBUG] Validating mask for layer: encoder.5.3.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv1
[DEBUG] Layer encoder.5.3.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv1
[DEBUG] Layer encoder.5.3.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv1
[DEBUG] Validating mask for layer: encoder.5.3.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv2
[DEBUG] Layer encoder.5.3.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv2
[DEBUG] Layer encoder.5.3.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv2
[DEBUG] Validating mask for layer: encoder.5.3.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv3
[DEBUG] Layer encoder.5.3.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv3
[DEBUG] Layer encoder.5.3.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv3
[DEBUG] Validating mask for layer: encoder.6.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv1
[DEBUG] Layer encoder.6.0.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv1
[DEBUG] Layer encoder.6.0.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv1
[DEBUG] Validating mask for layer: encoder.6.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv2
[DEBUG] Layer encoder.6.0.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv2
[DEBUG] Layer encoder.6.0.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv2
[DEBUG] Validating mask for layer: encoder.6.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv3
[DEBUG] Layer encoder.6.0.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv3
[DEBUG] Layer encoder.6.0.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv3
[DEBUG] Validating mask for layer: encoder.6.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.downsample.0
[DEBUG] Layer encoder.6.0.downsample.0 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.downsample.0
[DEBUG] Layer encoder.6.0.downsample.0 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.downsample.0
[DEBUG] Validating mask for layer: encoder.6.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv1
[DEBUG] Layer encoder.6.1.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv1
[DEBUG] Layer encoder.6.1.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv1
[DEBUG] Validating mask for layer: encoder.6.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv2
[DEBUG] Layer encoder.6.1.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv2
[DEBUG] Layer encoder.6.1.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv2
[DEBUG] Validating mask for layer: encoder.6.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv3
[DEBUG] Layer encoder.6.1.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv3
[DEBUG] Layer encoder.6.1.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv3
[DEBUG] Validating mask for layer: encoder.6.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv1
[DEBUG] Layer encoder.6.2.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv1
[DEBUG] Layer encoder.6.2.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv1
[DEBUG] Validating mask for layer: encoder.6.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv2
[DEBUG] Layer encoder.6.2.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv2
[DEBUG] Layer encoder.6.2.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv2
[DEBUG] Validating mask for layer: encoder.6.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv3
[DEBUG] Layer encoder.6.2.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv3
[DEBUG] Layer encoder.6.2.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv3
[DEBUG] Validating mask for layer: encoder.6.3.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv1
[DEBUG] Layer encoder.6.3.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv1
[DEBUG] Layer encoder.6.3.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv1
[DEBUG] Validating mask for layer: encoder.6.3.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv2
[DEBUG] Layer encoder.6.3.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv2
[DEBUG] Layer encoder.6.3.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv2
[DEBUG] Validating mask for layer: encoder.6.3.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv3
[DEBUG] Layer encoder.6.3.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv3
[DEBUG] Layer encoder.6.3.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv3
[DEBUG] Validating mask for layer: encoder.6.4.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv1
[DEBUG] Layer encoder.6.4.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv1
[DEBUG] Layer encoder.6.4.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv1
[DEBUG] Validating mask for layer: encoder.6.4.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv2
[DEBUG] Layer encoder.6.4.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv2
[DEBUG] Layer encoder.6.4.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv2
[DEBUG] Validating mask for layer: encoder.6.4.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv3
[DEBUG] Layer encoder.6.4.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv3
[DEBUG] Layer encoder.6.4.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv3
[DEBUG] Validating mask for layer: encoder.6.5.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv1
[DEBUG] Layer encoder.6.5.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv1
[DEBUG] Layer encoder.6.5.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv1
[DEBUG] Validating mask for layer: encoder.6.5.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv2
[DEBUG] Layer encoder.6.5.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv2
[DEBUG] Layer encoder.6.5.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv2
[DEBUG] Validating mask for layer: encoder.6.5.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv3
[DEBUG] Layer encoder.6.5.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv3
[DEBUG] Layer encoder.6.5.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv3
[DEBUG] Validating mask for layer: encoder.7.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv1
[DEBUG] Layer encoder.7.0.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv1
[DEBUG] Layer encoder.7.0.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv1
[DEBUG] Validating mask for layer: encoder.7.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv2
[DEBUG] Layer encoder.7.0.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv2
[DEBUG] Layer encoder.7.0.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv2
[DEBUG] Validating mask for layer: encoder.7.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv3
[DEBUG] Layer encoder.7.0.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv3
[DEBUG] Layer encoder.7.0.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv3
[DEBUG] Validating mask for layer: encoder.7.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.downsample.0
[DEBUG] Layer encoder.7.0.downsample.0 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.downsample.0
[DEBUG] Layer encoder.7.0.downsample.0 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.downsample.0
[DEBUG] Validating mask for layer: encoder.7.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv1
[DEBUG] Layer encoder.7.1.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv1
[DEBUG] Layer encoder.7.1.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv1
[DEBUG] Validating mask for layer: encoder.7.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv2
[DEBUG] Layer encoder.7.1.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv2
[DEBUG] Layer encoder.7.1.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv2
[DEBUG] Validating mask for layer: encoder.7.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv3
[DEBUG] Layer encoder.7.1.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv3
[DEBUG] Layer encoder.7.1.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv3
[DEBUG] Validating mask for layer: encoder.7.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv1
[DEBUG] Layer encoder.7.2.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv1
[DEBUG] Layer encoder.7.2.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv1
[DEBUG] Validating mask for layer: encoder.7.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv2
[DEBUG] Layer encoder.7.2.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv2
[DEBUG] Layer encoder.7.2.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv2
[DEBUG] Validating mask for layer: encoder.7.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv3
[DEBUG] Layer encoder.7.2.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv3
[DEBUG] Layer encoder.7.2.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv3
Training and communication for Round 2...
Epoch 1/2
----------
Epoch 2/2
----------
Epoch 1/2
----------
Epoch 2/2
----------
Epoch 1/2
----------
Epoch 2/2
----------
Skipping missing parameter: conv1.bias
Skipping missing parameter: encoder.0.bias
Skipping missing parameter: encoder.4.0.conv1.bias
Skipping missing parameter: encoder.4.0.conv2.bias
Skipping missing parameter: encoder.4.0.conv3.bias
Skipping missing parameter: encoder.4.0.downsample.0.bias
Skipping missing parameter: encoder.4.1.conv1.bias
Skipping missing parameter: encoder.4.1.conv2.bias
Skipping missing parameter: encoder.4.1.conv3.bias
Skipping missing parameter: encoder.4.2.conv1.bias
Skipping missing parameter: encoder.4.2.conv2.bias
Skipping missing parameter: encoder.4.2.conv3.bias
Skipping missing parameter: encoder.5.0.conv1.bias
Skipping missing parameter: encoder.5.0.conv2.bias
Skipping missing parameter: encoder.5.0.conv3.bias
Skipping missing parameter: encoder.5.0.downsample.0.bias
Skipping missing parameter: encoder.5.1.conv1.bias
Skipping missing parameter: encoder.5.1.conv2.bias
Skipping missing parameter: encoder.5.1.conv3.bias
Skipping missing parameter: encoder.5.2.conv1.bias
Skipping missing parameter: encoder.5.2.conv2.bias
Skipping missing parameter: encoder.5.2.conv3.bias
Skipping missing parameter: encoder.5.3.conv1.bias
Skipping missing parameter: encoder.5.3.conv2.bias
Skipping missing parameter: encoder.5.3.conv3.bias
Skipping missing parameter: encoder.6.0.conv1.bias
Skipping missing parameter: encoder.6.0.conv2.bias
Skipping missing parameter: encoder.6.0.conv3.bias
Skipping missing parameter: encoder.6.0.downsample.0.bias
Skipping missing parameter: encoder.6.1.conv1.bias
Skipping missing parameter: encoder.6.1.conv2.bias
Skipping missing parameter: encoder.6.1.conv3.bias
Skipping missing parameter: encoder.6.2.conv1.bias
Skipping missing parameter: encoder.6.2.conv2.bias
Skipping missing parameter: encoder.6.2.conv3.bias
Skipping missing parameter: encoder.6.3.conv1.bias
Skipping missing parameter: encoder.6.3.conv2.bias
Skipping missing parameter: encoder.6.3.conv3.bias
Skipping missing parameter: encoder.6.4.conv1.bias
Skipping missing parameter: encoder.6.4.conv2.bias
Skipping missing parameter: encoder.6.4.conv3.bias
Skipping missing parameter: encoder.6.5.conv1.bias
Skipping missing parameter: encoder.6.5.conv2.bias
Skipping missing parameter: encoder.6.5.conv3.bias
Skipping missing parameter: encoder.7.0.conv1.bias
Skipping missing parameter: encoder.7.0.conv2.bias
Skipping missing parameter: encoder.7.0.conv3.bias
Skipping missing parameter: encoder.7.0.downsample.0.bias
Skipping missing parameter: encoder.7.1.conv1.bias
Skipping missing parameter: encoder.7.1.conv2.bias
Skipping missing parameter: encoder.7.1.conv3.bias
Skipping missing parameter: encoder.7.2.conv1.bias
Skipping missing parameter: encoder.7.2.conv2.bias
Skipping missing parameter: encoder.7.2.conv3.bias
[INFO] Starting validation for Round 2...
True labels sample: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]
Predicted labels sample: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
Predicted probabilities sample: [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]
 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]
 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]
 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]
 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]]
NaN detected in predicted probabilities array.
[[nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 ...
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]]

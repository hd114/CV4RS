Lines that potentially need to be canonized 309
Using device: cuda:0
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    8209 filtered patches indexed
    8209 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7150 filtered patches indexed
    7150 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    4263 filtered patches indexed
    4263 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7180 filtered patches indexed
    7180 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    3248 filtered patches indexed
    3248 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    15720 filtered patches indexed
    15720 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
[INFO] Collecting local mean and std from clients...
[INFO] Calculating data mean and standard deviation...
[INFO] Data mean: 1053.059326171875, Data std: 1082.97412109375
[INFO] Calculating data mean and standard deviation...
[INFO] Data mean: 1429.1602783203125, Data std: 1643.434326171875
[INFO] Calculating data mean and standard deviation...
[INFO] Data mean: 1795.9522705078125, Data std: 1149.1971435546875
[INFO] Global data mean: 1328.435791015625, Global data std: 1258.6239013671875
Initializing LRP Pruning...
LRP initialized successfully.
=== Round 1/3 ===
Training and communication for Round 1...
[INFO] Calculating data mean and standard deviation...
[INFO] Data mean: 1053.059326171875, Data std: 1082.9739990234375
Epoch 1/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.8877880379580969
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.6810815121316617
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.3266158178960215
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.23513813090686037
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.24179555447290943
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.2332952096028966
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.20731407447375183
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.23433895183517345
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.2378380527954222
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.1924235020814303
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.20380653606657953
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.1913238826738593
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.18106636817712934
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.21397088292999497
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.1774223674818651
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.1772193180283764
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.1784569369430812
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.23256888573170995
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.18370089806492423
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.16585686557534882
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.17504083621264196
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.16536951491391932
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.19151105874985525
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.18737337018764116
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.17369725236178338
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.16895344891921948
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.16172472703688132
[DEBUG] Batch 27: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 27: 0.17613360252008342
[DEBUG] Batch 28: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 28: 0.16277393092648165
[DEBUG] Batch 29: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 29: 0.1656696674881461
[DEBUG] Batch 30: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 30: 0.15616592169339796
[DEBUG] Batch 31: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 31: 0.16070043951479124
[DEBUG] Batch 32: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 32: 0.16918293727656147
[DEBUG] Batch 33: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 33: 0.16261732583884242
[DEBUG] Batch 34: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 34: 0.15408569549527373
[DEBUG] Batch 35: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 35: 0.16007303416124377
[DEBUG] Batch 36: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 36: 0.15439719233371332
[DEBUG] Batch 37: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 37: 0.15277233738580362
[DEBUG] Batch 38: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 38: 0.154294624528147
[DEBUG] Batch 39: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 39: 0.1490751063037044
[DEBUG] Batch 40: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 40: 0.1435056795331215
[DEBUG] Batch 41: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 41: 0.1355009028157829
[DEBUG] Batch 42: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 42: 0.14792278491279673
[DEBUG] Batch 43: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 43: 0.1511317536003636
[DEBUG] Batch 44: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 44: 0.13765822612829556
[DEBUG] Batch 45: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 45: 0.14256899603305173
[DEBUG] Batch 46: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 46: 0.14638570931282102
[DEBUG] Batch 47: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 47: 0.13602297380084924
[DEBUG] Batch 48: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 48: 0.15786259761383659
[DEBUG] Batch 49: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 49: 0.14134616674248204
[DEBUG] Batch 50: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 50: 0.1426953393214905
[DEBUG] Batch 51: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 51: 0.14923898894087465
[DEBUG] Batch 52: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 52: 0.14105757515651043
[DEBUG] Batch 53: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 53: 0.1520436565085652
[DEBUG] Batch 54: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 54: 0.1494315465945702
[DEBUG] Batch 55: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 55: 0.13618299912880277
[DEBUG] Batch 56: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 56: 0.13766635339463273
[DEBUG] Batch 57: Data shape: torch.Size([213, 10, 120, 120]), Labels shape: torch.Size([213, 19])
[DEBUG] Loss for batch 57: 0.13510362454275895
[INFO] Training epoch completed successfully.
Epoch 2/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.13737886479599182
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.13767052014134185
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.1442747823219429
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.13268403645007404
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.1315002503524253
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.141899188799237
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.12994177266194057
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.12795407623347238
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.14239285585303954
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.1495123293565796
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.13036493991783996
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.13025133948674694
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.12716806070626202
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.1280176652835226
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.14239549799641904
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.13341908836740551
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.13213568627183972
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.11765394110764142
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.13090163763186896
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.1388912862496944
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.13292946324036106
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.1320027491387133
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.12175100213570532
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.13866330433030333
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.13378409511689687
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.13319036119741767
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.12548860110176463
[DEBUG] Batch 27: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 27: 0.1331533965312215
[DEBUG] Batch 28: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 28: 0.13680772021394286
[DEBUG] Batch 29: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 29: 0.12726957304030712
[DEBUG] Batch 30: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 30: 0.1217520012412673
[DEBUG] Batch 31: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 31: 0.1308520081043621
[DEBUG] Batch 32: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 32: 0.1412986137148792
[DEBUG] Batch 33: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 33: 0.1268958342626087
[DEBUG] Batch 34: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 34: 0.13575027092888167
[DEBUG] Batch 35: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 35: 0.13007520447913842
[DEBUG] Batch 36: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 36: 0.12583016896160856
[DEBUG] Batch 37: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 37: 0.1244385917662315
[DEBUG] Batch 38: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 38: 0.13350721009495065
[DEBUG] Batch 39: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 39: 0.14059818694081916
[DEBUG] Batch 40: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 40: 0.12682242905810606
[DEBUG] Batch 41: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 41: 0.12906333989962768
[DEBUG] Batch 42: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 42: 0.12227453593462574
[DEBUG] Batch 43: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 43: 0.12104808600856237
[DEBUG] Batch 44: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 44: 0.126734286397632
[DEBUG] Batch 45: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 45: 0.12453646783494442
[DEBUG] Batch 46: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 46: 0.1531642699906892
[DEBUG] Batch 47: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 47: 0.15796407793148634
[DEBUG] Batch 48: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 48: 0.16514256584091042
[DEBUG] Batch 49: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 49: 0.12878109099815974
[DEBUG] Batch 50: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 50: 0.12108208433291111
[DEBUG] Batch 51: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 51: 0.1311899985617977
[DEBUG] Batch 52: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 52: 0.13585635296078802
[DEBUG] Batch 53: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 53: 0.13962549393897694
[DEBUG] Batch 54: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 54: 0.12941664507894568
[DEBUG] Batch 55: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 55: 0.1240230711662289
[DEBUG] Batch 56: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 56: 0.13493495127030697
[DEBUG] Batch 57: Data shape: torch.Size([213, 10, 120, 120]), Labels shape: torch.Size([213, 19])
[DEBUG] Loss for batch 57: 0.13421394435695438
[INFO] Training epoch completed successfully.
[INFO] Calculating data mean and standard deviation...
[INFO] Data mean: 1429.160400390625, Data std: 1643.4342041015625
Epoch 1/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.8683212622850527
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.4486766357496305
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.253005141651721
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.2566097846440847
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.24807749247458344
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.21428056667871778
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.18998273453577327
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.17488289735713092
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.19364536622906972
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.19658566105264938
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.18315153009603072
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.18747998234562296
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.17868814055053242
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.17027152734356307
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.17578205938414593
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.18416147344226158
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.22579251499813174
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.17722677400002076
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.15127210300266397
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.18551123095371017
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.1647439898530235
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.15868053905067825
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.1467904525458904
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.1685219070384323
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.15971298574272533
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.14855855576309213
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.15940094610257885
[DEBUG] Batch 27: Data shape: torch.Size([238, 10, 120, 120]), Labels shape: torch.Size([238, 19])
[DEBUG] Loss for batch 27: 0.12830418945632802
[INFO] Training epoch completed successfully.
Epoch 2/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.1569214495814546
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.13935710469227935
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.12850501475772402
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.16131499324748988
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.13011080806799522
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.1709645700376321
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.14646740941819938
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.13681487195760336
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.14819358363482227
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.15401831794774598
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.12134499246470969
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.1293468029949734
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.16296935454147626
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.12487976239838985
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.142694986377039
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.13635226040435658
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.1272119038418696
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.13820797566521453
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.15637882400459127
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.13552691536299258
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.15602452831775007
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.13767957269755932
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.14496709611413677
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.16632230967962214
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.12631440690535922
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.1573653831292803
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.12944951270839755
[DEBUG] Batch 27: Data shape: torch.Size([238, 10, 120, 120]), Labels shape: torch.Size([238, 19])
[DEBUG] Loss for batch 27: 0.12337749923915793
[INFO] Training epoch completed successfully.
[INFO] Calculating data mean and standard deviation...
[INFO] Data mean: 1795.9521484375, Data std: 1149.1971435546875
Epoch 1/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.9414163770316625
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.6684530476978332
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.34313183509261025
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.3099519727072607
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.24785362974594385
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.2590400355713985
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.24727683978952109
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.3073380411338378
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.24614989323471986
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.24088116114706087
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.22082698217971128
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.1984295463494579
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.20766382510954284
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.20344009855613648
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.19906689663749647
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.19877959837120315
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.19297486439044445
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.21211974759361588
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.1837778945102417
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.18641244620251962
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.22547662761547205
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.17762260835337848
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.21453521715215784
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.2279732942074229
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.20853908633378487
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.21372693874345233
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.18319259158376527
[DEBUG] Batch 27: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 27: 0.19720918770481227
[DEBUG] Batch 28: Data shape: torch.Size([12, 10, 120, 120]), Labels shape: torch.Size([12, 19])
[DEBUG] Loss for batch 28: 0.1650268410063418
[INFO] Training epoch completed successfully.
Epoch 2/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.18594006771725136
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.21333188303688347
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.22132934333020732
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.2206168895856044
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.202173272918595
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.1815713187094896
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.19245541334841892
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.19843189509131326
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.16565680518304984
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.19198077243106548
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.2083033371889774
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.18063384603371893
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.16515236487546608
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.17366480032044243
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.17761138819865868
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.1885489041771105
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.16960798026735538
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.19115248125152853
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.19163314788125554
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.16027153632081317
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.1762830203920711
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.16586311949185553
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.1797008141231186
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.16894882189550597
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.1730598690897317
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.1823300351142579
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.1533042004168704
[DEBUG] Batch 27: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 27: 0.19390999612594884
[DEBUG] Batch 28: Data shape: torch.Size([12, 10, 120, 120]), Labels shape: torch.Size([12, 19])
[DEBUG] Loss for batch 28: 0.22638828655248
[INFO] Training epoch completed successfully.
[INFO] Starting validation for Round 1...
[DEBUG] Batch 0: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 1: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 2: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 3: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 4: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 5: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 6: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 7: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 8: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 9: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 10: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 11: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 12: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 13: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 14: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 15: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 16: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 17: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 18: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 19: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 20: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 21: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 22: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 23: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 24: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 25: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 26: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 27: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 28: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 29: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 30: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 31: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 32: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 33: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 34: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 35: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 36: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 37: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 38: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 39: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 40: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 41: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 42: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 43: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 44: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 45: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 46: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 47: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 48: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 49: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 50: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 51: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 52: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 53: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 54: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 55: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 56: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 57: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 58: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 59: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 60: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 61: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 62: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 63: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 64: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 65: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 66: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 67: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 68: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 69: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 70: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 71: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 72: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 73: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 74: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 75: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 76: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 77: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 78: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 79: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 80: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 81: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 82: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 83: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 84: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 85: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 86: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 87: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 88: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 89: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 90: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 91: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 92: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 93: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 94: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 95: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 96: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 97: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 98: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 99: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 100: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 101: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 102: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 103: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 104: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 105: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 106: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 107: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 108: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 109: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 110: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 111: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 112: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 113: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 114: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 115: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 116: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 117: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 118: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 119: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 120: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 121: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[DEBUG] Batch 122: Data shape: torch.Size([104, 10, 120, 120]), Labels shape: torch.Size([104, 19])
[DEBUG] True labels sample: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]
[DEBUG] Predicted probabilities sample: [[0.0008549  0.07415656 0.00222568 0.07161435 0.00155269 0.03325299
  0.06555759 0.00447174 0.10473525 0.02691104 0.12721473 0.54753405
  0.07264417 0.00285047 0.00425004 0.02040244 0.00268601 0.14590538
  0.02965791]
 [0.00085841 0.07414417 0.00222626 0.07183515 0.00154932 0.03333777
  0.06561325 0.0044765  0.10464434 0.02695124 0.12741166 0.54736054
  0.07269505 0.00285479 0.00424962 0.02042887 0.00269127 0.14620207
  0.02968821]
 [0.00085565 0.07390017 0.00222456 0.07170619 0.00154927 0.03338052
  0.06541588 0.00446728 0.10435811 0.02690474 0.12754604 0.54721534
  0.07255285 0.00284771 0.00424947 0.02042949 0.00268843 0.14585245
  0.02976661]
 [0.00085463 0.07381152 0.0022189  0.07156466 0.00154868 0.03326301
  0.06541216 0.00446353 0.10414964 0.02685226 0.12731417 0.5470627
  0.07261675 0.00285089 0.00424552 0.02038663 0.00268551 0.14621337
  0.02964556]
 [0.00085363 0.0741158  0.002217   0.0716482  0.0015484  0.03332972
  0.06541598 0.00446644 0.10404705 0.02691804 0.12749535 0.54715466
  0.07247585 0.00284584 0.00423523 0.02040044 0.00269045 0.1461959
  0.02974971]]
Bug fix for empty classification report.
micro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.3795
macro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.2492

[INFO] Performing LRP Pruning in Round 1...
[INFO] Computing LRP pruning mask...
Erstelle DataLoader fr Land: Finland
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([5])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([5, 19])
Relevance computation successful. Relevance shape: torch.Size([5, 10, 1, 5])
[INFO] Relevance maps computed for 53 layers.
[DEBUG] Layer: conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.0.downsample.0
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.1.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.1.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.1.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.2.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.2.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.2.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.5.0.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.0.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.0.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.0.downsample.0
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.1.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.1.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.1.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.2.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.2.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.2.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.3.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.3.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.3.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.6.0.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.0.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.0.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.0.downsample.0
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.1.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.1.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.1.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.2.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.2.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.2.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.3.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.3.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.3.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.4.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.4.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.4.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.5.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.5.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.5.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.7.0.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.0.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.0.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.0.downsample.0
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.1.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.1.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.1.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.2.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.2.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.2.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 1617
[INFO] Using device: cuda
Layer: conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.1115e+17, 7.5054e+16, 5.0788e+17, 2.7301e+16, 4.2162e+16, 5.0938e+17,
        4.8420e+17, 2.2081e+17, 7.0649e+16, 1.9352e+17, 1.5540e+17, 2.2888e+17,
        2.6547e+17, 4.2031e+16, 7.9089e+17, 5.3381e+17, 9.5279e+17, 3.2169e+16,
        9.1640e+16, 3.6488e+17, 1.1668e+17, 1.5049e+17, 1.4523e+17, 5.7243e+17,
        1.9185e+17, 3.3133e+17, 5.0935e+17, 4.0870e+17, 1.7598e+17, 3.9552e+17,
        1.9975e+17, 2.4714e+17, 3.8643e+17, 2.0556e+17, 7.3409e+17, 2.7470e+17,
        9.7956e+16, 1.4891e+17, 1.8542e+17, 3.4233e+17, 3.8445e+17, 3.8504e+17,
        3.7875e+17, 2.5096e+17, 5.5798e+17, 4.5562e+17, 1.1181e+17, 4.7577e+17,
        6.2498e+16, 4.4527e+17, 2.7757e+17, 1.3578e+17, 2.5044e+17, 2.2090e+17,
        5.0180e+17, 1.4434e+17, 3.1263e+17, 5.9031e+17, 1.5688e+17, 3.1070e+17,
        2.0867e+17, 7.8196e+17, 3.6246e+17, 5.1187e+16])
Layer: encoder.4.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.5172e+16, 7.7694e+16, 2.3432e+16, 4.4823e+16, 2.0542e+16, 8.1657e+16,
        1.6881e+17, 2.3183e+16, 1.6410e+17, 2.4615e+17, 1.7217e+17, 1.4755e+17,
        1.7894e+17, 3.5405e+17, 2.4797e+16, 3.7809e+16, 3.2887e+16, 1.6332e+17,
        1.8293e+17, 2.2280e+16, 2.3805e+16, 3.3541e+16, 6.0718e+16, 4.1746e+16,
        1.7995e+17, 2.1592e+17, 4.1656e+16, 8.3623e+16, 2.2552e+17, 2.6197e+17,
        1.3763e+17, 8.4888e+16, 2.0385e+17, 1.5514e+17, 1.1990e+17, 6.9979e+16,
        5.7958e+16, 1.9871e+17, 1.9183e+17, 1.8160e+17, 2.9855e+16, 2.2936e+17,
        1.6836e+17, 1.5290e+16, 1.9092e+17, 2.0306e+17, 2.1810e+17, 3.4046e+17,
        3.6997e+16, 8.0288e+16, 1.1276e+17, 5.0650e+16, 1.1953e+17, 1.6865e+16,
        7.8376e+16, 2.4313e+16, 1.6002e+16, 6.0277e+16, 8.7451e+16, 6.2013e+16,
        2.5200e+17, 3.5196e+16, 2.4567e+16, 6.0635e+16])
Layer: encoder.4.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.4793e+17, 2.3487e+17, 2.6812e+17, 2.3625e+17, 1.0290e+17, 2.9706e+16,
        2.1121e+17, 1.7483e+17, 8.5614e+16, 3.6719e+16, 4.7866e+16, 2.2862e+17,
        1.9999e+17, 3.0513e+17, 3.0150e+16, 1.2406e+17, 2.7408e+17, 3.0827e+17,
        1.6077e+17, 1.9957e+17, 3.6211e+17, 1.3250e+17, 1.6724e+17, 3.5118e+17,
        4.4639e+16, 8.2641e+16, 1.1025e+17, 5.2311e+16, 2.6082e+17, 2.2387e+17,
        2.7415e+16, 7.4981e+16, 1.4450e+17, 2.1113e+17, 1.9181e+17, 3.7100e+16,
        7.0758e+16, 5.8685e+17, 2.5311e+17, 2.0633e+17, 2.6511e+17, 4.9169e+16,
        6.9409e+16, 3.3996e+17, 1.2846e+17, 3.5479e+17, 9.5756e+16, 4.7585e+17,
        5.0713e+16, 6.8613e+16, 3.7972e+17, 3.2987e+17, 1.1146e+17, 1.2680e+17,
        1.9726e+17, 4.3177e+17, 1.8249e+17, 5.5528e+16, 1.3075e+17, 1.9362e+17,
        2.1555e+17, 1.5241e+17, 5.5244e+16, 4.2548e+17])
Layer: encoder.4.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5.4137e+14, 1.4241e+14, 9.6065e+14, 2.3746e+14, 3.6794e+15, 3.9762e+14,
        1.1089e+15, 1.5487e+14, 5.8280e+14, 8.8444e+15, 3.9458e+15, 2.8021e+14,
        7.5282e+14, 2.9747e+14, 1.2289e+14, 1.2863e+15, 2.5019e+14, 2.6585e+14,
        3.1596e+14, 1.4840e+14, 2.0004e+14, 3.0944e+15, 3.4323e+14, 9.3831e+13,
        1.0418e+14, 1.6066e+14, 7.5439e+14, 2.8438e+15, 1.4707e+15, 2.6407e+14,
        8.3011e+13, 7.1739e+15, 3.8986e+14, 2.1844e+15, 1.8276e+15, 5.1677e+14,
        8.0544e+13, 2.1494e+14, 6.1126e+14, 4.2076e+14, 3.8384e+15, 7.6617e+14,
        1.0976e+16, 1.4906e+15, 1.1005e+18, 6.1888e+14, 5.1862e+14, 3.1535e+14,
        2.7806e+14, 9.8276e+15, 5.2081e+14, 9.3441e+14, 4.2784e+15, 4.1509e+13,
        1.2933e+15, 8.3478e+14, 3.4803e+15, 2.1376e+14, 1.9925e+16, 6.4305e+13,
        6.1827e+14, 3.1579e+15, 3.3716e+15, 6.6480e+14, 5.0255e+14, 1.0720e+14,
        1.2193e+14, 1.5907e+13, 6.5343e+14, 1.6052e+14, 1.3582e+14, 6.5208e+14,
        3.3830e+14, 2.3553e+14, 7.7017e+14, 8.9752e+14, 9.3604e+13, 4.5583e+13,
        2.2245e+14, 4.9794e+15, 6.8359e+14, 4.9709e+14, 7.5844e+14, 2.5332e+13,
        4.4474e+14, 1.1451e+14, 1.2839e+15, 1.3836e+15, 2.3890e+14, 3.5275e+15,
        1.1550e+15, 3.8456e+15, 8.1938e+14, 2.7135e+14, 1.1878e+15, 6.9125e+14,
        4.7089e+15, 6.7754e+15, 3.2990e+15, 3.6674e+14, 4.9703e+14, 2.9232e+15,
        8.7310e+14, 6.8688e+16, 7.0267e+15, 4.1788e+14, 8.4482e+14, 2.1843e+14,
        4.1706e+14, 1.0978e+15, 2.3182e+14, 1.9496e+14, 7.1084e+13, 4.4023e+13,
        8.4204e+13, 3.7852e+15, 3.1844e+15, 6.6234e+15, 7.7540e+15, 9.7516e+14,
        1.2309e+15, 1.4493e+15, 3.5227e+15, 1.1745e+15, 1.8291e+15, 1.0033e+16,
        3.2346e+15, 1.0475e+15, 4.7723e+15, 9.3802e+14, 3.5909e+15, 5.7999e+14,
        6.1499e+13, 1.2459e+14, 4.5220e+14, 1.8239e+15, 1.8003e+16, 1.1947e+14,
        2.9309e+14, 1.3384e+15, 2.4530e+14, 9.8779e+14, 1.0299e+14, 1.8957e+15,
        1.6330e+14, 1.5282e+14, 6.0738e+13, 3.8847e+15, 4.5116e+13, 2.6801e+15,
        1.2917e+15, 7.0684e+14, 1.7944e+14, 1.2760e+15, 1.0517e+16, 6.1461e+14,
        1.0800e+15, 2.7316e+15, 2.1119e+15, 5.0621e+14, 7.7726e+14, 2.2581e+14,
        2.5481e+13, 2.5073e+16, 1.1954e+15, 2.5022e+15, 3.0491e+14, 6.5226e+13,
        1.3024e+14, 5.8794e+14, 7.7596e+13, 1.3493e+15, 5.9876e+14, 5.4452e+14,
        1.7031e+16, 2.3034e+14, 1.0195e+15, 1.4282e+15, 4.5860e+14, 3.3645e+14,
        5.9022e+13, 2.6831e+15, 8.4719e+14, 1.5937e+14, 4.5429e+15, 1.2098e+15,
        1.3464e+15, 9.2758e+13, 4.9526e+14, 5.5192e+14, 2.9763e+14, 1.1459e+14,
        5.0576e+15, 1.6829e+14, 1.9823e+14, 1.2486e+15, 1.8924e+14, 3.7212e+13,
        1.5164e+14, 1.7893e+14, 5.2265e+14, 4.8999e+16, 1.9029e+15, 2.8065e+13,
        1.0186e+15, 4.2663e+14, 1.3761e+14, 1.0061e+15, 2.2977e+14, 1.4138e+15,
        8.4737e+14, 1.3742e+15, 8.2924e+13, 1.7894e+14, 1.5396e+14, 7.9591e+14,
        1.0197e+15, 3.6854e+14, 4.4226e+14, 2.0567e+15, 1.2322e+15, 1.7947e+15,
        1.4889e+14, 4.2386e+14, 2.0450e+15, 7.5124e+16, 1.5078e+15, 7.8753e+14,
        9.0998e+14, 1.3239e+14, 1.2734e+14, 7.1269e+14, 5.5458e+13, 3.1355e+14,
        7.9772e+15, 6.1741e+14, 2.6192e+14, 1.7101e+14, 1.4879e+15, 1.6837e+15,
        3.4040e+15, 5.0973e+14, 6.6440e+13, 1.5375e+14, 2.2136e+14, 5.0668e+14,
        3.7247e+15, 5.0768e+14, 1.2434e+15, 5.3805e+14, 2.4093e+13, 2.0799e+14,
        1.4892e+15, 8.0346e+14, 6.4992e+13, 4.2063e+14])
Layer: encoder.4.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.1408e+15, 4.4042e+14, 6.1541e+14, 2.7213e+14, 5.2371e+15, 2.9647e+14,
        6.9346e+14, 8.0476e+14, 3.2391e+14, 8.1988e+15, 3.0554e+15, 5.3926e+14,
        9.6865e+14, 4.1730e+14, 9.6288e+14, 2.4331e+15, 9.3254e+14, 2.4949e+14,
        9.4290e+14, 4.2228e+14, 9.4302e+14, 3.0834e+15, 1.2602e+14, 1.0510e+14,
        1.2528e+15, 1.3307e+14, 1.2104e+15, 2.2862e+15, 2.8270e+14, 4.3487e+14,
        1.2696e+15, 8.1823e+15, 3.5658e+14, 1.6485e+15, 2.2887e+15, 3.2496e+14,
        8.0307e+14, 9.1070e+14, 2.0833e+14, 1.6315e+15, 1.5427e+15, 7.2691e+14,
        9.2410e+15, 2.4784e+15, 1.1013e+18, 2.5513e+14, 6.0693e+14, 1.9065e+14,
        1.9397e+14, 1.0407e+16, 1.3007e+15, 1.6904e+15, 7.1395e+15, 2.2400e+14,
        1.4818e+15, 4.0282e+14, 3.8877e+15, 2.4539e+14, 2.0327e+16, 4.6359e+14,
        8.0654e+14, 1.0302e+15, 2.6938e+15, 2.0693e+15, 5.8232e+14, 3.1780e+14,
        6.6568e+14, 1.1751e+14, 1.1733e+15, 7.1138e+14, 1.4722e+14, 1.3507e+15,
        8.8481e+14, 1.0904e+14, 6.9086e+14, 2.1965e+14, 6.3484e+14, 1.0234e+14,
        4.1324e+14, 5.7135e+15, 4.1128e+14, 7.2234e+14, 1.6410e+15, 1.7873e+14,
        1.4676e+15, 9.7476e+14, 6.4681e+14, 1.8248e+15, 2.8523e+14, 4.0206e+15,
        1.2020e+15, 4.0063e+15, 2.3238e+15, 7.4015e+14, 3.8163e+14, 5.5187e+14,
        4.6565e+15, 7.7446e+15, 5.2023e+15, 1.1636e+15, 4.8654e+14, 1.4014e+15,
        2.4086e+15, 6.8539e+16, 7.2974e+15, 6.5156e+14, 6.2982e+14, 2.6557e+14,
        6.3693e+14, 6.5558e+14, 8.1495e+14, 5.0442e+14, 6.0146e+14, 4.1452e+14,
        1.0172e+15, 3.0240e+15, 3.5130e+15, 4.4928e+15, 7.8048e+15, 4.8389e+14,
        1.0772e+15, 1.4748e+15, 3.8846e+15, 1.7181e+15, 1.4345e+15, 9.0224e+15,
        5.1117e+15, 8.3686e+14, 4.6414e+15, 1.7948e+15, 3.6975e+15, 7.5893e+14,
        1.3422e+15, 8.3259e+14, 2.9408e+14, 1.6417e+15, 1.7436e+16, 6.4360e+14,
        3.3774e+14, 8.0382e+14, 3.5538e+14, 5.1161e+14, 2.6801e+14, 2.5142e+15,
        2.5914e+14, 7.0267e+14, 2.4553e+15, 5.2365e+15, 9.2055e+14, 1.5930e+15,
        9.4002e+14, 9.6224e+14, 8.1509e+14, 5.9684e+14, 1.5514e+16, 1.1768e+15,
        1.1824e+15, 1.7457e+15, 2.5850e+15, 7.9249e+14, 7.9212e+14, 1.8742e+15,
        3.3267e+14, 2.4128e+16, 2.8935e+15, 1.9539e+15, 4.5326e+14, 6.0605e+14,
        3.2534e+14, 1.8335e+15, 1.6271e+14, 2.6869e+15, 1.2467e+15, 1.3249e+15,
        1.6336e+16, 1.5342e+14, 4.5861e+14, 5.7369e+14, 1.1633e+15, 7.2149e+14,
        3.6240e+14, 4.2395e+15, 5.3461e+14, 6.8969e+14, 3.9648e+15, 1.5145e+15,
        5.6706e+14, 1.2275e+15, 6.6723e+14, 1.0156e+15, 8.0375e+13, 2.6471e+15,
        3.9783e+15, 5.0513e+14, 1.7649e+14, 1.2071e+15, 5.4520e+14, 3.8517e+14,
        7.0199e+14, 5.6558e+14, 2.5677e+14, 4.8783e+16, 8.0936e+14, 1.7220e+15,
        3.8039e+14, 3.8552e+14, 1.5942e+15, 2.2947e+14, 4.6343e+14, 1.6371e+15,
        1.5021e+15, 3.1736e+14, 4.8215e+14, 3.0644e+14, 3.4312e+14, 1.2964e+15,
        1.5687e+15, 1.3404e+15, 4.0646e+14, 1.5606e+15, 8.5935e+13, 2.1734e+15,
        3.5464e+14, 7.1485e+14, 7.3696e+14, 7.4988e+16, 1.5772e+14, 5.1546e+14,
        9.7944e+14, 3.4760e+14, 1.5811e+14, 3.6691e+14, 7.3179e+14, 1.1464e+15,
        8.5301e+15, 6.5255e+14, 9.7764e+14, 2.7618e+14, 1.0039e+15, 7.3936e+14,
        6.9794e+15, 1.4065e+15, 8.0417e+14, 1.7131e+14, 1.6616e+14, 8.5019e+14,
        4.4780e+15, 5.1431e+14, 1.9567e+15, 6.2886e+14, 8.9571e+14, 1.0439e+15,
        1.6168e+15, 2.2210e+15, 2.4481e+14, 9.3115e+14])
Layer: encoder.4.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([6.2050e+14, 2.9867e+15, 1.0747e+15, 1.4920e+15, 4.6993e+15, 5.9052e+14,
        1.5431e+15, 1.8837e+15, 6.7646e+14, 1.7074e+15, 1.7849e+14, 1.4097e+15,
        2.2096e+15, 8.7690e+14, 7.1662e+14, 5.9325e+14, 9.3108e+14, 1.3601e+15,
        7.2773e+14, 1.7670e+15, 3.4155e+15, 1.4460e+15, 5.2835e+14, 1.2957e+15,
        2.1089e+15, 1.3566e+15, 3.2879e+14, 6.1641e+14, 8.1254e+14, 4.4828e+14,
        1.3484e+15, 1.9124e+15, 8.9970e+14, 8.1069e+14, 3.9808e+14, 1.0687e+15,
        1.3815e+15, 5.2400e+14, 5.5360e+14, 1.0047e+15, 8.2723e+14, 6.6734e+14,
        2.7401e+14, 1.9141e+15, 1.2924e+15, 6.8760e+14, 8.8683e+14, 1.8011e+15,
        1.8679e+15, 1.3749e+15, 9.1213e+14, 1.3468e+15, 5.4191e+14, 1.1972e+15,
        1.0796e+15, 1.2192e+15, 1.4483e+15, 2.7825e+15, 2.8548e+15, 1.0214e+15,
        1.2659e+15, 9.9389e+14, 2.0760e+15, 1.0349e+15])
Layer: encoder.4.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.0248e+14, 5.7409e+14, 1.4664e+15, 2.3116e+14, 1.5500e+15, 4.1405e+15,
        9.0662e+14, 1.9026e+15, 1.4061e+15, 3.2248e+15, 2.0493e+15, 6.4984e+14,
        3.9137e+14, 1.6217e+15, 1.0019e+15, 2.2340e+15, 2.6914e+15, 4.6962e+14,
        2.5396e+15, 1.7804e+15, 1.6655e+15, 2.1663e+15, 9.2784e+14, 1.1056e+15,
        3.5618e+15, 2.7761e+15, 4.1384e+14, 6.2914e+14, 5.7037e+14, 1.1418e+15,
        1.9868e+15, 3.3355e+15, 4.7320e+15, 1.2780e+15, 3.4682e+15, 2.6913e+15,
        1.1495e+15, 2.1495e+15, 1.5066e+15, 1.5567e+15, 3.3044e+15, 1.8771e+15,
        2.3599e+15, 5.4980e+14, 5.1886e+14, 1.2393e+15, 2.2916e+15, 5.2571e+14,
        1.7720e+15, 7.9770e+14, 3.5159e+15, 4.5424e+15, 2.8071e+15, 9.8971e+14,
        3.3231e+15, 1.3846e+15, 1.0308e+15, 3.9386e+15, 1.0213e+15, 3.8023e+14,
        3.5092e+15, 1.8517e+15, 2.4027e+14, 2.1518e+15])
Layer: encoder.4.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([9.7839e+13, 1.0761e+13, 3.2760e+13, 1.4993e+14, 3.1966e+14, 2.1064e+13,
        2.1031e+15, 5.0970e+13, 6.7629e+13, 2.3640e+14, 3.1768e+14, 8.8197e+13,
        4.8477e+13, 4.6725e+13, 4.0601e+13, 1.2049e+14, 3.8056e+13, 4.7924e+14,
        5.6327e+13, 9.7847e+13, 3.5302e+13, 1.1742e+14, 9.0075e+13, 1.6399e+13,
        2.6446e+13, 5.9866e+13, 4.0886e+13, 2.6024e+14, 5.3841e+12, 3.8619e+14,
        4.6801e+13, 1.1140e+14, 1.1191e+13, 3.6286e+14, 1.5294e+14, 7.5256e+13,
        1.4823e+14, 2.6596e+14, 7.6097e+13, 4.0673e+13, 4.7004e+15, 9.5487e+14,
        2.1107e+14, 3.2827e+13, 2.6386e+14, 6.0282e+13, 3.1499e+14, 1.4526e+13,
        4.0103e+14, 7.0836e+14, 1.1920e+14, 8.7770e+13, 3.0086e+15, 9.4344e+13,
        2.1549e+14, 5.1508e+14, 1.3712e+14, 8.8665e+13, 6.1569e+13, 1.3593e+14,
        7.3158e+14, 5.9341e+14, 2.3689e+14, 1.0401e+14, 9.4257e+13, 5.4949e+13,
        7.1593e+13, 4.2729e+14, 3.5802e+13, 8.9580e+13, 1.3190e+14, 4.0751e+13,
        3.1241e+13, 3.2531e+14, 6.7553e+13, 6.5728e+13, 2.9393e+13, 4.8957e+13,
        5.1313e+14, 1.5795e+14, 1.7066e+14, 6.8622e+13, 1.1240e+15, 2.1970e+14,
        1.1070e+14, 2.5357e+12, 2.5935e+13, 1.5048e+14, 3.0042e+14, 2.9316e+14,
        3.5905e+15, 1.0524e+14, 7.6708e+13, 9.3827e+13, 9.7672e+13, 1.2194e+14,
        2.4223e+14, 5.1089e+13, 1.5474e+13, 5.4819e+14, 6.8881e+13, 2.8564e+14,
        5.4932e+13, 2.5397e+14, 1.3298e+15, 2.2510e+13, 2.0111e+14, 5.2688e+13,
        9.8768e+13, 6.4190e+13, 2.6501e+14, 2.6179e+14, 8.9030e+13, 5.5419e+13,
        1.6623e+14, 2.2785e+14, 2.6668e+14, 1.9363e+14, 5.3504e+13, 2.4902e+14,
        2.3537e+14, 7.9168e+14, 3.9279e+14, 8.2732e+13, 1.6595e+14, 6.2822e+14,
        1.8214e+14, 4.7013e+13, 4.8045e+14, 2.5411e+14, 1.9779e+14, 1.2500e+14,
        3.5551e+14, 3.4804e+13, 3.9483e+13, 9.6052e+13, 3.6656e+14, 4.7261e+13,
        9.2603e+13, 4.1650e+13, 9.7358e+12, 1.6949e+14, 1.8468e+14, 3.2708e+12,
        2.0823e+14, 9.9529e+13, 5.0386e+13, 1.8027e+14, 1.3427e+13, 1.1123e+14,
        1.7538e+14, 4.4041e+14, 2.2657e+14, 2.0625e+14, 3.9093e+15, 2.2122e+14,
        1.4143e+14, 3.9050e+14, 6.2049e+13, 1.5494e+14, 2.2252e+14, 4.7707e+13,
        3.3095e+14, 9.7065e+13, 2.1897e+14, 1.7857e+14, 2.1788e+14, 9.7704e+13,
        4.0489e+13, 3.2423e+14, 1.9784e+14, 3.0703e+14, 1.4147e+14, 1.6790e+13,
        1.5986e+14, 8.1190e+13, 3.0391e+13, 3.6447e+13, 2.1620e+13, 6.8383e+13,
        3.5099e+14, 1.7997e+15, 7.6068e+13, 3.0010e+14, 2.2932e+13, 3.3305e+13,
        1.3790e+14, 4.8867e+14, 2.1772e+14, 9.7541e+12, 1.9601e+14, 1.0560e+15,
        5.9010e+14, 9.9271e+12, 1.4701e+14, 3.0385e+14, 1.7470e+13, 9.9246e+13,
        9.8255e+13, 1.3910e+14, 2.4131e+14, 6.6851e+13, 1.3266e+14, 1.8801e+14,
        8.8395e+12, 4.6138e+13, 4.7623e+14, 2.1423e+14, 5.6281e+14, 1.2418e+13,
        3.6060e+14, 3.7061e+14, 2.5789e+13, 1.6193e+13, 2.5890e+14, 1.2341e+15,
        8.3573e+13, 2.6937e+14, 4.6961e+14, 5.2478e+14, 2.1095e+13, 1.6118e+14,
        2.6605e+13, 1.6038e+14, 7.4276e+13, 2.5194e+14, 3.0357e+14, 2.4195e+14,
        2.0279e+14, 2.1575e+14, 1.9050e+13, 2.0892e+14, 1.6624e+14, 2.2836e+14,
        2.4055e+14, 3.2373e+14, 1.3457e+14, 4.8959e+13, 5.0746e+14, 4.1121e+13,
        1.9417e+15, 3.2704e+14, 9.5469e+13, 1.8266e+13, 3.3427e+14, 3.2646e+14,
        3.1541e+14, 1.5037e+13, 4.2476e+13, 5.5508e+13, 2.4670e+13, 1.6484e+14,
        2.2012e+14, 2.2238e+14, 9.5978e+13, 9.1027e+13])
Layer: encoder.4.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.7455e+14, 9.9333e+13, 1.2055e+15, 1.6666e+14, 5.5724e+14, 3.6542e+14,
        2.6308e+14, 7.7884e+13, 3.6206e+14, 8.1859e+14, 1.2877e+14, 3.0553e+14,
        7.4413e+13, 3.1350e+13, 8.5654e+14, 5.3604e+14, 9.7471e+13, 4.9681e+14,
        1.0847e+15, 2.4298e+14, 1.0380e+15, 1.2482e+15, 1.3347e+14, 1.9055e+14,
        3.8158e+14, 1.8232e+14, 3.6894e+14, 1.7768e+14, 4.6579e+14, 7.8496e+13,
        5.2800e+14, 7.9761e+14, 1.6762e+14, 2.8884e+14, 3.3654e+14, 3.1289e+14,
        1.0345e+14, 1.1479e+14, 1.7787e+14, 8.5527e+14, 3.4860e+14, 6.0762e+14,
        1.9840e+14, 6.1037e+14, 4.4765e+14, 8.9734e+14, 1.1063e+14, 6.4429e+14,
        2.0053e+14, 3.5239e+14, 1.3065e+14, 1.1908e+14, 1.8749e+14, 3.8230e+14,
        1.2808e+14, 5.7695e+14, 2.3839e+14, 3.9251e+14, 8.2789e+14, 3.1890e+14,
        6.3944e+14, 2.8000e+14, 6.7173e+14, 9.4495e+14])
Layer: encoder.4.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.6969e+14, 1.4698e+15, 8.0549e+14, 5.8108e+14, 3.9064e+14, 6.2087e+14,
        6.4487e+14, 2.7670e+14, 1.7075e+15, 8.2501e+14, 1.1257e+15, 5.3619e+14,
        8.2361e+14, 4.1513e+14, 4.3917e+13, 1.2212e+15, 7.1103e+14, 1.7619e+15,
        1.3863e+15, 1.7547e+14, 5.4592e+14, 2.4208e+14, 2.5943e+14, 8.9690e+14,
        1.6673e+14, 1.1241e+15, 5.0144e+14, 1.3766e+15, 5.9480e+14, 6.7375e+14,
        6.0298e+14, 5.4226e+14, 3.1353e+14, 7.9836e+14, 8.9543e+14, 6.0794e+13,
        7.5675e+13, 3.5660e+13, 9.5869e+13, 1.0372e+15, 5.8654e+14, 2.8831e+14,
        7.8624e+14, 1.2518e+14, 2.8173e+14, 4.6103e+14, 8.4221e+14, 4.2208e+14,
        9.4054e+13, 5.3924e+14, 6.6534e+14, 3.8173e+14, 1.7355e+14, 9.6252e+14,
        1.5115e+14, 1.0402e+15, 5.8984e+14, 4.9712e+14, 9.3556e+14, 5.8183e+14,
        2.5164e+14, 4.4339e+14, 4.0883e+14, 1.6126e+14])
Layer: encoder.4.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.5212e+11, 9.4768e+10, 2.1534e+11, 8.2090e+11, 1.3422e+11, 4.8474e+11,
        3.9785e+11, 2.9455e+11, 1.2729e+11, 1.4965e+11, 1.1614e+11, 1.8161e+12,
        6.9525e+11, 3.2376e+11, 2.9990e+11, 1.7451e+11, 5.9863e+10, 2.2491e+11,
        1.1140e+11, 4.4569e+11, 9.0149e+10, 3.3194e+11, 8.4285e+10, 1.4426e+11,
        8.3622e+10, 5.6986e+10, 9.9328e+13, 2.8089e+12, 4.8852e+10, 3.9059e+11,
        5.8464e+12, 7.2868e+11, 4.4746e+10, 3.7841e+11, 1.0210e+12, 4.2662e+11,
        4.6329e+11, 1.6277e+11, 1.2537e+11, 4.1625e+10, 9.3853e+11, 2.7173e+11,
        3.1315e+11, 8.8808e+11, 7.9165e+11, 1.7489e+12, 1.6421e+11, 8.2621e+10,
        5.8171e+11, 5.1530e+11, 2.1721e+10, 1.7402e+11, 2.1120e+11, 4.9781e+11,
        2.3024e+11, 4.7855e+12, 4.4419e+11, 1.2740e+11, 2.0497e+11, 4.1004e+11,
        1.2723e+11, 2.9056e+11, 1.3313e+12, 6.6494e+12, 6.4834e+10, 3.3412e+11,
        3.4741e+11, 4.3873e+11, 2.8411e+11, 3.7081e+11, 1.6526e+11, 1.5903e+11,
        3.0778e+10, 4.2310e+10, 4.5540e+12, 2.5142e+11, 2.1479e+11, 4.6196e+10,
        5.8668e+10, 1.4211e+11, 1.6596e+11, 1.1794e+11, 3.3516e+11, 2.5845e+11,
        6.2181e+10, 2.9883e+10, 2.0391e+11, 5.4209e+10, 3.0950e+11, 2.4963e+11,
        3.2396e+15, 1.5397e+11, 6.0174e+12, 1.7560e+12, 1.3435e+11, 2.1364e+12,
        3.0836e+11, 1.0855e+11, 2.3844e+11, 5.7908e+11, 3.7978e+11, 2.2229e+11,
        1.6729e+12, 2.6686e+11, 1.5206e+11, 9.7203e+11, 2.5417e+11, 1.5749e+11,
        1.6707e+11, 2.5354e+11, 2.5086e+11, 2.3277e+11, 3.9407e+11, 4.0828e+11,
        2.0842e+11, 1.0029e+11, 9.8844e+11, 1.7995e+11, 2.9808e+11, 1.7038e+11,
        2.4804e+11, 2.0484e+12, 2.9984e+11, 6.3492e+10, 8.3836e+11, 1.2038e+11,
        6.6196e+10, 1.1449e+12, 2.1127e+12, 4.5413e+11, 2.1801e+11, 2.0231e+12,
        3.1791e+11, 5.1061e+10, 7.8738e+10, 1.0088e+12, 3.4411e+11, 5.3243e+11,
        1.5856e+11, 2.9270e+11, 2.2207e+12, 1.7154e+12, 4.2865e+11, 9.2854e+10,
        3.6443e+11, 1.9455e+10, 2.0907e+11, 8.9416e+10, 1.5453e+10, 6.0366e+11,
        2.7585e+11, 1.3905e+12, 1.7692e+11, 2.1350e+11, 8.2280e+11, 3.9287e+12,
        4.6879e+11, 1.5363e+12, 4.5210e+12, 1.4792e+11, 3.0722e+11, 1.6680e+12,
        1.9722e+11, 4.1025e+11, 6.3107e+11, 3.6079e+11, 2.5583e+11, 4.0634e+11,
        6.8915e+11, 9.7677e+10, 3.9539e+12, 5.4781e+10, 1.1967e+11, 2.8711e+11,
        2.6015e+11, 8.0086e+10, 3.0714e+11, 1.5425e+11, 2.3893e+10, 3.3091e+11,
        1.3288e+12, 9.0643e+11, 9.3619e+11, 1.5621e+11, 2.2998e+11, 2.6625e+11,
        1.2661e+11, 2.2029e+11, 1.2479e+11, 9.1103e+10, 4.1164e+11, 1.7548e+11,
        2.1374e+11, 4.2023e+12, 1.7917e+11, 4.7351e+11, 8.3905e+11, 5.2422e+10,
        6.1943e+10, 1.6221e+12, 1.2071e+12, 3.1814e+11, 2.0112e+11, 1.3067e+12,
        2.8876e+11, 2.0680e+12, 1.7545e+11, 7.0032e+11, 8.2495e+11, 2.0557e+11,
        3.2509e+12, 3.8193e+11, 2.7785e+11, 1.5542e+11, 1.1404e+11, 5.4541e+11,
        6.5103e+10, 7.1870e+11, 2.2734e+11, 1.3322e+11, 4.6615e+11, 5.0592e+11,
        6.6638e+10, 1.1267e+11, 2.9040e+11, 4.3242e+12, 6.5779e+10, 2.5145e+12,
        1.6238e+11, 2.2145e+11, 5.2902e+10, 3.4697e+11, 1.3264e+11, 4.3394e+11,
        2.8675e+12, 4.1562e+11, 1.2189e+12, 1.9778e+10, 3.7198e+12, 4.4602e+11,
        1.7459e+11, 2.7048e+11, 1.8398e+11, 2.3080e+12, 2.4790e+11, 5.0050e+10,
        1.4907e+12, 6.3566e+10, 2.3746e+11, 5.0739e+11, 1.1125e+12, 2.9631e+11,
        8.1318e+11, 9.4873e+11, 6.6507e+11, 4.3910e+11])
Layer: encoder.5.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.9895e+11, 3.7718e+11, 3.0968e+11, 3.6645e+11, 3.3078e+11, 2.5527e+11,
        6.6934e+11, 3.1548e+11, 2.1971e+11, 2.5786e+11, 4.4104e+11, 2.4394e+11,
        3.1161e+11, 3.8222e+11, 6.3718e+11, 3.5826e+11, 3.4879e+11, 3.5110e+11,
        3.4493e+11, 4.4199e+11, 3.6048e+11, 2.7143e+11, 4.2039e+11, 4.4744e+11,
        2.9553e+11, 2.7394e+11, 2.6312e+11, 3.2940e+11, 4.2636e+11, 3.3854e+11,
        3.3478e+11, 3.6411e+11, 2.0304e+11, 4.2545e+11, 2.6708e+11, 3.4667e+11,
        4.6394e+11, 3.0936e+11, 2.8773e+11, 4.5179e+11, 4.6936e+11, 4.6050e+11,
        4.3907e+11, 4.0309e+11, 3.5187e+11, 6.6380e+11, 2.1133e+11, 3.4714e+11,
        3.6779e+11, 2.7718e+11, 6.5133e+11, 4.9706e+11, 2.6832e+11, 5.2599e+11,
        2.5027e+11, 4.1289e+11, 3.4573e+11, 3.4711e+11, 3.1168e+11, 2.3695e+11,
        3.2084e+11, 3.3297e+11, 3.9815e+11, 3.2459e+11, 4.6900e+11, 4.1216e+11,
        3.1398e+11, 2.0848e+11, 5.3046e+11, 4.3855e+11, 4.3179e+11, 2.3948e+11,
        3.7488e+11, 5.0694e+11, 2.9397e+11, 2.2375e+11, 3.3917e+11, 3.6232e+11,
        1.8548e+11, 6.9687e+11, 3.0264e+11, 5.2358e+11, 5.9846e+11, 4.5056e+11,
        4.7083e+11, 3.1635e+11, 3.3463e+11, 2.8655e+11, 3.1538e+11, 4.8594e+11,
        2.3933e+11, 5.0250e+11, 6.4871e+11, 3.5092e+11, 2.6990e+11, 5.7857e+11,
        3.5445e+11, 2.0687e+11, 3.0053e+11, 5.0976e+11, 6.0880e+11, 3.5823e+11,
        4.3572e+11, 3.0765e+11, 3.4947e+11, 4.2836e+11, 4.4683e+11, 3.9038e+11,
        5.0584e+11, 5.5677e+11, 3.8048e+11, 1.9092e+11, 4.5678e+11, 2.2422e+11,
        4.5698e+11, 4.6636e+11, 2.7788e+11, 2.5823e+11, 3.9224e+11, 3.5701e+11,
        4.9242e+11, 3.2980e+11, 3.6519e+11, 3.7701e+11, 3.6048e+11, 1.8411e+11,
        4.0879e+11, 3.1091e+11])
Layer: encoder.5.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.1967e+11, 1.0342e+12, 7.0372e+11, 5.3359e+11, 7.0407e+11, 6.0650e+11,
        4.0253e+11, 4.3162e+11, 1.0128e+12, 8.0452e+11, 6.6653e+11, 4.7416e+11,
        3.7382e+11, 5.1485e+11, 4.2644e+11, 5.5292e+11, 5.7707e+11, 4.5439e+11,
        3.6561e+11, 7.2456e+11, 4.8492e+11, 6.8529e+11, 3.1584e+11, 4.5323e+11,
        5.7493e+11, 7.1727e+11, 7.9944e+11, 7.8053e+11, 3.9759e+11, 3.8181e+11,
        9.6944e+11, 4.0593e+11, 4.7372e+11, 5.3344e+11, 7.1227e+11, 7.5346e+11,
        6.8792e+11, 3.9253e+11, 5.9429e+11, 4.1631e+11, 9.0404e+11, 5.0552e+11,
        3.6786e+11, 5.0042e+11, 8.9454e+11, 6.2522e+11, 5.5563e+11, 5.6049e+11,
        6.0288e+11, 3.2981e+11, 4.5530e+11, 6.5215e+11, 5.4057e+11, 3.5341e+11,
        7.8063e+11, 5.3309e+11, 4.0070e+11, 2.6798e+11, 6.1566e+11, 5.5203e+11,
        6.4191e+11, 6.8880e+11, 6.9156e+11, 7.8440e+11, 4.5639e+11, 7.4042e+11,
        6.8822e+11, 8.2957e+11, 4.9090e+11, 6.3584e+11, 5.1590e+11, 1.0566e+12,
        5.4686e+11, 6.0944e+11, 5.2327e+11, 5.8587e+11, 7.7887e+11, 5.0787e+11,
        5.3388e+11, 5.2827e+11, 6.1714e+11, 7.0513e+11, 3.2585e+11, 7.1784e+11,
        5.1110e+11, 6.9896e+11, 5.0731e+11, 7.2159e+11, 2.9703e+11, 3.3467e+11,
        6.6955e+11, 4.1860e+11, 5.5945e+11, 5.3058e+11, 6.2156e+11, 2.7437e+11,
        6.9544e+11, 5.9097e+11, 5.2675e+11, 4.8137e+11, 3.8407e+11, 5.7021e+11,
        6.6466e+11, 6.4539e+11, 5.9207e+11, 2.5794e+11, 6.2259e+11, 6.3420e+11,
        7.5883e+11, 3.6631e+11, 5.0771e+11, 7.8362e+11, 7.4734e+11, 5.5367e+11,
        3.0154e+11, 5.3142e+11, 5.9248e+11, 9.8872e+11, 5.7823e+11, 5.8721e+11,
        1.0492e+12, 8.7559e+11, 1.0618e+12, 6.4215e+11, 7.4760e+11, 7.1752e+11,
        3.6471e+11, 4.7340e+11])
Layer: encoder.5.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.3136e+09, 2.3534e+10, 1.6403e+09, 2.4778e+10, 1.2987e+09, 8.5497e+09,
        1.6362e+10, 4.1010e+09, 1.3431e+11, 1.0151e+10, 1.2554e+10, 1.0899e+09,
        1.5202e+11, 4.5478e+10, 2.9096e+09, 4.9428e+10, 8.7257e+09, 9.3964e+09,
        1.6967e+09, 5.9158e+09, 1.0833e+10, 9.3445e+10, 4.6530e+09, 2.3823e+10,
        2.6083e+09, 3.2097e+11, 3.7597e+10, 2.4287e+10, 5.5882e+09, 3.0001e+09,
        8.2719e+08, 2.7201e+09, 5.3242e+09, 7.4497e+09, 1.0726e+10, 1.9603e+10,
        4.0734e+09, 9.6376e+09, 1.1507e+10, 2.4241e+10, 7.5959e+10, 1.7275e+10,
        2.3973e+09, 6.7028e+09, 2.2649e+09, 3.2399e+09, 1.8370e+10, 1.0195e+10,
        6.5608e+09, 2.0528e+10, 2.3120e+11, 4.4928e+10, 3.2666e+09, 9.3342e+08,
        1.0621e+10, 1.9585e+09, 1.2131e+10, 7.0870e+09, 2.9483e+09, 5.7754e+10,
        9.4974e+09, 5.8810e+10, 1.3004e+10, 7.7368e+09, 2.7904e+09, 8.7968e+09,
        5.7517e+09, 3.7526e+09, 1.0804e+10, 2.1950e+09, 1.2741e+10, 2.1091e+10,
        9.0867e+09, 2.9390e+10, 2.5815e+10, 1.8556e+11, 3.1270e+09, 3.5763e+09,
        1.1501e+09, 1.3497e+10, 1.8929e+11, 3.5913e+10, 1.4312e+10, 1.7577e+09,
        2.5205e+09, 2.2471e+10, 4.6395e+09, 1.6309e+10, 1.4781e+10, 5.0204e+10,
        1.2202e+09, 1.0906e+10, 1.7962e+10, 2.2843e+09, 1.2951e+10, 4.1438e+10,
        1.8297e+10, 1.7744e+10, 5.2927e+09, 4.5621e+09, 8.4051e+10, 1.5451e+09,
        4.1998e+11, 8.5475e+09, 1.3942e+10, 5.9304e+09, 1.7549e+09, 6.3444e+09,
        1.3372e+10, 2.1062e+09, 1.0076e+10, 1.4761e+10, 4.0818e+09, 7.1821e+09,
        1.4980e+09, 8.7812e+09, 1.9074e+09, 1.4505e+09, 3.6564e+09, 1.3945e+10,
        1.8955e+10, 1.1483e+10, 9.7290e+09, 5.3829e+09, 2.2335e+09, 2.8716e+09,
        8.5472e+09, 3.3759e+09, 2.2322e+10, 1.4467e+10, 1.0212e+10, 1.9253e+09,
        4.2596e+09, 8.1198e+09, 7.8530e+09, 6.3697e+10, 1.5746e+10, 8.2219e+08,
        2.8959e+09, 3.4894e+10, 3.8967e+10, 2.2110e+10, 1.9704e+10, 2.7261e+11,
        2.7198e+09, 1.6419e+10, 2.3646e+09, 3.1392e+09, 2.2362e+09, 2.0916e+09,
        1.1171e+11, 8.9597e+09, 1.7518e+10, 1.8481e+10, 1.8781e+11, 6.9577e+09,
        1.5353e+10, 9.0270e+09, 4.2672e+09, 1.3222e+09, 2.3700e+10, 6.9042e+10,
        1.3262e+10, 3.1277e+09, 8.7815e+09, 1.3201e+10, 5.4100e+09, 1.5506e+10,
        8.1569e+09, 8.3292e+09, 4.8950e+10, 8.6755e+08, 2.2743e+10, 7.0990e+09,
        5.1011e+09, 1.4151e+10, 4.5671e+09, 2.2983e+11, 6.3429e+09, 5.2221e+10,
        1.4668e+10, 5.0092e+10, 3.0356e+09, 1.2154e+09, 3.9192e+10, 4.3049e+09,
        7.3408e+09, 6.3110e+10, 2.0973e+10, 6.1100e+10, 6.7786e+09, 1.3408e+10,
        4.4899e+09, 5.8908e+10, 2.9053e+09, 2.1648e+09, 7.2722e+09, 2.1346e+10,
        8.4009e+08, 2.3384e+10, 9.7584e+09, 1.9849e+10, 2.3213e+09, 1.9955e+09,
        9.6176e+09, 1.6549e+10, 1.0988e+10, 1.6780e+09, 2.2697e+11, 8.8014e+09,
        1.1139e+10, 1.4660e+10, 2.7293e+10, 2.7151e+09, 8.4200e+09, 2.2038e+10,
        9.4143e+09, 2.0555e+09, 3.8906e+09, 3.4512e+10, 1.7141e+10, 4.8946e+10,
        1.7334e+10, 4.4166e+10, 6.1102e+09, 2.0254e+10, 5.5696e+10, 3.4954e+10,
        1.5862e+09, 6.1521e+09, 1.8328e+10, 1.9703e+09, 5.2750e+10, 1.8236e+10,
        3.1101e+09, 6.1723e+10, 1.3777e+10, 8.4061e+10, 7.1235e+10, 5.4432e+09,
        3.1124e+10, 3.1242e+10, 1.6457e+10, 1.0454e+10, 4.3309e+09, 5.4360e+09,
        1.5125e+10, 1.7330e+10, 6.5898e+10, 1.3804e+10, 2.1733e+10, 7.1419e+10,
        3.1941e+10, 1.6501e+10, 3.1316e+10, 9.4923e+09, 1.7668e+10, 1.0358e+10,
        4.3962e+09, 5.8745e+09, 5.4818e+09, 1.1233e+09, 6.6920e+08, 2.6360e+09,
        2.0053e+10, 3.1891e+09, 7.0090e+08, 1.7106e+10, 2.0462e+11, 3.9455e+10,
        2.3972e+10, 1.4219e+10, 1.0118e+11, 4.5520e+09, 2.5023e+10, 1.0754e+12,
        9.4618e+09, 1.7717e+09, 8.0477e+10, 1.7090e+11, 3.7418e+10, 2.6639e+09,
        1.0797e+10, 4.8517e+10, 2.1846e+10, 5.6024e+10, 8.5124e+09, 1.2259e+10,
        7.8192e+09, 2.5514e+10, 3.9119e+09, 8.6771e+09, 1.2317e+10, 9.7173e+09,
        1.1666e+09, 8.0017e+09, 2.3343e+10, 6.8386e+09, 1.7562e+10, 9.3799e+09,
        2.5977e+10, 2.1507e+09, 6.5344e+10, 1.3082e+09, 3.7313e+09, 1.6109e+10,
        2.8211e+09, 9.5549e+10, 7.4742e+10, 4.9916e+10, 3.5867e+09, 2.7493e+09,
        1.2183e+10, 1.9197e+10, 5.6062e+09, 2.4452e+09, 6.4362e+09, 1.2135e+09,
        1.7011e+10, 1.5730e+10, 1.4243e+10, 1.1748e+09, 6.7896e+09, 3.7291e+09,
        9.7995e+09, 9.4678e+09, 2.6089e+11, 5.2060e+10, 2.2539e+10, 6.4541e+09,
        1.2747e+11, 7.1770e+09, 1.1804e+10, 9.1849e+11, 1.1249e+09, 7.6246e+09,
        1.4346e+10, 2.0274e+09, 2.5168e+10, 4.8444e+10, 2.1032e+09, 1.5178e+10,
        3.5844e+09, 3.6988e+10, 2.0019e+10, 4.6922e+09, 1.4941e+11, 2.2129e+09,
        2.9282e+10, 1.2264e+10, 2.4306e+10, 1.3943e+10, 9.4965e+09, 2.0797e+10,
        2.3269e+09, 1.3982e+09, 4.6563e+09, 5.2912e+08, 2.2742e+10, 1.3616e+10,
        7.8903e+09, 6.2298e+10, 5.4882e+09, 2.5494e+10, 2.0492e+10, 1.8828e+09,
        1.2708e+09, 7.4914e+09, 4.4425e+09, 5.4090e+10, 2.3201e+09, 5.5728e+09,
        4.6415e+10, 1.1820e+11, 1.5078e+10, 3.6393e+09, 2.3224e+10, 9.8603e+09,
        5.1030e+09, 4.2363e+10, 4.2337e+11, 4.0899e+09, 5.9031e+09, 8.4002e+10,
        3.1309e+09, 3.7999e+09, 2.8586e+11, 2.3937e+10, 5.6031e+09, 3.3960e+10,
        2.2175e+10, 5.0115e+10, 6.3269e+09, 3.2247e+09, 1.2749e+10, 4.6292e+11,
        8.5041e+10, 1.0725e+11, 1.2530e+12, 3.8223e+09, 3.0185e+10, 4.6417e+09,
        7.9083e+09, 8.1517e+10, 8.5937e+09, 5.0253e+09, 8.7517e+09, 4.7235e+10,
        3.2106e+10, 3.4142e+10, 6.8705e+09, 5.3688e+09, 3.5403e+10, 1.7589e+11,
        3.7163e+09, 1.9803e+10, 2.8454e+10, 3.7381e+09, 2.0290e+10, 2.3456e+10,
        3.3248e+09, 1.3999e+10, 1.7719e+10, 3.1375e+10, 4.4987e+10, 8.6291e+10,
        1.1157e+10, 8.0734e+08, 4.0824e+08, 6.6850e+09, 4.3837e+09, 6.7560e+09,
        1.5893e+09, 1.3268e+10, 4.3565e+09, 3.8963e+10, 9.5560e+09, 2.6585e+11,
        1.3240e+10, 4.3743e+10, 2.0269e+10, 2.1924e+10, 1.5167e+09, 1.2986e+10,
        1.9568e+10, 1.6421e+10, 3.0990e+09, 2.0320e+10, 3.6391e+09, 1.8085e+10,
        1.0944e+10, 7.4169e+09, 1.4866e+09, 1.2121e+10, 1.4089e+11, 1.8788e+09,
        1.6818e+10, 1.6326e+10, 2.9689e+09, 6.6441e+10, 1.3012e+11, 2.0786e+09,
        6.0367e+09, 1.7611e+09, 1.1143e+11, 1.0649e+09, 6.6051e+10, 5.0441e+08,
        1.8089e+10, 2.0693e+09, 1.8947e+10, 3.0383e+09, 2.5340e+10, 3.6668e+10,
        3.5716e+10, 2.0571e+09, 4.4414e+09, 3.6724e+09, 4.8058e+10, 2.4787e+10,
        1.2158e+10, 1.2766e+09, 3.0061e+10, 1.4050e+09, 1.1444e+10, 5.1520e+09,
        2.5033e+10, 4.9031e+09, 4.2133e+10, 3.4728e+10, 1.6408e+10, 5.1049e+09,
        1.6679e+10, 8.8685e+10, 2.9811e+10, 1.5022e+10, 3.5036e+09, 1.1879e+10,
        1.4136e+10, 4.8485e+09, 1.4180e+10, 2.1712e+09, 1.0521e+10, 6.8728e+09,
        1.8255e+09, 5.2106e+10, 1.5643e+10, 4.4554e+09, 1.9671e+11, 2.8064e+10,
        8.1018e+09, 1.9402e+10])
Layer: encoder.5.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.4006e+10, 3.5963e+10, 8.4476e+09, 2.3649e+10, 9.6833e+09, 1.9008e+10,
        2.5710e+10, 5.8956e+09, 1.8135e+11, 1.2983e+10, 8.5893e+09, 8.4309e+09,
        1.5320e+11, 5.2011e+10, 8.0035e+09, 5.5429e+10, 3.1704e+10, 1.6271e+10,
        1.2011e+10, 3.0226e+10, 2.1400e+10, 8.1861e+10, 9.0032e+09, 4.3983e+10,
        2.3434e+10, 3.1922e+11, 4.9902e+10, 2.7987e+10, 5.3856e+09, 7.5212e+09,
        1.2760e+10, 8.7549e+09, 9.3473e+09, 8.9457e+09, 2.6524e+10, 2.7132e+10,
        3.9223e+09, 1.7714e+10, 2.2127e+10, 3.2307e+10, 7.1478e+10, 2.1968e+10,
        7.2520e+09, 1.1447e+10, 9.0277e+09, 7.9073e+09, 2.5819e+10, 1.9182e+10,
        5.8626e+09, 2.4666e+10, 2.1517e+11, 4.8476e+10, 7.4123e+09, 5.0633e+09,
        2.1254e+10, 4.6102e+09, 2.6450e+10, 1.2746e+10, 1.1010e+10, 7.0166e+10,
        1.5370e+10, 1.2353e+10, 9.4598e+09, 2.5322e+10, 3.0018e+09, 1.4002e+10,
        1.2883e+10, 8.4286e+09, 7.8680e+09, 4.1396e+09, 1.9060e+10, 3.5392e+10,
        2.8857e+10, 2.4223e+10, 2.2449e+10, 1.9367e+11, 2.7628e+10, 8.6970e+09,
        1.1721e+10, 1.6473e+10, 1.8826e+11, 3.4683e+11, 2.1004e+10, 9.7596e+09,
        1.0420e+10, 5.1088e+10, 8.0424e+09, 3.6529e+10, 1.2495e+10, 3.1349e+10,
        3.3017e+10, 2.3361e+10, 2.8389e+10, 1.4788e+10, 1.6605e+10, 4.2687e+10,
        3.1576e+10, 1.2066e+10, 1.3550e+10, 2.7313e+10, 9.9056e+10, 4.1400e+09,
        4.3462e+11, 4.6728e+09, 1.7056e+10, 1.7370e+10, 9.3283e+09, 6.4983e+09,
        2.5152e+10, 3.9662e+09, 3.0144e+10, 3.6305e+10, 9.3594e+09, 2.7209e+10,
        1.0009e+10, 6.4935e+09, 1.4526e+10, 1.0061e+10, 7.9682e+09, 1.7503e+10,
        4.3412e+10, 1.5106e+10, 1.4001e+10, 3.6122e+10, 4.6549e+09, 7.4216e+09,
        1.6225e+10, 1.2403e+10, 1.4712e+10, 3.2422e+10, 3.0440e+10, 9.9682e+09,
        1.1487e+10, 1.1753e+10, 6.9435e+09, 6.8319e+10, 1.0692e+10, 1.1887e+10,
        2.0029e+10, 3.7154e+10, 4.2734e+10, 4.5574e+10, 1.6541e+10, 2.7381e+11,
        2.6205e+10, 3.0240e+10, 4.7845e+09, 1.5493e+10, 8.2307e+09, 1.1428e+10,
        1.0015e+11, 1.0529e+10, 1.9924e+10, 2.3271e+10, 1.6294e+11, 7.0039e+09,
        1.0699e+10, 2.6160e+10, 2.9408e+10, 1.1428e+10, 1.4242e+10, 7.1682e+10,
        1.2078e+10, 2.1971e+10, 8.2761e+09, 1.3407e+10, 1.7242e+10, 1.9055e+10,
        6.8164e+09, 6.2584e+09, 3.3526e+10, 2.2960e+10, 3.3532e+10, 2.2391e+10,
        1.4135e+10, 3.9352e+10, 2.6530e+09, 1.9998e+11, 1.4416e+10, 4.5576e+10,
        1.9855e+10, 5.9791e+10, 1.1686e+10, 2.6620e+10, 5.1568e+10, 9.8583e+09,
        4.0844e+09, 7.0239e+10, 7.9097e+10, 6.3984e+10, 1.4385e+10, 2.9995e+10,
        2.1292e+10, 4.6386e+10, 1.0522e+10, 9.3640e+09, 2.8381e+09, 3.6869e+10,
        1.6207e+10, 2.6228e+10, 1.1249e+10, 2.4370e+10, 1.5686e+10, 1.3089e+10,
        8.0626e+09, 1.6960e+10, 2.6121e+09, 6.5746e+09, 2.2796e+11, 4.7661e+09,
        1.9079e+10, 1.1453e+10, 1.7840e+10, 9.4101e+09, 1.7896e+10, 1.3414e+10,
        9.1108e+09, 2.6943e+09, 6.8323e+09, 4.2313e+10, 3.2660e+10, 7.0275e+10,
        2.4668e+10, 4.1399e+10, 1.2971e+10, 1.6465e+10, 7.8779e+10, 3.2642e+10,
        1.2201e+10, 2.6076e+10, 2.4058e+10, 1.0251e+10, 8.4431e+10, 2.8112e+10,
        1.4824e+10, 7.2345e+10, 4.7992e+09, 8.7354e+10, 8.1427e+10, 2.3709e+10,
        1.2426e+10, 1.4009e+10, 3.1318e+10, 1.1613e+10, 2.2526e+10, 5.3054e+09,
        1.0121e+10, 2.7376e+10, 3.9466e+10, 2.2306e+10, 5.1780e+09, 7.5695e+10,
        2.4683e+10, 2.1398e+10, 2.4239e+10, 9.8404e+09, 2.7332e+10, 4.7162e+10,
        2.2963e+10, 4.8500e+09, 1.6898e+10, 1.1703e+10, 2.0916e+10, 9.2405e+09,
        1.3332e+10, 2.9498e+10, 2.1752e+10, 1.9977e+10, 1.8980e+11, 5.5171e+10,
        2.3828e+10, 2.6457e+10, 1.1811e+11, 1.0060e+10, 2.4689e+10, 1.0959e+12,
        1.3088e+10, 4.7213e+09, 7.9429e+10, 1.5660e+11, 4.4907e+10, 2.6301e+09,
        3.7255e+10, 2.7134e+10, 2.2790e+10, 6.8355e+10, 1.6739e+10, 4.4245e+09,
        2.1985e+10, 3.2097e+10, 1.7576e+10, 8.7847e+09, 2.6203e+10, 1.6985e+10,
        1.5111e+10, 2.4417e+10, 3.6530e+10, 7.9418e+09, 1.5381e+10, 3.4811e+10,
        2.1962e+10, 1.6490e+10, 5.5180e+10, 5.5974e+09, 1.2712e+10, 1.6925e+10,
        9.1542e+09, 1.2564e+11, 6.1300e+10, 5.5590e+10, 4.5261e+09, 1.7019e+10,
        9.5703e+09, 2.7507e+10, 3.1105e+10, 1.6467e+10, 9.7619e+09, 1.6194e+10,
        2.3166e+10, 1.9793e+10, 1.7314e+10, 4.8924e+09, 9.9623e+09, 3.2545e+10,
        1.9985e+10, 2.2365e+10, 2.4898e+11, 7.8250e+10, 3.1484e+10, 1.5987e+10,
        1.4048e+11, 1.5525e+10, 1.6111e+10, 9.0989e+11, 1.3154e+10, 1.1396e+10,
        1.6589e+10, 9.7319e+09, 1.9832e+10, 4.0555e+10, 6.6928e+09, 2.7620e+10,
        1.9131e+10, 5.0971e+10, 3.4849e+10, 1.1176e+10, 1.4994e+11, 1.6370e+10,
        3.7505e+10, 1.6991e+10, 1.9597e+10, 8.1539e+09, 1.3557e+10, 1.4470e+10,
        3.4705e+09, 1.1577e+10, 1.1244e+10, 1.2828e+10, 1.1890e+10, 3.5155e+10,
        2.2578e+10, 6.2460e+10, 1.4785e+10, 1.7137e+10, 3.3306e+10, 1.6097e+10,
        9.7180e+09, 5.7951e+09, 5.7504e+09, 5.4831e+10, 1.2390e+10, 1.9068e+10,
        1.7192e+10, 1.2624e+11, 1.3728e+10, 5.9952e+09, 3.7066e+10, 1.0002e+10,
        1.1431e+10, 5.4382e+10, 4.3983e+11, 3.3220e+09, 2.2623e+10, 7.2251e+10,
        1.2355e+10, 3.9274e+09, 2.8457e+11, 3.0010e+10, 1.7158e+10, 1.9322e+10,
        3.3413e+10, 4.7779e+10, 2.3424e+10, 1.8634e+10, 1.6139e+10, 4.6333e+11,
        8.8105e+10, 1.1620e+11, 1.2582e+12, 1.1430e+10, 2.5509e+10, 5.3506e+09,
        1.5796e+10, 6.8740e+10, 2.0800e+10, 6.6229e+09, 1.1573e+10, 5.6448e+10,
        2.0595e+10, 1.7879e+10, 7.2904e+09, 2.4015e+10, 4.5222e+10, 1.9247e+11,
        9.0590e+09, 1.1120e+10, 3.3899e+10, 1.4593e+10, 3.3095e+10, 2.1759e+10,
        1.2741e+10, 1.1570e+10, 3.1770e+10, 2.0080e+10, 6.1760e+10, 8.6866e+10,
        9.2718e+09, 9.9864e+09, 1.6043e+10, 6.4719e+09, 7.2154e+09, 9.7742e+09,
        6.2511e+09, 3.0757e+10, 1.1649e+10, 2.4433e+10, 8.6033e+09, 2.5544e+11,
        2.0679e+10, 4.4043e+10, 1.7375e+10, 1.9337e+10, 1.8087e+10, 1.8788e+10,
        1.5438e+10, 2.6002e+10, 5.2248e+09, 3.5660e+10, 9.9525e+09, 1.4797e+10,
        2.0596e+10, 1.5729e+10, 1.7040e+10, 1.7424e+10, 1.2722e+11, 5.9893e+09,
        2.7409e+10, 2.2213e+10, 7.2893e+09, 6.7037e+10, 1.1685e+11, 1.2575e+10,
        9.5695e+09, 1.2805e+10, 1.2189e+11, 1.0195e+10, 5.6304e+10, 3.4353e+09,
        1.0993e+10, 1.5344e+10, 2.6379e+10, 1.1374e+10, 7.2936e+09, 2.4791e+10,
        2.6041e+10, 2.4359e+10, 5.7944e+09, 1.5469e+10, 2.1579e+10, 3.1960e+10,
        2.1834e+10, 1.5045e+10, 2.1752e+10, 8.4811e+09, 3.8942e+09, 1.5276e+10,
        1.8153e+10, 1.3572e+10, 1.3917e+10, 3.4778e+10, 2.8024e+10, 1.3416e+10,
        1.9487e+10, 8.1377e+10, 3.2912e+10, 2.2316e+10, 1.0438e+10, 1.9100e+10,
        1.8478e+10, 2.0659e+10, 2.4335e+10, 5.9779e+09, 1.1275e+10, 1.6786e+10,
        1.0126e+10, 4.7579e+10, 3.6393e+10, 1.1611e+10, 1.8337e+11, 3.2566e+10,
        1.9059e+10, 3.2077e+10])
Layer: encoder.5.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.3436e+10, 1.6173e+10, 2.6390e+10, 3.7919e+10, 1.7996e+10, 2.4782e+10,
        2.0873e+10, 3.0510e+10, 5.7110e+10, 2.5959e+10, 4.0753e+10, 4.6960e+10,
        3.2914e+10, 5.5119e+10, 3.3444e+10, 2.2945e+10, 3.8003e+10, 3.4482e+10,
        4.1771e+10, 2.7787e+10, 1.9697e+10, 1.7796e+10, 2.0658e+10, 2.3928e+10,
        3.6416e+10, 2.6860e+10, 2.0045e+10, 1.4627e+10, 1.8304e+10, 2.3803e+10,
        2.7629e+10, 2.5059e+10, 6.4316e+10, 2.5546e+10, 2.7055e+10, 1.5358e+10,
        2.1454e+10, 1.4082e+10, 6.7071e+10, 7.0386e+09, 4.0441e+10, 2.6994e+10,
        1.2801e+10, 3.4597e+10, 3.6025e+10, 9.1788e+09, 3.5201e+10, 4.4257e+10,
        4.6033e+10, 3.0532e+10, 2.2372e+10, 3.7137e+10, 4.1470e+10, 2.0114e+10,
        2.6433e+10, 4.6711e+10, 2.8159e+10, 3.0566e+10, 5.1572e+10, 3.6404e+10,
        1.8172e+10, 1.3073e+10, 2.9863e+10, 2.4473e+10, 3.6809e+10, 3.9388e+10,
        1.8815e+10, 4.6117e+10, 1.3398e+10, 3.6467e+10, 2.1091e+10, 1.5728e+10,
        3.3755e+10, 2.0090e+10, 2.5090e+10, 3.8670e+10, 3.3167e+10, 4.2577e+10,
        4.3984e+10, 3.3774e+10, 4.6934e+10, 2.6231e+10, 2.4858e+10, 8.9668e+09,
        4.6504e+10, 6.1045e+10, 2.5957e+10, 1.5158e+10, 7.8225e+09, 2.6791e+10,
        1.7170e+10, 1.5805e+10, 4.1186e+10, 1.3811e+10, 3.1256e+10, 1.4160e+10,
        2.3699e+10, 2.9030e+10, 3.8162e+10, 2.8257e+10, 1.4101e+10, 5.2649e+10,
        4.1096e+10, 4.3177e+10, 1.6013e+10, 8.0574e+10, 4.8741e+10, 4.0519e+10,
        7.0811e+10, 4.3441e+10, 2.2464e+10, 3.1463e+10, 1.6447e+10, 1.1318e+10,
        2.2188e+10, 3.6612e+10, 2.3616e+10, 4.4869e+10, 4.8565e+10, 2.9341e+10,
        1.0507e+10, 5.6036e+10, 1.8612e+10, 1.6542e+10, 3.8507e+10, 2.2535e+10,
        1.3661e+10, 2.5918e+10])
Layer: encoder.5.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.7551e+10, 9.5076e+10, 2.6406e+10, 5.0304e+10, 3.4562e+10, 5.0038e+10,
        3.0288e+10, 1.0238e+11, 8.5128e+10, 6.0179e+10, 5.1128e+10, 5.8063e+10,
        5.5428e+10, 2.6848e+10, 6.4433e+10, 2.2483e+10, 3.8284e+10, 4.6999e+10,
        4.5925e+10, 3.5699e+10, 5.6441e+10, 7.0373e+10, 1.4171e+10, 4.0850e+10,
        4.5775e+10, 4.9763e+10, 5.2530e+10, 3.4635e+10, 8.3866e+10, 6.3373e+10,
        2.8835e+10, 8.8173e+10, 5.9904e+10, 4.3591e+10, 4.9098e+10, 5.2523e+10,
        1.0025e+11, 4.2215e+10, 2.7454e+10, 4.2166e+10, 3.2943e+10, 4.9410e+10,
        6.1054e+10, 3.9450e+10, 6.0780e+10, 3.2615e+10, 2.4856e+10, 1.4014e+11,
        4.0226e+10, 2.7224e+10, 6.5279e+10, 4.3099e+10, 6.0685e+10, 5.6632e+10,
        3.2114e+10, 2.8202e+10, 9.3929e+10, 4.9390e+10, 5.2011e+10, 7.4509e+10,
        3.7937e+10, 2.2092e+10, 3.0609e+10, 9.8749e+10, 6.3969e+10, 7.7448e+10,
        4.3984e+10, 4.6199e+10, 4.4323e+10, 5.5212e+10, 2.7349e+10, 1.9293e+10,
        3.1662e+10, 3.1511e+10, 8.4360e+10, 5.3154e+10, 6.1475e+10, 5.6270e+10,
        4.5354e+10, 3.5151e+10, 5.2107e+10, 5.2730e+10, 3.6128e+10, 5.3887e+10,
        2.1457e+10, 3.0836e+10, 2.5491e+10, 3.0492e+10, 8.0901e+10, 5.4371e+10,
        6.7972e+10, 4.5817e+10, 1.9573e+10, 8.3390e+10, 4.9477e+10, 5.9014e+10,
        3.3017e+10, 3.1003e+10, 1.6350e+10, 7.1887e+10, 2.5375e+10, 7.3086e+10,
        9.4068e+10, 3.0394e+10, 1.0298e+11, 5.8698e+10, 3.8113e+10, 4.2861e+10,
        5.9565e+10, 5.0901e+10, 5.9894e+10, 3.0758e+10, 5.5531e+10, 5.0119e+10,
        6.2033e+10, 2.9178e+10, 3.6586e+10, 4.9151e+10, 3.1974e+10, 8.3459e+10,
        3.4944e+10, 8.7732e+10, 9.9061e+10, 3.4919e+10, 1.1890e+10, 1.7062e+10,
        2.0146e+10, 2.1268e+10])
Layer: encoder.5.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.4375e+09, 3.2903e+08, 2.0912e+09, 3.0205e+08, 2.3917e+08, 4.7983e+08,
        1.3536e+09, 1.7229e+09, 2.5493e+10, 5.9035e+08, 4.6840e+09, 7.0539e+08,
        2.1124e+09, 2.8912e+09, 3.8900e+09, 7.7539e+08, 1.5292e+09, 6.4476e+09,
        2.0868e+09, 6.2750e+08, 3.9430e+08, 2.7495e+09, 1.5415e+09, 1.0210e+09,
        5.2342e+08, 3.4036e+09, 5.7351e+09, 5.3634e+09, 3.5565e+09, 3.3466e+09,
        2.7808e+09, 2.7542e+09, 6.4016e+09, 3.1928e+09, 2.1133e+09, 3.1150e+09,
        1.3042e+08, 1.7825e+09, 5.6632e+09, 3.6012e+09, 2.1297e+09, 2.2617e+10,
        2.0648e+08, 1.2989e+09, 9.9201e+08, 5.8875e+08, 2.6873e+09, 1.1351e+09,
        4.4808e+08, 2.3587e+09, 3.9024e+09, 2.1564e+09, 9.2729e+08, 2.8862e+09,
        1.3262e+09, 5.8343e+08, 1.0736e+09, 1.8453e+09, 1.1081e+09, 3.1000e+09,
        1.3601e+09, 3.2233e+10, 3.6884e+08, 4.3462e+09, 2.4528e+08, 4.6233e+08,
        2.9487e+09, 2.7362e+09, 1.9176e+09, 1.9129e+09, 9.3505e+08, 3.3417e+09,
        1.5696e+09, 7.6922e+08, 1.1381e+09, 1.5161e+09, 5.6233e+09, 4.8012e+08,
        3.2024e+09, 2.4825e+09, 2.7271e+09, 3.5455e+11, 8.2323e+09, 3.4173e+09,
        2.8527e+09, 1.6692e+10, 1.9933e+09, 4.7954e+09, 2.4276e+08, 3.3154e+09,
        5.5057e+08, 1.8141e+09, 1.0799e+09, 9.3933e+08, 7.5687e+09, 6.2284e+09,
        4.6110e+09, 1.3609e+09, 2.6145e+09, 6.5503e+08, 3.6305e+08, 6.1649e+08,
        3.1962e+09, 4.5047e+08, 1.4175e+09, 2.6441e+09, 2.8504e+08, 1.8457e+09,
        2.1037e+09, 2.2051e+09, 3.2200e+09, 2.2177e+09, 1.5719e+08, 2.0652e+09,
        1.9342e+09, 5.7761e+08, 2.8598e+08, 1.1028e+08, 1.2890e+09, 5.9419e+09,
        1.4038e+09, 1.0375e+09, 2.9847e+09, 2.5773e+09, 2.7662e+08, 4.4244e+09,
        5.5741e+09, 6.4804e+08, 2.2376e+10, 1.2500e+09, 2.1445e+09, 1.5737e+09,
        3.7778e+09, 2.3055e+09, 3.1932e+09, 5.3885e+09, 2.9464e+09, 2.9785e+09,
        2.1081e+09, 7.1565e+08, 2.9124e+09, 5.2741e+09, 1.1173e+09, 1.1893e+09,
        2.6277e+09, 2.9595e+09, 1.6003e+09, 2.8958e+09, 1.2809e+09, 1.4061e+09,
        7.6049e+08, 4.8509e+09, 3.4678e+09, 6.1773e+09, 7.0913e+10, 5.0365e+08,
        2.3516e+09, 1.8843e+09, 6.0088e+08, 2.0899e+09, 2.4365e+09, 2.3472e+08,
        7.5071e+08, 7.0310e+08, 3.6398e+09, 6.9684e+08, 4.1220e+09, 2.9426e+09,
        1.3469e+09, 1.1933e+09, 1.0795e+09, 8.7187e+08, 7.5347e+08, 4.4759e+09,
        3.4167e+08, 7.7628e+08, 3.3254e+09, 6.1212e+09, 2.0858e+09, 3.7975e+09,
        8.5921e+08, 1.6345e+09, 2.8255e+09, 1.2303e+09, 7.6627e+09, 1.3317e+09,
        4.3573e+09, 2.3272e+09, 3.3345e+10, 1.5582e+10, 3.2549e+09, 6.3205e+08,
        3.8696e+08, 6.3895e+08, 2.9626e+08, 2.4111e+09, 1.0479e+09, 1.5453e+09,
        1.3145e+09, 1.4201e+10, 8.8874e+08, 2.9456e+09, 3.0190e+09, 1.1915e+09,
        3.4465e+09, 5.6157e+08, 4.6866e+09, 4.2247e+08, 1.4555e+09, 1.3249e+09,
        3.7600e+09, 3.0777e+09, 7.0736e+08, 9.0717e+08, 9.0143e+09, 3.4113e+09,
        1.6295e+08, 1.4297e+09, 5.6614e+09, 1.7507e+09, 1.6817e+09, 2.8121e+09,
        6.6899e+08, 1.0915e+09, 2.2963e+09, 3.1374e+09, 1.7410e+08, 6.2333e+08,
        2.0886e+09, 1.0609e+09, 2.6581e+09, 2.1302e+09, 1.1529e+10, 1.9364e+09,
        2.0956e+08, 1.2383e+09, 4.9458e+08, 1.2238e+09, 1.0453e+09, 9.2634e+08,
        7.8277e+08, 7.9388e+08, 1.3846e+09, 3.4974e+09, 3.0507e+09, 4.9618e+09,
        2.4314e+09, 2.3162e+09, 3.0691e+09, 6.2712e+09, 1.9314e+09, 2.9087e+09,
        5.0634e+10, 6.5720e+09, 2.0094e+09, 2.0973e+09, 3.3688e+09, 1.9257e+09,
        1.3382e+09, 2.1632e+09, 4.7578e+08, 2.4090e+09, 1.8505e+08, 4.9980e+08,
        4.6333e+09, 3.8349e+09, 1.9451e+08, 2.4836e+09, 2.4492e+09, 4.8659e+09,
        5.4051e+09, 1.3617e+09, 1.7387e+09, 2.2222e+09, 3.1112e+09, 1.0368e+09,
        1.6907e+09, 6.6933e+07, 1.4050e+09, 1.7680e+09, 1.8254e+09, 3.9325e+09,
        8.9347e+08, 1.9429e+09, 2.7972e+09, 2.3980e+09, 2.1913e+09, 2.9549e+08,
        6.2998e+08, 3.7764e+09, 1.2241e+09, 2.9918e+09, 2.7523e+09, 3.3641e+09,
        1.9579e+09, 9.7082e+08, 4.3558e+09, 1.3304e+09, 1.9533e+09, 7.2516e+09,
        5.8635e+09, 5.6351e+08, 5.1184e+08, 1.8764e+08, 5.0635e+08, 1.9581e+09,
        3.4915e+09, 1.5723e+09, 6.4519e+09, 2.8158e+09, 2.3563e+09, 5.6183e+09,
        2.6815e+09, 1.8026e+09, 1.1128e+09, 8.1376e+08, 9.6649e+08, 1.4485e+09,
        1.5277e+09, 7.8271e+09, 2.0934e+09, 3.5107e+09, 1.0155e+09, 2.3321e+08,
        5.2861e+08, 4.6831e+09, 1.6697e+09, 3.5649e+09, 1.2394e+09, 8.9577e+08,
        6.4325e+09, 3.6793e+09, 1.1360e+10, 1.1750e+09, 1.9215e+09, 3.7827e+09,
        2.0648e+09, 2.6819e+09, 6.5138e+08, 1.4750e+09, 1.7153e+08, 2.5724e+09,
        8.0338e+07, 6.4751e+08, 1.5415e+09, 2.8290e+09, 3.9372e+09, 4.3814e+09,
        1.9730e+09, 1.1792e+09, 3.5177e+09, 1.2202e+09, 2.4670e+09, 3.9565e+09,
        4.5463e+09, 1.8700e+09, 6.3874e+08, 2.1365e+09, 3.0413e+09, 9.2140e+08,
        8.4582e+08, 1.9399e+09, 3.8415e+08, 6.2938e+08, 2.9464e+09, 2.8312e+09,
        1.5404e+09, 4.5322e+08, 1.5559e+09, 2.9673e+09, 1.6013e+08, 3.6159e+09,
        1.3089e+09, 4.1403e+08, 3.2296e+08, 8.0804e+08, 7.7418e+08, 6.3906e+09,
        3.5630e+08, 1.8799e+09, 7.7764e+09, 8.5393e+08, 1.4517e+09, 2.6850e+09,
        6.4062e+08, 3.1695e+08, 1.0648e+09, 1.7209e+09, 5.3516e+07, 3.0419e+09,
        2.6135e+09, 1.1983e+09, 2.4230e+09, 3.3694e+08, 2.5399e+09, 2.9810e+09,
        9.2234e+09, 1.3779e+09, 1.7149e+09, 2.7166e+09, 3.7211e+09, 1.5107e+09,
        8.9850e+09, 7.2192e+08, 1.8301e+08, 3.4017e+09, 1.5567e+09, 4.1565e+09,
        2.5668e+09, 1.8407e+09, 1.6299e+09, 3.5836e+08, 1.2277e+09, 1.8318e+09,
        2.9890e+08, 2.6119e+09, 1.5609e+09, 3.3752e+08, 5.9446e+08, 6.6137e+09,
        2.9060e+09, 2.5264e+09, 4.0934e+09, 7.3895e+09, 9.5243e+09, 2.0989e+09,
        1.0684e+09, 1.7598e+09, 4.2352e+09, 1.6584e+08, 2.9616e+09, 1.6337e+08,
        3.9965e+09, 6.8431e+08, 1.9119e+09, 3.0388e+09, 2.2583e+09, 3.4614e+09,
        5.3145e+09, 6.2249e+08, 1.3308e+09, 2.3408e+09, 2.7486e+09, 2.7236e+09,
        3.5442e+09, 2.7453e+09, 3.7304e+09, 8.8371e+09, 2.3048e+09, 3.8287e+09,
        2.2763e+09, 2.0787e+09, 3.0469e+09, 1.2636e+09, 1.5053e+09, 2.0841e+09,
        3.1459e+09, 3.7529e+09, 3.6685e+08, 1.6640e+09, 7.1548e+08, 4.8151e+08,
        3.3155e+09, 4.3157e+08, 4.0420e+09, 7.1537e+08, 1.7924e+09, 5.9028e+09,
        1.3482e+09, 1.0555e+09, 2.1237e+09, 4.1495e+09, 2.2084e+09, 1.9095e+09,
        9.4850e+08, 1.1008e+10, 3.0431e+08, 5.1389e+08, 2.4298e+09, 2.4318e+09,
        8.0682e+08, 3.7707e+09, 2.4300e+09, 1.6242e+09, 1.4048e+09, 1.7673e+09,
        1.6198e+09, 2.3641e+09, 4.6548e+08, 4.2967e+09, 3.3956e+09, 3.0683e+09,
        2.6939e+09, 1.0351e+10, 4.6291e+09, 2.9102e+09, 1.5370e+09, 2.5451e+09,
        1.4679e+09, 2.2203e+09, 3.1845e+08, 3.9623e+08, 1.5614e+09, 2.6392e+08,
        3.2025e+08, 6.2607e+08, 3.4704e+09, 1.6982e+09, 1.4983e+09, 1.0499e+09,
        1.5623e+08, 3.8318e+09])
Layer: encoder.5.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.4105e+09, 4.1602e+09, 7.5785e+09, 2.3597e+09, 4.4339e+09, 3.8970e+09,
        4.2045e+09, 1.3967e+10, 3.0294e+09, 5.1196e+09, 5.7295e+09, 3.8062e+09,
        1.0290e+10, 5.1636e+09, 4.8383e+09, 7.9734e+09, 2.8455e+09, 4.6816e+09,
        4.1659e+09, 1.3890e+10, 3.5803e+09, 2.6161e+09, 3.6341e+09, 2.1162e+09,
        2.9501e+09, 4.2675e+09, 6.9298e+09, 4.5282e+09, 7.8008e+09, 1.8417e+09,
        1.2821e+09, 5.2540e+09, 2.9592e+09, 7.0397e+09, 2.4215e+09, 6.8684e+09,
        7.4531e+09, 7.3318e+09, 3.9165e+09, 4.3724e+09, 2.9302e+09, 5.1487e+09,
        1.3707e+10, 3.1591e+09, 3.2222e+09, 9.5545e+09, 7.8013e+09, 6.5321e+09,
        2.7944e+09, 2.9900e+09, 4.8995e+09, 1.9205e+09, 3.4395e+09, 7.1228e+09,
        3.9958e+09, 7.4488e+09, 2.3190e+09, 2.4186e+09, 4.5898e+09, 7.2053e+09,
        1.1257e+10, 4.1787e+09, 5.9518e+09, 9.1916e+09, 1.1330e+10, 2.3609e+09,
        9.9123e+09, 8.8684e+09, 5.6600e+09, 4.9293e+09, 2.9783e+09, 5.7667e+09,
        5.5156e+09, 3.1346e+09, 3.4299e+09, 6.7630e+09, 5.5202e+09, 9.5392e+09,
        3.2336e+09, 9.3744e+09, 1.1684e+10, 5.6391e+09, 4.4222e+09, 4.7605e+09,
        3.3430e+09, 5.8828e+09, 4.4700e+09, 1.4614e+10, 4.0466e+09, 1.1208e+10,
        1.1668e+10, 8.0058e+09, 2.4839e+09, 6.7398e+09, 2.9652e+09, 4.9958e+09,
        7.4185e+09, 9.8213e+09, 3.1145e+09, 9.6279e+09, 9.1486e+09, 2.4672e+09,
        1.1352e+10, 4.9900e+09, 3.8507e+09, 1.1233e+10, 3.1022e+09, 4.2002e+09,
        3.7334e+09, 6.5822e+09, 4.3606e+09, 2.1557e+09, 8.6011e+09, 2.9427e+09,
        5.9546e+09, 4.8327e+09, 1.6295e+09, 2.7660e+09, 2.3348e+09, 3.1331e+09,
        7.0227e+09, 3.5535e+09, 6.6601e+09, 8.5359e+09, 2.4521e+09, 4.2563e+09,
        6.2834e+09, 1.1393e+10])
Layer: encoder.5.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.1639e+09, 5.8545e+09, 7.9156e+09, 6.6097e+09, 2.4233e+10, 1.1169e+10,
        7.6029e+09, 1.4493e+10, 9.7752e+09, 7.3170e+09, 1.4659e+10, 7.8758e+09,
        4.8473e+09, 4.7524e+09, 2.8128e+09, 1.2924e+10, 4.9757e+09, 1.2115e+10,
        1.1201e+10, 9.9182e+09, 9.8781e+09, 2.0190e+10, 1.1270e+10, 2.5485e+10,
        1.0336e+10, 1.3906e+10, 4.4486e+09, 7.1666e+09, 1.9589e+10, 9.8548e+09,
        1.3507e+10, 8.9881e+09, 2.0238e+10, 8.1237e+09, 1.6274e+10, 7.8868e+09,
        1.5151e+10, 3.4556e+09, 3.7759e+09, 1.2187e+10, 6.9365e+09, 1.8292e+10,
        1.0874e+10, 1.8351e+10, 4.3791e+09, 4.0983e+09, 9.3007e+09, 8.5218e+09,
        7.8064e+09, 1.3078e+10, 4.5592e+09, 9.5490e+09, 1.4624e+10, 1.6440e+10,
        1.0459e+10, 1.6885e+10, 9.3129e+09, 4.7510e+09, 8.0825e+09, 1.5087e+10,
        9.4718e+09, 3.3161e+09, 1.0559e+10, 9.3613e+09, 1.6574e+10, 1.0873e+10,
        7.5432e+09, 1.1901e+10, 8.6002e+09, 8.8088e+09, 7.4977e+09, 1.6879e+10,
        6.4808e+09, 1.0599e+10, 5.4294e+09, 7.9132e+09, 8.6852e+09, 1.2539e+10,
        6.5424e+09, 1.3447e+10, 9.3802e+09, 1.9759e+10, 1.4669e+10, 1.3891e+10,
        1.0768e+10, 8.6350e+09, 7.5233e+09, 1.3792e+10, 9.1704e+09, 1.6924e+10,
        2.0450e+10, 1.5103e+10, 3.7735e+09, 7.2111e+09, 1.5203e+10, 2.4753e+10,
        1.2953e+10, 9.1373e+09, 1.0881e+10, 2.8197e+09, 4.5321e+09, 6.3843e+09,
        1.2287e+10, 6.9071e+09, 1.6690e+10, 1.5311e+10, 1.1959e+10, 1.7172e+10,
        7.3685e+09, 8.5498e+09, 9.3723e+09, 9.8935e+09, 9.5205e+09, 2.0764e+10,
        4.3394e+09, 1.9781e+10, 1.3926e+10, 7.7437e+09, 7.5688e+09, 5.7378e+09,
        1.0373e+10, 1.1212e+10, 1.0256e+10, 8.4734e+09, 4.1146e+09, 1.4809e+10,
        7.1263e+09, 1.2056e+10])
Layer: encoder.5.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.1329e+09, 1.1672e+07, 2.2622e+08, 6.4335e+07, 5.0009e+07, 2.5411e+08,
        9.2318e+07, 3.5070e+08, 2.6106e+08, 2.2640e+07, 1.9217e+08, 9.7504e+07,
        5.7378e+08, 2.9995e+08, 1.8826e+08, 1.1417e+08, 7.0325e+08, 3.0519e+09,
        2.3909e+08, 1.4904e+08, 7.5051e+07, 4.0652e+09, 9.4216e+07, 2.8241e+08,
        1.9827e+08, 1.5192e+08, 2.1477e+07, 3.5103e+07, 4.9423e+08, 2.0293e+08,
        4.1394e+08, 1.1015e+08, 6.9817e+07, 5.1410e+08, 2.0343e+09, 5.7160e+08,
        1.2384e+07, 1.6137e+08, 5.1315e+08, 1.9475e+09, 9.9068e+07, 9.2169e+08,
        4.6979e+07, 2.2927e+08, 2.1497e+08, 1.2510e+07, 3.4014e+07, 2.9426e+08,
        1.4696e+07, 1.0537e+08, 2.2920e+08, 1.4687e+08, 3.7740e+07, 6.0555e+07,
        3.7248e+08, 3.7441e+07, 1.9872e+08, 1.4263e+08, 3.6049e+07, 2.7341e+08,
        4.8613e+08, 2.2781e+08, 2.6284e+07, 2.5170e+08, 3.7316e+07, 4.2560e+07,
        2.7350e+08, 3.3204e+08, 8.9776e+08, 7.0962e+08, 1.2383e+08, 2.9057e+08,
        1.1831e+08, 2.3213e+08, 1.6087e+08, 2.7115e+08, 6.1649e+07, 5.3062e+06,
        5.6636e+08, 2.6850e+08, 1.3690e+08, 2.5793e+07, 4.1587e+08, 1.6997e+08,
        3.6210e+08, 1.6382e+08, 2.9278e+08, 1.2402e+08, 1.0513e+08, 4.5266e+08,
        2.6423e+07, 3.9813e+08, 3.6343e+07, 5.8887e+08, 1.7093e+08, 1.3662e+09,
        2.2818e+08, 9.5364e+07, 3.1750e+08, 1.7758e+07, 1.4518e+07, 3.8849e+07,
        5.1981e+08, 8.1295e+07, 5.4325e+08, 3.9616e+08, 4.3929e+07, 2.3845e+08,
        1.8698e+08, 2.7126e+08, 3.1961e+08, 6.7605e+08, 1.4777e+07, 1.5385e+08,
        4.8558e+08, 2.1773e+07, 2.3548e+08, 5.0945e+07, 4.9783e+08, 2.4658e+08,
        4.0054e+07, 4.0098e+08, 3.1318e+07, 5.3301e+08, 7.5555e+07, 1.6252e+08,
        2.5954e+08, 2.0764e+07, 4.8151e+08, 1.3741e+08, 5.8553e+07, 7.1046e+08,
        3.3449e+08, 1.8302e+08, 2.6870e+08, 4.4014e+08, 3.8528e+08, 1.4115e+09,
        9.0423e+07, 3.3353e+08, 1.5677e+08, 4.7341e+07, 6.5112e+07, 2.9311e+08,
        1.1874e+09, 1.1488e+08, 4.8600e+08, 2.5994e+08, 1.4734e+08, 6.0887e+07,
        1.9018e+08, 4.8706e+08, 6.2352e+08, 1.3915e+08, 6.9896e+10, 6.4374e+07,
        8.5937e+08, 2.1014e+08, 9.2111e+07, 8.8854e+07, 2.6421e+08, 1.8962e+07,
        1.0565e+07, 1.3206e+08, 4.2573e+08, 4.1325e+07, 4.6535e+08, 8.6473e+07,
        8.6225e+07, 1.2726e+08, 5.8647e+08, 8.3262e+07, 1.0980e+08, 2.4614e+08,
        4.9519e+07, 5.8691e+08, 1.9153e+08, 1.2487e+09, 1.8793e+08, 1.1180e+09,
        5.9860e+09, 4.3322e+08, 3.6851e+08, 4.0629e+08, 1.6908e+08, 3.1926e+08,
        1.6527e+07, 1.8655e+09, 1.8753e+10, 4.9216e+09, 6.6968e+08, 6.8814e+08,
        1.0497e+08, 5.1684e+07, 2.9054e+07, 1.9554e+08, 1.2046e+07, 1.0742e+08,
        1.0429e+09, 7.2188e+07, 2.5345e+07, 2.1913e+08, 6.8586e+07, 4.0964e+08,
        4.6618e+08, 1.5038e+08, 7.2363e+07, 3.1140e+08, 3.5130e+08, 3.5666e+08,
        1.6853e+08, 4.9659e+08, 2.8409e+09, 3.5789e+08, 8.9881e+09, 5.2042e+09,
        5.7413e+07, 7.0301e+08, 9.3236e+07, 6.2452e+07, 2.6417e+08, 4.1147e+08,
        1.7733e+09, 5.9565e+08, 5.4092e+08, 2.5748e+08, 1.5675e+08, 6.5031e+08,
        1.2905e+08, 1.7434e+08, 5.6499e+07, 3.5320e+08, 6.7606e+08, 7.8218e+08,
        4.6597e+07, 2.0837e+07, 2.3524e+08, 1.3196e+08, 2.9451e+08, 8.0220e+07,
        2.3566e+08, 6.9737e+07, 5.1645e+07, 4.6203e+08, 6.3143e+08, 2.3055e+08,
        8.0133e+07, 3.3985e+08, 5.3515e+08, 2.2237e+08, 2.9657e+08, 2.6310e+08,
        1.0497e+09, 2.7534e+08, 2.0908e+08, 4.9807e+08, 1.3070e+08, 1.0648e+08,
        4.9311e+08, 5.3874e+08, 6.4375e+07, 2.6359e+08, 3.6852e+06, 1.1199e+07,
        4.1506e+08, 2.4521e+08, 2.0719e+07, 3.2070e+08, 4.4852e+08, 3.5799e+08,
        2.1648e+08, 6.7676e+07, 4.0791e+08, 2.5596e+08, 3.6982e+08, 1.1206e+08,
        2.6905e+08, 8.4327e+07, 8.7245e+08, 1.7577e+08, 1.6350e+09, 1.8705e+09,
        1.0310e+08, 1.0858e+08, 4.9653e+08, 1.3802e+08, 4.1521e+08, 2.4224e+07,
        5.0472e+07, 7.8245e+07, 6.3866e+07, 7.6985e+07, 1.8879e+08, 3.0645e+08,
        1.6255e+08, 8.4580e+07, 1.2542e+08, 2.5957e+08, 1.1720e+08, 3.2411e+08,
        4.9124e+08, 3.0872e+07, 9.8010e+07, 2.6971e+07, 1.0576e+08, 1.7913e+07,
        1.0526e+09, 5.3689e+07, 8.7194e+07, 1.9183e+09, 5.2994e+08, 1.5230e+09,
        1.0920e+08, 2.0052e+08, 5.1921e+07, 6.2561e+06, 1.9703e+08, 3.4859e+08,
        4.4396e+08, 2.2604e+09, 8.3489e+08, 1.1325e+09, 5.4172e+08, 1.2672e+08,
        3.1100e+07, 6.8099e+08, 1.1692e+08, 5.9972e+07, 1.0100e+09, 8.7609e+07,
        9.9125e+07, 5.8351e+08, 9.0559e+09, 1.1706e+09, 1.7824e+09, 1.3411e+08,
        1.1606e+09, 4.1432e+08, 1.3858e+09, 3.4312e+08, 1.3699e+08, 2.7154e+08,
        1.9429e+07, 2.7575e+08, 4.0732e+08, 1.0436e+08, 9.8833e+07, 3.0621e+08,
        3.9754e+07, 2.0166e+08, 5.5310e+08, 6.5216e+08, 2.6036e+08, 2.7162e+07,
        8.0508e+08, 4.7180e+08, 3.2175e+07, 3.6847e+08, 2.7852e+08, 1.0097e+08,
        1.0281e+08, 1.1350e+08, 7.8699e+06, 3.4759e+08, 3.8031e+08, 1.2328e+08,
        1.9821e+08, 7.3172e+07, 2.3028e+08, 3.3741e+08, 2.6106e+07, 6.9790e+08,
        2.4802e+08, 8.3725e+07, 2.2451e+09, 1.3929e+08, 4.5422e+08, 1.7909e+08,
        2.9491e+07, 5.6885e+08, 2.4314e+08, 1.6701e+08, 1.9684e+08, 7.0747e+08,
        2.3471e+07, 2.7406e+07, 6.2429e+07, 3.7096e+08, 1.3576e+08, 1.5298e+08,
        2.7173e+09, 5.7984e+07, 2.2558e+08, 8.2764e+06, 8.3662e+07, 3.4950e+08,
        1.6906e+08, 3.4129e+08, 1.0110e+08, 1.9781e+08, 3.3957e+08, 2.3112e+08,
        3.9550e+09, 2.5493e+08, 1.0339e+08, 5.9960e+08, 8.5332e+07, 4.9576e+08,
        3.8188e+08, 6.8301e+07, 2.2908e+09, 1.0139e+07, 6.9833e+07, 1.7915e+08,
        1.8407e+08, 3.9932e+08, 1.1904e+09, 1.2826e+07, 9.1935e+07, 7.2722e+07,
        1.1222e+08, 1.3789e+07, 9.8357e+08, 3.4092e+08, 6.4607e+09, 7.3649e+07,
        4.2255e+08, 3.0141e+08, 6.6887e+08, 1.1627e+08, 1.6802e+08, 2.6153e+07,
        1.6705e+08, 7.4633e+07, 6.6777e+07, 1.9771e+08, 1.0619e+09, 4.3252e+08,
        2.8512e+08, 7.8831e+07, 4.6504e+07, 1.1739e+08, 6.5119e+08, 2.2043e+09,
        2.8594e+08, 2.0260e+08, 1.4163e+08, 6.2738e+08, 1.1694e+08, 2.5878e+09,
        1.3297e+09, 7.4106e+08, 1.7839e+08, 1.1450e+08, 3.5723e+08, 3.5418e+07,
        4.7100e+08, 9.6338e+08, 2.3062e+07, 4.2495e+07, 7.5966e+08, 3.5702e+07,
        3.8212e+08, 2.8950e+07, 1.4596e+08, 4.3448e+08, 6.2877e+07, 3.4240e+08,
        1.1705e+08, 3.9635e+08, 3.0794e+08, 2.8540e+08, 2.3923e+09, 3.1490e+08,
        2.0511e+08, 4.2468e+08, 1.2463e+08, 1.6403e+07, 5.3868e+07, 2.4314e+08,
        3.1943e+08, 5.8020e+08, 1.9885e+08, 2.6469e+08, 1.5606e+08, 6.4809e+08,
        4.6708e+08, 2.6493e+07, 1.8739e+08, 1.5473e+08, 9.4704e+07, 4.6172e+08,
        6.3466e+07, 1.1526e+09, 4.8766e+07, 1.2053e+08, 1.0392e+08, 9.0116e+08,
        1.7711e+08, 1.6962e+08, 9.7704e+07, 2.5347e+07, 3.2432e+08, 2.2465e+07,
        1.6902e+08, 4.3616e+08, 2.9279e+08, 9.4318e+08, 7.1984e+07, 3.5270e+07,
        2.4502e+07, 9.5845e+07])
Layer: encoder.5.3.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.0909e+09, 6.0852e+08, 3.9614e+08, 1.7862e+09, 1.4906e+09, 7.0697e+08,
        2.3339e+08, 6.6321e+08, 4.7139e+08, 8.0178e+08, 1.0836e+09, 1.2127e+09,
        1.1288e+09, 7.9067e+08, 3.4546e+08, 1.8102e+08, 3.7149e+08, 9.2227e+08,
        7.4938e+08, 2.2251e+08, 1.3401e+09, 8.5725e+08, 1.5291e+09, 7.5983e+08,
        4.9251e+08, 5.5915e+08, 1.3315e+09, 2.6393e+08, 1.0023e+09, 2.5990e+08,
        6.9594e+08, 5.8536e+08, 8.1554e+08, 4.7313e+08, 1.8134e+09, 1.4055e+09,
        1.0475e+09, 8.3758e+08, 7.6008e+08, 1.0216e+09, 8.5400e+08, 1.1426e+09,
        7.5172e+08, 2.6893e+08, 2.0002e+08, 1.0713e+09, 8.9187e+08, 4.3738e+08,
        2.8638e+08, 1.5298e+09, 6.8837e+08, 7.7916e+08, 4.9522e+08, 6.8190e+08,
        1.2828e+09, 1.8965e+08, 1.7212e+09, 2.9257e+08, 2.3402e+08, 1.1239e+09,
        1.4915e+08, 1.3203e+09, 9.6015e+08, 5.0048e+08, 1.1655e+09, 1.4716e+09,
        9.0445e+08, 1.5809e+09, 1.0435e+09, 1.1257e+09, 3.7405e+08, 1.8452e+08,
        9.6228e+08, 4.2501e+08, 7.3628e+08, 4.6193e+08, 4.9695e+08, 2.3489e+08,
        7.5902e+08, 4.9667e+08, 7.0359e+08, 8.8298e+08, 1.3487e+09, 8.0052e+08,
        9.4394e+08, 7.4408e+08, 1.5271e+09, 1.1867e+09, 1.3057e+08, 3.0978e+08,
        6.7799e+08, 6.5877e+08, 1.2463e+09, 6.6014e+08, 6.8556e+08, 1.0839e+09,
        1.3871e+09, 4.7319e+08, 1.0512e+09, 1.3678e+09, 4.4047e+08, 1.1971e+09,
        1.4130e+08, 5.9502e+08, 1.1552e+09, 3.0937e+08, 1.2339e+09, 2.0192e+09,
        4.3936e+08, 1.3384e+09, 1.7390e+09, 2.4974e+08, 1.1211e+09, 3.9741e+08,
        2.0147e+09, 4.8015e+08, 8.0179e+08, 1.6939e+09, 2.8666e+08, 8.7528e+08,
        1.6802e+09, 6.3953e+08, 1.2552e+09, 4.7647e+08, 7.9284e+08, 4.9203e+08,
        1.7013e+09, 1.4719e+09])
Layer: encoder.5.3.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([9.4244e+08, 2.7717e+09, 5.7308e+08, 2.7726e+09, 1.7356e+09, 9.1653e+08,
        9.6987e+08, 6.5559e+08, 3.1906e+09, 1.3414e+09, 4.2714e+08, 3.4943e+09,
        7.6138e+08, 6.5680e+08, 3.4281e+08, 1.5311e+09, 1.5704e+09, 6.7830e+08,
        8.5090e+08, 8.7934e+08, 9.7692e+08, 9.5732e+08, 1.5498e+09, 2.6240e+09,
        1.3722e+09, 3.0541e+08, 1.7491e+09, 9.3443e+08, 1.6949e+09, 1.6013e+09,
        8.4176e+08, 6.4658e+08, 3.8792e+09, 2.0556e+09, 1.7538e+09, 3.4529e+08,
        2.0170e+09, 1.1171e+09, 5.4617e+08, 1.1541e+09, 3.3480e+09, 2.0741e+09,
        1.2903e+09, 3.9519e+09, 4.3635e+08, 1.4513e+09, 2.5067e+09, 1.2600e+09,
        3.9255e+08, 2.0513e+09, 1.0411e+09, 1.7256e+09, 1.8378e+09, 1.9369e+09,
        4.3465e+08, 1.0562e+09, 3.4693e+08, 9.8730e+08, 1.3411e+09, 1.0531e+09,
        7.9789e+08, 2.5386e+09, 8.6868e+08, 1.4993e+09, 2.0433e+09, 6.8147e+08,
        1.7253e+09, 5.7341e+08, 1.3393e+09, 1.6016e+09, 2.5185e+09, 1.3338e+09,
        1.9127e+09, 1.2925e+09, 7.7455e+08, 8.3620e+08, 1.3195e+09, 6.9874e+08,
        3.7857e+08, 4.2097e+09, 1.2809e+09, 6.5899e+08, 1.8121e+09, 2.7836e+09,
        1.2277e+09, 1.1358e+09, 1.2768e+09, 1.0605e+09, 2.7001e+09, 1.2148e+09,
        1.2145e+09, 1.8472e+09, 1.1447e+09, 2.9249e+09, 1.9343e+09, 2.7712e+09,
        6.2525e+08, 1.3613e+09, 1.1698e+09, 6.4583e+08, 2.4154e+09, 1.2968e+09,
        4.0586e+08, 1.1572e+09, 2.2414e+09, 1.2737e+09, 8.3416e+08, 8.8376e+08,
        2.1295e+09, 1.0653e+09, 1.1509e+09, 2.9456e+09, 1.0368e+09, 9.9243e+08,
        4.6380e+08, 2.2708e+09, 1.7925e+09, 1.6381e+09, 8.4281e+08, 2.8075e+09,
        6.1249e+08, 9.0387e+08, 1.4652e+09, 2.4126e+09, 1.3096e+09, 2.9313e+09,
        8.5263e+08, 2.1618e+09])
Layer: encoder.5.3.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.7719e+07, 1.9036e+06, 2.7661e+07, 7.3229e+07, 4.6978e+06, 3.7991e+07,
        8.3609e+07, 1.4705e+07, 7.5440e+07, 6.1198e+06, 3.2742e+07, 2.0737e+07,
        2.4644e+07, 6.4034e+07, 3.6163e+07, 1.4001e+07, 5.1839e+07, 2.0178e+07,
        4.3686e+08, 4.8243e+08, 8.5957e+06, 1.8422e+07, 1.0356e+07, 1.2666e+08,
        2.4428e+08, 7.0684e+07, 2.0987e+07, 4.6599e+07, 1.5581e+07, 9.9550e+07,
        4.8967e+07, 3.6796e+07, 9.6344e+07, 3.2360e+07, 1.2811e+07, 5.1256e+07,
        1.8249e+06, 3.2230e+08, 1.0670e+08, 7.8966e+07, 1.1183e+08, 1.5500e+08,
        3.5812e+07, 7.7983e+07, 1.0569e+08, 1.0883e+07, 6.1397e+06, 7.2000e+07,
        5.0771e+06, 1.9964e+08, 9.8892e+06, 4.5198e+07, 7.0335e+06, 1.4688e+07,
        1.2332e+08, 3.0302e+07, 6.8610e+06, 3.7948e+07, 4.0708e+07, 3.1473e+07,
        2.5405e+07, 1.8181e+08, 2.3740e+06, 1.5204e+08, 1.7870e+07, 1.1774e+07,
        1.3592e+08, 6.4782e+07, 9.0614e+07, 1.2593e+08, 4.0079e+07, 1.9296e+08,
        2.8025e+08, 1.0386e+08, 1.7365e+07, 5.8334e+08, 1.1774e+07, 1.4980e+06,
        3.3962e+07, 7.6810e+07, 4.1060e+07, 2.7472e+08, 2.5744e+08, 3.4746e+06,
        1.5348e+07, 1.9869e+07, 6.0345e+07, 2.5636e+06, 8.7619e+06, 2.7349e+08,
        8.2798e+06, 1.6680e+08, 3.8040e+06, 2.7880e+07, 4.6116e+07, 4.5680e+07,
        4.5252e+07, 1.2136e+07, 1.0281e+08, 1.8676e+06, 5.9725e+06, 3.1356e+07,
        6.1913e+08, 1.8575e+07, 5.3890e+07, 2.3401e+07, 8.7270e+07, 8.5207e+06,
        3.3746e+07, 7.1928e+07, 2.4603e+07, 3.7478e+07, 7.1350e+06, 7.5617e+07,
        5.7867e+08, 1.1052e+07, 7.2386e+06, 2.7904e+07, 1.0845e+08, 2.1572e+07,
        1.1932e+07, 3.5632e+07, 3.2441e+07, 5.8172e+07, 7.4685e+06, 5.5438e+07,
        8.6604e+07, 9.1183e+05, 5.1629e+07, 2.5551e+08, 2.4606e+07, 8.8487e+07,
        4.2249e+07, 2.5304e+08, 1.2927e+08, 6.1246e+07, 3.3680e+07, 7.4674e+07,
        7.2813e+06, 1.9436e+08, 7.5064e+07, 6.8327e+06, 9.3498e+06, 1.2633e+07,
        2.0576e+07, 2.4023e+07, 1.6933e+08, 6.4356e+07, 1.1703e+07, 4.5739e+07,
        1.0211e+07, 1.4776e+07, 1.6937e+07, 8.0316e+07, 1.1576e+08, 2.3127e+06,
        7.7748e+07, 3.0687e+07, 5.8054e+06, 4.4213e+07, 1.2023e+08, 8.2551e+06,
        1.4995e+07, 5.8755e+06, 2.4960e+07, 2.5192e+07, 9.1862e+07, 4.7499e+07,
        2.7054e+07, 2.4435e+07, 1.5989e+07, 2.8888e+07, 1.8275e+07, 2.5558e+07,
        2.4118e+07, 7.6622e+08, 1.9140e+08, 3.7836e+07, 2.6221e+07, 2.3570e+07,
        6.4929e+06, 4.4433e+07, 3.9720e+07, 3.1221e+07, 8.9533e+07, 8.2016e+07,
        3.9837e+07, 5.0778e+07, 7.5278e+09, 5.7244e+07, 7.1967e+07, 8.8525e+07,
        2.7651e+07, 1.8826e+08, 6.5831e+06, 8.9444e+06, 8.9905e+06, 1.9556e+07,
        4.5518e+07, 6.3304e+06, 2.7941e+06, 1.6719e+07, 3.3047e+07, 5.5146e+07,
        4.2348e+06, 7.7711e+07, 4.3026e+07, 6.4125e+06, 5.7475e+07, 8.7069e+07,
        3.8569e+07, 3.8279e+07, 3.7705e+07, 7.5849e+07, 2.2428e+08, 7.6865e+07,
        2.1100e+08, 1.5592e+08, 1.5819e+07, 3.1312e+07, 8.3623e+07, 4.0675e+07,
        6.2610e+07, 2.8723e+07, 2.0821e+08, 2.3207e+08, 1.7158e+07, 5.2134e+08,
        3.6299e+07, 1.3980e+07, 1.3333e+07, 1.0244e+08, 9.9043e+07, 6.2230e+06,
        3.0754e+06, 6.0890e+06, 3.0013e+07, 9.3844e+06, 1.6855e+07, 1.4358e+07,
        1.2309e+08, 3.4870e+06, 1.8100e+07, 3.4631e+07, 9.4748e+07, 4.5936e+07,
        2.1965e+07, 2.7118e+07, 1.0614e+08, 2.6622e+07, 3.6236e+07, 9.4405e+07,
        1.0622e+08, 1.0686e+08, 4.4509e+06, 2.3344e+07, 1.8175e+07, 2.2966e+08,
        9.3635e+07, 6.4810e+07, 9.3128e+06, 9.9233e+06, 2.4686e+06, 3.6190e+06,
        5.3894e+07, 6.4503e+07, 1.8111e+06, 9.2110e+07, 5.8789e+07, 6.8796e+07,
        1.6906e+07, 4.9402e+07, 4.4767e+07, 5.5204e+07, 3.0165e+07, 8.8948e+07,
        2.5445e+07, 2.7513e+06, 1.0387e+08, 7.6033e+07, 2.7242e+07, 4.8707e+07,
        1.0130e+07, 2.9730e+07, 1.3121e+08, 1.1724e+08, 8.8302e+07, 2.0341e+07,
        5.1793e+06, 3.6472e+07, 5.6164e+07, 9.3776e+07, 3.4546e+07, 1.4554e+08,
        1.3178e+08, 6.4546e+07, 1.9773e+07, 5.8151e+08, 3.1000e+07, 4.1112e+07,
        5.6965e+08, 1.7537e+07, 4.6806e+06, 4.9885e+06, 8.2999e+06, 2.8131e+07,
        6.2966e+07, 2.8666e+07, 6.1023e+07, 4.8497e+08, 3.1149e+07, 8.8106e+07,
        4.3495e+07, 2.0176e+08, 3.6057e+07, 9.2013e+06, 9.0514e+07, 6.1665e+07,
        2.6732e+08, 3.5127e+07, 7.6885e+08, 3.1337e+07, 7.6940e+06, 8.9398e+06,
        1.5294e+07, 9.5325e+07, 6.2396e+07, 2.7760e+06, 2.4600e+08, 1.5272e+07,
        9.8208e+06, 1.5032e+07, 1.3869e+08, 1.6031e+08, 8.3580e+08, 6.3622e+07,
        3.7569e+07, 2.9740e+08, 6.1773e+08, 2.3419e+08, 7.4923e+06, 3.7600e+07,
        2.2590e+07, 1.3235e+08, 9.9535e+07, 6.6371e+07, 3.4182e+08, 2.2140e+07,
        5.6048e+06, 1.6814e+07, 9.7838e+07, 1.2535e+07, 8.2979e+07, 2.6344e+07,
        2.1664e+08, 8.6647e+07, 1.3795e+07, 2.0779e+08, 1.1279e+07, 5.0369e+07,
        1.1628e+07, 4.2714e+07, 6.9880e+06, 2.0153e+07, 4.4673e+07, 1.2110e+07,
        1.4363e+08, 1.6998e+06, 6.5275e+06, 1.2735e+08, 7.1069e+07, 3.6614e+07,
        3.1529e+08, 3.0124e+07, 4.0647e+07, 7.7796e+07, 1.2992e+08, 3.7703e+07,
        2.1544e+07, 1.6729e+07, 1.9910e+08, 1.0756e+08, 2.1765e+07, 4.0790e+07,
        3.7222e+06, 6.4507e+06, 8.2549e+07, 1.3261e+07, 4.2766e+06, 1.7101e+07,
        3.6495e+08, 2.7726e+07, 1.0935e+08, 8.3583e+06, 1.0470e+07, 3.4475e+08,
        1.3769e+08, 5.9943e+07, 1.0068e+08, 4.7836e+07, 4.4195e+07, 1.0903e+08,
        1.9235e+07, 1.1762e+08, 6.2343e+07, 3.6384e+08, 8.8846e+06, 9.6011e+07,
        1.3336e+07, 2.6520e+07, 7.4531e+07, 1.6717e+07, 1.6654e+07, 2.7367e+07,
        1.1132e+07, 4.1418e+07, 6.7978e+07, 1.1481e+07, 1.1735e+08, 6.5692e+07,
        4.0921e+07, 6.8042e+06, 3.6389e+07, 1.7463e+08, 2.6591e+07, 1.9067e+07,
        1.9189e+08, 1.1107e+08, 8.4016e+07, 5.4481e+06, 2.6409e+07, 3.6076e+06,
        2.3698e+07, 7.4049e+06, 6.1485e+07, 1.9469e+08, 1.7373e+08, 2.2905e+08,
        6.4512e+07, 3.0116e+07, 1.8399e+07, 6.0885e+08, 1.1235e+08, 2.3176e+07,
        1.0370e+08, 2.8861e+08, 8.1379e+07, 3.2903e+08, 9.8414e+07, 5.0930e+09,
        1.3428e+08, 4.3358e+08, 1.2714e+08, 1.3701e+07, 3.6067e+07, 9.8865e+07,
        8.1751e+07, 1.9803e+07, 5.6390e+07, 1.1324e+07, 7.6727e+07, 4.5371e+06,
        4.8176e+07, 3.9566e+06, 2.2447e+08, 1.1935e+08, 1.5013e+07, 1.5268e+07,
        4.6722e+07, 5.5318e+07, 7.1931e+07, 8.7563e+07, 2.5425e+08, 2.3332e+07,
        1.7920e+08, 1.2058e+07, 3.2512e+07, 2.6664e+06, 5.0836e+07, 1.1624e+08,
        4.6497e+07, 1.3231e+08, 1.8541e+07, 1.5074e+08, 3.9891e+07, 3.7262e+07,
        8.6509e+07, 3.3187e+07, 3.1053e+08, 4.4706e+07, 2.8525e+09, 6.8524e+08,
        7.0255e+07, 2.1752e+08, 7.0471e+07, 2.1332e+07, 6.9998e+07, 1.2392e+08,
        1.5193e+08, 4.4249e+07, 1.7978e+07, 6.8910e+06, 2.2181e+08, 3.6917e+06,
        1.4898e+07, 8.2334e+07, 7.4636e+07, 2.2401e+08, 5.2547e+06, 9.0717e+07,
        3.7789e+06, 5.2281e+07])
Layer: encoder.6.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5.1345e+07, 1.3684e+08, 3.0972e+07, 1.1443e+08, 1.2704e+08, 7.6726e+07,
        8.8292e+07, 2.9205e+08, 7.6630e+07, 8.6575e+07, 2.0017e+08, 1.6958e+07,
        3.2979e+07, 3.9971e+07, 7.4289e+07, 3.3873e+07, 1.1752e+07, 6.9716e+07,
        1.6097e+08, 5.4709e+07, 1.7785e+08, 2.1221e+07, 8.4629e+07, 5.9835e+07,
        3.1002e+07, 2.6308e+07, 5.5627e+07, 8.8114e+07, 9.7200e+07, 9.8867e+07,
        9.0327e+07, 3.6900e+07, 1.2852e+08, 1.3782e+08, 4.1775e+07, 8.0166e+07,
        1.3762e+08, 4.0378e+07, 2.0557e+07, 9.7167e+07, 1.6219e+08, 5.5520e+07,
        9.5234e+07, 7.0260e+07, 8.1997e+07, 1.4144e+08, 1.7706e+08, 7.6176e+07,
        9.5091e+07, 1.0015e+08, 3.8743e+07, 1.0114e+08, 2.7742e+08, 4.7828e+07,
        1.2216e+08, 1.5308e+08, 8.4529e+07, 6.0712e+07, 7.7971e+07, 1.1651e+08,
        4.8061e+07, 6.2458e+07, 5.9541e+07, 4.0297e+07, 5.3095e+07, 1.5368e+08,
        1.4762e+08, 6.1955e+07, 1.3058e+08, 2.6810e+08, 8.1770e+07, 2.3629e+07,
        7.6231e+07, 3.0010e+08, 4.3676e+07, 2.8561e+07, 9.8741e+07, 5.8131e+07,
        6.8583e+07, 2.4114e+07, 8.7624e+07, 7.4605e+07, 9.9931e+07, 3.7715e+07,
        2.9212e+07, 1.1176e+08, 5.3708e+07, 1.1433e+08, 8.0314e+07, 1.9173e+08,
        6.0966e+07, 1.4644e+08, 1.3151e+08, 5.7077e+07, 1.0047e+08, 3.3226e+07,
        8.6783e+07, 1.0765e+08, 1.2760e+08, 2.1762e+07, 8.5521e+07, 1.4701e+08,
        1.0702e+08, 6.2894e+07, 6.6133e+07, 1.0959e+08, 1.4899e+08, 7.7731e+07,
        2.3891e+07, 4.0626e+07, 4.3536e+07, 5.9656e+07, 8.5425e+07, 6.5527e+07,
        1.9386e+08, 1.6130e+08, 3.5349e+07, 1.9753e+07, 1.3099e+07, 3.4043e+07,
        7.2094e+07, 1.7006e+08, 1.2731e+08, 8.7566e+07, 6.3373e+07, 4.2280e+07,
        8.7022e+07, 2.2582e+07, 1.6311e+08, 5.2424e+07, 5.0954e+07, 7.8061e+07,
        6.1613e+07, 8.3589e+07, 9.0919e+07, 7.8404e+07, 6.0405e+07, 4.3219e+07,
        6.1154e+07, 1.5348e+08, 3.3001e+07, 1.8053e+08, 2.5823e+08, 1.8354e+08,
        7.2263e+07, 6.0484e+07, 5.9298e+07, 8.4551e+07, 1.0707e+08, 3.6630e+07,
        1.6315e+07, 1.4312e+08, 1.4172e+08, 2.1039e+08, 2.9752e+07, 9.3408e+07,
        9.9915e+07, 9.0879e+07, 7.3141e+07, 7.6633e+07, 6.3089e+07, 1.2698e+08,
        2.0663e+08, 1.7762e+08, 3.4718e+07, 1.5168e+08, 1.0646e+08, 1.4831e+08,
        1.0309e+08, 2.4130e+08, 2.2063e+08, 8.4148e+07, 8.0013e+07, 1.6019e+08,
        1.2504e+07, 1.0306e+08, 2.3538e+08, 2.1283e+08, 2.0021e+08, 2.6885e+07,
        8.4898e+07, 2.5772e+08, 3.6478e+07, 7.7636e+07, 1.4316e+07, 1.0789e+08,
        1.3298e+07, 9.7789e+07, 1.7631e+08, 5.7722e+07, 6.8724e+07, 1.0800e+08,
        2.7876e+07, 9.6242e+07, 1.8123e+07, 2.3606e+07, 1.2516e+08, 8.4738e+07,
        1.4632e+08, 5.8098e+07, 1.6723e+08, 5.5071e+07, 1.3793e+08, 1.6757e+08,
        1.0732e+08, 6.0681e+07, 1.4651e+08, 7.2998e+07, 2.0364e+08, 2.0050e+07,
        4.3752e+07, 2.1868e+07, 2.6375e+07, 1.7788e+08, 5.2829e+07, 5.0491e+07,
        4.6008e+07, 6.1516e+07, 3.6735e+07, 1.2541e+08, 4.4400e+07, 4.1767e+07,
        1.0193e+08, 1.0923e+08, 7.2099e+07, 8.4904e+07, 7.4647e+07, 3.2900e+08,
        8.8240e+07, 3.6496e+07, 5.2143e+07, 1.8300e+08, 9.7922e+07, 2.1632e+08,
        9.2780e+07, 1.7458e+08, 1.0236e+08, 1.3164e+08, 2.9035e+07, 9.2295e+07,
        1.3495e+08, 2.5684e+08, 1.5855e+07, 6.5068e+07, 1.9467e+08, 8.9760e+07,
        1.0143e+08, 2.1656e+07, 7.3680e+07, 1.0895e+08, 3.9818e+07, 8.0339e+07,
        1.8095e+08, 6.4807e+07, 1.1108e+08, 4.6870e+07])
Layer: encoder.6.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.7589e+08, 1.6222e+08, 2.2151e+08, 1.9426e+08, 5.3837e+07, 2.2926e+08,
        2.9904e+08, 2.3127e+08, 1.6728e+08, 9.7943e+07, 9.9711e+07, 5.7068e+07,
        1.2257e+08, 4.3910e+08, 2.3722e+08, 1.0437e+08, 2.8229e+08, 1.1139e+08,
        6.9014e+08, 1.9845e+08, 3.8234e+08, 1.8736e+08, 2.6728e+08, 1.5000e+08,
        2.1913e+08, 1.8321e+08, 2.2809e+08, 1.6832e+08, 7.1779e+07, 8.7120e+07,
        6.7180e+07, 3.2821e+08, 1.7553e+08, 2.5702e+08, 5.1884e+08, 3.7175e+08,
        2.5614e+08, 5.5920e+07, 2.1415e+08, 9.3088e+07, 7.3372e+07, 3.6983e+08,
        2.8403e+08, 1.4624e+08, 1.5356e+08, 2.7124e+08, 1.0390e+08, 2.0191e+08,
        5.2818e+07, 3.1121e+08, 1.4678e+08, 7.6328e+07, 2.5957e+08, 1.9643e+08,
        6.3536e+07, 8.9667e+07, 2.1643e+08, 1.8726e+08, 3.8448e+08, 8.9053e+07,
        1.5356e+08, 3.0928e+08, 3.2902e+08, 2.3523e+08, 8.3111e+07, 3.7964e+08,
        2.8295e+08, 1.6576e+08, 3.9408e+08, 2.8849e+08, 1.5358e+08, 2.0297e+08,
        1.5521e+08, 3.9296e+08, 1.8569e+08, 2.4058e+08, 1.1434e+08, 3.9665e+08,
        3.3116e+07, 4.5476e+07, 1.4983e+08, 9.7644e+07, 1.5938e+08, 1.2579e+08,
        7.3051e+07, 1.2292e+08, 1.1048e+08, 4.2659e+08, 1.2560e+08, 1.6312e+08,
        3.0248e+08, 2.8139e+07, 2.8293e+08, 3.0100e+08, 8.6298e+07, 3.3451e+08,
        1.2592e+08, 2.2382e+08, 1.6876e+08, 7.4211e+07, 3.3001e+08, 6.7094e+07,
        2.3721e+08, 4.9537e+08, 2.7370e+07, 7.0667e+07, 4.0136e+08, 3.8330e+07,
        8.9005e+07, 1.5725e+08, 1.2286e+08, 1.9368e+08, 1.9122e+08, 2.7630e+08,
        6.7460e+07, 2.8745e+08, 3.5570e+08, 5.3167e+08, 1.3475e+08, 7.0692e+07,
        3.0103e+08, 2.1465e+08, 2.0861e+08, 1.0106e+08, 5.8690e+07, 1.3749e+08,
        6.5538e+07, 1.5374e+08, 3.5885e+08, 1.5285e+08, 4.3940e+07, 5.8907e+07,
        4.9417e+08, 2.6960e+08, 1.0975e+08, 8.4892e+07, 1.9212e+08, 2.0000e+08,
        5.1173e+07, 3.8388e+08, 8.9989e+07, 9.7631e+07, 2.6439e+08, 1.1498e+08,
        1.9749e+08, 1.8939e+08, 9.7087e+07, 6.1498e+07, 5.9077e+07, 1.8697e+08,
        4.5085e+07, 1.0128e+08, 4.0185e+07, 3.1108e+08, 8.3231e+07, 8.1430e+07,
        3.7130e+08, 3.8957e+08, 3.0349e+08, 3.1465e+08, 6.1654e+07, 1.4907e+08,
        3.7034e+08, 2.6421e+08, 5.4113e+08, 7.5054e+07, 3.5672e+08, 2.6898e+08,
        3.2164e+08, 2.1411e+08, 1.0986e+08, 1.3346e+08, 9.1009e+07, 2.4708e+08,
        2.7623e+08, 3.7412e+08, 1.2775e+08, 1.1139e+08, 1.1345e+08, 2.3673e+08,
        1.0613e+08, 6.9541e+07, 6.6685e+07, 9.3938e+07, 2.4696e+08, 3.9462e+07,
        6.4911e+07, 1.9848e+08, 5.5049e+08, 5.6048e+08, 6.3133e+07, 2.8117e+08,
        5.8201e+07, 2.9149e+08, 2.2267e+08, 1.1712e+08, 1.5369e+08, 1.7752e+08,
        2.6829e+08, 1.4371e+08, 6.1341e+08, 7.1282e+07, 1.3954e+08, 2.8721e+08,
        1.3438e+08, 3.2843e+08, 1.3848e+08, 1.1822e+08, 1.5616e+08, 2.1910e+08,
        5.7898e+08, 3.1864e+08, 2.7324e+08, 6.7267e+07, 4.6832e+07, 1.5198e+08,
        4.8498e+08, 2.9601e+08, 9.6336e+07, 7.4274e+07, 4.0324e+08, 3.0688e+08,
        2.0722e+08, 3.0108e+08, 3.2304e+08, 2.6005e+08, 2.1239e+08, 1.8379e+08,
        1.9822e+08, 1.9098e+08, 6.0858e+07, 1.7922e+08, 1.3232e+08, 1.9236e+08,
        2.6926e+08, 1.5565e+08, 5.8103e+07, 3.6083e+08, 4.8650e+08, 2.1609e+08,
        1.0234e+08, 1.4326e+08, 6.4416e+07, 1.3534e+08, 3.9053e+08, 1.4029e+08,
        7.7620e+07, 2.5427e+08, 2.3755e+08, 1.8950e+08, 2.6846e+08, 1.0583e+08,
        7.4103e+07, 1.3788e+08, 1.4740e+08, 5.7487e+07])
Layer: encoder.6.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 83207.1641,  53230.6602, 274230.4375,  ...,  58625.5000,
        144467.8750, 630364.4375])
Layer: encoder.6.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([146940.2500, 198868.7656, 373410.2812,  ..., 296116.6875,
        252671.4219, 870342.3750])
Layer: encoder.6.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 561011.2500,  881292.5000,  961701.3125,  622002.6875,  543106.7500,
        1081914.3750, 1487838.2500, 1653692.7500, 1111645.8750,  751488.3125,
         721639.1875, 1000999.1250,  752002.3125, 1804184.7500,  595215.3750,
        1880522.5000, 1639218.2500, 1834222.0000, 1121000.8750, 1632766.2500,
        1449956.1250, 2367234.7500, 1126297.0000,  863509.1875, 1106530.5000,
         748439.9375, 1296024.0000, 1802167.2500,  562634.6875,  561093.8750,
        1127066.3750, 1275375.3750, 1224964.3750,  761507.1250,  964345.9375,
        1432057.3750, 1185286.6250, 1566266.0000,  715914.6875, 1346821.0000,
        1025531.8750,  991793.2500, 1554906.3750, 1566198.5000,  961988.8750,
        1336163.2500, 1065792.5000, 1762364.6250, 1406668.1250, 1763598.0000,
        1806706.1250,  540622.7500, 1148502.0000, 1540493.7500, 1492971.3750,
        1604561.5000, 1209732.5000,  923912.3750,  764870.4375,  604096.1875,
        1505326.3750, 1042253.6250, 1219074.7500,  987838.6250,  917270.1250,
         820462.7500, 1164427.0000,  812362.5000,  869190.8750,  502196.9062,
        1456578.5000,  776384.3125, 1363302.8750,  804240.3125, 1388786.3750,
        1340355.2500,  990943.3750,  891749.8125, 2258245.2500, 1862403.0000,
        1562849.3750,  854392.3125, 1238894.8750, 1411279.2500,  963743.3750,
        1101083.1250, 1240133.5000,  627349.5625, 1352630.7500,  619843.1875,
         464925.3438, 1130011.6250, 1917754.0000, 1067714.3750, 1972056.5000,
         925677.6875,  672403.3125,  968745.2500, 1224322.8750, 1008285.5000,
         708386.8125,  702902.5625,  950583.3125, 1057499.1250, 1692211.8750,
         569775.8125,  799932.0000, 1857809.8750, 1142452.5000, 1811942.7500,
         808974.8750, 1097299.7500, 1278936.5000, 1054479.3750, 1024973.8125,
        1805049.7500, 1011727.8750,  403858.9062, 1757058.6250, 1357128.1250,
         623766.7500,  520957.3125, 1194232.1250, 2864197.7500,  452063.0938,
         900963.4375, 1289985.8750, 1077870.0000, 1256833.5000,  780942.6875,
         948227.2500, 1329712.1250,  693866.1250, 1220878.0000,  960063.5625,
        1255388.6250, 1232212.3750,  961786.6875,  636851.5000, 1326606.7500,
        1365151.5000,  517525.5000, 1011589.8125,  584497.8750, 1027933.4375,
         578090.6250,  538796.7500,  709112.9375, 1142814.1250, 1021501.0000,
        1816372.6250,  520036.6875, 1482530.3750, 1003012.1875, 1444866.5000,
         910082.1250,  720635.6875,  976792.3125, 1718076.2500, 2005874.7500,
        1527641.3750,  600623.6875,  604497.0000,  787223.6875, 1410382.3750,
        1081586.5000, 1140555.2500, 1525004.1250,  760015.0000,  822068.5625,
         607858.8125,  381580.6562, 1196322.3750,  510250.0312,  653077.4375,
        1024422.9375, 1457325.7500,  750739.8750,  758355.1875, 1567213.3750,
        1049188.7500, 1031580.0000,  972817.3750,  757234.5625, 1120224.6250,
         751123.8125,  879246.3125, 1318897.5000, 1600562.7500, 2295595.0000,
         762108.4375,  921965.1250,  644187.3750, 1296365.6250,  527672.0625,
        1307631.7500,  848894.6875, 1511340.5000,  890667.8750, 1186651.8750,
        1160341.7500,  647299.1875, 1132931.1250,  750436.4375, 1374082.0000,
        1188325.8750, 1302678.6250, 1569164.0000, 1430029.5000,  660456.3750,
        1236675.2500, 1652959.0000,  927646.3125,  813449.1875, 1255950.8750,
        1008298.8750, 1262040.7500, 1062549.3750,  987963.4375, 1128474.2500,
         322949.8438, 1213627.0000, 1129950.5000,  358362.2500, 1262880.0000,
         616607.2500,  431143.9688,  656470.1875,  761943.9375, 1331163.2500,
         528565.9375, 1035693.8125,  570710.5000, 1307433.1250,  654327.0625,
        1943517.5000, 1148295.8750, 1354420.2500, 1110274.6250, 1044113.3125,
         955801.8750, 1434024.8750,  653707.8125, 1139530.8750,  778770.4375,
         603201.3125, 1083950.3750,  841284.1875, 1154605.6250,  818675.7500,
        1476592.8750, 1506274.2500, 1208595.7500,  991031.9375, 1553955.8750,
         462188.3438])
Layer: encoder.6.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3316310.2500, 3398813.5000, 3198084.0000, 3949621.5000, 1415066.2500,
        3718449.7500, 5984511.0000, 4504958.5000, 6770180.0000, 2439634.0000,
        2758832.5000, 4681830.5000, 3651525.2500, 4308648.5000, 1753412.7500,
        2994750.5000, 2715528.5000, 3158653.7500, 4482755.0000, 2095004.3750,
        4878968.0000, 2977272.0000, 4137951.5000, 2747393.5000, 2913443.0000,
        2900611.2500, 6195714.0000, 2981532.0000, 2103568.2500, 3803988.0000,
        2593710.7500, 1625612.1250, 2358800.5000, 3750789.2500, 1164921.5000,
        2605745.7500, 5767959.5000, 2640272.7500, 6000339.5000, 2016646.3750,
        1989707.3750, 7177169.5000, 3859487.7500, 2245306.5000, 3906154.2500,
        2576612.5000, 1668694.2500, 4467052.5000, 1418414.1250, 2140446.5000,
        5252680.5000, 3697908.0000, 4832841.0000, 2924237.0000, 3132522.5000,
        2328297.5000, 6520077.5000, 4125056.0000, 3165088.7500, 5262252.5000,
        2811974.5000, 3646173.7500, 4927904.5000, 2245874.2500, 5858593.5000,
        2469120.7500, 1851082.3750, 5026540.5000, 3638423.0000, 2239285.2500,
        5319796.0000, 2982129.5000, 1722915.0000, 1883944.7500, 3529552.7500,
        1448328.7500, 1428553.8750, 4166642.0000, 6154770.0000, 2423563.5000,
        2523668.2500, 4828240.0000, 2386720.2500, 1709039.0000, 4266504.5000,
        2658305.0000, 3341551.0000, 5222583.0000, 3918878.7500, 2610022.7500,
        4401287.5000, 1862996.6250, 6304324.5000, 2244766.0000, 1513596.0000,
        3579599.0000, 1719959.5000, 3503390.2500, 3975556.7500, 2249084.0000,
        4333012.0000, 2563294.0000, 2099789.0000, 4762426.0000, 3771179.2500,
        2869478.2500, 4396935.5000, 3009292.0000, 3740404.7500, 5055303.5000,
        7964058.5000, 3917645.0000, 3882520.0000, 2716932.0000, 1473994.5000,
        2759634.2500, 3264805.2500, 4066850.2500, 2382765.5000, 3296803.7500,
        4577581.5000, 2175331.5000, 2370421.5000, 4584938.0000, 1674899.0000,
        1777964.5000, 4502599.0000, 3639720.7500, 2723798.2500, 2190942.0000,
        4057314.0000, 2920971.0000, 6989270.5000, 4769472.0000, 3262055.0000,
        4477131.0000, 4123138.0000, 5238407.5000, 5478884.0000, 2778544.2500,
        3806079.0000, 4865701.5000, 2346745.5000, 5010437.5000, 2484148.5000,
        2853955.2500, 3803551.0000, 2813378.7500, 3580215.0000, 3187231.2500,
        2981263.0000, 3236065.7500, 5340925.0000, 4619269.0000, 3521048.5000,
        5391549.0000, 3446914.7500, 5181605.0000, 2630903.7500, 2662705.0000,
        5354068.0000, 4107758.2500, 3069547.7500, 3642942.5000, 2948471.2500,
        1960915.3750, 4447303.0000, 1722750.8750, 1425419.5000, 1712803.3750,
        3196338.0000, 3874709.0000, 2461386.5000, 2327489.0000, 2424291.2500,
        1956358.3750, 2793069.7500, 2591325.2500, 2078888.0000, 5854254.5000,
        2866401.2500, 3237729.5000, 7854909.5000, 5236400.0000, 3242567.5000,
        4038337.2500, 1999407.1250, 6796116.5000, 4720671.0000, 2348355.2500,
        2226814.2500, 5253117.5000, 2627536.2500, 4302605.0000, 2517559.7500,
        2684072.7500, 2828129.0000, 2678571.2500, 4844444.5000, 2053536.7500,
        4277004.5000, 3157730.0000, 2173028.7500, 3816489.0000, 3420539.0000,
        4249844.0000, 4624056.0000, 1906645.8750, 4349201.5000, 2901462.2500,
        1821125.3750, 2313203.0000, 2766275.2500, 5698207.5000, 1277685.1250,
        1488566.3750, 2948274.2500, 1829483.2500, 2193044.7500, 3161162.5000,
        2220347.5000, 2018449.7500, 2951844.5000, 4767382.5000, 5339554.0000,
        3727898.7500, 5093266.0000, 4107831.0000, 5162525.0000, 1997576.1250,
        4273007.5000, 2690558.2500, 4307675.0000, 1910309.7500, 2112124.0000,
        3336630.5000, 1970960.2500, 1807239.1250, 3464822.5000, 3217154.2500,
        1449272.6250, 1689993.2500, 4576444.0000, 2512214.7500, 6525411.0000,
        1734113.1250, 1839459.1250, 3021986.2500, 1960933.8750, 3130702.5000,
        4475567.5000, 3002050.2500, 2334298.5000, 4745687.5000, 2732843.2500,
        4911640.0000])
Layer: encoder.6.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([231913.8281,   8729.4082,  18248.4590,  ..., 211948.1875,
          3320.8818,  12497.0752])
Layer: encoder.6.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([297008.1562, 252580.4062, 227950.2188, 199042.1406, 262977.6562,
        256164.9531, 365804.1250, 294470.5625, 289797.5312, 355874.1562,
        265073.0312, 255566.2500, 278865.8125, 260884.0156, 347316.4688,
        345061.0938, 267958.4062, 304528.4375, 280447.7500, 268390.4688,
        259208.0469, 329094.3750, 253763.6562, 255749.0156, 228129.1875,
        275828.4375, 321544.2188, 313364.0938, 219773.5938, 325341.2500,
        235082.1875, 455877.3125, 320048.8438, 243574.7500, 253467.2969,
        338243.2188, 271301.9375, 295575.2188, 200606.1719, 337413.4688,
        241261.0156, 343179.7188, 211213.1562, 214464.1875, 282403.1562,
        321083.7500, 300499.4062, 266759.8438, 344644.0938, 288776.0312,
        408368.6250, 409329.4688, 212903.2812, 210553.2500, 392197.4375,
        308879.5625, 248469.9375, 342576.7188, 263535.5000, 341794.7188,
        236759.1875, 253539.0156, 330775.2500, 433868.2500, 245731.2344,
        331996.1250, 252789.3906, 253446.4062, 548324.4375, 275348.5625,
        347571.1875, 300193.5000, 362812.6875, 251174.4844, 300248.3125,
        251428.9844, 332888.9062, 285198.2812, 299057.9688, 279945.1875,
        302659.3750, 361801.0625, 307778.1562, 269920.0938, 285455.8750,
        422613.3125, 226594.1875, 276331.0938, 282794.8125, 292819.7188,
        269114.8125, 423335.0312, 406190.2812, 289587.6875, 331142.2500,
        276614.5625, 299650.1250, 343981.2188, 355516.9375, 202881.6250,
        271784.7500, 290634.4062, 398944.8438, 311761.4375, 256512.4219,
        324592.0312, 374785.1875, 396935.0938, 305296.2188, 390663.6875,
        343870.2188, 249122.7188, 264026.3438, 268119.2812, 269473.1250,
        392981.5938, 344844.3750, 288932.5312, 243484.0781, 289634.5938,
        286999.5312, 379721.2812, 322499.9688, 513590.4062, 305254.3125,
        332657.3438, 266005.9688, 216465.4219, 287424.8125, 262792.9062,
        313660.8125, 219307.0156, 250526.7969, 312935.7188, 425939.1250,
        244029.7031, 263479.3125, 287855.4375, 214496.2188, 336462.0938,
        249304.5000, 246760.7188, 446967.6562, 365012.9688, 300113.4688,
        288563.3125, 278085.0312, 255492.1094, 263690.8125, 343124.5000,
        282620.3750, 411570.5938, 312217.7188, 500677.9062, 235613.6094,
        376911.3438, 317437.0312, 258475.1094, 246386.9531, 194523.2656,
        303673.0000, 231845.0938, 219148.9375, 212257.9375, 601016.3125,
        220916.0938, 359509.3125, 279175.0312, 201380.7031, 276381.4688,
        424883.4062, 328804.7188, 260790.1875, 226762.9688, 475034.6250,
        441598.9688, 267807.4375, 294450.2500, 377324.6250, 260544.3438,
        237419.5000, 255024.8750, 210860.6875, 336177.8438, 222354.2188,
        348844.2812, 224699.2656, 290531.3438, 195311.3750, 282020.8750,
        343465.9688, 305059.7812, 469840.5938, 289194.3125, 256515.8906,
        218823.2344, 228057.3281, 200693.1094, 244214.4375, 320617.7500,
        261347.5156, 359026.0000, 248338.6406, 303969.2812, 332947.4062,
        302174.2188, 211884.8438, 311428.1250, 372685.9375, 217699.2188,
        441232.8438, 295014.8125, 415589.9375, 320097.6562, 351894.9062,
        271818.0625, 233791.7812, 411243.7812, 226984.8125, 285525.1875,
        239651.5156, 331512.8438, 273761.3750, 346712.5000, 263260.4688,
        230603.4844, 278018.3438, 347264.9688, 263535.8750, 267197.7188,
        195449.1094, 308425.3438, 288661.1875, 343581.9375, 277985.7812,
        204635.6719, 248407.4375, 383093.7500, 261696.7500, 260771.2500,
        226848.2500, 254326.2656, 352913.6250, 266964.1875, 339523.2812,
        265912.5938, 269546.1562, 331736.2500, 312544.2188, 287814.6250,
        344766.0312, 406250.9375, 150760.0625, 336165.1250, 232465.6562,
        219569.7188])
Layer: encoder.6.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 691270.5625, 1348494.0000, 1019631.1875, 1086454.0000,  765575.3125,
        1230568.7500, 1109644.1250, 1350207.5000, 1026774.1875, 1205122.3750,
        1437325.3750,  655944.6875,  975054.0000,  951027.0625, 1127705.3750,
        1028240.7500, 1307867.3750, 1044522.3750, 1121811.2500, 1343533.2500,
         727285.8750, 1061874.8750,  866368.4375, 1369387.5000, 1025479.8125,
        1083268.3750,  791625.7500,  972079.0000,  907103.5000, 1123364.7500,
        1294127.2500, 1595947.0000,  789061.0625, 1259226.6250,  728228.7500,
         843832.8750, 1050142.7500,  838134.2500,  870007.8125, 1099079.0000,
        1228735.8750,  747882.5000, 1266994.5000, 1636013.8750, 1105156.6250,
        1037687.0000, 1050019.1250, 1328137.6250, 1359634.6250,  876260.6250,
         743828.1250,  705656.6250, 1304434.7500, 1007712.7500, 1105690.6250,
        1355353.3750, 1461118.3750, 1104900.8750,  861551.5625, 1002048.2500,
        1046837.0000, 1013551.3750,  984213.5625,  816407.7500,  810804.9375,
        1088475.2500, 1049568.1250,  836651.4375, 1366081.2500, 1306411.6250,
        1097217.5000, 1260799.0000, 1200877.3750,  932083.3750, 1264230.3750,
        1050554.8750,  972911.1250, 1041145.9375,  969463.2500, 1104978.8750,
         662923.6250,  854637.9375, 1148732.3750,  906900.7500,  853387.0000,
        1115787.7500, 1970000.7500, 1314513.5000, 1296434.8750,  683050.0625,
         951489.0000,  830038.3125, 1002973.7500, 1316073.6250, 1274641.0000,
        1239676.2500, 1081664.2500,  824890.7500, 1012037.1250,  939695.3125,
        1034931.6875, 1026385.7500,  953106.8125, 1112485.1250, 1072299.1250,
        1450499.2500,  973589.4375, 1114453.0000, 1321579.3750,  878404.9375,
         984018.4375,  772119.0625, 1457337.8750,  987968.6875,  970116.2500,
        1205430.6250, 1124364.6250,  902390.5000, 1447685.5000,  664430.4375,
         969818.7500, 1194981.6250, 1890262.1250, 1026331.9375,  958876.5625,
        1037328.0000, 1042338.3125, 1045504.9375, 1080897.2500, 1157725.3750,
        1372799.1250, 1004866.6250, 1062985.7500, 1060440.3750, 1299156.0000,
         941376.0625, 1136737.3750, 1465360.2500, 1260392.1250, 1563604.2500,
        1279956.1250, 1297393.8750, 1255876.3750, 1225311.0000, 1123800.5000,
         813605.8125, 1141191.7500, 1174772.5000,  979406.9375, 1137434.7500,
        1387233.2500, 1047724.2500,  971753.3125, 1180814.2500,  870779.0625,
         955007.6875,  966902.2500, 1295604.7500,  867472.2500, 1109907.8750,
         696480.7500,  732632.8750, 1221973.3750,  970757.7500, 1113058.2500,
        1185857.3750, 1037079.2500,  735201.2500, 1113040.5000, 1406494.0000,
        1233955.6250,  856411.1250,  819774.6875,  828178.5000, 1081181.3750,
        1270462.8750, 1490825.3750,  769692.7500, 1744492.6250,  737224.5625,
        1273241.5000, 1183724.8750, 1623994.8750,  870766.3750, 1026453.5000,
         743276.8750, 1024484.9375,  920304.4375, 1013254.0000,  694976.6875,
        1086577.1250,  951157.3125, 1060890.8750,  944735.9375, 1172016.3750,
        1292773.2500,  760670.3125, 1290824.5000, 1340536.5000,  760984.8750,
        1138403.5000,  922409.5625, 1129394.3750, 1052097.2500,  857957.3125,
        1534909.8750,  973826.3125, 1406334.0000, 1115859.8750,  862046.3750,
         942652.3125, 1111017.7500, 1183821.6250, 1400530.0000, 1136838.2500,
         965578.5000, 1417740.6250,  880176.6250, 1059548.8750,  743969.6875,
        1209227.3750,  757312.9375, 1564661.8750, 1098875.6250,  756205.8750,
         744893.0000,  810780.1875, 1061145.2500, 1542775.7500, 1181737.2500,
        1051629.5000,  921594.6250, 1121722.5000, 1182140.5000, 1073259.7500,
         966694.3125,  835100.0000, 1245036.0000,  977584.4375, 1314421.6250,
         679905.0625, 1287398.1250,  965464.0625,  836661.1875,  716740.3125,
        1095779.3750, 1009538.3750,  954250.0625, 1174504.5000,  822247.1875,
        1077099.1250, 1338216.7500, 1214306.6250, 1410050.0000,  630868.8750,
        1263247.5000])
Layer: encoder.6.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 92457.4531,   3192.7832,   1421.2386,  ..., 110432.3906,
          5157.2544,  11435.2090])
Layer: encoder.6.3.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([103756.2578, 115429.5625, 111551.9922, 128842.6172, 163483.6406,
         82726.4688,  92560.1250, 137433.2188,  90034.1250,  93648.9062,
        109916.7500, 111787.9844,  67988.0391, 144271.6719, 110709.2656,
        130740.0000,  83368.3672, 113698.6328,  91667.6953, 110983.6875,
         71688.2812, 100178.9062, 105631.0312, 113598.6875, 103765.1719,
         88643.1562, 109983.6797, 125819.2109,  81344.6484, 105538.1406,
        113370.7734,  76629.9766, 120232.8359, 116210.2656, 120480.2891,
        112952.4297,  66294.8125, 107537.3203, 109156.3203,  93087.7656,
        106757.5469,  98166.5859, 122764.8359,  89202.2812,  95056.0703,
         92009.4297, 149932.0938, 123599.7891,  71368.5625, 122998.8047,
        130682.2578, 137651.4375, 103307.4531, 109460.2656, 108831.5469,
        120017.3125,  63229.3984, 105897.0234, 135192.7812,  92147.7188,
         77862.2500,  86461.1562,  74971.8516,  54603.9141,  84099.4219,
         93468.1016, 122459.6406, 133111.1406, 104966.0312, 122732.9141,
        106800.8594, 101855.5078,  97513.1328,  77673.5234,  87712.9531,
        107754.8203,  70616.4531, 144938.1250,  79285.2500,  84024.9531,
        135299.6406, 123335.2500,  87906.7344, 118430.8125, 109568.2266,
         98105.1797, 126837.2734,  78474.4375,  65911.4219,  84765.9219,
        118797.1875,  79772.0156,  80630.9141,  89535.8516,  94545.8281,
        139952.2031, 116642.2812, 100848.2031,  87471.4453, 101038.9844,
         86079.7266,  86182.4688,  92881.7891, 121160.3281, 108897.8203,
         93940.6094,  66771.0703,  79264.7344, 112909.5938, 114271.1328,
        128656.9219, 118899.1484, 123465.0156, 100972.2422,  81092.1094,
        102976.5781,  89433.5938,  99766.7656,  86148.3281,  91644.1172,
        123403.7344, 145441.8125, 101753.8281,  97583.9688, 114608.6406,
         83467.1094,  94266.4766,  78239.8750, 105733.4375,  96869.6328,
        119234.5625, 101200.7969, 104469.8438,  96155.4531,  65943.7578,
        139654.2500, 114545.2891, 116718.6875,  97797.4844,  86708.0938,
         97191.0781, 108334.5000,  75359.9766,  92331.1797, 128225.2188,
         85901.1406,  95672.2734, 117389.5312,  75612.4609, 153057.7969,
         93090.5391, 128666.5000,  73585.3047, 141335.8750,  76671.5703,
        106405.5469, 103519.9062,  71492.0234, 106318.3047,  97016.3750,
        109745.4375,  91717.8281,  94173.8125,  89631.8359,  82312.0000,
        133918.0312, 106670.9453,  71103.1953,  86431.8594,  98238.6406,
        117770.6250,  98578.1562,  76517.6953,  92537.5859,  82465.2578,
        104053.9766, 117412.0156, 105361.8672,  98389.2422, 102103.6484,
         79116.6562, 121547.2188,  86959.3516,  93980.3672,  86328.8438,
        103826.0000,  67925.5469,  80808.0547, 127100.0391, 102524.1641,
         92974.2891, 112291.3906, 108466.1328, 115337.8516,  84417.3672,
        108402.3594, 103291.5469, 122501.3203, 116079.4375,  96096.2578,
        102684.5469,  76996.6562,  99701.0703,  87311.2891,  94357.9453,
         91290.2188, 116747.7734,  92523.6406,  99457.9453, 119695.2969,
        113091.2734, 130151.3984,  93842.2578,  94961.9062,  96785.9062,
         98053.9844, 101773.0859, 100164.5781, 118608.1172,  85610.7891,
         88516.7188,  79810.1641,  76149.0078, 101637.8906, 153752.2344,
         93388.5156,  94794.0156,  88674.8281, 124898.7812, 110727.0234,
         87679.0156, 115736.4375,  68311.5156, 107027.3047,  55285.0547,
        106672.5391, 112787.8438,  73272.2578,  83585.0781, 162872.8438,
         94896.2656,  96975.8516, 123618.1641, 133645.4688, 126067.9141,
        114715.8672,  91346.3906,  94605.7031, 120886.9453, 104632.7031,
         70527.9609, 129258.7188, 105613.6250, 142467.0469, 127715.8438,
        115194.3984])
Layer: encoder.6.3.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([362273.3750, 503246.1562, 388465.2500, 507022.8750, 307971.6250,
        466168.5625, 380794.7188, 569840.8125, 426534.2500, 475269.4688,
        562246.4375, 456873.4375, 502966.5938, 482426.7188, 328478.0312,
        270362.8125, 487651.3125, 498411.3438, 590013.0625, 583514.0000,
        271730.1562, 523826.4062, 346537.8438, 474866.5625, 412544.7188,
        300204.5625, 526385.0000, 435688.7812, 376589.5938, 363445.5938,
        554788.1875, 329774.9062, 397398.6250, 563606.5625, 433879.1250,
        376563.5312, 368493.0625, 404120.5312, 273467.3750, 655536.8750,
        437123.2500, 318866.1250, 398666.6562, 337345.5312, 302958.4062,
        420181.5938, 416727.8438, 401490.7812, 452283.0312, 401903.7812,
        361442.8750, 578286.0000, 363891.8125, 356535.6562, 443367.5938,
        472036.4375, 432694.8750, 538960.3125, 380735.9062, 445767.0000,
        448973.6875, 461418.1250, 259919.4844, 336427.6250, 412189.8750,
        431705.2500, 308130.5312, 544910.8125, 349722.1250, 448762.2500,
        479768.0000, 396768.6250, 345432.6562, 499745.0000, 349316.1562,
        484718.1250, 362838.8438, 509558.9688, 442492.5938, 397261.3438,
        302687.5000, 507510.4688, 358551.3125, 353964.5625, 658081.0625,
        416150.4062, 333796.6562, 490072.2188, 421962.2500, 303259.2500,
        330772.2812, 375161.4688, 309857.8125, 365582.6875, 508946.0938,
        437805.3125, 418375.7500, 456458.0312, 440427.2500, 473958.1875,
        502296.6250, 506635.5312, 496051.0000, 292271.7500, 477201.3750,
        302502.9062, 358818.2812, 406502.4062, 403732.1250, 340016.1875,
        429096.7812, 405577.7812, 401179.4688, 322608.3125, 422826.3750,
        354622.7188, 318379.2188, 337948.0312, 458948.0000, 440631.6250,
        396046.9688, 308545.7812, 308388.9688, 379189.6250, 395818.3125,
        430861.3750, 316276.0938, 338865.6875, 376526.3438, 411389.6562,
        283518.8750, 400096.6562, 515684.9688, 361517.8125, 443560.9062,
        368875.4375, 418329.5625, 454061.8438, 488158.9375, 465623.5312,
        552392.5000, 469783.5625, 365321.8750, 411638.6562, 406464.3750,
        561625.7500, 401441.8125, 542263.0000, 357099.2812, 470054.0312,
        432687.2812, 377335.5000, 445889.1562, 430035.3750, 501232.9688,
        414217.0625, 370896.8438, 310820.5312, 515423.8750, 311103.4062,
        461760.2188, 488889.7812, 600440.1875, 488400.3438, 366533.1250,
        519765.6875, 464805.8125, 366093.0312, 580397.2500, 484004.4375,
        424987.1250, 350557.4062, 463265.1250, 463715.0312, 473148.3125,
        399574.1562, 363361.0000, 436142.5312, 317114.6562, 351643.9688,
        294762.5938, 506178.2812, 335900.8750, 320482.3125, 530099.5000,
        424237.9688, 360643.9688, 577734.2500, 429382.2500, 524860.8125,
        619892.9375, 348554.1562, 475888.0000, 393416.8750, 518710.7812,
        362310.6875, 452166.3438, 399538.0312, 521434.9688, 454761.2812,
        427171.3438, 421197.2500, 395100.5938, 392355.0625, 509082.9062,
        402518.5000, 294284.6875, 472956.7812, 428922.8438, 445754.1875,
        257837.1562, 378511.6875, 370500.8125, 358065.6562, 339565.8438,
        546205.7500, 284319.7500, 444776.7812, 484655.9062, 564587.5625,
        360617.5625, 431933.8750, 595960.5000, 544471.6250, 322813.0312,
        406514.1562, 479070.8750, 287836.8125, 320496.8750, 269360.1562,
        488048.8438, 326138.1250, 351288.8125, 532576.1250, 336440.0000,
        540875.3750, 411000.4062, 484499.2812, 358273.4688, 351644.7188,
        406788.5938, 351330.7812, 562026.6875, 361236.5000, 362141.0938,
        552242.5000, 382127.3438, 443651.3125, 612371.3750, 506976.1562,
        436949.3125, 453072.4375, 562698.0625, 491710.4062, 486430.4375,
        362063.9688])
Layer: encoder.6.3.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7743.5742, 1080.5502,  982.4584,  ..., 8384.3623, 1569.6129,
        4657.3955])
Layer: encoder.6.4.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([34905.1367, 32767.5723, 28987.2168, 29553.7227, 33918.5898, 43363.2617,
        29186.2656, 27614.3086, 31008.3555, 24941.2656, 22244.2637, 25792.9180,
        42659.0000, 28733.7441, 52282.4688, 47621.3008, 34367.5586, 36271.2891,
        32018.2793, 31149.6914, 25274.1445, 27232.0117, 31770.6875, 38577.8008,
        33890.2148, 47864.8672, 44319.7422, 28115.7832, 35265.0117, 31387.4902,
        43496.7070, 42242.8008, 21318.2441, 30861.5020, 28106.9238, 30595.9863,
        27893.8008, 32134.8164, 38753.3789, 36276.9961, 35894.1484, 26794.7285,
        42371.3281, 36875.3672, 37623.6445, 29331.0137, 20013.2520, 36640.4023,
        30066.4043, 48610.0000, 38042.7773, 26459.7363, 37400.9062, 33419.3398,
        41824.0820, 25542.0273, 41937.8203, 25863.6113, 21584.9707, 36320.4180,
        33050.9805, 40759.5312, 25166.1309, 36852.1289, 31676.6660, 60561.0586,
        36729.2773, 52941.3789, 36290.0859, 26228.4980, 35171.2969, 48892.2578,
        28234.6777, 29452.4258, 41793.9297, 28673.9199, 34787.1758, 26836.6289,
        45014.1016, 37485.0742, 26639.1758, 37723.4766, 42447.0156, 44733.5703,
        25898.7969, 35254.3477, 31412.1035, 24547.7344, 31466.1582, 45774.2383,
        49819.8477, 31606.2637, 30640.1016, 35587.1992, 39685.6602, 30306.1328,
        28437.0449, 41951.0039, 25762.9531, 21799.1582, 32262.3867, 26878.1133,
        35050.8906, 29188.8652, 38335.6602, 27208.8672, 31369.9238, 39702.9805,
        25188.4590, 30364.7734, 28378.0840, 29934.9707, 35789.4297, 38574.9453,
        32373.3535, 28960.4258, 28510.5371, 27170.5215, 43370.4805, 32375.1562,
        34045.8594, 23962.3867, 32870.8164, 39889.0859, 25721.2285, 25211.8457,
        26289.2285, 37537.5117, 27442.4082, 29330.6504, 37977.8359, 35435.6992,
        33021.6680, 32986.3008, 31622.8438, 46237.6797, 30200.6113, 35207.9102,
        46055.1172, 39119.2305, 39527.9297, 30587.3008, 30729.9922, 37629.5117,
        33521.5195, 33589.2578, 48479.5859, 38231.2578, 26480.6152, 28235.1387,
        38405.7109, 29647.4707, 26383.5996, 23141.3730, 26616.9023, 14941.3125,
        30058.3203, 39163.7227, 46058.7266, 24942.9121, 30209.0645, 39724.0859,
        26691.1270, 31104.5879, 29940.8398, 51714.1719, 34982.1133, 37162.6953,
        24150.0684, 38388.2461, 45681.5938, 33550.6836, 39035.3789, 32406.9121,
        27513.8086, 31065.5684, 24773.5410, 33899.8359, 30633.3008, 31708.3320,
        40812.3008, 30141.3203, 35212.4453, 43654.4297, 30144.2441, 42659.9336,
        25682.9121, 34223.8359, 49480.7773, 42522.7500, 32853.5781, 43419.2266,
        25841.0527, 34497.9492, 25016.1660, 37796.8281, 36201.7070, 42437.6680,
        36863.3008, 32441.3008, 23248.6777, 29686.3574, 28065.0566, 58203.3438,
        30561.6152, 44433.0430, 31500.2090, 33861.1172, 29881.7109, 36302.0820,
        35724.0117, 20428.6348, 37373.2188, 30349.6758, 37735.8516, 37919.2461,
        32658.8613, 23486.1465, 45635.2148, 32714.2793, 36031.2695, 29108.5527,
        30346.4941, 31285.5234, 38646.1406, 29558.1953, 32987.4531, 38547.5586,
        27297.5762, 41240.2656, 32707.6680, 25805.4414, 41889.1797, 42223.7891,
        33711.7344, 37449.9297, 28859.1816, 45557.0234, 36143.1914, 45075.1328,
        30470.2793, 34933.9336, 20459.0254, 42129.8594, 30530.1875, 38953.5703,
        30519.3574, 39698.7188, 38937.3945, 36892.2617, 31451.5215, 33017.8047,
        38380.0820, 28825.7129, 46816.5352, 23579.6875])
Layer: encoder.6.4.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([174108.6250, 153395.5781, 131140.0625, 176355.0156, 204670.6406,
        157620.1719, 195493.5469, 181440.3438, 262294.5625, 233974.0156,
        139564.7500, 164759.1094, 182176.0312, 184274.5469, 157254.8438,
        180019.2031, 178308.7188, 188569.8281, 185375.4688, 249160.5000,
        164109.0000, 166142.7188, 204245.9219, 178901.9062, 158678.5469,
        214089.8281, 208787.0938, 144760.7344, 197015.3750, 199973.7500,
        170525.9688, 175797.5000, 129962.9531, 136346.8125, 202627.7812,
        201247.5312, 190099.6406, 115850.8984, 140962.2812, 255490.4062,
        176160.8281, 211531.4375, 191331.7188,  96940.8281, 179625.5625,
        167607.6094, 163979.3125, 143433.4688, 150550.3281, 151733.1094,
        120380.6406, 194976.7969, 149456.5156, 149340.5156, 206565.8281,
        172557.5000, 177958.4219, 173195.2969, 201054.2344, 130536.0547,
        177630.7188, 140762.3750, 118625.4844, 152706.7969, 149952.0469,
        199629.9062, 205986.2188, 155558.7500, 142840.3906, 136286.2344,
        140837.3125, 163699.8125, 214843.0156, 116188.4844, 185306.2969,
        157064.2031, 198735.4375, 254602.7656, 202645.6719, 139564.8438,
        240947.0156, 148816.0000, 146392.0938, 160388.5312, 223567.2188,
        162573.4219, 206082.1875, 201281.5938, 108717.5547, 186968.2656,
        164389.0000, 159911.1562, 143096.8438, 129886.3125, 178972.0938,
        158736.4375, 176107.2188, 153001.4062, 156685.4375, 213527.7031,
        200695.1406, 192324.1094, 142083.9375, 152284.2188,  98260.2109,
        173196.7500, 147238.3438, 193274.5000, 148009.7656, 176422.3125,
        234898.5938, 135115.1406, 176175.8594, 215890.9375, 134154.0156,
        192834.4062, 137804.0625, 230529.7500, 170610.0312, 202217.0469,
        121971.0781, 176970.4375, 128689.1406, 159914.5625, 204567.9688,
        164340.7031, 182949.9531, 199378.2969, 219354.5000, 169707.0469,
        173957.5312, 185936.2969, 176611.4062, 192375.6250, 132790.3594,
        163680.7031, 177811.0469, 178616.3750, 133546.0312, 173375.3281,
        157878.7344, 162089.1875, 139320.4375, 157957.6250, 192137.9219,
        216053.2031, 150717.4375, 122868.9297, 193099.5469, 174458.4531,
        133372.4844, 128010.3203, 185544.6875, 198232.5781, 109232.6641,
        220307.5156, 202648.9062, 217053.7969, 177573.0000, 174700.9688,
        116539.3281, 152227.5938, 155736.9062, 168339.9062, 125634.4219,
        172472.4844, 115748.2578, 129914.9688, 214679.4062, 206226.2969,
        174238.2812, 187172.2031, 174058.3438, 209583.6250, 189015.3906,
        223937.8750, 162468.4219, 139561.5469, 179514.9844, 178617.0625,
        214214.7344, 216842.5312, 177204.8281, 133513.1250, 139077.1250,
         98138.1797, 172259.0469, 180450.2188, 158521.9062, 103341.7500,
        124067.9688, 171771.8594, 139046.9688, 228211.3906, 148729.7969,
        178507.4375, 117443.4453, 157497.4219, 155021.4531, 148346.5312,
        144421.3125, 170775.6875, 172765.9531, 126283.8828, 150678.3594,
        164758.4375, 185504.1875, 179493.5938, 206696.5156, 124802.3828,
        166345.4062, 198726.0312, 222550.3594, 165339.5156, 163392.6719,
        201144.7500, 155324.1406, 190542.1406, 131267.5781, 198283.0312,
        141272.6094, 184472.2500, 144113.1250, 166495.5312, 204684.2188,
        161957.9531, 196237.5000, 190359.2812, 190335.3906, 188315.5625,
        150652.1719, 158937.9219, 175230.6562, 153564.6875, 198225.3750,
        123194.2891, 149178.7500, 230747.4375, 168499.3594, 134306.5000,
        198511.6562, 190827.8438, 210805.9062, 162488.5625, 188225.5469,
        145924.4375, 157570.9219, 126279.8438, 138762.2188, 145665.7031,
        148047.8906, 205832.9688, 174700.2344, 252457.6562, 146987.0938,
        148245.5938])
Layer: encoder.6.4.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 6400.1533,   141.9508,   978.8753,  ..., 17356.6621,   140.7028,
         2556.4219])
Layer: encoder.6.5.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([13843.2793, 22312.5781, 22106.6113, 13007.2119, 20997.6211, 19497.0566,
        19262.9727, 24593.5469, 27880.2637, 22699.9961, 22121.2852, 15255.8623,
        12730.2334, 25861.2617, 21577.1641, 22035.2480, 25723.0859, 23472.3574,
        19106.6777, 31616.2188, 20633.7480, 17100.0801, 25456.7383, 14040.8838,
        31535.8750, 15752.4375, 14540.8887, 30181.1152,  9909.5117, 25818.5352,
        25273.9668, 32346.2676, 19488.2109, 16741.1504, 19832.9238, 28401.0566,
        22699.0703, 22947.3633, 22652.8867, 27748.6035, 25656.3809, 21408.2129,
        21111.1914, 33107.0664, 26324.4238, 31593.8164, 34289.8398, 27819.8340,
        18593.8438, 24517.6582, 31320.4746, 22614.0625, 18320.9551, 20615.4199,
        30120.8223, 26382.3340, 23228.9922, 26082.2812, 21896.1934, 23287.7910,
        18691.8262, 28502.2695, 20699.5605, 28185.2949, 25578.7090, 24037.1816,
        22158.1855, 34848.5938, 19399.2617, 11245.6152, 22340.5996, 22971.3789,
        17278.3145, 24546.2793, 27069.6152, 18703.4961, 30568.4922, 25748.6309,
        22224.1445, 27534.5723, 34640.7656, 20574.8184, 31710.6406, 23883.6523,
        30840.7441, 25571.4434, 16446.7012, 16254.4619, 24900.8281, 20588.7656,
        13007.7822, 19086.4844, 26545.0078, 26151.5039, 18160.2402, 18930.9512,
        26324.5547, 12596.4697, 32822.3945, 26240.5176, 20447.4434, 14873.0791,
        26456.8477, 27325.6133, 33766.2539, 17854.4961, 22620.6445, 28103.5312,
        25818.1445, 19620.0820, 25091.5781, 15248.1729, 24692.1133, 22071.1797,
        23410.5332, 28430.3418, 23793.5801, 19921.4492, 14809.3359, 19406.3457,
        28418.0137, 27952.7832, 19656.8945, 20214.6934, 21705.6992, 17578.1855,
        21216.1699, 23807.1074, 33096.0625, 30946.8496, 29663.2676, 30140.3340,
        37327.1172, 29026.7188, 22868.0098, 31788.4219, 37896.8398, 38316.5391,
        20334.2695, 32471.6211, 24406.3633, 27856.3535, 18943.0859, 19660.8242,
        27004.2637, 18945.4863, 20183.3008, 23328.9355, 25147.7734, 30713.4414,
        28234.3340, 23155.4238, 40035.1641, 24697.3125, 29398.0859, 24574.8340,
        27415.1738, 26533.8672, 14626.0908, 18365.2715, 39932.6992, 38563.2812,
        17789.3301, 31692.1113, 22765.4883, 27760.4316, 20947.9590, 17400.1680,
        21767.1562, 16143.2295, 23264.6094, 31497.7676, 33836.0781, 28259.5859,
        24924.4844, 28763.6641, 23394.7871, 26640.9785, 20971.4922, 16953.2617,
        19021.3398, 40617.5391, 35411.4102, 24628.2559, 27629.2168, 23416.8262,
        23139.8613, 29478.4121, 21737.1797, 14024.9854, 19314.6426, 17814.4238,
        18372.0781, 25215.1699, 33691.0000, 17182.9609, 18020.8906, 27984.4785,
        30448.6738, 31574.6133, 24066.4121, 15351.5771, 15915.2480, 17609.8379,
        11307.5508, 15363.0117, 27883.6777, 19056.6699, 16332.1914, 21144.3594,
        37218.2344, 23374.8691, 21787.6133, 26665.7051, 28842.8789, 18712.6270,
        30728.8867, 19378.1543, 19801.4961, 23009.8223, 33109.8711, 27079.9141,
        18984.9883, 23142.8555, 29767.5059, 26068.3867, 30925.7266, 19960.8926,
        19071.3457, 25483.9395, 30047.0840, 36457.0898, 27175.9648, 23268.6914,
        25463.8516, 15235.0264, 19693.7539, 23532.2891, 38674.7227, 33727.4961,
        26362.3613, 15844.1611, 25429.7148, 17928.8750, 16280.4375, 22995.9805,
        16853.4824, 17830.3770, 16306.9238, 28611.5332, 23537.4863, 28921.8301,
        19293.0938, 19300.2031, 19401.8125, 38922.6562])
Layer: encoder.6.5.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([140322.2188, 146094.1562, 115026.9688, 105344.8281, 131379.8906,
        168842.4062, 200572.2500, 127805.3984,  72141.0000, 106438.0781,
        110940.8281, 152847.6719,  65138.7148, 105293.2188, 147503.1875,
        153505.3750, 111808.3750,  96977.9219, 111512.8516, 162576.0625,
        180772.8750, 120234.2266, 108039.9922, 122916.8203, 129367.4062,
        109768.0312, 147129.1406, 180122.1719, 128411.0000, 104993.6484,
        125879.1016, 110975.4375, 130627.1328, 121049.5234, 141410.7812,
        106287.0625, 116983.9297, 131093.6094, 112851.3359,  96513.3516,
        139373.4844, 113079.3438, 117692.3047, 146627.4688,  86541.4297,
        145182.7188, 205153.7812, 133546.6719,  80852.9453, 112647.3438,
        108207.3984,  78621.6484,  97103.3203, 122862.3828, 111372.1484,
        130513.7969,  80405.0000, 123164.5234,  83743.8125, 108981.3359,
         99415.2656, 108259.0312, 146541.9688,  82186.7266, 107149.6172,
        174861.0000, 133570.6250, 125434.0547, 124306.1094, 114669.2109,
         89551.6172, 100003.8984, 100701.7734, 159620.0781, 107987.8125,
        126720.7734, 130869.9688, 150451.1250,  84130.2266, 123619.5312,
        107906.9375, 155851.0469, 112359.3906, 143758.9688,  91337.6250,
        169359.8125, 144872.8750, 136602.8906, 135589.8906,  95085.6953,
        145109.5000, 102583.2344,  85507.4531,  94439.2422, 120785.3594,
        184535.0938,  76867.8672, 119121.3594, 133942.3594, 142674.5938,
         96867.6406,  87778.4453, 133877.8125, 133040.7031, 122179.6562,
        156256.4844, 101989.0703, 134228.0625, 166390.5156, 158178.0156,
        105895.7109,  83874.3281, 125988.0625, 138749.0781, 133306.1562,
        107602.9219, 130974.0547, 100724.7578, 107673.2109, 112588.3984,
        126568.2500, 171049.5000,  96206.0625, 111252.1016, 109926.1406,
        123293.0938, 140769.9844,  67634.9922, 201102.7812, 100762.4531,
         92221.8984,  80988.5938, 113328.9766, 142381.6250, 140644.2188,
        125789.8438, 164493.0156,  88364.6953, 111872.8906, 110473.8906,
        163230.9844, 111412.8828,  77089.4844, 154441.9844,  74091.3984,
        125651.7109, 140397.8438, 146465.6094, 103750.3281,  67130.2500,
        112492.7656, 140763.4375, 121009.4453, 149955.6250, 151490.4062,
         93762.8750, 107830.3828, 179845.8438, 203227.4219,  92626.9766,
        141528.1875, 165606.0938,  86079.6797, 109593.8906, 115486.3203,
        136751.1875, 122365.1328, 118632.9766, 112379.6875,  76369.9297,
        118753.1484, 129330.9531, 115732.6641, 163029.5938,  87579.1797,
         91688.8438, 106339.2500, 115184.6953,  75741.2656, 118249.1562,
        136424.5156, 163872.8750, 121746.8438, 177485.0156,  70684.3672,
        121438.9062, 103747.5234, 113982.8672, 125610.2578, 107811.5078,
        100685.3516, 138661.2188, 116778.5391, 146473.9219, 122683.4297,
        117432.1953, 124896.4375, 153241.5781,  91672.2578, 169487.5625,
        118570.5547, 129321.8594, 126984.0078, 137948.8281, 111455.4688,
         91447.5234, 109353.6016,  99655.7188,  95249.5938,  95118.9609,
        120885.7969, 113178.7109, 153465.3438,  91057.7578, 171290.0625,
        133337.2344, 122107.7422, 103106.5547, 113467.1719,  92470.2500,
        118870.6328, 102582.5938, 147586.1250, 130088.3438, 127438.0391,
        163489.4688, 139146.0625, 114105.0938, 156066.7344, 119348.9922,
        120546.9219, 112199.6328, 155228.9062,  95571.9844, 150669.2344,
        149525.3281, 127258.1484,  58428.7188, 108226.0078,  90363.1406,
         98335.8906, 164901.6719, 122490.7891,  97072.1250, 105118.6250,
        117617.9766, 119090.4844,  79931.5625, 124871.3750,  73563.6562,
        163344.2500,  76450.6484, 133600.6562,  97711.7891, 136582.1719,
        113646.0938])
Layer: encoder.6.5.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1630.8217,  126.7035,  123.2338,  ..., 1543.8511,   21.5210,
          38.9497])
Layer: encoder.7.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 746.9221,  848.5455,  749.8898,  865.8135,  723.8069,  535.7543,
         778.2226,  833.8350,  778.1295,  739.3731,  752.5340,  673.2799,
         597.9942,  905.0641,  639.2354,  639.0020,  685.6691,  818.8125,
         664.3844,  657.6459,  678.8279,  656.6205,  737.3392,  669.2442,
         710.2844,  758.3368,  596.5491,  594.5674,  707.5023,  581.3528,
         692.0995,  758.7717,  735.6155,  657.1127,  794.3072,  804.8054,
         815.1507,  713.1259,  839.0060,  628.1470,  520.7070,  646.4761,
         819.2917,  724.4720,  678.4717,  595.4197,  636.5906,  928.5620,
         707.6426,  756.1183,  792.2780,  684.9622,  711.0391,  610.7602,
         783.9819,  735.8582,  621.5188, 1005.6358,  646.9017,  598.8577,
         726.5123,  895.5648,  768.2048,  910.1989,  724.8156,  712.2742,
         866.3622,  598.2416,  641.9946,  593.0487,  671.9719,  613.4991,
         778.5121,  637.5454,  609.2191,  769.4858,  809.1772,  771.0596,
         583.7579,  676.6677,  718.3175,  949.0280,  736.4597,  960.1400,
         888.9200,  698.4484,  717.6937,  896.5010,  761.4934,  636.7596,
         787.6275,  792.5765,  682.9325,  658.9291,  718.7745,  599.0557,
         567.2160,  770.2405,  706.2321,  713.2448,  693.8781,  693.3132,
         621.8743,  863.4830,  672.6152,  768.9341,  723.5853,  740.8745,
         581.0333,  991.0248,  626.7106,  878.2575,  891.8170,  619.8557,
         787.4774,  786.1653,  686.6750,  884.6192,  599.2664,  762.8483,
         847.6147,  851.7214,  577.1098,  680.4631,  720.6099,  645.0065,
         690.0547,  987.0189,  633.8051,  680.6256,  659.9486,  600.7147,
         629.5020,  589.9689,  694.3715,  746.1728,  911.2689,  729.9745,
         867.3260,  681.7395,  711.0913,  594.3644,  572.1575, 1023.7254,
         830.9976,  550.0215,  829.6819,  727.4629,  601.2579,  729.7737,
         758.2785,  801.3904,  792.8907,  682.3676,  754.4410,  557.0212,
         594.5787,  505.0799,  650.1529,  571.3494,  593.4559,  689.4584,
         754.9214, 1026.1947,  779.7902,  694.4354,  866.6132,  671.4304,
         735.8021,  671.4493,  743.1584,  921.3331,  766.7371,  721.1169,
         776.8367,  914.4291,  592.6272,  926.9453,  726.6619,  807.7921,
         781.0483,  986.8848,  613.4043,  713.3963,  716.0738,  925.0049,
         761.2980,  908.1047,  571.5114,  781.0187,  719.8544,  707.2915,
         546.0277,  539.7059,  815.7985,  669.7635,  947.9435,  890.9868,
         593.5638,  750.5615,  768.5404,  559.8644,  673.9419,  742.5207,
         663.8984,  777.5076,  772.2828,  765.6525,  888.7430,  915.9855,
         525.5408,  640.7308,  756.3328,  725.7870,  897.6950,  633.3885,
        1002.2369,  760.5078,  760.9130,  780.0413,  831.7358,  899.8357,
         657.6369,  691.4808,  954.5734,  905.7432, 1092.5442,  723.9142,
         837.9689,  765.9225,  728.1218, 1044.1355,  738.7638,  850.0969,
         961.6436,  775.4025,  657.8074,  739.8736,  748.2484,  611.3489,
         719.1832,  679.6288,  823.2687,  727.1210,  836.6354,  983.7570,
         789.7422,  714.4144,  902.8488,  514.5522,  859.1078,  555.4341,
         857.8156,  745.1570,  856.1483,  730.9122,  834.9760,  657.0379,
         511.9008,  622.5157,  538.0330,  733.4616,  689.2072,  603.5466,
         718.9672,  690.7390,  829.8028,  682.4196,  634.2820,  683.4645,
         741.0571,  771.5864,  810.7715,  670.0647, 1027.9833,  680.1589,
         674.1448,  745.9562,  492.2331,  572.3310,  872.5394,  735.7332,
         781.9319,  955.5850,  804.2024,  796.4579,  652.5825,  819.2592,
        1067.0632,  906.2706,  773.2194,  630.1198,  640.8980,  697.7394,
         768.1074,  551.1808,  859.1519,  806.4066,  848.9127,  780.3816,
         681.6214,  762.3815,  615.8954,  654.7812,  717.8903,  531.6382,
         798.7146,  795.8232,  601.0747,  630.0404,  668.3114,  580.5239,
         910.1760,  541.0581,  636.2309,  596.9098,  654.5786,  707.2877,
         652.9656,  602.5895,  755.0172,  828.4334,  735.7889,  755.0820,
         865.2980,  847.3793,  637.2530,  635.3685,  781.7554,  615.3350,
         931.7428,  610.4272,  812.6003,  813.9387,  705.8563,  664.8574,
         542.9257,  593.9591,  627.8655,  653.0021,  639.1426,  727.5208,
         736.8326,  737.3035,  769.0631,  861.7909,  642.4296,  694.9485,
         943.5655,  771.5625,  682.5233,  762.4670,  561.6080,  620.9134,
         754.8992,  731.6096, 1075.8220,  715.2094,  552.3346,  767.5726,
         788.1730,  715.4214,  698.1425, 1003.5695,  806.6985,  675.1388,
         798.9582,  923.5184,  806.0400,  885.6088,  993.7142,  581.8813,
         755.5615,  870.4753,  784.9908,  740.5746,  593.0479,  659.4065,
         807.6277,  723.5924,  641.7203,  681.2386,  787.2831,  562.5073,
         739.8153,  884.8121,  730.9265, 1011.3685,  717.1035,  763.8371,
         783.4110,  689.0244,  834.8224,  666.6988,  599.8560,  775.5022,
         754.4344,  636.0114,  815.3669,  834.6610,  820.6245,  911.5440,
         643.7422,  777.7007,  754.6765, 1107.6235,  485.2881,  824.2303,
         622.8831,  789.3551,  720.7907,  676.3341,  742.4769,  869.4283,
         701.7579,  718.3586,  589.3866,  661.6313,  888.8735,  839.7410,
         782.0283,  719.4815,  927.0474,  811.9921,  737.8829,  691.9435,
         705.8891,  547.2582,  722.2161,  813.1521,  668.5963,  645.3773,
         920.0521,  647.6949,  704.9353,  643.9240,  664.2844,  574.7132,
         666.3790,  600.0244,  700.9771,  538.5790,  777.8704,  733.9298,
         560.6006,  814.2245,  794.8744,  968.4062,  655.0872,  735.6684,
         848.6670,  668.9287,  680.5220,  972.6965, 1013.0313,  812.6843,
         728.8479,  892.9611,  630.2596,  650.7837,  689.2844,  702.9842,
         725.8630,  704.3759,  801.6874,  795.2731,  678.8380,  705.4423,
         809.1432,  810.2931,  808.9296,  638.1171,  758.6486,  505.5789,
         676.0593,  703.3813,  843.7872,  680.7157,  617.5575,  829.9070,
         730.3181,  707.7159,  660.4571,  814.7509,  917.0538,  757.2141,
         680.1609,  759.7250,  953.3386,  689.3615,  625.5226,  558.9304,
         840.0737,  557.9797,  787.3354,  630.8423,  668.7050,  770.4582,
         565.3716,  690.0016,  910.5385,  954.7056,  787.3856,  814.9533,
         686.1525,  906.4480,  920.1919, 1124.6666,  564.1198,  611.3895,
         838.4198,  644.2001])
Layer: encoder.7.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 9131.6924,  9451.4297,  7928.9487,  5676.8950,  8407.8643,  8551.7080,
         9350.7432,  7857.7856,  8752.9629,  7759.7329,  6981.6406,  7773.4570,
         8751.0615,  9427.2256,  8004.6445,  8671.2803,  8988.7871,  8748.8545,
         7813.0859,  5584.9517,  8452.9658,  9079.0596,  6462.9736, 10564.3418,
         9115.4678,  5433.4307,  7852.7310,  7689.4346,  6037.9111, 10340.3477,
         8379.5527,  6577.2812,  9101.1484,  8303.2549,  7490.8931,  6889.9248,
         8798.6738,  7086.3374,  6365.6138,  8295.1328,  9272.7637,  8975.7998,
         7836.0381,  7928.8062,  8674.4658,  9926.2725,  7067.2114,  8938.8164,
         8593.4502,  9684.8643,  9523.7354,  9698.3496,  7349.7842,  8038.8281,
         8921.9199,  6791.7344,  8578.9668,  8689.4678,  7428.1328,  7470.5527,
         8605.8193,  7686.5723,  7808.9639,  7722.6064,  8826.7344,  7228.9370,
         9001.8398,  7898.4893,  8966.1211,  8590.9893,  9269.1445, 10118.9873,
         8901.2178,  6882.1953, 12378.0645,  8408.0322,  9248.3174,  8393.3652,
         7872.7993,  9154.4541,  7738.9312,  9268.9365,  9397.0586,  7254.3975,
         7747.4219,  9873.2246,  8661.8457,  9853.9209,  6016.0620,  6770.4419,
         9012.7422,  8863.4697,  7438.6982,  7185.8701,  8761.6816,  9845.8018,
         7894.9590, 11109.0273,  8630.8750,  7661.1577,  8304.8184,  7397.8501,
         6824.6685,  8258.1514,  8322.5566,  8706.9951,  9331.7607,  6266.9453,
         6773.1836,  7764.4980,  8540.8623,  6811.3853,  7820.9565,  7794.4336,
         9149.9160,  7349.5425,  7844.0776,  9178.2734, 11179.6729,  6305.2598,
         7329.4834,  7944.4648,  7685.5254,  8084.1890,  9672.1299,  8046.3926,
         7089.6758,  6529.7119,  7848.4912,  7864.6694, 10310.1338,  9098.9375,
         7226.4858,  8019.3169,  6843.0190,  7360.0791,  9218.3984,  7780.1284,
         7573.5762,  8945.3848,  6849.4160,  9663.2393,  8482.9912,  7452.4248,
         7291.6201, 10238.0576,  9905.0234,  9299.6426,  5821.8140,  8922.6055,
         8307.8320,  7796.8267,  8376.3867,  9084.4102,  7337.9771,  8528.1250,
         8933.4717,  6495.2124,  8519.1582, 10846.7432,  9161.4951,  8643.3691,
         8489.7588,  6440.6865,  6939.1875,  8310.4395,  8105.6577,  8047.0493,
         8459.1074, 10025.7734,  6942.2842, 10153.0420,  6239.0928,  7080.7251,
         7472.5625,  9255.7861,  9053.7432,  8690.5518,  7604.1445,  6836.0762,
        11012.0518,  7084.3760,  9287.4004, 10963.2676, 10724.6602,  6576.6216,
         9310.5117,  8601.9277,  7708.6475,  7524.5571,  7788.5190,  7968.1646,
         7516.4097,  7254.0093,  7715.1074,  6146.0869,  8440.2842,  7150.0913,
         9961.6436,  7593.7021,  9658.3076,  7617.0942,  8265.3486,  7780.5244,
         7345.5693,  8373.4189,  8706.6396,  8663.9414,  7362.3784,  8461.4131,
         9420.9990,  8905.4014,  8064.7246,  8421.1133,  9364.5078,  8818.6465,
         6114.3647,  9729.9658, 10133.0078,  7529.6797,  6503.5703,  6480.6743,
         7676.0596,  8127.3135,  8776.7178,  8304.7705,  8745.0391,  7428.4487,
         7580.8179,  6651.3823,  8378.4609,  7699.3511,  8923.6582,  7184.2578,
         7133.4980,  9219.9053,  7246.3286,  6585.8447,  8683.7754,  8620.5098,
         6374.2461,  7551.8994,  9141.1270,  9296.2754,  9070.6582,  9790.8857,
         5951.5850,  6830.1538, 11266.1348,  9819.0928,  8907.5000,  8403.7139,
         7312.0122,  7677.0830,  8523.7119,  8093.7793,  6877.1729,  6200.0054,
         7639.8208,  8526.6104,  9296.0771,  8436.2998,  8931.8008,  8065.6641,
         8962.4121,  8388.6299,  8810.1357,  6863.1265,  8546.5205,  6505.6655,
        10767.1592,  8516.0127,  7198.9810,  8464.0254,  8570.5869,  8810.2773,
         8303.9844,  9108.5898, 11151.0186,  9331.6289,  8585.4258,  8185.4766,
         7962.7246,  9744.7676,  7256.2554,  6956.8564,  7399.3789,  7879.3677,
         7179.1606,  8467.6143,  8298.2773,  7905.7871,  7410.4214,  8611.9873,
         7374.9863,  7265.8604,  8146.9902,  9099.6416,  9533.9375, 11293.3408,
         8661.4893,  9199.0830,  8737.7754,  7779.0571,  9071.1367,  7370.9160,
         9807.3721,  9464.8926,  9144.6104,  6500.3862,  8855.4570,  6145.3159,
         8126.3340,  6800.9614,  8510.5879,  9293.7109,  7786.9282,  8624.2783,
         9180.9053,  9687.9883,  7078.2871,  8172.8867, 10396.3623,  7920.7129,
         8767.4082,  7732.9380,  6993.3931,  7222.3994,  8311.9551,  9189.1953,
         6297.9546,  6503.6953,  7454.0063,  7533.4756,  8190.6304,  8200.4863,
         9372.9121,  7175.8057,  9024.0508,  7378.5059,  7760.7930,  9460.1211,
         7761.1152,  8177.2007,  7105.0771,  6291.9233, 10864.8281,  6437.7803,
         6500.0835,  8382.5508,  8150.5503,  7452.9170,  7989.9785,  8685.2305,
         9205.1035,  7202.0156,  9588.5215,  6913.7329,  7448.8135,  6807.2056,
         6735.3535,  9473.4600,  8239.8398,  9446.3086,  8567.8926,  8134.5020,
         9583.7910,  9614.0010,  8293.2129,  7885.9478,  7186.4932,  8621.0273,
         6831.7905,  7980.4287,  7428.9272,  7875.9453,  8776.6982,  8493.8955,
         7673.7368,  8058.4141,  6693.1011,  9313.8623, 10557.7080,  5845.3755,
         8332.7012, 10760.0352,  8624.5625,  7076.8311,  8572.4834,  6604.1626,
         7824.8638,  9951.5410,  8476.3633,  8357.4707,  9700.6348, 10018.5605,
         6891.9609,  7756.3013, 12548.3525, 10705.6240,  6899.9761,  7513.9878,
         9271.4912,  7727.5654,  8332.4971,  7045.7417,  8899.4629,  9243.6074,
         6296.8848,  6594.5024,  7364.1211, 12948.8955, 10173.5850,  7683.2280,
         9920.7900,  8062.8950,  7473.3936,  7062.7866,  8849.9932,  8389.4551,
         7313.5098,  9101.0176,  8475.6748,  7770.0303,  9384.1553,  9842.9912,
        11455.2676,  8235.8662,  8610.0986,  9336.7090,  8999.1045,  8798.4268,
         8316.9277,  8203.6094,  8498.3916,  9383.9287, 11684.1338,  9653.5488,
         9954.9717,  8028.7178,  7278.8008, 12177.6953,  9235.2002,  6756.4097,
         7158.4033,  6846.6436,  8189.8936,  8629.1221,  8646.5732,  6838.6372,
         6880.3169,  8567.5234,  7466.5044,  6594.0586,  8651.6807,  8972.5811,
         6435.3003,  8766.5303,  9056.0078,  8280.6221, 10478.4531,  7660.7388,
         8821.3545,  7619.2681,  6390.2559,  8850.9512,  8595.7285,  9192.7588,
         8755.3457,  6597.1963,  8299.6123, 10273.9082,  9547.3027,  7732.7627,
         8411.3340, 10120.3008,  7170.2695,  8239.7129, 10105.1826,  7361.5132,
         6363.5278, 10644.2959,  9441.1641, 10793.3418,  7637.3701,  8872.4551,
         8018.0938,  8337.3994,  7918.6943, 10498.8359,  7689.0332,  8310.9268,
        11868.2793,  8550.0391,  7367.8755,  9341.8291,  8505.2939,  8906.9199,
         7409.8213,  7532.9175,  7488.6235,  7826.9121,  8987.4922,  7068.1904,
         7480.8223,  9151.3574,  7516.7852, 11490.2676,  6832.2866,  8778.0576,
         8517.2490,  8332.5664])
Layer: encoder.7.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 56.5557, 670.4290,  19.2115,  ...,  22.3603,  28.8999,  21.5429])
Layer: encoder.7.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 173.8679, 1542.8311,  157.5686,  ...,  188.0888,  257.6398,
         112.5288])
Layer: encoder.7.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 924.6524, 1103.4301, 1564.4423, 1310.5302,  754.6478, 1106.1752,
         812.5215,  936.7127, 1005.9424,  709.9758,  914.7902, 1031.7847,
        1579.1766, 1129.9196,  761.3162, 1154.2343,  995.9689,  964.8243,
        1715.1110, 1123.7224, 1486.7781,  802.1470, 1423.4918, 1306.9788,
        1005.7661,  924.3292,  997.1362,  896.4448,  874.4746, 1112.3411,
        1128.8530,  662.5430, 1851.6259, 1024.8702, 1135.0563, 1172.6404,
        1306.3170, 1138.3604, 1071.7920, 1004.4218, 1302.5088, 1713.5790,
         848.0624,  864.7668,  740.0381,  753.4348,  915.3177,  813.0347,
        1161.0206,  647.0286, 1339.7620, 1606.3101,  908.4830, 2036.5785,
        1569.5885,  843.2730, 1176.6085,  962.5007,  902.7479,  877.0541,
         760.6984, 1092.0521,  909.5097,  928.8112, 1476.1206, 1266.5796,
        1487.2837, 1251.6859,  713.1848,  681.3148, 1166.8809, 1026.2931,
        1454.2369, 1018.0750,  853.9537, 1006.5776,  817.6661, 1003.4422,
        1118.1555,  753.4057, 1430.5533,  898.6365, 1466.2124,  773.0706,
        1269.5991, 1056.1372, 1413.6370,  960.6263,  803.6541, 1235.7463,
        1118.0557,  829.4086,  905.4974, 1392.5623, 1333.3549, 1039.0543,
        1069.8591,  772.2401, 1185.3199, 1116.9204, 1419.6198,  612.3669,
         956.2002, 1079.9065,  958.1961, 1109.4445, 1403.1998,  910.7296,
        1138.4602, 1308.0474, 1093.2947, 2045.3647, 1072.1544, 1103.2920,
         675.7977,  698.5430,  953.2333,  813.9675,  860.5962, 1191.9307,
        1099.3862, 1086.9841, 1659.3718, 1448.9148, 1209.8536, 1235.0701,
        1391.8859, 1078.5365,  581.4201,  880.0803, 1065.3789, 1162.5690,
        1030.1998, 1436.9623,  685.1266, 1197.9412, 1044.7448, 1911.7660,
         668.0762, 1376.4341,  697.4487, 1279.6161, 1454.0151,  850.2982,
         807.8129,  765.3268,  850.5330,  981.7135,  816.2625, 1265.8253,
        1264.5319, 1031.3615,  827.5478, 1041.4606,  896.9364, 1390.2079,
        1021.1974, 1314.5479, 1015.4225,  659.3279, 1205.8043, 1076.0621,
        1218.3132, 1541.9275,  993.9195,  924.0994, 1071.7515,  975.0251,
         680.9393,  839.0981,  706.1545, 1161.3296, 1482.5223, 1143.4113,
        1532.4346, 1331.4026,  784.8613, 1719.3752, 1128.1949, 1229.3992,
         793.9519, 1175.8281,  877.7551, 1025.5745,  846.5677, 1223.1346,
        1283.8612, 1103.2585, 1441.4133, 1031.7325,  999.5566,  916.1661,
        1211.9996, 1192.5636,  990.6794,  724.6266, 1070.5634, 1298.7762,
        1279.8705,  958.4065,  789.4481,  799.3581,  924.5027, 1369.5298,
        1485.1267, 1022.0284,  950.2862, 1287.3271, 1457.2228, 1273.0807,
        1315.5005, 1401.0000,  661.1494,  865.9822, 1472.4020, 1038.0276,
        1522.4382,  822.3914, 1714.3998, 1187.6108, 1106.7971, 1180.8899,
         940.6818,  861.1665, 1006.3964, 1054.2771, 1213.6265,  757.6919,
        1395.8586, 1073.0220, 1871.9589, 1063.6613, 1334.7582,  844.8831,
        1158.4122, 1475.6708,  686.6703,  919.8608, 1016.7488,  853.8085,
        1139.7184, 1176.3612,  690.3171, 1131.7145, 1320.6373, 1385.7589,
        1397.1719,  815.9948, 1198.3260, 1256.6086, 1333.7283, 1348.1305,
         638.9203,  826.8774, 1250.6399,  979.8740, 1135.1328,  942.1347,
        1035.0403, 1866.8839, 1262.6725, 1231.5581, 1052.2958, 1146.8145,
        1009.1811, 1057.8727, 1287.3529,  861.5370, 1079.7340, 1206.4213,
        1454.7415, 1042.5775, 1260.1259, 1181.8080, 1066.8724,  953.4056,
         963.6409,  756.5698, 1123.2913,  864.5726,  981.5536, 1308.2357,
         814.8102, 1158.8210, 1190.3165, 1073.8347,  669.8768, 1129.5239,
         984.5976, 1277.4539, 1019.6219,  666.5632,  760.4876,  653.1953,
         786.6096, 1161.8787,  894.3591,  954.8483, 1036.8097,  810.1229,
        1126.9797, 1539.8359,  733.6432, 1232.2881, 1245.8209,  862.4397,
        1320.1742, 1066.3234,  937.2817, 1073.2867, 1098.0083, 1189.4471,
        1071.9611,  680.6052,  912.2339,  628.9718, 1466.7833,  965.5277,
        1139.9006, 1233.5066, 1598.4650,  915.8344, 1115.5618,  863.4742,
        1008.7080,  729.4352,  848.9921,  724.3938, 1383.0734, 1348.0790,
        1223.9227,  963.7534,  918.2885, 1128.3248,  768.4815,  983.7797,
        1067.9996,  691.1727, 1117.4644, 1208.1382, 1116.1299,  959.5736,
         962.9875, 1982.1899, 1174.5583,  946.4977, 1140.9586, 1191.0546,
        1755.2175, 1344.2610, 1108.7610,  941.1873, 1118.9023,  842.3347,
        1210.6401, 1411.1614, 1113.9899,  953.9243, 1631.8262, 1356.4642,
         883.6843,  967.4911, 1125.6202,  866.8781, 1032.7527, 1026.5240,
         941.1650, 1092.5768,  860.5426,  954.0200,  843.7389, 1494.8021,
        1643.4307,  801.1618, 1146.2904, 1049.3700,  736.0821, 1190.0847,
        1389.1090, 1221.3151,  966.0952, 1290.7510,  966.3791,  815.3312,
        1069.9375,  935.9760, 1365.6676, 1452.8566, 1034.2759, 1336.2263,
        1195.8390, 1402.8179,  801.6408, 1387.6056,  861.4276, 1102.2064,
        1285.8857,  709.7899, 1376.6827,  872.5977,  708.8458, 1270.9240,
        1137.0797,  985.2432, 1148.5809, 1012.0417, 1442.7483, 1355.2853,
         818.9066,  864.1547, 1176.4351,  934.9110,  928.4666, 1087.4895,
        1064.5563, 1609.9077,  855.1395, 1149.9742, 1305.6293, 1139.9305,
         945.3700, 1026.9481,  926.3372, 1152.6353,  871.7537, 1131.6249,
        1119.3616, 1070.5555, 1599.3937,  921.2756,  947.8651, 1162.4989,
        1163.3921,  667.3253, 1164.8470, 1225.9736, 1333.1318, 1146.2994,
        1461.6436,  962.8513, 1008.4163, 1142.2878,  941.3223, 1039.4229,
         999.4822, 1285.1208, 1203.5509, 1518.9723,  652.0410,  883.8190,
        1153.4025,  932.6505,  929.8433,  681.7335, 1071.1921, 1059.4054,
        1197.9852,  935.2214, 1249.5433, 1131.4915,  897.4492, 1057.4149,
         820.5351, 1030.7416, 1142.1732, 1143.0768, 1420.4368, 1477.1136,
        1085.9656, 1062.9700,  707.1434,  601.4579, 1545.1660,  889.6491,
         865.7131,  609.9445, 1163.4362, 1099.3877, 1015.7649, 1117.2402,
         911.6398, 1099.5531, 1149.6858, 1358.3082, 1011.5043, 1020.5236,
         859.6296, 1247.7510, 1485.7063, 1075.4230, 1284.8481, 1925.1454,
         836.8624, 1010.1804, 1259.1866, 1249.9111,  944.5960, 1024.8185,
         815.6138,  866.2897, 1621.3171, 1306.5072,  876.3340, 1432.9641,
         965.6310, 1163.0441, 1165.5184, 1341.3896, 1366.4872,  830.1145,
        1110.0475, 1155.8037])
Layer: encoder.7.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 7485.6255, 11066.2549, 11807.4502,  9583.1230, 10159.7490, 14324.8623,
         6968.5664,  8319.8242, 13073.3096,  8445.9229, 13656.6641,  7512.7622,
        10047.3047,  8792.1299,  9932.7998,  8904.4258,  5813.0083, 10084.8809,
         6559.8218,  7659.2661,  8329.3223, 11586.8965,  7607.3906, 10661.5781,
         7901.6152,  8896.7939, 13485.5762,  8565.9014, 11534.4326,  8273.3066,
         7049.9092,  6220.4609, 10177.1973,  9171.4521,  8486.6123, 12817.4150,
         8675.7637,  8880.6807, 10870.7754, 12000.4844, 14342.9961,  9771.5654,
         4443.9307,  7986.3281,  8184.2354,  9118.2812,  9710.6270,  7804.7397,
        12956.2158,  7378.4116,  9939.1201,  7227.6782, 10166.3008, 14253.2236,
         5900.3115, 10794.6045,  6576.2241, 10562.4502,  8715.6035, 12336.2998,
        11762.8936,  8191.9717,  8697.2812, 11521.2734,  6510.5610,  9054.7500,
        12125.2959, 10043.5000,  9252.0635,  9116.8730,  8396.5479, 10027.4658,
        12552.6377, 12256.6084,  8626.4277,  9873.9561,  9586.1289,  9535.2764,
         6737.4072,  6336.1353,  8174.4321, 10254.4502, 10459.3008,  9972.8750,
         7576.5996,  7224.7324, 10646.2920,  8689.6660,  8817.9473, 10797.6826,
        13093.0205,  9732.6201, 10787.8662,  8766.5215, 11826.4873, 14303.9746,
         9010.2070,  8589.1943, 10994.7041, 10132.8711, 12971.8867, 11123.5283,
         8387.0283, 10208.4561, 10813.2881,  9469.6621,  6283.0532,  9247.4561,
         6645.1538,  8211.6250, 12928.8506,  8524.6211,  7194.6284,  8582.1055,
        12047.9180,  9427.9893,  8895.5264, 10102.5127, 13372.6660, 10313.5898,
        11597.6328, 10393.3711,  8130.7446, 13317.9316, 13483.8691,  9652.9287,
        11395.2051,  7240.9307, 11488.8789, 11937.9121,  8738.9521,  8502.4072,
        12296.9033,  9995.7393,  9755.3350,  8666.9346, 10894.9893,  9546.3418,
         8113.9102,  6448.0913,  7617.0415, 10322.1250, 10877.3213, 13975.1719,
        10413.8076, 12477.4336,  7302.9331, 10044.6104, 10041.7861,  8399.7002,
         9618.0537,  7785.6045,  7823.0498,  7575.6260,  8041.9126,  7577.1865,
         9810.5781,  8983.3779,  8487.2744,  9452.9883, 10064.8896,  8181.9136,
         8681.2705,  9518.8262,  8431.3496,  7811.3989,  7865.2686,  9251.9062,
         7978.7344,  6783.2949, 10138.9668, 16100.6582,  9609.9121,  5061.7222,
        11576.3613,  8167.0669, 11564.6250, 12139.4160,  8850.4727,  9296.0205,
         8398.2002,  9229.8496,  9771.2656,  8812.0615, 11613.8418, 12545.9990,
        10001.0254, 11173.2031,  9295.8398, 10489.0762,  7786.9473,  6496.6143,
         9515.7266, 11050.4346,  8908.1543,  8808.8838,  8845.2891, 11031.9961,
        10922.5186, 10156.8770, 10924.4648, 11355.5830, 11928.5771,  8845.4814,
         7488.6382,  6888.4722, 12714.6689,  9141.5957, 10913.9795, 11106.4150,
        12333.5039,  8276.2773,  9017.9443,  9930.6533, 14752.6621, 10307.8486,
        11800.5322,  8573.1172,  5717.9214,  7622.0229, 12154.8125,  9539.4385,
        10409.9629,  8029.0391,  8392.4932,  8990.0928, 10281.6846, 11498.1484,
        11356.8018,  9217.8105,  8941.6680, 11449.8984,  9285.7129, 13379.0225,
         7320.0278, 10626.4395,  7809.5742, 10436.0898, 11113.7119,  7522.2861,
         8634.5078, 12942.5498,  9605.9756, 14167.7920,  9025.2305,  5899.2271,
         6437.5171, 10837.0410, 12542.6699,  9435.7617, 13220.9248,  8589.8545,
        10486.9756, 11361.6748,  5701.9443, 12099.2461, 11067.6221, 10365.0332,
        12303.0586,  6411.9199, 10712.4053,  5677.1313,  9228.3994, 11972.1084,
         8594.9766, 12840.0049,  9616.0127,  8322.7012,  8887.9727,  9167.6152,
         7137.4067, 10629.0527,  9454.4209, 10536.2314, 10149.8652,  9404.1201,
        13781.8799, 10670.7314,  9067.2080, 10580.3701, 12356.4141,  8547.6465,
        12631.2422, 10941.7217, 13845.7422,  8552.3535,  8968.1025, 10805.3018,
        10567.4834, 13343.8525,  9554.4951, 16182.6738,  7801.6729, 12437.3965,
        11911.2188,  9594.4375,  9677.4551,  8519.8145, 10089.7236,  8184.0522,
         8480.6123,  6646.1416,  9670.0303,  7032.7998,  6014.2783,  9800.6094,
        10246.9873, 11583.2197, 12617.2568, 15744.3525,  9814.6162,  9983.1289,
         9280.5244,  7753.8569, 12103.7402,  8432.6670,  9867.6641, 10101.8369,
         8794.7314,  9698.8086, 10586.2227,  8197.6758, 10501.5000,  9875.1475,
        10633.0420,  8185.1499, 10353.8154, 11245.6035, 11701.1797,  6573.4561,
        10118.5479,  9375.1934,  7778.8779, 10125.7393,  8388.6816,  9859.2725,
        12723.8896,  9026.2510, 10856.4238, 11200.2119, 11231.3613, 15628.2607,
        11750.2100, 11229.8545,  7763.7056, 11858.8057, 12840.5391,  8456.3730,
         8054.1250,  6751.9053,  7071.8203, 14181.9648,  8414.3379,  7866.4873,
        12706.9854, 10275.2949,  8288.7900, 10502.2988, 10845.3232, 10938.3623,
         6945.1641,  8749.2031,  6541.2998,  8731.1553,  7491.4805,  9344.7842,
         9641.4209, 13561.6309, 10506.2666,  8579.3291, 10124.2471, 10453.9971,
         9156.7627, 12604.5732,  8076.8696, 10416.8350,  7646.2852,  7050.7788,
         9995.2471, 12616.6523, 10497.8105,  8951.4531,  9170.9141, 11827.8232,
         9924.1836, 10933.9678,  8365.7031, 11595.2061,  8630.6572, 11473.6719,
         9428.3027, 12445.8965, 10875.3311, 11699.3555,  9388.5527,  9370.1152,
         9573.9551,  9598.3555, 10891.0762, 11343.7012,  5874.8975,  7948.0571,
         9895.4658,  8886.8242,  8400.8857,  9874.5029,  6764.2329,  8446.0186,
         8101.9565, 11379.2578, 10361.0859, 13880.9365, 10693.8721,  7234.0767,
         8489.6055,  6920.7773,  6711.5845, 11262.4551,  8528.0859,  6349.3789,
        10611.8574, 11572.9424,  8418.2598, 14007.8271, 10928.9902, 10594.6426,
         9134.6855,  7443.4321,  7159.3091,  9182.0332,  7209.0879, 10128.5791,
         7935.3960, 17711.4277,  8484.2266,  8465.3457,  8596.2705,  6785.1978,
         9105.5889, 10638.0693, 10268.0732, 10297.2920,  9841.7109,  9447.1514,
        10131.4492,  9091.2549, 11980.3066,  7426.2529,  6658.1836,  9460.6973,
        11200.1309, 12004.7637,  9880.6982, 11468.5146,  8810.4541, 12054.2881,
        10768.5566, 10180.1953, 10103.6572, 10409.6240, 13993.1953,  8328.7842,
        10742.3145, 10784.6074, 10335.9189, 11906.9238, 12269.3320,  9566.2314,
         7163.8794,  9270.8506,  8786.1504,  9254.2266, 15282.6641,  6931.2783,
        10572.0547,  9663.0068, 11704.3730,  8172.4844,  9024.7021,  7261.4404,
         7364.1475,  6192.9624,  9164.3350,  8023.5859,  9870.4502, 11773.6943,
         8987.0381,  8851.7998,  7352.4253,  7649.7310, 11285.7197,  8284.8623,
        11667.8262,  7603.1362,  7817.0259,  8069.2529, 10469.6992, 13708.9570,
        10476.6660,  8435.8262,  6795.1714,  6549.9717, 11095.3311,  7117.3628,
        12113.3242,  9776.6357, 10594.7705,  5272.5718,  7503.5464,  8532.2285,
         8818.5957,  7206.6353])
Layer: encoder.7.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 118.0712,  546.9335,  114.4285,  ...,  126.8533, 2132.0208,
         143.9166])
Layer: encoder.7.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 616.5471,  750.8711, 1369.0885,  828.1767,  781.1356, 1271.6578,
         878.8856,  770.2664, 1007.0651, 1039.2075, 1356.0624,  699.5085,
        1197.9296,  680.4980,  660.1960,  851.4455, 1065.1853,  874.1011,
        1000.3014, 1346.8137,  940.8605, 1027.5164, 1072.1289,  705.5347,
         973.7184,  890.8704, 1033.9706,  969.6160,  890.2390,  941.7475,
         830.8401, 1004.7433,  870.0487,  726.7114, 1100.6831, 1435.6398,
         637.6270,  830.2932,  905.1024,  985.5331,  549.2230,  898.6003,
         776.3402,  834.1710,  645.2778,  848.4244,  811.0090,  654.2768,
         803.8221, 1244.8134, 1090.0858,  896.2266,  786.2891,  773.2599,
         767.4223, 1248.6437, 1022.6850,  934.7095, 1379.4493,  485.1376,
        1286.8699,  676.1944,  868.9517,  593.5970,  837.7775,  706.8795,
         855.1815, 1090.6405,  710.9671, 1116.6493,  827.8793,  596.4240,
         928.8420,  972.2971,  781.8321, 1006.2974,  644.3405, 1146.1555,
        1211.8715, 1049.7386, 1049.9746, 1034.9133,  838.1613,  912.3002,
        1088.5548, 1258.5100,  958.9102,  700.1312,  963.6256,  674.9759,
         842.3366,  677.0551,  934.2293, 1044.0513,  700.9754,  710.6796,
         735.8820,  896.8818,  868.9328, 1093.0138, 1063.9978, 1042.8770,
        1064.9119, 1079.1923,  915.2776,  684.4492,  860.9395,  544.8171,
         862.8762,  868.8055, 1150.2413, 1037.7212, 1160.5685,  841.9902,
        1087.4351,  974.3293,  891.7919,  688.3720,  792.4082, 1340.2734,
         901.8093,  918.8015,  880.3596,  796.4698,  850.6225,  889.7582,
        1032.1991,  672.7556,  851.3098, 1157.1589,  647.5233,  868.7255,
        1176.7413,  808.0858, 1107.7230, 1010.0277,  905.7562,  925.5717,
         822.2286,  890.3389,  876.1743,  846.8729,  754.2147,  655.6583,
         893.7608, 1234.1531,  800.2306,  855.0031,  876.0625, 1052.7477,
         627.1703, 1004.6254,  815.5856,  968.6163,  884.7571,  930.2807,
         720.2972,  702.5990,  829.9000,  941.9445,  907.9567, 1073.5525,
        1167.7062,  495.8408, 1407.7572,  728.2503,  573.3571, 1160.9027,
         781.0854, 1156.8220, 1038.7280, 1423.9924,  912.4493,  951.3311,
        1218.2305,  860.0080,  540.8375,  755.3082, 1125.1964, 1315.0518,
         948.2828,  896.0597,  797.6093,  887.6299,  889.1934,  550.0568,
         899.0266,  920.8211,  936.7645,  718.7068,  824.1307,  975.4059,
         945.3390,  939.6982,  660.4632,  936.8899,  917.0330, 1101.3672,
        1584.3589,  679.6885,  731.2642,  878.9845,  930.5823,  893.1287,
        1177.1162,  842.4559,  961.0969,  676.1750,  668.9670, 1139.9917,
         774.3640,  757.1678,  769.5474, 1061.4878,  826.9955, 1088.9420,
         540.1139,  791.7169,  868.8394,  924.0861,  896.5743, 1305.4709,
         668.8387,  776.3857, 1067.6849, 1059.9110,  950.9677,  904.9550,
         749.8819,  865.7174, 1082.2292, 1183.8687,  844.1685, 1595.0146,
        1093.3246,  905.9055,  803.0554,  831.3281, 1130.7881, 1148.8223,
         860.3745,  741.0916,  778.4135,  980.8918,  896.5600,  829.5781,
        1115.3270,  740.2319,  777.8695, 1080.9718,  743.4712,  796.5103,
        1325.4141,  759.1207,  734.6196,  931.0722,  735.8259, 1139.1469,
        1050.1647, 1238.6979, 1200.8876,  819.8457,  771.4413,  714.2753,
        1061.3453,  860.9635, 1058.0842, 1050.0687,  965.0972,  632.6713,
        1227.5377, 1056.4399,  885.4376,  880.3338, 1202.0490,  762.1681,
         785.4566, 1000.7684,  852.9536,  968.3158, 1033.8214,  904.7241,
        1044.4724,  868.9852,  896.0237,  848.6964,  668.9134,  938.7479,
         781.6609,  914.3437, 1570.2222,  561.3370, 1178.0029,  551.3172,
         916.5925,  903.5728,  771.3284,  672.5436, 1364.7863,  633.1663,
        1137.8716, 1031.3253,  997.6668,  660.7988,  997.3748, 1065.3038,
        1084.5966,  823.8030,  809.2847,  845.6132,  897.2048,  844.9459,
         945.9937,  787.9166,  985.8352, 1014.6508,  654.6450,  615.4466,
         827.3744, 1214.7872, 1306.7250, 1700.2489,  863.8245, 1036.3586,
         933.8174,  709.2609, 1116.4767,  800.8735,  846.4641,  979.6498,
        1058.3215,  777.1584, 1029.2014,  804.0207,  753.8995,  771.6016,
         935.8585,  715.8237,  905.3193,  718.8580, 1033.6431,  624.9327,
        1508.9325, 1216.8354, 1169.9752, 1181.4537,  985.4390, 1194.7271,
         906.3250, 1029.7205, 1054.0800, 1809.4990,  603.3683,  841.1732,
         759.1310, 1163.1857,  786.9812, 1308.2228,  942.9348,  706.6623,
         620.8674,  980.9643,  826.2457,  989.1661,  801.0279, 1109.1848,
        1124.6302,  743.6108,  857.2784,  742.1378,  818.7593,  762.6072,
        1298.2084, 1031.8690,  697.1373, 1139.1805,  676.1242,  809.2120,
        1165.2406,  927.4029, 1124.7963, 1140.4205, 1037.5735,  907.7326,
         718.0699, 1008.8357, 1072.9104,  686.0710,  939.7145,  985.4301,
         953.9132, 1205.8418,  936.5685,  528.6085, 1216.4960,  702.0140,
         479.5972,  924.8870,  912.2148,  734.9821, 1043.1741, 1117.6340,
        1028.2589,  852.4159, 1152.9271,  891.1695, 1188.2302, 1036.3633,
         782.3419,  693.0582,  771.7468, 1110.9800, 1158.9098,  852.9283,
        1106.3735,  943.9701, 1186.4376,  919.4079,  794.6326,  953.6455,
         913.1871, 1143.7578,  894.7465,  579.4211, 1050.6171,  603.0995,
        1240.8483, 1219.0840,  831.9561,  621.6820,  760.9950, 1288.9396,
         604.8386,  795.2986,  877.5202,  809.8055,  964.9612, 1663.4730,
         969.7060, 1062.2179,  746.2615, 1122.1908, 1178.3544, 1204.8405,
         794.6618,  845.1770,  741.0020, 1293.9563,  574.9089, 1050.7777,
        1012.0420, 1287.8153,  740.1085,  992.3722,  762.1898,  871.4024,
         759.8755, 1097.2397, 1211.1997,  631.7013,  734.3499,  982.9113,
        1272.8049,  870.7593,  771.0717,  958.3649,  891.1626, 1181.6892,
        1317.8059, 1029.3417,  695.8906, 1153.3521, 1094.8092,  697.6052,
         891.1058,  648.2968, 1052.0421,  770.9675, 1048.9326, 1026.5825,
         743.3098,  659.6864,  773.3444,  693.1000,  750.5129,  683.6309,
         620.7532,  795.2427,  821.0116, 1276.2410,  859.6572,  695.0760,
         810.5569, 1078.9619,  804.9250,  844.7285,  602.1663,  884.7951,
         950.9562, 1608.3497, 1050.5770,  813.0264,  912.5083,  693.7101,
         801.1349, 1178.3129, 1173.9263,  809.3104,  699.9821,  872.5480,
         487.6529,  958.6201])
Layer: encoder.7.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 8016.3140, 10804.9326, 11303.4814,  8115.0723,  5245.1245, 10303.1953,
        12867.0127, 12393.4971,  6961.2788,  8927.4219, 13871.3799, 10881.4355,
         8399.9619,  9334.6709,  8452.4092,  8464.6426,  9644.2070,  8280.9160,
         9581.9775, 10004.9268,  6499.9844, 10192.0273,  8192.8838,  9468.8223,
         9802.1621,  7453.5601,  9710.6602, 11290.4844, 12017.7334, 10688.8135,
         8497.9961,  6778.0503,  8970.4932, 10694.5439,  7707.4526,  9068.2734,
         7651.6108,  8740.6826,  9021.8936,  8211.4580,  8872.5332,  7749.9092,
         8443.4932, 10317.4736,  9847.7051,  8573.9746,  8762.2627, 12538.9307,
        13128.3945, 15033.8340,  9033.3750, 11500.3301,  9381.6426, 11679.7920,
         6725.2803, 13478.8945,  8110.8438,  9715.9756,  8510.0156,  8804.0205,
        12057.5176,  8758.4551, 10462.1895,  9938.8076,  7616.4175,  9343.0928,
         9632.8428, 11244.2773,  7786.7104,  8480.6426,  8866.7119,  6982.2632,
        10278.8047,  6757.1113, 11838.2949, 11019.6309, 11241.2705,  9762.4766,
        10334.1904,  8043.4077, 11283.5020,  8176.3013,  8634.1494, 10336.9990,
        10292.7344,  9318.1338,  8632.6914,  5174.9717,  6944.9097, 11530.8086,
         9281.9043,  9321.0137, 10204.0723,  5677.0762,  8232.2188,  7725.4302,
        10585.4160, 10575.3174, 11543.3252, 10336.1641,  8428.5566,  6242.3486,
         7980.4663, 14265.4443,  8591.5303, 12491.7051, 10813.3271,  8954.2461,
         9141.6836,  9913.5693,  9169.7314,  9615.3936,  7262.3032,  9503.2510,
         7514.3838, 18270.3457,  9382.7676,  6705.6416,  6837.4458,  7801.6836,
        11333.5762, 14493.2412,  7020.8477,  8321.0361,  9463.2490, 10747.5674,
        12493.8115,  6681.5488, 12173.9453, 10850.8174, 12269.9072, 10141.5273,
         8608.8467,  8126.8965,  7361.0146,  5384.8652,  9248.8223,  7468.5728,
         8821.1943,  8385.1934, 12571.4150,  7469.7188,  6172.6826,  8763.4277,
         6095.4790, 12550.2520, 12771.8730, 10681.0576, 13045.9375,  8615.9863,
         9488.0371,  7595.6968,  8466.3613,  7689.6733,  7202.7568, 11311.0967,
         6716.5806, 10238.9707,  8119.6533,  8437.3740,  6703.3037, 13037.2432,
        11830.4121, 11830.3916,  8923.0850, 13140.8779, 10097.2852,  7902.1670,
        13624.4619, 11973.9463, 14050.8516,  8288.5381, 10334.9238, 10699.8330,
         9586.9307, 11250.5605,  9600.2568,  7115.6968,  7724.8018, 10206.6367,
        10738.4902,  9535.3125,  8793.6348, 10640.4092, 11206.4297, 12135.6094,
         8042.0645,  9581.1055,  8127.3247,  7324.7441, 13969.4424, 11967.9219,
         8765.6309,  8714.1611, 13068.5010,  8628.3936, 13670.5986,  6469.1885,
        10531.0703, 12990.7305, 10871.3750, 10480.4609,  9000.9756, 11610.3809,
        11369.4170, 11178.1924,  7224.6357,  5991.2974, 12596.8574,  9416.2529,
         8132.8730,  8856.9404, 10134.0479, 13607.7705,  8603.4990,  6999.7847,
        10249.7510,  8926.1592, 10157.2812, 10058.9834,  7858.0454,  6033.1631,
         7594.6772, 12779.2412,  8862.7441, 12349.3145, 11399.0801,  9432.3076,
         8558.5098,  9413.0557,  9015.0986,  9297.6709, 12129.1875,  9560.6523,
         9414.6865, 10402.4160, 16532.5371, 10198.9209, 14086.0479,  9255.0068,
        11104.4111,  9399.7168, 12290.7285,  5639.9541, 12193.0840,  9395.0127,
        10006.2861, 10759.4287,  8706.3525, 10773.1738, 13250.5703,  8368.5645,
         6396.1064,  9920.8398, 10130.7031, 10623.5547,  7999.4512, 12979.9893,
         7917.3730,  7637.8003,  9230.2783, 11997.3799,  9978.3623, 10508.1660,
         7271.3867, 10366.1133, 10305.6914,  7733.8647, 11720.1416,  8589.8672,
         9146.8623, 10980.1436,  6926.1392, 12320.8584, 13653.8281, 13233.9805,
         8106.4658,  9549.8818,  8656.4990,  9089.8496, 11434.3291,  8948.8027,
        13930.3447,  7453.9209,  8591.2666,  6332.2505, 12780.5732, 10822.3320,
         5985.9932, 10254.9658,  7964.9741,  8710.5557, 11705.0469, 10992.0957,
        11965.9990,  9163.9883, 12498.9502,  6973.1826,  9713.9746,  7737.0410,
         8213.2373,  9972.0859, 10433.7334,  5925.4590, 11661.6387,  6830.6802,
         8409.6396,  8769.1416,  8309.6934,  7212.3364,  8567.3984, 11978.7461,
        11597.2920,  9659.6396,  7816.4819,  6204.4297, 13065.1445, 11656.3086,
         6287.9209, 10027.0713,  6753.5308, 13781.2695, 11636.2227,  9833.2793,
         9270.6143, 12280.6309,  8411.0332,  9737.7910, 11079.9824,  7230.1392,
         9376.4805, 10530.9385, 14799.5039,  9989.2607, 10922.9268, 11607.0674,
        11062.0684, 14645.4326,  8836.4082,  9271.5537,  9684.0127,  8999.3066,
        14255.0889, 12032.8760,  4269.1143, 14309.7275,  9863.4766, 10039.5352,
        10740.7070, 10652.5078,  7607.1577, 12952.7236,  7885.8809,  5809.4585,
         8337.5654,  7700.4937, 11365.6133, 14268.0312, 12456.2188, 13601.9102,
        10830.6152, 12168.8184, 11944.2422, 11221.2158,  9778.5879,  9897.0381,
         7775.7261,  9182.8984, 10568.2783, 14446.7207, 12194.5566,  5359.7891,
         9506.1826, 14261.0918, 15794.7090, 10198.6494, 10519.1680,  9208.2285,
        10578.2080,  9632.5566,  9707.8018,  9057.3457,  6130.7925, 12231.7666,
         7134.2568,  7597.7456, 10367.8887,  9057.8477, 14507.4268, 15211.2764,
         9700.4277,  9095.0869, 11909.9258,  9149.6953, 10647.9287,  7843.8086,
         8499.8584, 15001.1504, 10619.2979, 12565.9258,  8821.3086,  8070.9927,
        11100.6885,  7440.6323,  7461.1211,  7819.8467, 11895.1543, 14486.9473,
        12107.0635,  9224.3818, 11024.4619, 11209.6299, 12358.4824, 13532.6289,
        12013.6562,  8075.9653,  9898.1260,  7349.0376,  8418.0879, 13587.4121,
        11596.2275, 10683.1201, 10054.3105, 10199.8828,  8313.1426,  9604.8223,
         9487.1816, 13837.7803,  9287.4805, 12451.6016,  7333.4248, 11192.1719,
        10060.0996,  8608.6895,  9437.5947, 10883.9209, 11290.6357,  8417.3857,
         8130.1123, 11234.9727,  9671.6797,  9106.2852,  7760.3330,  6814.2544,
         8045.7388,  8263.8818, 10290.0742, 10981.6064, 15128.4756,  8706.7627,
         9416.8740,  7758.7090, 11093.2334,  5548.6167,  7900.3540,  5375.4302,
        11431.9131, 10824.3613,  7955.5859, 11826.9639,  8677.1611,  9721.8857,
         9281.9443,  8011.7573,  9875.4492, 11016.8271,  9519.3564,  9786.6357,
        12245.9395, 15507.4229,  6738.4795,  9932.0547, 10524.4512, 11679.9395,
        10832.1172, 12997.9258, 10965.3604, 11521.5449,  8701.0830, 12262.2666,
        15624.2393,  9322.7764, 10332.8721, 12008.3984, 15771.6865,  9484.8047,
        14624.6445,  9081.7686,  9477.9619,  9999.2139,  8261.4941, 10892.7129,
         7312.1655,  9547.0742, 10348.9316,  7630.3110,  7375.3628,  8873.9297,
        11869.4521,  8912.1182, 11858.6240,  9190.2480,  6773.4141, 11263.9062,
         9800.6240,  7064.6738,  9453.7939, 10779.2920, 10163.1387, 10066.0049,
         6829.5732, 13186.8564])
Layer: encoder.7.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 230.8958,  115.4006,    0.0000,  ...,  298.0926, 1525.0974,
           0.0000])
[DEBUG] Global concept maps computed with 53 layers.
[INFO] Using device: cuda
Layer: conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.4.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.4.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.4.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.4.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.4.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.4.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.4.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0.], device='cuda:0')}}
Layer: encoder.5.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1.], device='cuda:0')}}
Layer: encoder.5.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0.], device='cuda:0')}}
Layer: encoder.5.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.5.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1.], device='cuda:0')}}
Layer: encoder.5.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.5.3.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.3.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1.], device='cuda:0')}}
Layer: encoder.5.3.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.6.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.6.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.6.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.6.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.6.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.6.3.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.3.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.3.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.6.4.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.6.4.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.6.4.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.7.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.7.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.7.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.7.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.7.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.7.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.7.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 1., 1., 0.], device='cuda:0')}}
[DEBUG] Global pruning mask: OrderedDict([('conv1', {'Conv2d': {'weight': tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0')}}), ('encoder.4.0.conv1', {'Conv2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0')}}), ('encoder.4.0.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0')}}), ('encoder.4.0.conv3', {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1.], device='cuda:0')}}), ('encoder.4.0.downsample.0', {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}}), ('encoder.4.1.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.1.conv2', {'Conv2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0')}}), ('encoder.4.1.conv3', {'Conv2d': {'weight': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.2.conv1', {'Conv2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.2.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0')}}), ('encoder.4.2.conv3', {'Conv2d': {'weight': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.0.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0.], device='cuda:0')}}), ('encoder.5.0.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0.], device='cuda:0')}}), ('encoder.5.0.conv3', {'Conv2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.0.downsample.0', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.1.conv1', {'Conv2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 1.], device='cuda:0')}}), ('encoder.5.1.conv2', {'Conv2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 0.], device='cuda:0')}}), ('encoder.5.1.conv3', {'Conv2d': {'weight': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0')}}), ('encoder.5.2.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}}), ('encoder.5.2.conv2', {'Conv2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1.], device='cuda:0')}}), ('encoder.5.2.conv3', {'Conv2d': {'weight': tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0')}}), ('encoder.5.3.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1.], device='cuda:0')}}), ('encoder.5.3.conv2', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        0., 1.], device='cuda:0')}}), ('encoder.5.3.conv3', {'Conv2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0')}}), ('encoder.6.0.conv1', {'Conv2d': {'weight': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.0.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.0.conv3', {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.0.downsample.0', {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0')}}), ('encoder.6.1.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.1.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.1.conv3', {'Conv2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}}), ('encoder.6.2.conv1', {'Conv2d': {'weight': tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0.], device='cuda:0')}}), ('encoder.6.2.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}}), ('encoder.6.2.conv3', {'Conv2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0')}}), ('encoder.6.3.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.3.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.3.conv3', {'Conv2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 1.], device='cuda:0')}}), ('encoder.6.4.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0')}}), ('encoder.6.4.conv2', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        1., 1., 0., 0.], device='cuda:0')}}), ('encoder.6.4.conv3', {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:0')}}), ('encoder.6.5.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 0., 1.], device='cuda:0')}}), ('encoder.6.5.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.5.conv3', {'Conv2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 0., 0.,  ..., 1., 0., 0.], device='cuda:0')}}), ('encoder.7.0.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')}}), ('encoder.7.0.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.0.conv3', {'Conv2d': {'weight': tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.0.downsample.0', {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')}}), ('encoder.7.1.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0')}}), ('encoder.7.1.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0')}}), ('encoder.7.1.conv3', {'Conv2d': {'weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.2.conv1', {'Conv2d': {'weight': tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1.], device='cuda:0')}}), ('encoder.7.2.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 0., 1.], device='cuda:0')}}), ('encoder.7.2.conv3', {'Conv2d': {'weight': tensor([1., 1., 0.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0.,  ..., 1., 1., 0.], device='cuda:0')}})])
Full profiling results saved to /home/paul/projects/CV4RS-main/pruning_callgraph.txt
=== Round 2/3 ===
Applying pruning mask for Round 2...
[DEBUG] Validating mask for layer: conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 10, 7, 7])
[INFO] Successfully applied mask to weight in layer: conv1
[DEBUG] Layer conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 10, 7, 7])
[INFO] Successfully applied mask to weight in layer: conv1
[DEBUG] Layer conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: conv1
[DEBUG] Validating mask for layer: encoder.4.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv1
[DEBUG] Layer encoder.4.0.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv1
[DEBUG] Layer encoder.4.0.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv1
[DEBUG] Validating mask for layer: encoder.4.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv2
[DEBUG] Layer encoder.4.0.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv2
[DEBUG] Layer encoder.4.0.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv2
[DEBUG] Validating mask for layer: encoder.4.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv3
[DEBUG] Layer encoder.4.0.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv3
[DEBUG] Layer encoder.4.0.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv3
[DEBUG] Validating mask for layer: encoder.4.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.downsample.0
[DEBUG] Layer encoder.4.0.downsample.0 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.downsample.0
[DEBUG] Layer encoder.4.0.downsample.0 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.downsample.0
[DEBUG] Validating mask for layer: encoder.4.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv1
[DEBUG] Layer encoder.4.1.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv1
[DEBUG] Layer encoder.4.1.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv1
[DEBUG] Validating mask for layer: encoder.4.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv2
[DEBUG] Layer encoder.4.1.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv2
[DEBUG] Layer encoder.4.1.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv2
[DEBUG] Validating mask for layer: encoder.4.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv3
[DEBUG] Layer encoder.4.1.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv3
[DEBUG] Layer encoder.4.1.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv3
[DEBUG] Validating mask for layer: encoder.4.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv1
[DEBUG] Layer encoder.4.2.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv1
[DEBUG] Layer encoder.4.2.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv1
[DEBUG] Validating mask for layer: encoder.4.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv2
[DEBUG] Layer encoder.4.2.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv2
[DEBUG] Layer encoder.4.2.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv2
[DEBUG] Validating mask for layer: encoder.4.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv3
[DEBUG] Layer encoder.4.2.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv3
[DEBUG] Layer encoder.4.2.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv3
[DEBUG] Validating mask for layer: encoder.5.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv1
[DEBUG] Layer encoder.5.0.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv1
[DEBUG] Layer encoder.5.0.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv1
[DEBUG] Validating mask for layer: encoder.5.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv2
[DEBUG] Layer encoder.5.0.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv2
[DEBUG] Layer encoder.5.0.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv2
[DEBUG] Validating mask for layer: encoder.5.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv3
[DEBUG] Layer encoder.5.0.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv3
[DEBUG] Layer encoder.5.0.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv3
[DEBUG] Validating mask for layer: encoder.5.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.downsample.0
[DEBUG] Layer encoder.5.0.downsample.0 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.downsample.0
[DEBUG] Layer encoder.5.0.downsample.0 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.downsample.0
[DEBUG] Validating mask for layer: encoder.5.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv1
[DEBUG] Layer encoder.5.1.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv1
[DEBUG] Layer encoder.5.1.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv1
[DEBUG] Validating mask for layer: encoder.5.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv2
[DEBUG] Layer encoder.5.1.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv2
[DEBUG] Layer encoder.5.1.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv2
[DEBUG] Validating mask for layer: encoder.5.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv3
[DEBUG] Layer encoder.5.1.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv3
[DEBUG] Layer encoder.5.1.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv3
[DEBUG] Validating mask for layer: encoder.5.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv1
[DEBUG] Layer encoder.5.2.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv1
[DEBUG] Layer encoder.5.2.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv1
[DEBUG] Validating mask for layer: encoder.5.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv2
[DEBUG] Layer encoder.5.2.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv2
[DEBUG] Layer encoder.5.2.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv2
[DEBUG] Validating mask for layer: encoder.5.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv3
[DEBUG] Layer encoder.5.2.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv3
[DEBUG] Layer encoder.5.2.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv3
[DEBUG] Validating mask for layer: encoder.5.3.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv1
[DEBUG] Layer encoder.5.3.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv1
[DEBUG] Layer encoder.5.3.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv1
[DEBUG] Validating mask for layer: encoder.5.3.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv2
[DEBUG] Layer encoder.5.3.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv2
[DEBUG] Layer encoder.5.3.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv2
[DEBUG] Validating mask for layer: encoder.5.3.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv3
[DEBUG] Layer encoder.5.3.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv3
[DEBUG] Layer encoder.5.3.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv3
[DEBUG] Validating mask for layer: encoder.6.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv1
[DEBUG] Layer encoder.6.0.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv1
[DEBUG] Layer encoder.6.0.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv1
[DEBUG] Validating mask for layer: encoder.6.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv2
[DEBUG] Layer encoder.6.0.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv2
[DEBUG] Layer encoder.6.0.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv2
[DEBUG] Validating mask for layer: encoder.6.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv3
[DEBUG] Layer encoder.6.0.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv3
[DEBUG] Layer encoder.6.0.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv3
[DEBUG] Validating mask for layer: encoder.6.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.downsample.0
[DEBUG] Layer encoder.6.0.downsample.0 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.downsample.0
[DEBUG] Layer encoder.6.0.downsample.0 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.downsample.0
[DEBUG] Validating mask for layer: encoder.6.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv1
[DEBUG] Layer encoder.6.1.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv1
[DEBUG] Layer encoder.6.1.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv1
[DEBUG] Validating mask for layer: encoder.6.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv2
[DEBUG] Layer encoder.6.1.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv2
[DEBUG] Layer encoder.6.1.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv2
[DEBUG] Validating mask for layer: encoder.6.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv3
[DEBUG] Layer encoder.6.1.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv3
[DEBUG] Layer encoder.6.1.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv3
[DEBUG] Validating mask for layer: encoder.6.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv1
[DEBUG] Layer encoder.6.2.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv1
[DEBUG] Layer encoder.6.2.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv1
[DEBUG] Validating mask for layer: encoder.6.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv2
[DEBUG] Layer encoder.6.2.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv2
[DEBUG] Layer encoder.6.2.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv2
[DEBUG] Validating mask for layer: encoder.6.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv3
[DEBUG] Layer encoder.6.2.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv3
[DEBUG] Layer encoder.6.2.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv3
[DEBUG] Validating mask for layer: encoder.6.3.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv1
[DEBUG] Layer encoder.6.3.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv1
[DEBUG] Layer encoder.6.3.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv1
[DEBUG] Validating mask for layer: encoder.6.3.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv2
[DEBUG] Layer encoder.6.3.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv2
[DEBUG] Layer encoder.6.3.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv2
[DEBUG] Validating mask for layer: encoder.6.3.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv3
[DEBUG] Layer encoder.6.3.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv3
[DEBUG] Layer encoder.6.3.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv3
[DEBUG] Validating mask for layer: encoder.6.4.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv1
[DEBUG] Layer encoder.6.4.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv1
[DEBUG] Layer encoder.6.4.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv1
[DEBUG] Validating mask for layer: encoder.6.4.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv2
[DEBUG] Layer encoder.6.4.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv2
[DEBUG] Layer encoder.6.4.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv2
[DEBUG] Validating mask for layer: encoder.6.4.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv3
[DEBUG] Layer encoder.6.4.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv3
[DEBUG] Layer encoder.6.4.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv3
[DEBUG] Validating mask for layer: encoder.6.5.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv1
[DEBUG] Layer encoder.6.5.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv1
[DEBUG] Layer encoder.6.5.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv1
[DEBUG] Validating mask for layer: encoder.6.5.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv2
[DEBUG] Layer encoder.6.5.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv2
[DEBUG] Layer encoder.6.5.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv2
[DEBUG] Validating mask for layer: encoder.6.5.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv3
[DEBUG] Layer encoder.6.5.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv3
[DEBUG] Layer encoder.6.5.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv3
[DEBUG] Validating mask for layer: encoder.7.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv1
[DEBUG] Layer encoder.7.0.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv1
[DEBUG] Layer encoder.7.0.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv1
[DEBUG] Validating mask for layer: encoder.7.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv2
[DEBUG] Layer encoder.7.0.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv2
[DEBUG] Layer encoder.7.0.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv2
[DEBUG] Validating mask for layer: encoder.7.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv3
[DEBUG] Layer encoder.7.0.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv3
[DEBUG] Layer encoder.7.0.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv3
[DEBUG] Validating mask for layer: encoder.7.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.downsample.0
[DEBUG] Layer encoder.7.0.downsample.0 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.downsample.0
[DEBUG] Layer encoder.7.0.downsample.0 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.downsample.0
[DEBUG] Validating mask for layer: encoder.7.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv1
[DEBUG] Layer encoder.7.1.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv1
[DEBUG] Layer encoder.7.1.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv1
[DEBUG] Validating mask for layer: encoder.7.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv2
[DEBUG] Layer encoder.7.1.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv2
[DEBUG] Layer encoder.7.1.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv2
[DEBUG] Validating mask for layer: encoder.7.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv3
[DEBUG] Layer encoder.7.1.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv3
[DEBUG] Layer encoder.7.1.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv3
[DEBUG] Validating mask for layer: encoder.7.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv1
[DEBUG] Layer encoder.7.2.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv1
[DEBUG] Layer encoder.7.2.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv1
[DEBUG] Validating mask for layer: encoder.7.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv2
[DEBUG] Layer encoder.7.2.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv2
[DEBUG] Layer encoder.7.2.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv2
[DEBUG] Validating mask for layer: encoder.7.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv3
[DEBUG] Layer encoder.7.2.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv3
[DEBUG] Layer encoder.7.2.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv3
Training and communication for Round 2...
Epoch 1/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.2920220059154047
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.24112427540127984
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.42092125995262136
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.26470751573854634
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.24149957997316018
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.21756130357015416
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.20671980662905
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.19699365582405387
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.16496770119525764
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.16311297594194613
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.1625262976423473
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.16021188271832085
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.1636296791176559
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.1626652678720515
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.14496814507971353
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.1538070435202838
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.14908780717326814
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.14847210615144787
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.15356458354587985
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.16690711557596188
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.14443967214319645
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.1632119207644955
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.167911222044803
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.1684648618861665
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.1508009183516808
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.13983726586923687
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.13970980836909175
[DEBUG] Batch 27: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 27: 0.15352073104540573
[DEBUG] Batch 28: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 28: 0.1557096276228003
[DEBUG] Batch 29: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 29: 0.16074514662130412
[DEBUG] Batch 30: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 30: 0.15923079547349595
[DEBUG] Batch 31: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 31: 0.14075144100058026
[DEBUG] Batch 32: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 32: 0.15064537132073028
[DEBUG] Batch 33: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 33: 0.13445034816368898
[DEBUG] Batch 34: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 34: 0.14214368371222721
[DEBUG] Batch 35: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 35: 0.14270241315880708
[DEBUG] Batch 36: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 36: 0.15322211725766383
[DEBUG] Batch 37: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 37: 0.13015551103428302
[DEBUG] Batch 38: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 38: 0.12981832283028394
[DEBUG] Batch 39: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 39: 0.17135395418392307
[DEBUG] Batch 40: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 40: 0.15823827036230873
[DEBUG] Batch 41: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 41: 0.1384116442223822
[DEBUG] Batch 42: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 42: 0.1380724693063333
[DEBUG] Batch 43: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 43: 0.12787740244512705
[DEBUG] Batch 44: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 44: 0.14671896882593174
[DEBUG] Batch 45: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 45: 0.14158858410080932
[DEBUG] Batch 46: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 46: 0.14936178417553628
[DEBUG] Batch 47: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 47: 0.12837797558457528
[DEBUG] Batch 48: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 48: 0.12491158789737213
[DEBUG] Batch 49: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 49: 0.14103196097560355
[DEBUG] Batch 50: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 50: 0.1379334261621435
[DEBUG] Batch 51: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 51: 0.15340147238527527
[DEBUG] Batch 52: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 52: 0.13767242900105925
[DEBUG] Batch 53: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 53: 0.11971237148738467
[DEBUG] Batch 54: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 54: 0.13026584270743757
[DEBUG] Batch 55: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 55: 0.13008204940349594
[DEBUG] Batch 56: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 56: 0.14285769898815973
[DEBUG] Batch 57: Data shape: torch.Size([213, 10, 120, 120]), Labels shape: torch.Size([213, 19])
[DEBUG] Loss for batch 57: 0.1339120600928109
[INFO] Training epoch completed successfully.
Epoch 2/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.13326505981367068
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.13183998104489464
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.13334730707681594
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.12928579138953442
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.13471826318534688
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.1408133869009596
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.13401725283270935
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.12426666818228578
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.13481046946335318
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.13239262867273296
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.11651436766069342
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.1281561099917471
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.12512365875102843
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.1254778283508745
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.11533282533740997
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.12804985866314683
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.13031259768454173
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.1263087113300728
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.1281695567213455
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.13133990031378362
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.14061767062574063
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.12000727543178265
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.13606644921071367
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.1345941427448691
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.1294622827397132
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.12312241522562485
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.11787315880513387
[DEBUG] Batch 27: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 27: 0.1227727958785296
[DEBUG] Batch 28: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 28: 0.12857318079460536
[DEBUG] Batch 29: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 29: 0.12738808802768647
[DEBUG] Batch 30: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 30: 0.1311532735070976
[DEBUG] Batch 31: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 31: 0.11790079280912569
[DEBUG] Batch 32: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 32: 0.14898975145634488
[DEBUG] Batch 33: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 33: 0.12548942301077098
[DEBUG] Batch 34: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 34: 0.12719472940044302
[DEBUG] Batch 35: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 35: 0.1252278754261362
[DEBUG] Batch 36: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 36: 0.1103924244456364
[DEBUG] Batch 37: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 37: 0.12407614701456386
[DEBUG] Batch 38: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 38: 0.11308693024576756
[DEBUG] Batch 39: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 39: 0.12948032515015787
[DEBUG] Batch 40: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 40: 0.1285307613005358
[DEBUG] Batch 41: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 41: 0.11981542830376532
[DEBUG] Batch 42: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 42: 0.12155059416747241
[DEBUG] Batch 43: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 43: 0.11979539228748456
[DEBUG] Batch 44: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 44: 0.13334038445213386
[DEBUG] Batch 45: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 45: 0.11504628970105435
[DEBUG] Batch 46: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 46: 0.11060472048416467
[DEBUG] Batch 47: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 47: 0.11096559155118718
[DEBUG] Batch 48: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 48: 0.1157344031344105
[DEBUG] Batch 49: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 49: 0.12112208805487759
[DEBUG] Batch 50: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 50: 0.11665402409856446
[DEBUG] Batch 51: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 51: 0.12424361884713388
[DEBUG] Batch 52: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 52: 0.1105335340584711
[DEBUG] Batch 53: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 53: 0.12052835434613698
[DEBUG] Batch 54: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 54: 0.12167947103738204
[DEBUG] Batch 55: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 55: 0.12159325289773375
[DEBUG] Batch 56: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 56: 0.11569593920496328
[DEBUG] Batch 57: Data shape: torch.Size([213, 10, 120, 120]), Labels shape: torch.Size([213, 19])
[DEBUG] Loss for batch 57: 0.11797839645533113
[INFO] Training epoch completed successfully.
Epoch 1/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.3110558290604576
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.200293690737647
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.19035610297270797
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.17728011682061973
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.16274778464164555
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.16506176329218586
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.17178094841870792
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.14583091967077913
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.13220583827944926
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.18294555286591468
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.16038813661583307
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.15019287084563657
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.1329989616775413
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.13778869834946864
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.15507839399649578
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.1436698271942683
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.1454996659342639
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.1349770002127276
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.11628459790072634
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.11780168870850713
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.12974922736299604
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.139132992855671
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.13595976804897064
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.13389860912203236
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.12980153390416066
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.13746940001815225
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.123840770531401
[DEBUG] Batch 27: Data shape: torch.Size([238, 10, 120, 120]), Labels shape: torch.Size([238, 19])
[DEBUG] Loss for batch 27: 0.13912253092510762
[INFO] Training epoch completed successfully.
Epoch 2/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.1590619941361464
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.1733860902872308
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.1491430995284618
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.15361209195429834
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.1427288591636681
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.14726225385321093
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.15515558193256881
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.12746071104003198
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.14354960859581203
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.12946804189226996
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.10777365348956308
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.1331774304053382
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.11491489645905928
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.12268736037258589
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.12792139312752673
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.13324628685231155
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.12868441571422615
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.10722970196436832
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.13098472439054082
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.11782358556463643
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.1430992161101422
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.12656515830193832
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.14952421364694937
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.1227327519117692
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.12348994627331789
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.12843827227811144
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.11204046318170335
[DEBUG] Batch 27: Data shape: torch.Size([238, 10, 120, 120]), Labels shape: torch.Size([238, 19])
[DEBUG] Loss for batch 27: 0.12747821353500552
[INFO] Training epoch completed successfully.
Epoch 1/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.4403251244426209
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.2747338423224939
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.2304813751800951
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.23646640606638047
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.22972508222087692
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.21295630036562804
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.20072285379170818
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.20030815338005573
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.1899637522397753
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.20189309068550038
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.21531229130867033
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.2498090627977196
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.19882690102990783
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.1907165541028874
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.19721062641072626
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.1632010417201393
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.18216240291306676
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.16788856846940534
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.17597587561543926
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.17083925937153657
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.1739345724970304
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.16942820510517698
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.17416090677512142
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.15966837786523727
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.16808915319810752
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.18173537757428523
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.17110793942354469
[DEBUG] Batch 27: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 27: 0.16792283183882412
[DEBUG] Batch 28: Data shape: torch.Size([12, 10, 120, 120]), Labels shape: torch.Size([12, 19])
[DEBUG] Loss for batch 28: 0.27143024885337674
[INFO] Training epoch completed successfully.
Epoch 2/2
----------
[DEBUG] Batch 0: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 0: 0.19522257476015617
[DEBUG] Batch 1: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 1: 0.18670115503182447
[DEBUG] Batch 2: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 2: 0.18200188607004877
[DEBUG] Batch 3: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 3: 0.18534613757075719
[DEBUG] Batch 4: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 4: 0.16956054081969854
[DEBUG] Batch 5: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 5: 0.17039195035991514
[DEBUG] Batch 6: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 6: 0.20004477301762227
[DEBUG] Batch 7: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 7: 0.19200166513863776
[DEBUG] Batch 8: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 8: 0.17643937545273203
[DEBUG] Batch 9: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 9: 0.18666196165703725
[DEBUG] Batch 10: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 10: 0.17218868267512719
[DEBUG] Batch 11: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 11: 0.1795815299002167
[DEBUG] Batch 12: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 12: 0.180500156079018
[DEBUG] Batch 13: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 13: 0.16483708508283634
[DEBUG] Batch 14: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 14: 0.16135099799434907
[DEBUG] Batch 15: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 15: 0.1875149375066998
[DEBUG] Batch 16: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 16: 0.1817464463966593
[DEBUG] Batch 17: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 17: 0.15501704771348734
[DEBUG] Batch 18: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 18: 0.16651333012360803
[DEBUG] Batch 19: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 19: 0.15861072540418325
[DEBUG] Batch 20: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 20: 0.15603948580953939
[DEBUG] Batch 21: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 21: 0.1675103759232181
[DEBUG] Batch 22: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 22: 0.16832479908669873
[DEBUG] Batch 23: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 23: 0.17662040082288222
[DEBUG] Batch 24: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 24: 0.1625279626359963
[DEBUG] Batch 25: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 25: 0.1659239827206794
[DEBUG] Batch 26: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 26: 0.1508519071990003
[DEBUG] Batch 27: Data shape: torch.Size([256, 10, 120, 120]), Labels shape: torch.Size([256, 19])
[DEBUG] Loss for batch 27: 0.15346645808049303
[DEBUG] Batch 28: Data shape: torch.Size([12, 10, 120, 120]), Labels shape: torch.Size([12, 19])
[DEBUG] Loss for batch 28: 0.20856241399551115
[INFO] Training epoch completed successfully.
Skipping missing parameter: conv1.bias
Skipping missing parameter: encoder.0.bias
Skipping missing parameter: encoder.4.0.conv1.bias
Skipping missing parameter: encoder.4.0.conv2.bias
Skipping missing parameter: encoder.4.0.conv3.bias
Skipping missing parameter: encoder.4.0.downsample.0.bias
Skipping missing parameter: encoder.4.1.conv1.bias
Skipping missing parameter: encoder.4.1.conv2.bias
Skipping missing parameter: encoder.4.1.conv3.bias
Skipping missing parameter: encoder.4.2.conv1.bias
Skipping missing parameter: encoder.4.2.conv2.bias
Skipping missing parameter: encoder.4.2.conv3.bias
Skipping missing parameter: encoder.5.0.conv1.bias
Skipping missing parameter: encoder.5.0.conv2.bias
Skipping missing parameter: encoder.5.0.conv3.bias
Skipping missing parameter: encoder.5.0.downsample.0.bias
Skipping missing parameter: encoder.5.1.conv1.bias
Skipping missing parameter: encoder.5.1.conv2.bias
Skipping missing parameter: encoder.5.1.conv3.bias
Skipping missing parameter: encoder.5.2.conv1.bias
Skipping missing parameter: encoder.5.2.conv2.bias
Skipping missing parameter: encoder.5.2.conv3.bias
Skipping missing parameter: encoder.5.3.conv1.bias
Skipping missing parameter: encoder.5.3.conv2.bias
Skipping missing parameter: encoder.5.3.conv3.bias
Skipping missing parameter: encoder.6.0.conv1.bias
Skipping missing parameter: encoder.6.0.conv2.bias
Skipping missing parameter: encoder.6.0.conv3.bias
Skipping missing parameter: encoder.6.0.downsample.0.bias
Skipping missing parameter: encoder.6.1.conv1.bias
Skipping missing parameter: encoder.6.1.conv2.bias
Skipping missing parameter: encoder.6.1.conv3.bias
Skipping missing parameter: encoder.6.2.conv1.bias
Skipping missing parameter: encoder.6.2.conv2.bias
Skipping missing parameter: encoder.6.2.conv3.bias
Skipping missing parameter: encoder.6.3.conv1.bias
Skipping missing parameter: encoder.6.3.conv2.bias
Skipping missing parameter: encoder.6.3.conv3.bias
Skipping missing parameter: encoder.6.4.conv1.bias
Skipping missing parameter: encoder.6.4.conv2.bias
Skipping missing parameter: encoder.6.4.conv3.bias
Skipping missing parameter: encoder.6.5.conv1.bias
Skipping missing parameter: encoder.6.5.conv2.bias
Skipping missing parameter: encoder.6.5.conv3.bias
Skipping missing parameter: encoder.7.0.conv1.bias
Skipping missing parameter: encoder.7.0.conv2.bias
Skipping missing parameter: encoder.7.0.conv3.bias
Skipping missing parameter: encoder.7.0.downsample.0.bias
Skipping missing parameter: encoder.7.1.conv1.bias
Skipping missing parameter: encoder.7.1.conv2.bias
Skipping missing parameter: encoder.7.1.conv3.bias
Skipping missing parameter: encoder.7.2.conv1.bias
Skipping missing parameter: encoder.7.2.conv2.bias
Skipping missing parameter: encoder.7.2.conv3.bias
[INFO] Starting validation for Round 2...
[DEBUG] Batch 0: Data shape: torch.Size([128, 10, 120, 120]), Labels shape: torch.Size([128, 19])
[ERROR] NaN or Inf detected in logits.
Logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')

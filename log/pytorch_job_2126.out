Lines that potentially need to be canonized 309
Using device: cuda:0
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    8209 filtered patches indexed
    8209 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7150 filtered patches indexed
    7150 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 15549 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    4263 filtered patches indexed
    4263 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    7180 filtered patches indexed
    7180 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 13683 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    3248 filtered patches indexed
    3248 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Pre-filtered 59999 patches based on country and season (split ignored)
Loading BEN data for test...
    119825 patches indexed
    15720 filtered patches indexed
    15720 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Initializing LRP Pruning...
LRP initialized successfully.
=== Round 1/3 ===
Training and communication for Round 1...
Epoch 1/2
----------
Epoch 2/2
----------
Epoch 1/2
----------
Epoch 2/2
----------
Epoch 1/2
----------
Epoch 2/2
----------
[INFO] Starting validation for Round 1...
True labels sample: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]
Predicted labels sample: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
Predicted probabilities sample: [[0.00215799 0.063286   0.00741985 0.05421506 0.00390465 0.01409645
  0.08667658 0.0033335  0.0827398  0.01960829 0.09375197 0.45587784
  0.04841464 0.00860167 0.00977775 0.0259342  0.00998052 0.06554838
  0.01364147]
 [0.00216271 0.06344921 0.00744724 0.05429102 0.00392899 0.01409817
  0.08729856 0.00334794 0.08284903 0.01968908 0.09388679 0.4551444
  0.04841862 0.00864513 0.00980608 0.02609886 0.00998063 0.06576999
  0.01367913]
 [0.0021626  0.06352305 0.00747872 0.05424559 0.0039043  0.0140953
  0.08752113 0.00334576 0.08251935 0.01971137 0.09412243 0.45380366
  0.04835241 0.00868152 0.00982278 0.02604889 0.00995347 0.06595159
  0.01365453]
 [0.00216225 0.06359571 0.0074657  0.05426173 0.00391227 0.0140757
  0.08745032 0.00334797 0.08251946 0.01968868 0.09394528 0.45362625
  0.04833858 0.008663   0.00979861 0.02609625 0.00996545 0.06594574
  0.01367058]
 [0.0021622  0.06369694 0.00745861 0.05410132 0.00390049 0.01409499
  0.08726992 0.00334186 0.08267125 0.01969164 0.09434404 0.4540555
  0.04842989 0.00865265 0.00980509 0.02603199 0.00994188 0.06566499
  0.0136737 ]]
Bug fix for empty classification report.
micro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.3232
macro     precision: 0.0000 | recall: 0.0000 | f1-score: 0.0000 | support: 0 | mAP: 0.2150

[INFO] Performing LRP Pruning in Round 1...
[INFO] Computing LRP pruning mask...
Erstelle DataLoader f√ºr Land: Finland
Pre-filtered 30767 patches based on country and season (split ignored)
Loading BEN data for train...
    237871 patches indexed
    14805 filtered patches indexed
    14805 patches indexed considering max_len
Merged metadata with snow/cloud metadata
Loaded 549488 labels
Loaded 549488 keys
Loaded mapping created
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([16])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([16, 19])
Relevance computation successful. Relevance shape: torch.Size([16, 10, 1, 16])
Targets shape: torch.Size([5])
Eye matrix shape: torch.Size([19, 19])
Output shape: torch.Size([5, 19])
Relevance computation successful. Relevance shape: torch.Size([5, 10, 1, 5])
[INFO] Relevance maps computed for 53 layers.
[DEBUG] Layer: conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.0.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.0.downsample.0
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.1.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.1.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.1.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.4.2.conv1
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.2.conv2
  Mask shape: torch.Size([64]), Non-zero elements: 64
[DEBUG] Layer: encoder.4.2.conv3
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.5.0.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.0.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.0.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.0.downsample.0
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.1.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.1.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.1.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.2.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.2.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.2.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.5.3.conv1
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.3.conv2
  Mask shape: torch.Size([128]), Non-zero elements: 128
[DEBUG] Layer: encoder.5.3.conv3
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.6.0.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.0.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.0.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.0.downsample.0
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.1.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.1.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.1.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.2.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.2.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.2.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.3.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.3.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.3.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.4.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.4.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.4.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.6.5.conv1
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.5.conv2
  Mask shape: torch.Size([256]), Non-zero elements: 256
[DEBUG] Layer: encoder.6.5.conv3
  Mask shape: torch.Size([1024]), Non-zero elements: 1024
[DEBUG] Layer: encoder.7.0.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.0.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.0.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.0.downsample.0
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.1.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.1.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.1.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 2048
[DEBUG] Layer: encoder.7.2.conv1
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.2.conv2
  Mask shape: torch.Size([512]), Non-zero elements: 512
[DEBUG] Layer: encoder.7.2.conv3
  Mask shape: torch.Size([2048]), Non-zero elements: 1788
[INFO] Using device: cuda
Layer: conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.0893e+18, 1.7951e+18, 1.3845e+18, 1.4735e+18, 3.2381e+18, 1.1303e+18,
        3.1863e+18, 4.4851e+17, 1.2495e+18, 1.2756e+18, 1.1170e+18, 1.9510e+18,
        5.1221e+17, 3.3344e+18, 1.2455e+18, 2.5133e+18, 1.5060e+18, 3.1069e+18,
        1.5720e+18, 1.6681e+18, 8.4193e+17, 2.5043e+18, 2.2952e+18, 1.5185e+18,
        1.4117e+18, 4.8960e+18, 1.3086e+18, 2.2826e+18, 2.3292e+18, 2.1573e+18,
        1.7424e+18, 9.7173e+17, 1.8962e+18, 2.9223e+18, 1.1617e+18, 2.2938e+18,
        1.9424e+18, 3.4249e+18, 2.1924e+18, 1.7776e+18, 2.3294e+18, 3.0817e+18,
        1.7495e+18, 1.7642e+18, 3.7868e+18, 1.3118e+18, 2.2748e+18, 3.2427e+17,
        1.1892e+18, 2.0507e+18, 6.5139e+17, 3.3570e+18, 3.4584e+18, 1.2075e+18,
        5.0142e+17, 1.0712e+18, 1.9580e+18, 1.4235e+18, 5.6533e+17, 6.8005e+17,
        1.4152e+18, 1.5001e+18, 3.1099e+18, 9.1670e+17])
Layer: encoder.4.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5.7732e+17, 5.7133e+17, 1.1996e+18, 8.8370e+17, 6.3065e+17, 4.3089e+17,
        6.2648e+17, 9.3778e+17, 6.9874e+17, 6.4556e+17, 2.6599e+17, 7.5333e+17,
        6.5468e+17, 5.2410e+17, 3.3295e+17, 1.2582e+18, 1.4490e+18, 1.7690e+18,
        1.1599e+18, 1.3122e+18, 6.6829e+17, 1.3836e+18, 1.1267e+18, 4.5607e+17,
        4.7818e+17, 1.5437e+18, 6.6087e+17, 3.9268e+17, 1.4401e+18, 1.5526e+18,
        1.1074e+18, 5.4551e+17, 7.7397e+17, 8.3584e+17, 8.0432e+17, 5.4504e+17,
        7.8176e+17, 1.2605e+18, 4.5783e+17, 1.8080e+18, 1.4730e+18, 3.9553e+17,
        2.9689e+17, 7.6162e+17, 2.0543e+18, 7.2193e+17, 4.6350e+17, 5.5984e+17,
        4.4373e+17, 9.5803e+17, 1.5682e+18, 1.3203e+18, 1.2970e+18, 1.2975e+18,
        8.4304e+17, 4.7805e+17, 6.2642e+17, 9.2184e+17, 4.6321e+17, 5.3312e+17,
        6.7498e+17, 5.4444e+17, 1.5175e+18, 8.4280e+17])
Layer: encoder.4.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.1121e+18, 7.7038e+17, 1.6389e+18, 2.0011e+18, 1.1624e+18, 2.6135e+18,
        1.3021e+18, 3.9860e+18, 1.3526e+18, 1.2468e+18, 1.8743e+18, 7.2384e+17,
        1.6406e+18, 1.0380e+18, 5.0459e+17, 7.3972e+17, 9.4505e+17, 1.3071e+18,
        9.5498e+17, 1.7720e+18, 2.3196e+18, 7.5357e+17, 1.3049e+18, 1.4796e+18,
        4.6634e+17, 1.9758e+18, 5.7055e+17, 1.3140e+18, 1.3804e+18, 6.5280e+17,
        1.9710e+18, 3.7054e+17, 1.1919e+18, 1.4399e+18, 2.4480e+18, 1.9475e+18,
        1.4748e+18, 1.7311e+18, 2.1956e+18, 3.1691e+18, 3.1445e+17, 8.0273e+17,
        8.5474e+17, 5.8870e+17, 1.0006e+18, 1.8462e+18, 7.4159e+17, 9.2353e+17,
        4.4943e+17, 1.0007e+18, 5.6972e+17, 5.0956e+17, 8.4113e+17, 7.6258e+17,
        1.0374e+18, 1.5249e+18, 1.8749e+18, 1.6704e+18, 1.4528e+18, 2.9007e+17,
        1.0283e+18, 2.7839e+18, 6.1747e+17, 1.9294e+18])
Layer: encoder.4.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.3409e+15, 1.4458e+15, 2.6146e+16, 1.6326e+15, 6.3983e+15, 1.1420e+16,
        3.2293e+15, 1.5515e+16, 1.4319e+15, 9.2456e+15, 5.2168e+14, 1.4895e+16,
        7.8636e+15, 2.3723e+16, 6.6064e+15, 1.2954e+17, 6.1606e+15, 8.1468e+14,
        5.8807e+15, 1.0286e+16, 1.5864e+16, 5.8905e+15, 9.2376e+16, 5.4189e+14,
        7.8925e+16, 2.1307e+15, 3.1208e+16, 1.3073e+15, 2.3726e+15, 2.9559e+15,
        1.7182e+15, 1.0500e+16, 1.5361e+15, 1.6225e+16, 2.7866e+15, 6.6145e+16,
        6.2160e+15, 5.0906e+15, 3.1928e+15, 2.0642e+15, 7.0698e+16, 4.5503e+16,
        5.2913e+15, 2.8123e+16, 4.0664e+15, 6.0876e+15, 3.5334e+15, 5.5110e+15,
        2.4885e+15, 4.6739e+15, 9.8297e+15, 6.9622e+16, 3.2712e+16, 1.7764e+16,
        6.6244e+15, 4.2131e+15, 1.4611e+16, 2.4858e+16, 1.0974e+16, 3.5806e+15,
        2.2586e+15, 9.8884e+14, 5.2105e+15, 6.1361e+16, 1.3304e+16, 1.4671e+16,
        8.6088e+15, 6.0886e+15, 4.2767e+16, 4.9002e+15, 2.7837e+14, 2.8341e+16,
        9.3657e+15, 1.3212e+16, 1.7759e+17, 1.3983e+16, 3.1906e+15, 3.1721e+15,
        1.3829e+16, 3.5999e+15, 7.0114e+16, 4.8558e+15, 8.7750e+15, 4.8410e+16,
        7.6149e+15, 1.7592e+17, 5.2903e+15, 7.4737e+15, 1.8012e+16, 1.1032e+16,
        2.3400e+15, 1.4405e+15, 4.4125e+15, 6.0406e+14, 2.3487e+16, 1.5567e+16,
        2.3840e+15, 1.1723e+16, 5.8498e+18, 1.5006e+16, 8.2449e+14, 4.7581e+15,
        2.4870e+16, 1.6860e+16, 1.4883e+16, 8.3647e+15, 1.5998e+15, 5.3944e+15,
        1.0938e+15, 3.5560e+15, 7.2942e+15, 8.9764e+14, 5.2340e+15, 5.6992e+15,
        3.6732e+16, 8.9066e+14, 2.3753e+16, 2.8663e+16, 1.0711e+15, 1.0632e+15,
        6.0313e+15, 7.6115e+14, 3.2194e+16, 1.6400e+15, 5.5001e+15, 3.5268e+15,
        2.2044e+16, 8.9803e+15, 1.4600e+15, 8.2617e+15, 1.8288e+15, 1.6142e+15,
        1.8383e+15, 6.3974e+14, 1.8014e+16, 1.7788e+16, 4.6117e+15, 8.0711e+16,
        7.6902e+15, 1.1685e+15, 2.5484e+16, 2.1218e+16, 3.7804e+16, 2.1828e+15,
        5.1141e+15, 2.0794e+16, 4.0564e+15, 5.2658e+14, 1.3141e+15, 1.3999e+15,
        2.4220e+15, 1.5800e+16, 4.1358e+15, 6.2131e+16, 2.6246e+15, 1.0957e+16,
        4.2607e+15, 5.7147e+15, 1.2187e+15, 1.5371e+15, 6.4751e+15, 4.3175e+15,
        2.0937e+15, 1.0805e+16, 3.3724e+16, 2.7046e+15, 6.7935e+15, 4.0597e+15,
        1.1222e+16, 2.2788e+16, 8.8981e+15, 1.0173e+18, 2.3709e+16, 1.9076e+15,
        9.7188e+15, 3.4950e+15, 9.4349e+15, 1.0146e+15, 4.8655e+15, 2.4097e+16,
        9.2113e+15, 2.7122e+16, 6.0731e+15, 3.0972e+16, 6.5817e+16, 4.4223e+14,
        1.2451e+16, 3.0056e+15, 6.9615e+15, 7.7214e+16, 1.9178e+16, 4.2984e+15,
        1.3474e+15, 3.2288e+16, 1.1100e+17, 7.9684e+15, 5.6766e+15, 1.5568e+16,
        2.5994e+16, 1.4596e+16, 1.6435e+16, 7.7716e+15, 5.1956e+15, 2.0797e+16,
        5.3241e+15, 2.1249e+15, 4.5175e+15, 3.7466e+15, 4.1571e+15, 1.3120e+16,
        4.5221e+15, 9.8686e+15, 5.7616e+15, 4.0779e+15, 8.9517e+15, 1.4788e+16,
        2.9747e+17, 2.5739e+15, 6.5235e+15, 1.1623e+17, 1.1109e+16, 1.0363e+16,
        6.6456e+15, 1.2426e+16, 7.4420e+16, 6.6887e+17, 1.1173e+17, 1.2985e+16,
        1.1993e+15, 6.4916e+16, 5.0597e+15, 4.0658e+15, 1.0339e+16, 2.5564e+15,
        6.0090e+15, 1.9571e+16, 5.8687e+15, 5.4973e+15, 8.1952e+15, 2.8449e+14,
        1.7501e+15, 1.3480e+15, 2.3995e+16, 6.9430e+16, 3.4580e+15, 1.4788e+16,
        1.3650e+16, 2.9708e+15, 5.6885e+15, 1.1005e+16, 5.6261e+15, 8.6485e+16,
        8.8134e+15, 2.2643e+16, 9.1670e+15, 4.2381e+15])
Layer: encoder.4.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.1985e+15, 9.9333e+15, 3.3103e+16, 1.2176e+16, 1.0208e+16, 9.5494e+15,
        7.0172e+15, 2.2998e+16, 2.1201e+15, 5.7004e+15, 5.5272e+15, 3.6603e+16,
        2.5851e+15, 1.6522e+16, 8.7144e+15, 1.3753e+17, 6.2602e+15, 4.2276e+15,
        7.4627e+15, 1.5228e+16, 2.1019e+16, 6.3835e+15, 9.7902e+16, 1.9027e+15,
        8.0408e+16, 4.3307e+15, 3.3910e+16, 9.9948e+15, 5.0255e+15, 3.7491e+15,
        4.3521e+15, 1.0668e+16, 7.2537e+15, 1.7871e+16, 5.1662e+15, 6.8252e+16,
        6.6586e+15, 9.2251e+15, 5.4463e+15, 1.5911e+15, 7.3014e+16, 3.9683e+16,
        1.2347e+16, 3.1340e+16, 4.8648e+15, 6.8476e+15, 6.2162e+15, 6.7164e+15,
        8.7243e+15, 3.8746e+15, 5.4569e+15, 7.5453e+16, 2.8522e+16, 1.1692e+16,
        9.3289e+15, 4.0008e+15, 1.8591e+16, 2.4213e+16, 6.0827e+15, 4.9642e+15,
        7.8329e+15, 4.9768e+15, 5.3596e+15, 6.2804e+16, 2.1765e+16, 1.8558e+16,
        8.2285e+15, 6.3159e+15, 4.8273e+16, 7.7561e+15, 2.2165e+15, 2.6424e+16,
        4.4052e+15, 4.7103e+15, 1.8103e+17, 5.1145e+15, 1.4214e+16, 6.1116e+15,
        1.3705e+16, 1.0799e+16, 7.4126e+16, 5.3198e+15, 1.8264e+16, 1.4174e+16,
        1.6248e+16, 1.6913e+17, 1.0945e+16, 1.5615e+16, 2.9067e+16, 1.5110e+16,
        3.4685e+15, 4.8982e+15, 5.9854e+15, 7.9237e+15, 2.5917e+16, 1.3249e+16,
        7.7536e+15, 1.5407e+16, 5.8416e+18, 1.0291e+16, 2.8268e+15, 9.2271e+15,
        2.6159e+16, 2.6278e+16, 2.1345e+16, 6.2343e+15, 4.1181e+15, 6.2903e+15,
        3.2499e+15, 8.0082e+15, 1.6355e+16, 5.7371e+14, 1.5851e+16, 8.3162e+15,
        2.9841e+16, 3.0499e+15, 2.4050e+16, 1.5929e+16, 1.0594e+16, 2.1400e+15,
        1.1899e+16, 3.8457e+15, 2.9198e+16, 6.8220e+15, 4.4028e+15, 3.7522e+15,
        1.7683e+16, 7.3186e+15, 3.0489e+15, 1.3995e+16, 5.9561e+15, 3.4929e+15,
        6.3262e+15, 4.4893e+15, 1.8057e+16, 1.7141e+16, 1.0818e+16, 9.5868e+16,
        6.3543e+15, 9.6688e+15, 3.3291e+16, 2.4621e+16, 4.3835e+16, 6.0028e+15,
        1.6205e+16, 2.1592e+16, 7.5743e+15, 6.9037e+15, 6.0621e+15, 4.1206e+15,
        1.2697e+16, 1.6887e+16, 3.6217e+15, 7.3016e+16, 4.6277e+15, 6.1335e+15,
        8.7988e+15, 8.0944e+15, 5.2824e+15, 1.8047e+15, 5.7566e+15, 6.6792e+15,
        8.6479e+15, 8.8849e+15, 3.6191e+16, 3.2177e+15, 9.7538e+15, 6.5171e+15,
        2.3497e+16, 2.3891e+16, 1.1095e+16, 1.0181e+18, 2.8257e+16, 5.0228e+15,
        6.8380e+15, 1.2339e+16, 1.5099e+16, 1.3348e+16, 8.5050e+15, 2.2889e+16,
        1.1966e+16, 2.4677e+16, 1.0295e+16, 2.1419e+16, 5.6803e+16, 4.1711e+15,
        4.4097e+15, 3.2897e+15, 1.7641e+16, 7.9937e+16, 1.4272e+16, 7.5600e+15,
        4.2682e+15, 4.4806e+16, 1.1180e+17, 1.4032e+16, 8.0203e+15, 1.9337e+16,
        2.6901e+16, 1.0216e+16, 1.3454e+16, 1.0903e+16, 8.4539e+15, 2.3488e+16,
        9.2163e+15, 4.7384e+15, 1.1009e+16, 5.3920e+15, 8.4334e+15, 2.0520e+16,
        3.4502e+15, 8.5983e+15, 4.4369e+15, 8.7966e+15, 1.3301e+16, 1.2524e+16,
        2.9946e+17, 1.1303e+16, 7.7394e+15, 1.3898e+17, 8.9453e+15, 1.1725e+16,
        9.4527e+15, 2.3335e+16, 7.9221e+16, 6.6866e+17, 1.0860e+17, 1.5315e+16,
        8.3339e+15, 7.1323e+16, 8.6154e+15, 6.1160e+15, 1.2427e+16, 2.3520e+15,
        2.4894e+15, 1.9459e+16, 9.0935e+15, 1.0431e+16, 9.5934e+15, 4.4016e+15,
        4.6917e+15, 1.4537e+15, 2.7004e+16, 7.1633e+16, 1.3199e+16, 1.8152e+16,
        2.2212e+16, 1.1429e+16, 4.3224e+15, 1.4578e+16, 7.7722e+15, 7.8130e+16,
        7.2394e+15, 1.1019e+16, 7.0672e+15, 1.0613e+16])
Layer: encoder.4.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5.1555e+15, 9.7715e+15, 9.0069e+15, 7.5608e+15, 4.3936e+15, 1.2403e+16,
        1.3089e+16, 2.1733e+16, 8.0896e+15, 8.4139e+15, 1.8469e+16, 2.0289e+16,
        8.4257e+15, 9.8773e+15, 9.1760e+15, 8.3260e+15, 1.1416e+16, 6.6927e+15,
        1.4381e+16, 1.3434e+16, 1.0783e+16, 1.0214e+16, 9.8597e+15, 1.5235e+16,
        5.8536e+15, 5.8501e+15, 1.0178e+16, 4.0372e+15, 1.7519e+16, 1.4469e+16,
        1.2355e+16, 5.7453e+15, 1.9168e+16, 2.8417e+15, 1.6248e+16, 1.2562e+16,
        9.1475e+15, 1.9373e+16, 1.9148e+16, 5.6403e+15, 1.4418e+16, 9.6499e+15,
        8.5468e+15, 1.3093e+16, 1.0203e+16, 2.0180e+16, 1.3602e+16, 5.2999e+15,
        8.3127e+15, 8.4664e+15, 1.2446e+16, 1.2883e+16, 5.7922e+15, 1.8332e+16,
        1.7183e+16, 1.5467e+16, 1.9531e+16, 1.4336e+16, 6.1276e+15, 9.3909e+15,
        7.3898e+15, 4.4055e+15, 1.0374e+16, 7.6873e+15])
Layer: encoder.4.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.7535e+16, 2.0928e+16, 1.1035e+16, 1.3647e+16, 2.1327e+16, 2.1583e+16,
        1.7491e+16, 5.2146e+15, 1.8305e+16, 2.3468e+16, 1.2890e+16, 1.3671e+16,
        5.6817e+15, 1.4515e+16, 1.4240e+16, 1.2431e+16, 1.4754e+16, 1.0450e+16,
        1.8037e+16, 4.9541e+15, 8.4355e+15, 8.1106e+15, 8.3634e+15, 6.6098e+15,
        1.4146e+16, 1.1037e+16, 2.5324e+16, 1.9530e+16, 6.0734e+15, 2.8277e+16,
        1.8679e+16, 2.4860e+16, 6.5173e+15, 6.2586e+15, 1.9112e+16, 4.1485e+15,
        6.1761e+15, 1.5801e+16, 2.0014e+16, 1.3079e+16, 5.2243e+15, 1.1131e+16,
        1.0676e+16, 1.3915e+16, 2.1005e+16, 7.0698e+15, 1.7225e+16, 1.7508e+16,
        2.3432e+16, 7.1537e+15, 1.1687e+16, 1.8919e+16, 2.6875e+16, 6.6386e+15,
        1.5587e+16, 6.7304e+15, 1.2182e+16, 7.9700e+15, 1.4051e+16, 1.7770e+16,
        3.4232e+15, 1.4455e+16, 2.4533e+16, 9.7594e+15])
Layer: encoder.4.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.0045e+15, 1.0445e+14, 1.0905e+15, 8.3173e+14, 3.3825e+14, 1.4230e+15,
        5.0029e+14, 2.4825e+14, 1.3081e+15, 6.7459e+14, 1.3652e+14, 1.0278e+16,
        1.6128e+15, 1.3950e+15, 3.0464e+15, 1.2170e+15, 1.4381e+14, 1.2725e+14,
        2.5911e+14, 8.7356e+14, 2.8785e+15, 1.4390e+15, 2.4498e+15, 1.3925e+15,
        1.0353e+15, 4.8160e+13, 2.5013e+15, 1.1185e+15, 2.2882e+14, 1.3208e+15,
        6.4505e+14, 1.6593e+15, 2.1543e+14, 2.1757e+15, 2.2542e+15, 6.0794e+14,
        3.5143e+15, 1.3540e+15, 2.1164e+15, 5.0231e+14, 3.8370e+14, 5.6644e+15,
        1.7699e+15, 7.7074e+14, 4.1294e+15, 1.3872e+15, 3.6235e+14, 5.5477e+14,
        8.4207e+14, 1.9060e+15, 1.5320e+15, 3.2528e+15, 3.8425e+14, 5.8785e+14,
        3.6739e+14, 1.4054e+15, 6.3068e+14, 2.3222e+15, 2.6187e+15, 4.6713e+14,
        3.7761e+14, 6.9578e+14, 1.4958e+14, 1.9773e+15, 2.0210e+15, 3.4563e+14,
        5.7100e+15, 1.9339e+15, 8.6785e+14, 2.7091e+15, 1.8453e+15, 2.8130e+14,
        8.6623e+14, 1.5790e+16, 4.8515e+14, 8.2147e+14, 1.3627e+14, 1.7300e+15,
        2.5330e+15, 1.2764e+15, 5.7836e+15, 5.9429e+14, 2.3189e+15, 4.4182e+16,
        7.0258e+14, 3.4172e+15, 3.5451e+14, 9.7146e+14, 6.4221e+15, 2.8156e+14,
        3.1093e+14, 6.8234e+14, 3.1449e+14, 1.5568e+14, 3.2804e+14, 7.6406e+15,
        2.3251e+14, 7.2259e+14, 7.4947e+14, 2.5115e+15, 3.4469e+14, 7.3408e+14,
        9.0927e+14, 9.8261e+15, 1.5880e+15, 7.1774e+14, 6.4809e+13, 1.4299e+15,
        2.4416e+15, 1.1160e+15, 5.9802e+14, 7.5314e+14, 2.4061e+15, 7.5009e+14,
        3.2993e+14, 6.1067e+14, 1.5531e+15, 1.1005e+15, 2.2131e+15, 7.9896e+13,
        1.5552e+15, 8.9920e+14, 8.5885e+14, 6.7484e+14, 1.4316e+15, 5.2154e+14,
        1.6770e+15, 1.6793e+15, 4.0481e+15, 8.0538e+14, 1.0315e+14, 1.1338e+15,
        8.1003e+14, 2.4623e+14, 3.3577e+15, 1.4439e+15, 1.4942e+15, 1.4791e+15,
        1.1563e+15, 2.9603e+15, 3.7341e+14, 5.1882e+14, 5.4425e+14, 7.9653e+14,
        4.1731e+15, 1.2267e+15, 1.4003e+15, 7.3876e+14, 2.5014e+14, 1.6478e+14,
        4.3278e+15, 1.2265e+15, 8.5729e+14, 1.6630e+15, 1.1518e+15, 9.9717e+14,
        2.2677e+15, 1.2585e+15, 1.4572e+14, 1.4237e+14, 1.1224e+15, 3.0170e+14,
        2.2467e+14, 8.3752e+14, 3.2507e+14, 1.1215e+15, 1.8920e+15, 9.5928e+14,
        2.2579e+15, 2.4018e+15, 2.8100e+15, 2.9313e+14, 4.3473e+14, 3.0914e+14,
        9.5195e+14, 2.4055e+14, 1.9878e+15, 1.9276e+15, 1.5411e+14, 3.5618e+14,
        1.3456e+15, 5.6926e+14, 3.7914e+14, 1.5346e+15, 3.4934e+15, 2.0113e+15,
        1.1929e+15, 7.3520e+14, 1.1650e+15, 5.4247e+15, 6.8982e+14, 8.1895e+14,
        1.8614e+14, 1.0908e+16, 8.6641e+14, 5.0735e+14, 2.7387e+14, 7.4779e+14,
        5.8756e+14, 2.3599e+15, 2.0485e+15, 8.6155e+14, 2.3074e+15, 1.1591e+16,
        4.2601e+14, 2.5635e+15, 2.3968e+14, 1.4867e+15, 1.4482e+15, 1.0817e+15,
        1.0673e+15, 1.9181e+15, 5.0142e+14, 9.6738e+15, 1.7996e+15, 7.3347e+14,
        3.8105e+14, 1.1893e+14, 8.5588e+14, 1.6222e+16, 2.7739e+15, 2.8471e+15,
        1.5176e+15, 3.4013e+14, 1.0654e+15, 1.1548e+15, 2.2326e+15, 6.0993e+14,
        5.6561e+15, 4.8558e+14, 1.1682e+15, 5.9483e+14, 4.4507e+14, 4.0851e+14,
        8.9472e+14, 5.2435e+14, 1.3584e+15, 9.5814e+14, 1.9100e+15, 1.4053e+14,
        2.6645e+14, 3.9501e+14, 5.3859e+14, 1.1899e+14, 1.3237e+15, 3.1201e+15,
        1.2396e+15, 7.8630e+14, 1.2416e+15, 1.0178e+15, 5.8855e+13, 6.7090e+15,
        5.7985e+14, 1.9738e+15, 1.7052e+15, 5.3948e+14])
Layer: encoder.4.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.2346e+15, 3.6024e+15, 3.4608e+15, 5.2205e+15, 3.1324e+15, 1.7611e+15,
        3.0543e+15, 5.4197e+15, 2.4352e+15, 6.9390e+15, 2.0418e+15, 2.2570e+15,
        4.6153e+15, 1.3685e+15, 2.2811e+15, 1.3655e+15, 3.2567e+15, 1.5853e+15,
        3.0578e+15, 3.6533e+15, 3.9719e+15, 3.3927e+15, 5.0535e+15, 2.3911e+15,
        2.2186e+15, 7.3398e+14, 4.2303e+15, 2.3317e+15, 3.5265e+15, 1.5348e+15,
        4.9303e+15, 2.8781e+15, 1.5039e+15, 1.6183e+15, 6.0380e+15, 2.6038e+15,
        3.3305e+15, 1.5684e+15, 5.2264e+15, 4.5071e+15, 2.3773e+15, 3.2033e+15,
        8.6952e+14, 3.9683e+15, 5.6156e+14, 1.1178e+15, 8.3357e+14, 2.1811e+15,
        5.5278e+15, 8.7087e+14, 1.2322e+15, 8.8486e+14, 5.2598e+15, 1.5034e+15,
        1.4224e+15, 3.8220e+15, 2.5942e+15, 9.2116e+14, 2.5093e+15, 4.9942e+15,
        3.8584e+14, 9.4620e+14, 3.5253e+15, 5.0899e+15])
Layer: encoder.4.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.8682e+15, 7.1559e+15, 6.8468e+15, 2.9164e+15, 7.0236e+14, 4.2220e+15,
        5.5316e+15, 4.6574e+15, 2.8467e+15, 1.2408e+15, 1.2187e+15, 3.7463e+15,
        1.6469e+15, 5.0506e+15, 1.7379e+15, 2.4630e+15, 2.6067e+15, 6.2562e+15,
        4.9988e+15, 1.2913e+15, 9.4259e+14, 4.5947e+15, 1.6103e+15, 1.1475e+15,
        2.1594e+15, 6.7469e+14, 5.8731e+15, 4.3120e+15, 5.2119e+15, 5.9617e+15,
        8.7303e+15, 2.2073e+15, 6.5542e+15, 2.5931e+15, 2.1769e+15, 3.4522e+15,
        2.6591e+15, 3.0173e+15, 1.2109e+15, 3.3267e+15, 2.8904e+15, 1.2859e+15,
        5.0542e+15, 2.7349e+15, 3.9612e+15, 4.2148e+15, 3.9799e+15, 2.0731e+15,
        6.3589e+15, 3.3645e+15, 3.6239e+15, 3.4125e+15, 1.1777e+15, 1.6990e+15,
        6.7719e+15, 2.4202e+15, 7.8822e+15, 1.9640e+15, 3.7995e+15, 8.1917e+15,
        2.1129e+15, 2.2472e+15, 3.5857e+15, 2.8111e+15])
Layer: encoder.4.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.3403e+13, 1.8283e+13, 1.3813e+13, 5.9815e+12, 3.9503e+12, 1.4122e+13,
        1.7482e+13, 9.4484e+12, 4.5796e+12, 2.0952e+13, 2.3217e+12, 9.9346e+12,
        1.2807e+13, 2.3671e+13, 5.2136e+12, 1.8172e+13, 3.7488e+13, 2.3898e+13,
        6.9578e+12, 6.1907e+12, 9.0933e+12, 4.3864e+12, 9.6436e+12, 6.0414e+12,
        3.7719e+12, 3.6890e+13, 1.2795e+13, 1.3236e+13, 3.2639e+13, 8.1243e+12,
        3.1689e+12, 1.2323e+13, 8.0202e+11, 5.6761e+13, 7.7932e+12, 1.9954e+13,
        1.2262e+13, 4.6337e+12, 1.4163e+13, 1.8526e+12, 9.4088e+12, 7.8434e+12,
        2.0523e+13, 2.4803e+13, 5.7268e+12, 6.7942e+12, 6.3026e+12, 1.3852e+13,
        1.5545e+12, 1.5921e+13, 9.4873e+12, 1.3591e+13, 5.3858e+13, 7.3273e+12,
        2.1672e+13, 1.5611e+13, 1.7573e+13, 2.2074e+13, 4.6480e+12, 1.7851e+13,
        3.5426e+12, 2.1213e+13, 3.5775e+12, 9.6870e+12, 1.6058e+13, 4.6420e+12,
        8.5901e+12, 1.0327e+13, 1.3762e+13, 5.5995e+12, 1.1713e+13, 3.9466e+12,
        7.0543e+12, 1.9119e+13, 3.9436e+13, 2.3302e+14, 4.1122e+12, 8.4387e+12,
        4.5929e+13, 5.3265e+12, 1.3098e+13, 5.6558e+12, 1.1917e+13, 1.8722e+13,
        3.8480e+12, 2.1672e+13, 2.3985e+15, 1.0228e+13, 6.2485e+12, 2.8788e+13,
        1.4491e+12, 2.8741e+13, 1.3812e+13, 1.8097e+12, 1.2865e+13, 4.1650e+12,
        7.7341e+12, 1.7914e+13, 1.7159e+13, 7.2065e+12, 1.6055e+12, 1.0181e+13,
        8.3894e+12, 1.3977e+13, 2.3065e+13, 1.2698e+13, 5.7261e+12, 4.0074e+12,
        5.8396e+12, 1.4234e+13, 8.7282e+12, 3.8318e+12, 2.7062e+13, 5.6432e+12,
        1.1386e+13, 6.3726e+12, 5.5290e+12, 1.9010e+13, 7.0735e+12, 8.9584e+12,
        6.3730e+12, 8.2499e+12, 1.1251e+14, 4.8055e+13, 1.3815e+13, 3.8880e+13,
        3.8417e+13, 2.6979e+12, 5.8384e+12, 1.0643e+14, 9.3593e+12, 9.0933e+12,
        7.5463e+12, 1.3296e+12, 2.9301e+13, 6.2173e+12, 1.3984e+13, 6.8662e+12,
        3.6085e+13, 1.3545e+13, 4.2239e+14, 2.0112e+12, 6.7205e+12, 5.4703e+12,
        4.1436e+13, 1.1640e+13, 1.8630e+14, 2.2828e+12, 1.6737e+12, 1.3377e+13,
        1.5811e+13, 8.0953e+12, 5.2673e+12, 2.9790e+13, 1.0542e+13, 3.4687e+12,
        2.1796e+13, 2.2839e+13, 2.0087e+12, 3.9841e+12, 5.8069e+13, 2.3557e+13,
        5.1752e+12, 7.5508e+12, 4.2013e+13, 9.9721e+12, 1.6150e+13, 1.6815e+13,
        1.2340e+13, 4.6952e+13, 6.8614e+12, 3.3448e+12, 2.0998e+13, 2.8412e+12,
        1.4450e+13, 8.3658e+12, 5.9654e+12, 1.1173e+13, 3.1596e+12, 3.8510e+13,
        8.2450e+12, 8.9869e+12, 2.3483e+12, 4.2598e+13, 8.2100e+12, 1.7616e+13,
        2.2697e+13, 1.7948e+13, 1.8647e+13, 1.5592e+16, 2.4815e+13, 1.3678e+13,
        3.7026e+12, 2.2214e+13, 2.4903e+13, 1.0760e+13, 2.5245e+12, 9.6420e+12,
        1.0121e+13, 1.0818e+13, 7.6063e+12, 2.6244e+12, 1.4704e+13, 1.2078e+13,
        2.7092e+13, 5.1190e+12, 2.0249e+12, 4.1705e+13, 1.4497e+13, 1.0390e+13,
        1.6322e+13, 8.9316e+12, 1.1918e+12, 5.6337e+12, 2.3078e+14, 7.4055e+12,
        3.7388e+12, 3.1499e+12, 1.1270e+13, 2.1747e+13, 5.7988e+12, 1.1779e+13,
        1.3125e+13, 3.5489e+13, 5.1143e+12, 6.6271e+12, 9.0481e+12, 2.3384e+13,
        2.3011e+15, 4.9197e+12, 4.8214e+12, 9.8267e+12, 2.6801e+13, 1.2466e+12,
        5.5404e+13, 6.9382e+12, 3.4327e+13, 1.6840e+13, 8.3127e+12, 1.8635e+12,
        1.3715e+13, 1.0016e+13, 3.5896e+12, 9.8764e+12, 5.4568e+14, 1.4079e+13,
        1.4656e+13, 1.0981e+13, 6.7408e+13, 3.6288e+12, 6.3644e+12, 2.4911e+13,
        1.1275e+14, 1.4853e+13, 7.2741e+12, 2.4653e+12])
Layer: encoder.5.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.8784e+13, 1.3453e+13, 1.3266e+13, 9.7879e+12, 6.6332e+12, 3.1044e+12,
        2.0243e+13, 2.4946e+13, 1.3382e+13, 2.5238e+13, 1.3583e+13, 1.7257e+13,
        1.4019e+13, 1.0501e+13, 8.2458e+12, 2.3705e+13, 1.3200e+13, 1.3018e+13,
        2.8234e+13, 1.2757e+13, 1.2471e+13, 9.5791e+12, 2.6046e+13, 1.9201e+13,
        1.9257e+13, 2.0660e+13, 1.0894e+13, 8.0372e+12, 2.4547e+13, 5.3497e+12,
        1.2417e+13, 1.2503e+13, 2.6473e+13, 6.0804e+12, 2.9458e+13, 2.9164e+13,
        6.0489e+12, 9.5117e+12, 1.1294e+13, 1.8945e+13, 5.8925e+12, 8.8183e+12,
        8.1874e+12, 2.2768e+13, 1.1198e+13, 2.0226e+13, 2.8488e+13, 7.7462e+12,
        1.8811e+13, 7.2363e+12, 2.2052e+13, 2.0339e+13, 7.3173e+12, 1.2212e+13,
        1.2458e+13, 1.0085e+13, 3.4319e+13, 2.2201e+13, 1.3292e+13, 2.5374e+13,
        1.3080e+13, 1.2467e+13, 9.3925e+12, 1.7034e+13, 8.1723e+12, 1.6992e+13,
        2.6384e+13, 2.0816e+13, 1.5166e+13, 3.0019e+13, 1.2166e+13, 2.5131e+13,
        1.0215e+13, 1.9845e+13, 2.0429e+13, 1.1328e+13, 1.3041e+13, 5.3094e+12,
        2.2414e+13, 2.1949e+13, 1.9025e+13, 7.8000e+12, 1.0654e+13, 8.5658e+12,
        1.3771e+13, 6.5974e+12, 7.0271e+12, 7.1294e+12, 1.3223e+13, 3.0398e+13,
        9.4875e+12, 1.8164e+13, 9.3337e+12, 1.3423e+13, 2.0529e+13, 1.2074e+13,
        2.0611e+13, 1.3097e+13, 2.0415e+13, 2.6764e+13, 8.8777e+12, 1.4084e+13,
        1.5536e+13, 2.1262e+13, 8.6564e+12, 1.1144e+13, 1.4769e+13, 3.0634e+13,
        2.5214e+13, 1.6266e+13, 5.0644e+12, 2.0032e+13, 9.0479e+12, 4.7213e+12,
        1.4756e+13, 1.8033e+13, 6.0565e+12, 1.3222e+13, 2.4908e+13, 1.3728e+13,
        1.3635e+13, 1.8357e+13, 3.7692e+12, 3.5049e+13, 2.3584e+13, 3.0465e+13,
        2.3495e+13, 2.4551e+13])
Layer: encoder.5.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.0758e+13, 2.4309e+13, 2.8247e+13, 2.1430e+13, 1.6140e+13, 1.9714e+13,
        1.2623e+13, 2.8518e+13, 1.4569e+13, 2.0207e+13, 3.2735e+13, 1.3773e+13,
        2.9352e+13, 7.0920e+12, 2.8496e+13, 3.5145e+13, 1.5730e+13, 3.1101e+13,
        1.9521e+13, 1.1610e+13, 1.8003e+13, 2.7488e+13, 2.3016e+13, 1.3381e+13,
        8.3583e+12, 2.7741e+13, 2.3366e+13, 1.6687e+13, 3.4389e+13, 1.1570e+13,
        1.8013e+13, 3.4922e+13, 1.4918e+13, 2.9332e+13, 1.3964e+13, 1.3457e+13,
        2.2730e+13, 1.9579e+13, 2.1636e+13, 3.9478e+13, 2.4024e+13, 2.6887e+13,
        2.6693e+13, 1.4132e+13, 2.2552e+13, 2.4262e+13, 2.3572e+13, 2.1502e+13,
        2.2303e+13, 7.2398e+12, 3.5470e+13, 2.8696e+13, 3.7162e+13, 3.8993e+13,
        5.7347e+13, 4.6981e+13, 3.0475e+13, 3.1258e+13, 1.2034e+13, 1.3683e+13,
        3.2156e+13, 6.1635e+13, 3.6428e+13, 6.9708e+12, 1.4382e+13, 4.9212e+13,
        1.3184e+13, 4.2385e+13, 3.9514e+13, 9.8262e+12, 3.4502e+13, 1.7700e+13,
        1.1863e+13, 8.6062e+12, 2.1039e+13, 3.2512e+13, 2.1814e+13, 3.6954e+13,
        1.5305e+13, 9.7238e+12, 1.4868e+13, 2.4258e+13, 2.0860e+13, 1.5658e+13,
        2.2595e+13, 2.7911e+13, 2.3122e+13, 5.1067e+13, 2.1966e+13, 2.3194e+13,
        7.7661e+12, 3.0477e+13, 1.7994e+13, 5.2550e+13, 1.0509e+13, 2.0682e+13,
        1.2805e+13, 2.3539e+13, 4.0190e+13, 4.2275e+13, 3.2341e+13, 2.6892e+13,
        1.9732e+13, 1.2639e+13, 1.3063e+13, 3.8463e+13, 4.0190e+13, 1.8955e+13,
        1.9143e+13, 3.2431e+13, 1.4387e+13, 1.9181e+13, 2.6980e+13, 2.1857e+13,
        2.7355e+13, 1.0985e+13, 4.2492e+13, 2.7339e+13, 3.2861e+13, 9.5241e+12,
        6.6342e+12, 1.2651e+13, 2.2212e+13, 2.0905e+13, 1.5103e+13, 3.1740e+13,
        2.7505e+13, 3.6745e+13])
Layer: encoder.5.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5.4129e+11, 1.0188e+12, 4.9152e+11, 2.7966e+10, 2.4498e+11, 1.3706e+11,
        1.8683e+10, 3.7250e+11, 1.2997e+11, 1.1960e+11, 7.1564e+10, 1.4055e+11,
        4.1159e+11, 7.3231e+11, 2.2185e+11, 1.9438e+10, 5.4660e+10, 6.9230e+10,
        5.0428e+10, 2.1242e+11, 1.0895e+11, 5.9693e+10, 1.4919e+11, 7.6699e+10,
        4.1520e+10, 8.6487e+11, 2.0382e+12, 2.5356e+10, 9.0213e+10, 1.3268e+13,
        5.8350e+10, 5.7853e+10, 1.5706e+11, 2.1958e+11, 4.8197e+10, 1.1598e+11,
        3.3165e+11, 1.3511e+11, 1.1500e+11, 6.8882e+10, 1.3341e+11, 1.0652e+12,
        4.4184e+11, 7.6790e+10, 4.1269e+10, 1.6271e+11, 1.6165e+11, 6.5282e+11,
        2.2322e+11, 5.0148e+10, 1.7663e+12, 2.9087e+10, 4.8296e+11, 7.3119e+10,
        2.0232e+11, 2.2488e+11, 4.1976e+11, 9.7971e+10, 6.5654e+10, 1.3885e+11,
        8.5958e+10, 8.7831e+10, 1.1166e+12, 1.7533e+11, 8.9124e+10, 5.3517e+11,
        4.8328e+11, 2.0165e+11, 3.0684e+10, 6.0367e+10, 5.7978e+10, 1.9965e+11,
        1.3750e+11, 5.7739e+10, 1.9378e+11, 1.2027e+11, 2.5790e+11, 5.2417e+10,
        8.3802e+10, 7.4495e+10, 2.3862e+11, 3.6678e+12, 7.0482e+10, 3.5174e+11,
        6.4205e+10, 1.5026e+11, 4.0109e+10, 2.4290e+10, 2.1670e+11, 6.5457e+11,
        2.4615e+11, 1.8086e+11, 1.2684e+11, 3.7755e+11, 1.1129e+11, 4.0941e+11,
        2.1277e+11, 1.3085e+11, 2.7904e+10, 2.9694e+10, 2.7386e+10, 5.1066e+10,
        5.0363e+11, 1.0238e+11, 2.4911e+10, 6.4037e+10, 4.0160e+11, 3.4032e+11,
        5.3365e+10, 1.6159e+11, 2.7048e+10, 2.9618e+10, 3.6343e+10, 1.4280e+11,
        6.3682e+10, 5.5561e+10, 6.3583e+10, 1.5687e+11, 3.0200e+11, 2.4591e+11,
        7.4494e+10, 8.4029e+11, 8.1087e+11, 1.4202e+11, 4.1569e+11, 8.1522e+10,
        1.8816e+11, 9.8240e+11, 1.8988e+11, 2.3044e+11, 2.9140e+10, 4.6445e+10,
        4.6372e+11, 1.2672e+12, 1.8948e+11, 7.4890e+11, 1.5336e+11, 3.1906e+12,
        3.8781e+10, 1.3234e+11, 1.7078e+10, 1.8490e+10, 2.9261e+11, 3.7237e+10,
        9.3143e+11, 4.6348e+10, 2.0925e+11, 7.1682e+10, 1.1212e+10, 2.5353e+11,
        9.7534e+10, 5.5831e+10, 9.0218e+10, 5.1337e+11, 4.7810e+11, 4.0925e+11,
        7.0799e+10, 6.4341e+11, 2.9976e+11, 3.0310e+10, 1.5319e+11, 8.5938e+10,
        1.3232e+11, 1.1615e+10, 1.3300e+11, 2.5791e+11, 4.4688e+11, 9.9856e+11,
        1.6533e+11, 6.0630e+11, 8.8054e+11, 1.4449e+11, 3.2198e+12, 6.0532e+11,
        3.8015e+11, 2.9727e+11, 1.4380e+11, 9.5784e+10, 2.0067e+12, 1.8714e+11,
        2.9324e+11, 3.5372e+10, 4.1695e+11, 4.0197e+10, 3.1365e+12, 4.9565e+11,
        1.9386e+10, 7.6935e+10, 2.7994e+11, 3.1359e+11, 8.0126e+10, 2.8078e+11,
        2.8175e+10, 4.5509e+10, 1.4573e+12, 7.1198e+10, 4.0201e+11, 4.3571e+10,
        1.0491e+11, 1.6028e+12, 6.6859e+10, 1.3775e+12, 3.2146e+11, 4.6010e+10,
        1.2762e+12, 1.8880e+11, 4.8016e+11, 4.5035e+11, 2.3955e+11, 1.2688e+11,
        5.8623e+10, 1.1848e+11, 9.8205e+10, 1.3799e+11, 5.8886e+11, 4.0016e+13,
        1.9120e+10, 2.8185e+11, 1.2229e+12, 5.5424e+11, 2.7931e+11, 1.1081e+11,
        3.2572e+10, 2.2067e+11, 2.0025e+12, 2.7204e+11, 5.3803e+11, 1.2099e+11,
        6.2575e+10, 5.1949e+12, 7.9933e+10, 1.3187e+11, 3.1519e+11, 1.5916e+12,
        3.2041e+11, 8.6854e+10, 1.7159e+11, 2.2254e+11, 3.2993e+11, 2.0965e+11,
        4.5908e+11, 4.1900e+11, 9.8388e+10, 7.2091e+11, 3.3229e+10, 2.0387e+11,
        8.8405e+11, 2.1334e+11, 3.8295e+11, 2.3802e+11, 3.6950e+11, 7.4048e+10,
        7.3678e+10, 2.6336e+11, 1.6572e+11, 1.4450e+11, 1.4849e+11, 2.1404e+11,
        3.4429e+10, 4.1301e+11, 4.0772e+11, 7.8396e+10, 2.2574e+11, 2.6124e+11,
        1.4726e+11, 3.3924e+11, 1.5312e+11, 1.1235e+11, 3.2562e+12, 5.3214e+12,
        3.1977e+10, 3.7588e+11, 1.0761e+12, 3.0414e+11, 1.2913e+11, 1.3200e+11,
        4.5877e+10, 1.1155e+12, 2.3381e+11, 4.3257e+10, 1.1808e+11, 1.2943e+11,
        8.7685e+10, 4.4395e+10, 4.6156e+11, 6.7777e+10, 2.5398e+11, 9.5258e+10,
        3.8568e+11, 1.9244e+12, 1.8725e+11, 3.2479e+12, 6.3578e+10, 2.0882e+11,
        6.5137e+10, 7.1271e+10, 7.2489e+11, 4.2832e+11, 3.0518e+11, 4.7908e+10,
        2.2955e+11, 1.6308e+11, 1.5865e+11, 1.8792e+11, 2.3537e+10, 1.9775e+10,
        5.6435e+10, 6.4386e+10, 5.0672e+10, 4.0711e+11, 6.3477e+10, 1.1259e+11,
        6.9245e+10, 3.8102e+10, 2.2714e+11, 6.5554e+10, 7.7495e+11, 1.5796e+12,
        9.6182e+11, 1.4631e+11, 1.6381e+11, 2.6701e+11, 3.4362e+11, 1.0240e+11,
        6.0000e+11, 8.8385e+10, 1.5430e+11, 8.5432e+10, 1.0327e+12, 4.4421e+11,
        2.4246e+11, 4.6609e+11, 1.5392e+11, 7.4572e+10, 2.4800e+11, 2.2660e+11,
        2.3414e+11, 1.1888e+11, 2.6826e+11, 8.4413e+10, 2.6129e+11, 4.1728e+11,
        1.1086e+14, 2.2109e+11, 1.9519e+11, 7.6584e+10, 2.7193e+11, 5.9698e+11,
        4.2368e+10, 7.6165e+10, 4.4123e+11, 4.5464e+10, 7.4533e+10, 4.9281e+11,
        6.9697e+11, 5.3703e+10, 9.4523e+10, 1.2691e+11, 3.2678e+11, 3.9520e+12,
        4.4497e+11, 2.5689e+11, 2.8588e+10, 2.5188e+10, 1.3672e+11, 6.7058e+10,
        2.3210e+11, 1.3629e+11, 7.8136e+10, 2.9117e+11, 1.5821e+12, 8.0471e+11,
        9.6376e+10, 7.9360e+11, 1.2419e+11, 5.5879e+10, 4.0296e+11, 6.4481e+10,
        1.3058e+11, 3.1086e+11, 5.6769e+12, 1.1266e+11, 7.0479e+11, 3.0169e+11,
        6.4285e+10, 3.1937e+10, 6.6011e+10, 4.9210e+11, 1.1982e+12, 4.0438e+10,
        2.9504e+11, 9.1390e+10, 1.6726e+11, 1.2235e+11, 1.0533e+11, 5.6904e+10,
        2.3707e+11, 1.5653e+11, 2.5360e+11, 3.9751e+11, 1.4719e+11, 2.6830e+12,
        9.6403e+10, 1.9272e+11, 2.5683e+11, 1.4153e+11, 8.9873e+10, 1.3808e+11,
        1.4693e+11, 3.9335e+11, 2.3556e+11, 1.1384e+12, 1.8455e+11, 3.5091e+11,
        7.4022e+10, 5.4383e+11, 1.9735e+10, 4.5723e+11, 2.5764e+11, 2.4700e+11,
        1.5781e+11, 6.1892e+11, 1.1313e+13, 5.7707e+11, 1.4484e+11, 1.7325e+11,
        1.5924e+11, 4.5557e+10, 1.4091e+11, 1.8642e+12, 2.2762e+10, 1.9738e+11,
        1.0449e+11, 3.6966e+11, 1.0702e+11, 2.2855e+11, 5.1760e+10, 4.4531e+11,
        1.3694e+11, 7.3442e+11, 1.0719e+11, 1.3710e+11, 2.7929e+11, 8.7996e+10,
        6.7354e+10, 1.2823e+12, 6.9305e+10, 4.3196e+10, 7.1474e+11, 5.9353e+11,
        3.5339e+11, 2.6485e+12, 4.6655e+10, 9.0827e+10, 1.2768e+12, 3.0185e+11,
        1.8958e+11, 6.2328e+10, 2.0299e+11, 2.9781e+11, 3.1688e+10, 2.8859e+11,
        1.8315e+11, 1.2934e+11, 8.1639e+10, 5.8902e+11, 1.7615e+11, 1.4900e+11,
        6.1810e+11, 1.0075e+11, 8.6500e+11, 2.4862e+11, 2.7854e+11, 1.9289e+12,
        5.9433e+10, 1.7519e+11, 3.9964e+11, 7.9289e+10, 2.9685e+11, 3.5058e+10,
        2.2504e+10, 8.9252e+10, 6.1797e+10, 9.0773e+10, 2.0086e+12, 1.0454e+12,
        1.4644e+11, 3.5735e+11, 2.2947e+11, 9.0503e+11, 1.8758e+11, 3.9409e+10,
        9.5431e+10, 1.1087e+11, 5.6643e+11, 1.2325e+11, 2.1001e+11, 2.3243e+11,
        1.1577e+11, 1.9975e+11, 1.9706e+11, 2.4052e+12, 3.1184e+10, 3.0971e+10,
        1.7974e+11, 2.6035e+11, 4.9705e+10, 1.9923e+11, 1.7988e+12, 6.6556e+11,
        3.2593e+11, 8.2427e+10])
Layer: encoder.5.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5.9574e+11, 1.1457e+12, 5.2029e+11, 1.4279e+11, 2.7641e+11, 2.0265e+11,
        9.7694e+10, 3.7366e+11, 3.0800e+11, 2.8033e+11, 1.9167e+11, 1.4279e+11,
        4.1413e+11, 8.2572e+11, 3.8724e+11, 8.0039e+10, 1.9107e+11, 8.4533e+10,
        1.7339e+11, 3.9601e+11, 1.7168e+11, 8.4544e+10, 9.7630e+10, 8.4064e+10,
        8.6884e+10, 7.8441e+11, 2.6782e+12, 5.9166e+10, 1.6966e+11, 1.3235e+13,
        1.6902e+11, 1.8723e+11, 9.5302e+10, 2.1053e+11, 9.3343e+10, 1.2636e+11,
        3.8230e+11, 6.7830e+10, 1.9859e+11, 1.8104e+11, 1.3662e+11, 1.0431e+12,
        4.1743e+11, 3.0714e+11, 1.3823e+11, 2.2665e+11, 2.7420e+11, 8.8290e+11,
        2.1487e+11, 8.8537e+10, 1.9759e+12, 1.4242e+11, 5.5245e+11, 2.4250e+11,
        3.2997e+11, 3.0732e+11, 3.6466e+11, 9.2652e+10, 1.7558e+11, 3.4610e+11,
        1.3091e+11, 7.5633e+10, 1.2767e+12, 2.8734e+11, 1.5809e+11, 5.7433e+11,
        5.4809e+11, 2.6224e+11, 1.9925e+11, 1.2149e+11, 2.1355e+11, 2.7761e+11,
        1.5270e+11, 2.0650e+11, 2.2485e+11, 1.1402e+11, 4.2209e+11, 1.2755e+11,
        2.1678e+11, 9.9916e+10, 8.3225e+10, 3.8204e+12, 1.1399e+11, 4.4940e+11,
        2.1936e+11, 1.4269e+11, 5.9439e+10, 2.2441e+11, 3.0754e+11, 6.1179e+11,
        3.5546e+11, 1.4152e+11, 2.1742e+11, 5.0290e+11, 2.7165e+11, 5.4829e+11,
        1.1652e+11, 2.7735e+11, 3.7174e+11, 3.4085e+11, 6.6453e+10, 2.5333e+11,
        5.2250e+11, 1.3954e+11, 1.0257e+11, 5.9688e+10, 4.1126e+11, 4.1564e+11,
        1.1813e+11, 1.8228e+11, 1.9075e+11, 1.8060e+11, 9.8463e+10, 1.2373e+11,
        4.9772e+10, 1.3625e+11, 2.4173e+11, 2.7244e+11, 5.6991e+11, 2.4164e+11,
        1.3110e+11, 1.0045e+12, 1.0343e+12, 2.5613e+11, 3.5042e+11, 1.4028e+11,
        3.5996e+11, 9.7201e+11, 2.9572e+11, 1.7191e+11, 5.4013e+10, 5.7537e+10,
        5.4346e+11, 1.2811e+12, 1.3900e+11, 6.5491e+11, 3.5494e+11, 3.0965e+12,
        8.6104e+10, 2.3669e+11, 1.8236e+11, 7.0593e+10, 2.7759e+11, 1.9673e+11,
        1.0191e+12, 1.8982e+11, 3.5667e+11, 2.5426e+11, 8.8446e+10, 2.2996e+11,
        1.1942e+11, 7.1504e+10, 2.4704e+11, 5.8399e+11, 5.8072e+11, 3.6425e+11,
        1.0429e+11, 6.6427e+11, 2.7427e+11, 1.2954e+11, 2.6430e+11, 1.0909e+11,
        1.1960e+11, 1.1181e+11, 1.8787e+11, 3.6621e+11, 6.2352e+11, 1.1674e+12,
        2.4541e+11, 5.8342e+11, 9.7912e+11, 1.4027e+11, 3.2120e+12, 6.6302e+11,
        4.5240e+11, 2.7366e+11, 1.3082e+11, 1.1402e+11, 2.0558e+12, 1.9328e+11,
        4.1955e+11, 8.3379e+10, 2.6903e+11, 6.2341e+10, 2.9810e+12, 5.0610e+11,
        1.0346e+11, 1.2155e+11, 2.1517e+11, 3.8056e+11, 1.6308e+11, 4.1271e+11,
        2.1065e+11, 1.0147e+11, 1.4406e+12, 1.8766e+11, 4.6658e+11, 2.7724e+11,
        1.8013e+11, 1.4791e+12, 1.9405e+11, 1.4190e+12, 3.1189e+11, 1.0798e+11,
        1.2928e+12, 2.3030e+11, 3.9896e+11, 3.2183e+11, 2.8876e+11, 2.4037e+11,
        2.0666e+11, 1.4963e+11, 1.5160e+11, 1.0391e+11, 6.9130e+11, 4.0081e+13,
        1.4462e+11, 4.2725e+11, 1.3554e+12, 5.9366e+11, 1.2570e+11, 2.7517e+11,
        1.6374e+11, 2.8159e+11, 1.9382e+12, 2.4564e+11, 6.0115e+11, 8.8556e+10,
        1.4205e+11, 7.6491e+12, 3.1724e+11, 2.1288e+10, 2.5459e+11, 1.7002e+12,
        3.4468e+11, 1.6545e+11, 1.3516e+11, 3.5518e+11, 3.8048e+11, 3.6202e+11,
        2.3805e+11, 5.5692e+11, 4.7519e+10, 6.0337e+11, 7.7153e+10, 1.8892e+11,
        1.2701e+12, 3.9674e+11, 4.7826e+11, 2.8754e+11, 3.6591e+11, 1.1786e+11,
        1.9434e+11, 1.3516e+11, 3.7727e+11, 1.8686e+11, 4.1012e+11, 2.1551e+11,
        1.2739e+11, 4.4915e+11, 7.4801e+11, 2.6629e+11, 2.3446e+11, 3.6060e+11,
        2.1872e+11, 2.4927e+11, 2.6436e+11, 1.3086e+11, 3.0678e+12, 5.2271e+12,
        1.0104e+11, 3.5506e+11, 1.0358e+12, 1.2087e+12, 1.6211e+11, 3.0787e+11,
        8.6285e+10, 1.0453e+12, 2.4749e+11, 1.3546e+11, 1.6738e+11, 2.8614e+11,
        4.4302e+10, 2.1965e+11, 6.4882e+11, 2.4303e+11, 6.1371e+11, 7.4793e+10,
        4.6339e+11, 2.2588e+12, 1.9187e+11, 3.2621e+12, 2.9563e+11, 3.1967e+11,
        6.8673e+10, 1.8453e+11, 9.3568e+11, 4.2014e+11, 3.1063e+11, 8.6692e+10,
        3.5582e+11, 2.5908e+11, 1.7621e+11, 1.2003e+11, 1.3878e+11, 3.6406e+11,
        1.6093e+11, 1.0828e+11, 1.2945e+11, 2.8652e+11, 8.3674e+10, 1.6720e+11,
        1.3752e+11, 8.6476e+10, 4.4390e+11, 1.7586e+11, 6.5728e+11, 1.7958e+12,
        9.6913e+11, 1.0618e+11, 2.7352e+11, 3.2903e+11, 2.7880e+11, 1.5777e+11,
        8.3973e+11, 1.6255e+11, 2.3152e+11, 2.3830e+11, 8.4819e+11, 4.3358e+11,
        4.2278e+11, 5.2861e+11, 1.8297e+11, 2.3058e+11, 3.9650e+11, 2.6453e+11,
        1.9590e+11, 1.3891e+11, 2.0112e+11, 1.7996e+11, 4.1059e+11, 4.7799e+11,
        1.1096e+14, 3.3114e+11, 1.9992e+11, 2.4071e+11, 1.7164e+11, 7.6533e+11,
        1.1147e+11, 3.9004e+11, 4.2304e+11, 1.2343e+11, 1.1281e+11, 5.4278e+11,
        9.5843e+11, 1.1142e+11, 6.6399e+10, 1.4311e+11, 4.1171e+11, 3.8804e+12,
        5.7576e+11, 2.6932e+11, 2.0253e+11, 5.4879e+10, 2.2392e+11, 2.6809e+11,
        3.9875e+11, 3.3953e+11, 1.5202e+11, 3.8781e+11, 1.6562e+12, 8.3630e+11,
        1.2628e+11, 8.1598e+11, 3.7756e+11, 1.3664e+11, 3.0982e+11, 3.2069e+11,
        1.4629e+11, 2.8446e+11, 5.8080e+12, 1.2149e+11, 5.9580e+11, 1.8148e+11,
        1.1503e+11, 1.6747e+11, 1.0927e+11, 5.8487e+11, 1.1139e+12, 8.7088e+10,
        1.2247e+11, 1.0655e+11, 1.4468e+11, 1.4523e+11, 6.4350e+10, 1.5169e+11,
        1.5566e+11, 1.5561e+11, 6.1102e+11, 4.2045e+11, 3.7452e+11, 2.7562e+12,
        1.3701e+11, 2.8943e+11, 1.8239e+11, 2.0917e+11, 1.1494e+11, 1.2392e+11,
        2.8915e+11, 4.0145e+11, 3.5433e+11, 1.1198e+12, 8.3737e+11, 1.7851e+11,
        8.6965e+10, 3.4300e+11, 6.9257e+10, 4.0464e+11, 3.6443e+11, 2.3361e+11,
        1.7933e+11, 6.3490e+11, 1.1136e+13, 6.8423e+11, 1.3498e+11, 2.8348e+11,
        2.3326e+11, 1.5782e+11, 2.5825e+11, 1.9174e+12, 1.1119e+11, 2.0606e+11,
        7.4563e+10, 5.0720e+11, 9.7508e+10, 2.0312e+11, 1.0835e+11, 4.1526e+11,
        2.5369e+11, 8.6892e+11, 1.8944e+11, 1.4575e+11, 3.0094e+11, 1.6401e+11,
        1.1247e+11, 1.2982e+12, 1.5981e+11, 2.8894e+11, 5.4988e+11, 5.1015e+11,
        3.1938e+11, 2.7368e+12, 8.6906e+10, 8.9232e+10, 1.4453e+12, 3.8322e+11,
        2.8613e+11, 3.0187e+11, 3.0329e+11, 2.7180e+11, 1.0976e+11, 2.5217e+11,
        2.0893e+11, 1.1980e+11, 2.5132e+11, 6.5244e+11, 3.4435e+11, 1.7552e+11,
        7.0513e+11, 3.2511e+11, 7.9438e+11, 2.3612e+11, 5.1914e+11, 1.9096e+12,
        1.0082e+11, 2.1183e+11, 3.9254e+11, 2.2567e+11, 2.8890e+11, 2.4484e+11,
        1.2967e+11, 2.1956e+11, 1.9052e+11, 1.6446e+11, 2.8168e+12, 1.2480e+12,
        4.0068e+11, 2.5408e+11, 2.3658e+11, 8.3712e+11, 2.3884e+11, 2.7436e+11,
        1.9216e+11, 2.6882e+11, 7.9295e+11, 1.4144e+11, 4.3536e+11, 1.4047e+11,
        2.1259e+11, 2.4926e+11, 1.0934e+11, 2.6499e+12, 6.8075e+10, 2.6122e+11,
        2.6301e+11, 4.6159e+11, 1.1238e+11, 2.2505e+11, 1.8176e+12, 7.9599e+11,
        5.6016e+11, 1.6970e+11])
Layer: encoder.5.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([4.3507e+11, 3.8247e+11, 2.4194e+11, 5.6080e+11, 3.2158e+11, 2.9003e+11,
        4.4895e+11, 3.4853e+11, 1.1717e+11, 3.8418e+11, 4.2156e+11, 2.1347e+11,
        1.9802e+11, 4.2182e+11, 4.2806e+11, 3.4957e+11, 3.8368e+11, 2.7200e+11,
        2.2911e+11, 2.3880e+11, 3.8423e+11, 1.3972e+11, 5.9641e+11, 2.1347e+11,
        5.0735e+11, 2.7360e+11, 1.8618e+11, 4.8475e+11, 3.3456e+11, 3.4011e+11,
        3.6743e+11, 2.9023e+11, 2.3216e+11, 2.5338e+11, 4.4015e+11, 2.9623e+11,
        3.2853e+11, 4.8359e+11, 2.1062e+11, 5.6202e+11, 2.1057e+11, 7.2391e+10,
        5.5810e+11, 3.3092e+11, 3.9274e+11, 4.9584e+11, 2.8213e+11, 2.7489e+11,
        1.6206e+11, 1.9364e+11, 1.8750e+11, 4.7936e+11, 2.8955e+11, 3.3919e+11,
        2.9815e+11, 1.8121e+11, 4.0660e+11, 3.1586e+11, 3.3413e+11, 6.3617e+11,
        2.5784e+11, 5.3204e+11, 5.5737e+11, 1.2282e+11, 5.2711e+11, 1.9166e+11,
        5.4386e+11, 5.2233e+11, 3.0398e+11, 2.3924e+11, 4.2542e+11, 2.5532e+11,
        2.1378e+11, 2.8358e+11, 2.2968e+11, 3.4603e+11, 1.4444e+11, 1.7460e+11,
        1.4668e+11, 2.2217e+11, 3.3222e+11, 1.4734e+11, 4.0227e+11, 4.3574e+11,
        1.4350e+11, 3.2304e+11, 3.4776e+11, 2.5293e+11, 3.7470e+11, 2.4862e+11,
        1.1592e+11, 1.6760e+11, 3.0536e+11, 2.4309e+11, 4.9286e+11, 4.4205e+11,
        2.5482e+11, 2.4838e+11, 2.6586e+11, 2.6869e+11, 2.1945e+11, 3.2903e+11,
        5.0574e+11, 2.4723e+11, 9.7164e+10, 1.2362e+11, 4.4839e+11, 3.7571e+11,
        5.4806e+11, 2.8705e+11, 2.9860e+11, 2.9072e+11, 3.7199e+11, 4.1863e+11,
        5.3013e+11, 3.4614e+11, 2.3277e+11, 1.9268e+11, 2.3420e+11, 3.1763e+11,
        3.5993e+11, 3.4832e+11, 2.1808e+11, 1.2217e+11, 2.1183e+11, 3.3026e+11,
        1.6581e+11, 6.0137e+11])
Layer: encoder.5.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.1343e+11, 4.4492e+11, 5.6840e+11, 3.6274e+11, 4.9971e+11, 4.2737e+11,
        4.9247e+11, 3.6365e+11, 4.5410e+11, 4.6827e+11, 5.4350e+11, 3.8949e+11,
        2.7468e+11, 3.4690e+11, 3.8390e+11, 3.1728e+11, 6.1838e+11, 4.1587e+11,
        4.9936e+11, 5.0529e+11, 3.9076e+11, 6.0296e+11, 5.1659e+11, 4.6394e+11,
        3.0224e+11, 2.6612e+11, 6.7896e+11, 2.6116e+11, 6.1418e+11, 5.6714e+11,
        6.0296e+11, 8.2939e+11, 1.2799e+11, 5.8829e+11, 5.1440e+11, 5.9786e+11,
        4.0990e+11, 2.9192e+11, 2.6800e+11, 3.0113e+11, 2.6755e+11, 2.7459e+11,
        2.2984e+11, 2.2484e+11, 4.9379e+11, 7.8995e+11, 1.0867e+12, 3.2566e+11,
        5.0062e+11, 4.3290e+11, 6.2164e+11, 5.4227e+11, 5.5780e+11, 1.9481e+11,
        2.0532e+11, 4.0831e+11, 6.2995e+11, 1.0274e+12, 3.1285e+11, 1.9403e+11,
        2.5576e+11, 5.5194e+11, 3.5646e+11, 7.0548e+11, 4.7556e+11, 7.6253e+11,
        5.2049e+11, 5.9043e+11, 3.6876e+11, 2.7170e+11, 6.6460e+11, 3.0104e+11,
        2.5697e+11, 3.6879e+11, 8.8454e+11, 5.4754e+11, 6.8859e+11, 2.8519e+11,
        9.7747e+11, 4.4381e+11, 4.1884e+11, 3.7578e+11, 6.3717e+11, 4.3815e+11,
        1.5803e+11, 6.5417e+11, 9.3621e+11, 3.5426e+11, 1.7315e+11, 5.1846e+11,
        9.6856e+11, 3.9087e+11, 2.7189e+11, 2.9772e+11, 2.4647e+11, 3.2628e+11,
        6.3254e+11, 5.0555e+11, 3.2131e+11, 3.8280e+11, 3.8203e+11, 2.8127e+11,
        2.6316e+11, 2.9994e+11, 4.5229e+11, 3.6512e+11, 3.5787e+11, 4.2221e+11,
        4.9972e+11, 6.0740e+11, 5.6179e+11, 4.1115e+11, 6.9105e+11, 5.0888e+11,
        2.5197e+11, 1.8230e+11, 8.8814e+11, 3.9237e+11, 5.0688e+11, 8.3157e+11,
        3.1917e+11, 5.9736e+11, 4.2485e+11, 8.7586e+11, 2.9185e+11, 2.9278e+11,
        9.3735e+11, 7.2154e+11])
Layer: encoder.5.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([3.0071e+10, 2.3258e+10, 2.7958e+10, 3.1939e+10, 1.1516e+10, 8.2202e+10,
        5.8789e+09, 3.4627e+10, 1.4338e+10, 3.7161e+10, 6.0657e+09, 1.0897e+10,
        3.3544e+10, 5.3960e+10, 6.7383e+09, 3.9207e+10, 1.5620e+10, 5.4389e+10,
        1.7984e+10, 4.0560e+10, 3.2634e+10, 1.5024e+10, 4.0908e+10, 3.6506e+10,
        1.4716e+10, 6.5141e+10, 4.9324e+11, 5.3638e+10, 5.6316e+10, 1.7672e+10,
        1.0274e+10, 1.0919e+10, 1.2557e+10, 6.4631e+10, 3.9907e+10, 1.1757e+10,
        9.5195e+09, 2.7268e+09, 5.4043e+09, 2.6609e+09, 1.5053e+10, 4.0513e+10,
        1.5643e+10, 2.5821e+09, 1.5243e+10, 9.1963e+09, 1.5867e+10, 3.4971e+10,
        2.4756e+11, 4.1736e+10, 1.1256e+11, 5.4344e+10, 4.7685e+09, 1.5108e+10,
        1.4312e+10, 2.6687e+10, 2.2924e+10, 5.5918e+09, 4.6631e+10, 4.7336e+10,
        3.0250e+10, 8.1818e+09, 3.2683e+10, 5.0880e+10, 2.0441e+10, 2.3315e+10,
        2.0005e+10, 2.5218e+10, 7.9636e+09, 1.5553e+10, 9.0298e+09, 1.7689e+10,
        1.1465e+10, 2.4998e+10, 3.1864e+10, 1.2073e+10, 1.4204e+10, 1.7536e+09,
        2.8149e+10, 1.2344e+10, 2.6043e+10, 3.2416e+10, 2.2006e+10, 3.8952e+10,
        2.9350e+10, 5.5204e+10, 1.4928e+09, 3.5990e+10, 2.8533e+10, 1.4159e+11,
        1.7517e+10, 1.2827e+10, 8.1542e+10, 2.9094e+10, 5.2756e+10, 9.6695e+09,
        1.0060e+10, 6.8934e+10, 1.4138e+10, 1.0028e+09, 2.3686e+10, 4.7294e+10,
        5.5587e+10, 1.6582e+10, 1.3671e+10, 3.1376e+10, 7.2561e+09, 1.2338e+10,
        1.8322e+10, 2.5253e+10, 7.4923e+10, 4.5112e+10, 2.9368e+10, 6.9455e+09,
        1.6989e+10, 5.6125e+10, 4.0728e+09, 3.7687e+10, 9.9314e+10, 2.9622e+10,
        6.0748e+10, 1.1515e+10, 8.6721e+10, 1.5699e+10, 3.7904e+10, 3.6075e+10,
        2.3041e+10, 1.7500e+10, 1.5685e+10, 3.3269e+10, 3.5459e+10, 2.4943e+10,
        2.0665e+10, 3.6726e+10, 2.6117e+10, 1.9715e+10, 3.4869e+10, 1.7606e+10,
        1.9037e+10, 3.2334e+10, 1.2129e+11, 2.2396e+10, 1.4025e+11, 1.4568e+10,
        8.7701e+09, 1.9383e+09, 8.3346e+09, 6.2822e+10, 2.1688e+10, 2.5787e+10,
        4.7912e+10, 3.4752e+09, 2.6354e+09, 8.6881e+09, 1.9072e+11, 3.7682e+10,
        4.9749e+10, 2.6007e+10, 5.3935e+10, 3.6155e+10, 2.9314e+10, 1.4118e+10,
        6.8429e+10, 2.2593e+10, 1.2158e+11, 2.2940e+10, 5.9262e+10, 1.2739e+11,
        3.7708e+10, 2.1102e+10, 2.7990e+10, 1.6690e+10, 2.0321e+10, 1.1083e+10,
        3.3987e+10, 7.9322e+09, 7.1971e+09, 8.7123e+09, 4.6924e+10, 2.6222e+10,
        3.5235e+10, 3.9162e+09, 6.1124e+10, 4.3237e+10, 5.6366e+10, 6.6948e+11,
        2.4081e+10, 1.8255e+09, 2.5578e+11, 3.1920e+10, 1.8117e+10, 7.8162e+09,
        2.8441e+09, 2.0572e+10, 4.2839e+10, 5.2652e+10, 1.7526e+11, 3.2078e+09,
        1.6077e+10, 3.7480e+10, 2.4473e+10, 3.1504e+10, 1.7140e+10, 6.1552e+09,
        2.8324e+10, 6.1131e+10, 1.3520e+10, 1.8730e+11, 1.9475e+10, 8.8236e+09,
        1.9056e+09, 1.8298e+10, 2.0489e+10, 3.0327e+10, 4.3906e+09, 1.5749e+10,
        4.3900e+10, 7.3801e+09, 6.8293e+09, 1.8600e+10, 1.8585e+11, 1.3985e+10,
        2.9151e+10, 2.7064e+10, 2.1616e+10, 4.4545e+10, 1.8335e+10, 6.3840e+10,
        3.5858e+10, 2.4611e+12, 8.9829e+09, 1.8733e+10, 1.3136e+10, 6.5056e+10,
        3.7852e+10, 2.4652e+09, 2.4437e+10, 1.3868e+10, 6.0151e+09, 6.6284e+09,
        1.5346e+10, 2.6337e+10, 4.2762e+09, 8.8230e+10, 3.8773e+09, 3.8312e+10,
        2.6790e+10, 1.8890e+10, 2.5039e+10, 3.8678e+10, 1.9264e+10, 3.6597e+10,
        2.1058e+10, 1.8344e+10, 6.2259e+10, 2.8919e+10, 5.5391e+10, 4.6184e+10,
        8.3061e+09, 2.1423e+10, 2.0839e+11, 5.6028e+09, 1.0715e+10, 8.7663e+09,
        1.8743e+10, 4.6194e+10, 6.5913e+10, 2.5871e+10, 2.3982e+10, 1.0224e+10,
        1.7583e+10, 4.7495e+10, 3.5945e+10, 3.6587e+10, 4.5928e+09, 2.0439e+10,
        4.5326e+09, 8.1231e+09, 1.2556e+10, 4.0226e+10, 1.3015e+10, 1.2288e+10,
        9.0502e+10, 3.5664e+10, 6.6523e+09, 1.7206e+10, 3.4887e+11, 9.3873e+09,
        1.1040e+10, 2.3479e+10, 4.5662e+10, 1.2663e+10, 7.4650e+09, 1.6239e+10,
        4.0597e+10, 1.6913e+10, 5.0365e+10, 1.1401e+10, 1.4257e+10, 9.7454e+09,
        7.4801e+10, 1.3707e+10, 5.5124e+10, 3.7749e+10, 1.0448e+10, 3.4264e+10,
        4.6106e+10, 4.6508e+10, 2.9641e+10, 1.9949e+10, 2.7543e+10, 4.2409e+10,
        2.5371e+09, 1.0147e+10, 3.6534e+11, 3.0714e+10, 6.6494e+09, 2.7845e+11,
        2.0107e+10, 9.2217e+09, 1.5069e+10, 7.1652e+10, 8.0593e+10, 2.0588e+10,
        1.5443e+10, 1.9792e+10, 8.6444e+10, 1.2375e+10, 1.1622e+11, 2.6467e+11,
        6.8459e+10, 1.9276e+10, 3.3866e+10, 3.8192e+10, 2.4395e+10, 3.9025e+10,
        2.4825e+10, 3.2022e+10, 5.0124e+10, 1.8974e+10, 2.0783e+10, 3.1967e+10,
        1.5680e+10, 2.1604e+10, 2.5935e+10, 1.6987e+10, 6.0003e+10, 6.6877e+10,
        1.8508e+10, 1.0118e+10, 4.7971e+10, 3.4897e+10, 1.5199e+10, 6.9081e+09,
        1.3426e+10, 2.2774e+09, 4.7122e+09, 1.9803e+10, 4.1804e+10, 3.6017e+10,
        3.9610e+10, 5.5741e+10, 1.3767e+10, 5.3233e+09, 2.6293e+10, 7.9958e+09,
        2.0285e+11, 2.1247e+10, 1.2723e+10, 3.1776e+10, 7.9865e+10, 2.8844e+10,
        5.3423e+10, 2.2657e+10, 8.2608e+10, 1.2886e+10, 4.3273e+10, 2.4026e+10,
        1.1751e+10, 1.4405e+10, 5.0024e+10, 4.4067e+10, 3.0257e+10, 8.6512e+09,
        3.9973e+10, 4.9778e+10, 4.4457e+10, 5.5845e+10, 1.5420e+10, 4.7025e+10,
        1.4974e+10, 1.5382e+10, 2.0166e+10, 8.8206e+10, 1.0359e+10, 2.1096e+10,
        1.5542e+10, 1.0547e+10, 2.0527e+11, 2.8278e+10, 1.0399e+10, 5.7413e+10,
        4.8090e+10, 3.4317e+10, 4.7448e+10, 4.9175e+10, 2.1823e+10, 1.3178e+10,
        1.6302e+10, 7.3104e+10, 1.7875e+10, 1.1093e+11, 5.5105e+11, 1.1242e+10,
        6.8244e+10, 3.3928e+10, 1.4197e+10, 3.4981e+10, 2.5488e+10, 1.7346e+10,
        1.9619e+10, 2.7088e+10, 5.0088e+10, 3.8616e+10, 2.6335e+10, 5.2205e+10,
        3.6340e+10, 7.8275e+09, 1.7823e+10, 5.6917e+09, 1.9164e+10, 6.6058e+10,
        2.6399e+10, 1.9669e+10, 1.0474e+10, 1.0965e+10, 2.2691e+09, 1.8795e+10,
        1.9761e+10, 3.3454e+10, 8.9128e+10, 1.7132e+10, 2.4220e+10, 3.6765e+09,
        1.3595e+10, 3.3562e+10, 7.3578e+10, 1.5632e+10, 2.4031e+10, 2.7230e+10,
        2.3864e+10, 3.0239e+10, 2.5734e+10, 6.5234e+09, 4.1284e+10, 1.1764e+11,
        2.9246e+10, 4.3388e+10, 1.0554e+10, 3.2981e+10, 2.0230e+10, 4.7460e+10,
        2.3469e+10, 7.4115e+10, 3.7939e+09, 1.9891e+10, 2.2769e+10, 1.2285e+10,
        2.7838e+10, 1.2713e+10, 8.6791e+09, 2.4657e+10, 1.8705e+10, 2.9590e+10,
        5.4767e+09, 1.0663e+10, 3.1533e+10, 1.4490e+10, 2.0351e+10, 9.3420e+09,
        3.4404e+10, 1.3531e+10, 1.0331e+10, 4.1030e+10, 6.2374e+11, 7.1624e+10,
        2.3127e+10, 1.2564e+10, 3.6656e+10, 4.6052e+10, 6.5264e+10, 4.4905e+10,
        2.9068e+10, 2.9636e+10, 1.9329e+10, 1.4205e+10, 3.7124e+10, 6.2595e+10,
        1.8450e+10, 3.3491e+09, 5.7995e+10, 5.7636e+10, 4.2594e+10, 1.0305e+10,
        4.2620e+10, 2.7687e+10, 9.1639e+10, 6.3849e+10, 6.9583e+10, 1.7060e+10,
        2.4493e+10, 4.9387e+10])
Layer: encoder.5.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([6.7887e+10, 6.8914e+10, 3.2596e+10, 7.1297e+10, 8.3659e+10, 6.0761e+10,
        2.9921e+10, 6.4706e+10, 8.6337e+10, 1.0144e+11, 1.0975e+11, 2.9371e+10,
        7.3058e+10, 1.0604e+11, 6.0750e+10, 8.9220e+10, 4.6699e+10, 6.8454e+10,
        1.2245e+11, 9.0422e+10, 1.0880e+11, 4.8921e+10, 1.6747e+11, 2.9655e+10,
        2.6403e+10, 6.3090e+10, 6.8244e+10, 1.1876e+11, 1.0100e+11, 6.3764e+10,
        8.2952e+10, 3.0898e+10, 7.2788e+10, 1.0116e+11, 7.2132e+10, 5.9338e+10,
        6.7660e+10, 5.9409e+10, 1.0777e+11, 1.6613e+11, 1.1853e+11, 4.7055e+10,
        8.0488e+10, 5.0725e+10, 4.5363e+10, 5.2079e+10, 6.7828e+10, 4.2875e+10,
        1.3392e+11, 8.4819e+10, 1.4187e+11, 5.5874e+10, 7.6543e+10, 1.4974e+11,
        4.4721e+10, 4.4231e+10, 5.4854e+10, 3.0450e+10, 1.6417e+10, 3.0792e+10,
        8.0842e+10, 3.0865e+10, 8.4550e+10, 1.4048e+11, 9.1575e+10, 1.1651e+11,
        3.1464e+10, 9.6915e+10, 2.7496e+10, 3.9518e+10, 2.7493e+10, 8.7751e+10,
        9.0012e+10, 1.5186e+11, 9.3868e+10, 5.6117e+10, 2.5989e+10, 1.4501e+11,
        4.3222e+10, 7.8705e+10, 1.2396e+11, 4.6412e+10, 9.6140e+10, 1.8690e+10,
        5.2495e+10, 3.9100e+10, 5.9829e+10, 9.5951e+10, 7.6708e+10, 6.3877e+10,
        7.0772e+10, 1.7210e+11, 4.9963e+10, 6.0749e+10, 2.3077e+10, 1.0489e+11,
        5.6859e+10, 1.1154e+11, 9.5265e+10, 8.0186e+10, 1.5592e+10, 6.2104e+10,
        2.1117e+11, 3.2385e+10, 3.8674e+10, 4.8161e+10, 7.2656e+10, 7.8767e+10,
        1.2355e+11, 1.0710e+11, 4.4856e+10, 1.9927e+10, 1.0425e+11, 2.7602e+10,
        3.5694e+10, 5.2375e+10, 3.5938e+10, 5.3383e+10, 6.0306e+10, 1.0053e+11,
        1.3367e+11, 1.3773e+11, 6.2047e+10, 1.1671e+11, 3.1424e+10, 1.0956e+11,
        5.5114e+10, 2.5912e+10])
Layer: encoder.5.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.8697e+10, 1.0528e+11, 7.4550e+10, 1.4052e+11, 1.0771e+11, 4.4756e+10,
        2.3317e+11, 4.0542e+10, 1.6244e+11, 7.5736e+10, 4.4875e+10, 7.0789e+10,
        8.2885e+10, 3.6460e+10, 1.0299e+11, 1.1881e+11, 1.1562e+11, 7.8571e+10,
        4.4747e+10, 4.8339e+10, 1.1627e+11, 5.9245e+10, 1.2328e+11, 4.3018e+10,
        1.0864e+11, 4.4054e+10, 6.0197e+10, 7.1612e+10, 2.3028e+11, 2.4779e+11,
        1.9343e+11, 2.5396e+11, 1.5691e+11, 1.2513e+11, 9.0222e+10, 1.2124e+11,
        1.7494e+11, 9.4340e+10, 2.8434e+10, 9.7028e+10, 5.6901e+10, 5.0362e+10,
        4.7365e+10, 1.1277e+11, 3.6689e+10, 7.0685e+10, 2.1888e+11, 1.0658e+11,
        1.8354e+11, 3.3281e+11, 4.7672e+10, 1.3553e+11, 7.3239e+10, 5.8992e+10,
        1.6368e+11, 1.0192e+11, 3.4367e+10, 1.8593e+11, 4.5673e+10, 2.8894e+11,
        9.1757e+10, 1.5081e+11, 1.8286e+11, 8.1224e+10, 1.2363e+11, 1.2258e+11,
        1.0901e+11, 2.1037e+11, 6.6951e+10, 5.6692e+10, 8.8519e+10, 2.8620e+10,
        1.3610e+11, 9.8723e+10, 1.3872e+11, 5.8930e+10, 1.3201e+11, 1.3765e+11,
        1.0361e+11, 1.2322e+11, 5.1093e+10, 1.3637e+11, 1.0270e+11, 1.6478e+11,
        5.0473e+10, 7.6827e+10, 1.5362e+11, 4.4535e+10, 2.3320e+10, 6.0381e+10,
        1.6755e+11, 6.4905e+10, 5.7211e+10, 1.2605e+11, 8.0834e+10, 1.7160e+11,
        1.5636e+11, 8.6761e+10, 1.4798e+11, 1.6576e+11, 1.2167e+11, 8.4802e+10,
        5.8382e+10, 7.1015e+10, 2.1831e+11, 9.1269e+10, 1.4102e+11, 8.6060e+10,
        1.1217e+11, 5.0505e+10, 8.9452e+10, 6.9885e+10, 2.1895e+11, 9.7421e+10,
        1.2928e+11, 9.6540e+10, 5.7459e+10, 7.0853e+10, 1.2034e+11, 7.0685e+10,
        2.9629e+10, 9.4727e+10, 2.1356e+11, 3.5596e+10, 1.0537e+11, 9.6481e+10,
        8.0507e+10, 4.7903e+10])
Layer: encoder.5.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.8173e+09, 4.1995e+09, 7.4884e+08, 6.6693e+08, 4.2836e+08, 1.2081e+09,
        2.3050e+08, 3.8216e+09, 2.5348e+09, 1.1541e+09, 3.0601e+09, 5.2724e+08,
        2.9305e+09, 8.5700e+08, 5.8891e+08, 1.6308e+09, 1.7856e+09, 6.6829e+09,
        1.0631e+09, 1.0610e+09, 9.4438e+08, 1.8355e+09, 1.6173e+09, 2.0442e+09,
        8.7983e+09, 5.3724e+09, 1.6468e+09, 1.8322e+09, 2.1731e+09, 2.3545e+09,
        1.6981e+09, 1.0118e+09, 6.0235e+08, 1.3714e+09, 1.0207e+09, 6.2941e+08,
        1.9972e+09, 1.4117e+09, 2.2279e+09, 2.4112e+09, 4.2398e+08, 3.2316e+08,
        2.1121e+09, 2.0083e+10, 6.2697e+08, 1.4599e+09, 1.6210e+09, 1.5849e+09,
        1.2201e+09, 6.8815e+08, 1.2100e+09, 1.1150e+09, 7.1027e+08, 7.8025e+08,
        1.9929e+08, 2.1118e+09, 4.3826e+08, 2.8123e+08, 9.6799e+08, 4.9192e+08,
        1.3354e+09, 7.8876e+08, 1.3396e+11, 9.4620e+08, 1.2058e+09, 2.2039e+09,
        2.3073e+08, 1.0126e+09, 3.1958e+08, 1.6168e+09, 1.8257e+09, 2.8090e+08,
        1.5085e+09, 4.3691e+09, 4.0165e+10, 1.7143e+08, 7.2897e+09, 3.0937e+08,
        2.7256e+09, 3.7395e+08, 1.5119e+09, 9.4600e+08, 1.0583e+09, 1.4422e+09,
        4.0979e+09, 8.4051e+08, 2.0733e+08, 2.9164e+09, 3.5362e+08, 2.3679e+09,
        2.1200e+09, 2.1773e+09, 9.0507e+08, 1.1602e+09, 2.8680e+09, 1.0937e+09,
        7.8740e+08, 1.4614e+09, 5.5616e+08, 1.0050e+08, 1.0956e+09, 2.2996e+10,
        8.9956e+08, 2.0932e+09, 1.5516e+09, 1.5735e+09, 5.1776e+08, 3.2310e+09,
        7.1523e+08, 8.0551e+08, 9.6132e+08, 1.1297e+09, 2.7623e+09, 1.2993e+09,
        3.6267e+09, 6.9630e+09, 3.0341e+09, 3.0981e+09, 4.7125e+10, 3.7322e+09,
        4.1127e+10, 7.6002e+08, 1.7883e+10, 2.2032e+09, 2.7375e+09, 1.0678e+09,
        1.4097e+09, 1.8389e+09, 5.0642e+08, 6.8234e+08, 6.4560e+09, 3.9660e+09,
        1.3015e+09, 2.1898e+09, 1.2258e+10, 4.8613e+08, 2.7982e+08, 2.3077e+10,
        2.7710e+09, 1.3553e+09, 4.2559e+08, 1.1858e+09, 9.0938e+08, 1.0197e+09,
        2.5714e+08, 4.5496e+08, 4.6777e+08, 2.5433e+09, 2.3845e+09, 1.0149e+10,
        7.0858e+08, 2.1388e+08, 7.3443e+08, 4.5665e+08, 6.2832e+08, 7.4338e+08,
        6.8142e+09, 7.0007e+08, 2.9988e+09, 2.7548e+09, 1.1169e+09, 3.3279e+10,
        1.6181e+09, 2.5386e+09, 2.7564e+09, 3.0886e+10, 2.0432e+09, 7.1182e+09,
        1.5173e+09, 2.2982e+10, 2.0436e+09, 1.5310e+09, 3.8808e+09, 5.8795e+09,
        5.6149e+09, 4.5472e+09, 6.2803e+08, 5.3758e+08, 3.0363e+09, 3.3153e+08,
        5.3918e+09, 2.7086e+08, 2.5277e+09, 3.1827e+09, 4.0156e+09, 3.7738e+09,
        6.3119e+09, 6.2850e+08, 2.8460e+09, 1.1858e+09, 5.6539e+08, 2.7830e+09,
        6.9828e+08, 3.3017e+09, 1.2936e+09, 1.9127e+09, 9.2625e+08, 5.2640e+08,
        5.3352e+09, 1.2361e+09, 4.3550e+09, 1.4040e+10, 1.0633e+09, 1.0208e+09,
        1.6609e+09, 1.7217e+09, 1.3119e+09, 1.3639e+09, 8.4200e+08, 2.7857e+08,
        1.3211e+08, 2.2461e+09, 1.0837e+09, 7.5054e+08, 2.5090e+08, 4.3002e+09,
        6.2868e+09, 8.9620e+09, 4.6005e+08, 7.1108e+09, 9.7468e+08, 2.8674e+09,
        1.2949e+09, 2.6796e+09, 9.6797e+08, 2.7272e+10, 3.4599e+09, 4.3421e+10,
        6.2813e+09, 2.2593e+09, 1.7107e+08, 2.0352e+08, 4.0998e+08, 1.9233e+09,
        3.1734e+09, 3.4878e+08, 1.1878e+10, 4.9669e+08, 1.7169e+09, 2.2828e+08,
        5.5544e+09, 2.8288e+09, 5.7371e+08, 1.3113e+09, 5.4349e+08, 1.8124e+09,
        1.8670e+09, 2.3428e+09, 2.8061e+09, 1.5228e+09, 6.5387e+08, 2.8014e+09,
        1.9446e+09, 3.0829e+09, 2.7341e+09, 1.1735e+10, 2.9808e+09, 1.0219e+09,
        1.1583e+09, 2.7115e+09, 1.8359e+09, 4.9183e+08, 6.8449e+09, 5.5353e+08,
        6.7338e+08, 3.9579e+08, 8.8459e+08, 1.4394e+09, 4.0516e+09, 4.1500e+08,
        1.0733e+09, 1.7807e+09, 1.4569e+10, 5.7836e+11, 2.6639e+08, 1.3556e+09,
        3.6751e+08, 1.7398e+10, 1.3681e+09, 1.7397e+09, 9.9234e+08, 1.6741e+08,
        8.2617e+08, 1.0495e+09, 7.3995e+08, 3.0926e+09, 1.9521e+09, 1.9796e+08,
        1.2181e+09, 1.1680e+09, 3.1094e+09, 8.2332e+08, 3.1928e+08, 1.7538e+09,
        3.0580e+09, 6.9405e+09, 1.7783e+09, 3.6209e+08, 3.0834e+09, 6.6956e+08,
        6.6578e+09, 1.8879e+09, 1.1997e+09, 1.5727e+09, 4.7127e+08, 1.2570e+09,
        1.4395e+09, 5.7506e+08, 3.0445e+08, 7.1463e+09, 2.1415e+09, 7.2380e+09,
        5.9574e+08, 2.7409e+09, 2.5009e+09, 1.9025e+09, 4.8690e+08, 1.1414e+09,
        1.2548e+09, 2.9331e+09, 4.0765e+09, 1.0840e+09, 2.0977e+09, 3.9963e+08,
        6.2105e+08, 1.1720e+10, 2.3079e+09, 2.0204e+09, 1.1442e+09, 1.8204e+09,
        3.4057e+09, 1.2555e+09, 3.3350e+09, 1.1234e+09, 2.0112e+10, 1.0387e+08,
        1.6228e+10, 3.2304e+08, 1.4481e+09, 1.0487e+09, 2.6798e+09, 9.4975e+08,
        4.3437e+08, 1.0788e+09, 5.7596e+08, 2.2792e+08, 1.2839e+09, 5.8397e+09,
        1.1010e+09, 8.6105e+08, 1.1505e+09, 4.0198e+10, 2.7188e+09, 9.6444e+08,
        1.1467e+09, 1.0484e+09, 3.2223e+08, 4.7583e+08, 2.0856e+09, 8.1741e+08,
        3.1032e+09, 4.2291e+09, 4.6482e+09, 5.0538e+07, 5.0789e+08, 6.7796e+08,
        6.3843e+08, 2.2487e+09, 1.6873e+08, 5.5450e+08, 2.7371e+09, 3.4781e+09,
        7.6246e+08, 9.1451e+08, 1.0813e+09, 3.9920e+09, 4.6382e+08, 1.9398e+09,
        1.5262e+09, 9.4442e+09, 6.8505e+09, 7.0143e+08, 3.3332e+09, 1.3296e+09,
        1.3032e+09, 2.3587e+09, 1.6085e+10, 4.5551e+08, 1.3476e+09, 4.7357e+09,
        4.4647e+09, 1.5959e+09, 2.9916e+09, 9.1668e+08, 1.0199e+09, 6.4487e+09,
        8.2649e+08, 5.6801e+08, 1.7617e+09, 3.1845e+09, 7.3285e+08, 2.8667e+09,
        1.4024e+09, 8.0344e+08, 3.1897e+09, 6.5791e+08, 1.2384e+09, 5.4789e+08,
        1.2093e+09, 6.8388e+08, 1.1883e+09, 2.3587e+09, 5.8216e+08, 9.8712e+08,
        2.3065e+09, 2.0129e+09, 2.8251e+09, 8.0315e+08, 1.3411e+09, 2.1921e+09,
        3.9487e+09, 1.2622e+09, 2.1033e+10, 2.3491e+09, 5.6984e+08, 4.6638e+10,
        1.8817e+09, 4.4115e+08, 2.2111e+09, 1.1359e+09, 5.5905e+08, 9.0500e+08,
        5.6479e+09, 3.2761e+08, 3.1469e+09, 2.1498e+09, 1.5251e+08, 1.5482e+09,
        1.4488e+09, 1.4350e+09, 4.6831e+09, 1.0488e+09, 2.0222e+09, 1.7789e+08,
        3.5474e+08, 9.6464e+08, 1.3492e+09, 2.3743e+09, 2.5695e+09, 6.5935e+08,
        4.1850e+09, 1.9584e+09, 8.8012e+08, 2.9381e+08, 1.6355e+09, 1.4140e+09,
        1.6955e+09, 2.5486e+09, 9.8917e+08, 4.4435e+09, 5.7965e+08, 2.1857e+09,
        1.1778e+09, 1.6145e+09, 2.4925e+08, 1.3688e+09, 9.2657e+08, 1.5688e+09,
        1.4634e+09, 6.3480e+08, 4.3651e+08, 2.1812e+09, 9.0558e+08, 2.7374e+08,
        6.5626e+08, 8.0464e+08, 1.8995e+09, 2.0014e+09, 6.1040e+09, 7.7902e+08,
        4.7595e+09, 1.7335e+10, 5.8876e+08, 7.9391e+08, 1.8123e+09, 2.2363e+09,
        1.3621e+08, 1.2617e+09, 2.8456e+09, 4.4754e+09, 8.1898e+08, 1.2702e+09,
        9.9386e+08, 2.5133e+09, 9.9175e+08, 7.6794e+08, 2.1707e+09, 8.9417e+09,
        3.9661e+08, 2.2681e+09, 1.4351e+09, 1.1478e+09, 7.4657e+08, 1.2180e+09,
        5.3358e+10, 2.8776e+09, 2.8127e+09, 1.0751e+09, 5.8475e+08, 2.3294e+09,
        4.2931e+09, 2.2541e+09])
Layer: encoder.5.3.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7.8763e+09, 7.4626e+09, 3.3110e+09, 2.3572e+09, 5.9267e+09, 6.8099e+09,
        6.3445e+09, 3.3185e+09, 4.9165e+09, 6.4327e+09, 1.1133e+09, 5.1336e+09,
        7.3543e+09, 2.3483e+09, 1.6289e+09, 3.2710e+09, 2.5406e+09, 4.5076e+09,
        5.7149e+09, 5.8864e+09, 4.4858e+09, 2.6415e+09, 6.4146e+09, 4.3042e+09,
        4.4346e+09, 9.0255e+09, 4.2884e+09, 4.7312e+09, 6.1600e+09, 2.8104e+09,
        2.4339e+09, 2.4588e+09, 4.8060e+09, 5.9995e+09, 9.5282e+09, 6.3297e+09,
        3.5838e+09, 2.6353e+09, 2.6666e+09, 3.3784e+09, 3.1667e+09, 4.2006e+09,
        4.8649e+09, 6.4581e+09, 5.5618e+09, 1.9256e+09, 1.1751e+10, 5.6073e+09,
        7.2482e+09, 4.2434e+09, 2.2874e+09, 4.4644e+09, 5.6257e+09, 2.1674e+09,
        2.8040e+09, 3.6193e+09, 2.3212e+09, 4.1585e+09, 4.9669e+09, 4.7832e+09,
        4.5843e+09, 4.5207e+09, 5.9779e+09, 4.4649e+09, 4.1815e+09, 5.8955e+09,
        3.2458e+09, 3.2591e+09, 6.3188e+09, 6.6458e+09, 2.7652e+09, 2.4748e+09,
        4.4673e+09, 6.0074e+09, 8.0008e+09, 7.2754e+09, 3.9680e+09, 1.5278e+09,
        3.2872e+09, 4.1868e+09, 1.2975e+10, 5.3804e+09, 6.4604e+09, 4.0423e+09,
        4.0644e+09, 5.6736e+09, 3.2906e+09, 3.8208e+09, 3.8667e+09, 4.5112e+09,
        5.2050e+09, 9.7800e+09, 6.9100e+09, 6.2511e+09, 6.8095e+09, 3.7528e+09,
        3.8635e+09, 3.7569e+09, 3.3576e+09, 2.3425e+09, 3.8310e+09, 6.6370e+09,
        5.6110e+09, 2.0582e+09, 7.1156e+09, 5.2370e+09, 8.6994e+09, 1.7671e+09,
        4.2526e+09, 3.9085e+09, 4.5889e+09, 3.0438e+09, 2.2908e+09, 3.7533e+09,
        5.0805e+09, 5.0307e+09, 8.9314e+09, 4.2373e+09, 9.2794e+09, 2.4324e+09,
        8.0211e+09, 4.9942e+09, 2.8257e+09, 2.0522e+09, 1.3733e+10, 5.7597e+09,
        8.3583e+09, 2.9865e+09])
Layer: encoder.5.3.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([6.4357e+09, 6.0755e+09, 3.8872e+09, 3.6756e+09, 4.6903e+09, 1.1048e+10,
        1.4342e+10, 9.5573e+09, 7.0850e+09, 6.9160e+09, 1.2804e+10, 9.8052e+09,
        6.3319e+09, 8.8044e+09, 1.2927e+10, 5.7710e+09, 1.5559e+10, 1.6530e+10,
        3.5274e+09, 5.1081e+09, 1.5776e+10, 1.3989e+10, 5.4674e+09, 5.0957e+09,
        7.8911e+09, 9.3258e+09, 5.9850e+09, 4.1506e+09, 4.7138e+09, 1.0026e+10,
        2.7590e+09, 5.8041e+09, 7.9436e+09, 9.0933e+09, 6.6988e+09, 7.9807e+09,
        6.0316e+09, 7.1518e+09, 8.5233e+09, 5.5582e+09, 8.4135e+09, 9.6081e+09,
        1.2476e+10, 8.3362e+09, 4.5989e+09, 3.3379e+09, 7.5521e+09, 7.6455e+09,
        5.3481e+09, 6.2328e+09, 3.8828e+09, 1.1594e+10, 3.0436e+09, 5.7648e+09,
        7.4849e+09, 9.0331e+09, 2.0087e+10, 5.2548e+09, 5.3435e+09, 8.3728e+09,
        9.5002e+09, 4.5730e+09, 5.9035e+09, 3.6123e+09, 1.4585e+10, 4.8277e+09,
        5.4828e+09, 6.1795e+09, 5.6289e+09, 1.2698e+10, 2.0880e+10, 7.1209e+09,
        8.0852e+09, 6.4255e+09, 1.8874e+10, 1.6825e+10, 1.3328e+10, 2.0471e+10,
        8.1997e+09, 4.0073e+09, 9.6681e+09, 6.3491e+09, 5.8099e+09, 5.4616e+09,
        5.7137e+09, 1.3733e+10, 7.6625e+09, 1.3907e+10, 8.1781e+09, 4.8148e+09,
        7.5808e+09, 9.3530e+09, 1.2785e+10, 6.6026e+09, 4.3811e+09, 5.7767e+09,
        3.0604e+09, 8.8079e+09, 9.0480e+09, 9.5579e+09, 1.2289e+10, 7.8895e+09,
        6.0522e+09, 7.9182e+09, 8.6391e+09, 8.6894e+09, 3.4676e+09, 7.8134e+09,
        6.6556e+09, 8.5777e+09, 4.3446e+09, 1.3464e+10, 4.3603e+09, 1.3284e+10,
        1.2739e+10, 1.0046e+10, 1.1803e+10, 1.2813e+10, 5.2662e+09, 5.3634e+09,
        1.3159e+10, 1.2290e+10, 4.0267e+09, 5.5349e+09, 1.1538e+10, 1.4584e+10,
        1.0425e+10, 1.6221e+10])
Layer: encoder.5.3.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.8794e+07, 2.0651e+08, 6.3302e+07, 2.5079e+07, 9.2553e+07, 7.1730e+08,
        5.5613e+06, 4.1231e+07, 1.1217e+08, 1.1599e+08, 4.4548e+07, 1.8142e+07,
        1.4873e+09, 1.0770e+08, 1.3509e+08, 4.2761e+08, 9.3009e+07, 3.1336e+08,
        2.5911e+07, 4.3240e+07, 1.4519e+08, 1.2065e+08, 6.1470e+07, 3.0145e+08,
        1.3410e+08, 1.3133e+08, 4.3292e+08, 1.1598e+08, 6.1269e+07, 7.5939e+07,
        2.6952e+07, 2.6888e+07, 2.3434e+07, 7.7489e+07, 3.0109e+07, 5.7112e+07,
        3.3827e+07, 1.0839e+07, 2.7712e+08, 1.8059e+07, 2.9771e+07, 1.7437e+07,
        2.8172e+07, 2.2145e+07, 3.8291e+08, 1.3162e+08, 1.1407e+08, 1.4899e+07,
        4.4930e+07, 2.8593e+08, 6.4982e+08, 5.2134e+07, 6.0293e+07, 8.9324e+06,
        3.3931e+07, 1.1241e+08, 1.5345e+08, 2.2895e+07, 5.5114e+08, 7.8298e+06,
        5.2369e+07, 2.0791e+07, 1.6125e+08, 6.9465e+07, 1.2247e+08, 2.9132e+07,
        3.0107e+07, 8.0618e+06, 3.5909e+07, 4.5888e+07, 3.5708e+08, 2.3222e+07,
        7.3056e+07, 1.2006e+08, 3.8597e+07, 7.5226e+06, 6.1832e+07, 1.1185e+07,
        9.0034e+07, 1.1753e+08, 3.5914e+08, 3.0170e+07, 9.8297e+06, 4.9703e+07,
        8.3835e+07, 8.7269e+07, 3.2382e+07, 9.1406e+07, 2.3262e+07, 5.8252e+07,
        9.1649e+07, 1.1378e+09, 1.3409e+07, 3.5656e+08, 1.5087e+08, 3.4365e+07,
        3.9809e+07, 1.1211e+08, 1.3587e+08, 1.0310e+07, 1.0960e+08, 4.8151e+07,
        1.6366e+08, 6.9116e+08, 2.1017e+07, 3.8824e+08, 2.7655e+08, 5.8006e+07,
        4.8134e+08, 1.6464e+07, 6.9840e+07, 1.0151e+08, 1.7632e+08, 3.5718e+07,
        6.4882e+07, 7.1859e+07, 3.4499e+08, 4.2403e+07, 1.0609e+08, 3.1873e+08,
        7.5713e+08, 3.4376e+07, 4.6279e+10, 9.4754e+07, 1.6997e+08, 8.2621e+07,
        1.2784e+08, 4.5538e+07, 5.7939e+07, 5.2664e+07, 8.0525e+07, 7.2120e+07,
        9.0365e+07, 2.4055e+07, 6.5720e+07, 1.6969e+08, 1.0433e+08, 7.9406e+07,
        1.2276e+08, 3.0782e+08, 6.8563e+07, 3.6721e+07, 2.2019e+08, 5.7192e+07,
        4.5144e+07, 2.8261e+07, 6.5975e+07, 6.8618e+07, 3.8773e+07, 5.1983e+08,
        5.0794e+07, 1.0639e+08, 7.9399e+06, 1.8529e+07, 1.5702e+07, 4.5591e+07,
        4.1955e+07, 8.1173e+07, 3.4428e+07, 3.7110e+07, 2.2590e+07, 8.7596e+07,
        3.5065e+07, 5.5148e+07, 9.3066e+07, 6.5506e+07, 4.7373e+08, 8.0643e+07,
        5.4825e+08, 3.6524e+07, 1.5416e+08, 9.1545e+07, 7.5321e+07, 6.1913e+08,
        5.7167e+07, 9.6233e+07, 2.6236e+07, 2.8852e+07, 5.1010e+09, 1.0752e+08,
        1.3107e+08, 8.4001e+06, 8.0619e+07, 2.0654e+08, 5.4165e+07, 1.0170e+08,
        1.1017e+08, 2.3079e+07, 2.2768e+08, 2.1463e+07, 9.3768e+06, 1.3268e+08,
        1.7936e+08, 6.6869e+08, 5.7103e+07, 5.5483e+07, 1.9548e+08, 4.7133e+07,
        9.1103e+09, 5.1136e+07, 8.1460e+07, 1.2681e+08, 4.9720e+07, 5.0120e+07,
        7.1897e+08, 5.0386e+07, 4.2714e+07, 6.9878e+07, 2.2515e+08, 1.9086e+08,
        1.3519e+07, 5.2075e+07, 2.4354e+08, 1.3890e+07, 1.8517e+08, 6.5786e+08,
        4.2236e+07, 2.3044e+07, 1.2366e+07, 1.1739e+08, 5.4584e+07, 9.3054e+07,
        2.7140e+07, 1.2515e+08, 6.8073e+08, 1.6985e+08, 3.8920e+07, 1.9679e+08,
        1.3814e+09, 1.2877e+08, 2.7905e+07, 1.1332e+07, 1.1591e+07, 1.9574e+08,
        3.1232e+07, 2.4433e+07, 1.8154e+08, 2.0697e+08, 2.2330e+08, 7.1154e+07,
        2.4254e+07, 3.5645e+07, 4.2519e+07, 4.0849e+07, 3.8121e+08, 3.2774e+08,
        2.4047e+08, 3.5600e+07, 1.6790e+08, 6.4533e+07, 4.9728e+08, 1.7436e+08,
        5.3122e+08, 6.5640e+08, 2.2079e+07, 6.2850e+07, 9.1459e+07, 1.1713e+08,
        2.1750e+07, 4.4278e+07, 9.0861e+07, 1.2026e+07, 2.9711e+08, 7.3970e+06,
        1.2453e+08, 2.0981e+07, 7.4313e+07, 3.6983e+08, 1.0592e+08, 1.2529e+07,
        2.1716e+08, 3.5998e+07, 1.7287e+08, 3.2401e+08, 3.6017e+07, 3.4758e+08,
        7.3624e+06, 2.3901e+08, 6.9708e+07, 9.6856e+07, 2.9068e+07, 1.6030e+07,
        7.0676e+07, 2.7154e+08, 1.7732e+07, 1.4577e+08, 1.6691e+08, 4.0128e+07,
        5.5966e+07, 5.2588e+07, 3.4580e+07, 2.8759e+08, 2.1537e+07, 1.8674e+08,
        8.2835e+07, 8.6081e+07, 1.5892e+08, 2.5360e+07, 4.8615e+07, 4.0139e+06,
        1.4221e+08, 1.5235e+08, 1.7472e+07, 3.2959e+08, 1.1851e+07, 7.3822e+07,
        9.2337e+07, 1.6704e+08, 4.7140e+07, 9.1273e+07, 9.3164e+07, 5.1790e+07,
        1.3426e+07, 1.7754e+08, 7.3750e+07, 1.0008e+08, 4.0311e+07, 5.3871e+07,
        1.9367e+08, 2.3006e+07, 1.0228e+08, 5.2847e+07, 6.2548e+07, 3.9615e+07,
        1.9047e+07, 7.8229e+07, 4.4218e+07, 1.2499e+08, 1.5550e+07, 5.5754e+07,
        7.0223e+07, 1.3332e+08, 4.3817e+08, 1.6487e+08, 1.3909e+08, 1.7545e+07,
        2.6622e+08, 1.8719e+07, 7.9014e+07, 3.9282e+07, 2.3944e+08, 1.0693e+08,
        1.5191e+07, 3.8841e+08, 1.8332e+08, 2.5252e+07, 2.8395e+07, 1.0396e+08,
        2.1069e+07, 1.7460e+08, 5.6263e+08, 1.3267e+08, 3.2639e+07, 1.2129e+07,
        1.1501e+08, 7.8644e+07, 1.1190e+07, 5.6800e+07, 5.9163e+08, 3.1461e+07,
        1.0298e+08, 5.7615e+07, 3.7642e+08, 2.0441e+06, 2.9121e+07, 4.1031e+07,
        1.5452e+08, 4.4535e+07, 1.8655e+07, 6.5388e+07, 1.0347e+08, 7.6453e+08,
        4.3946e+07, 5.7803e+07, 1.6714e+08, 1.6594e+08, 1.2099e+07, 5.4568e+07,
        8.6396e+07, 2.2794e+07, 5.9782e+07, 3.6634e+07, 9.7680e+07, 3.2327e+08,
        3.4822e+08, 4.3695e+08, 1.4281e+08, 3.9323e+07, 3.1519e+07, 3.5904e+07,
        1.0141e+08, 3.5979e+09, 1.4193e+08, 2.1176e+08, 1.1660e+08, 5.2240e+07,
        1.3686e+08, 1.9997e+08, 3.5208e+08, 1.9197e+08, 2.0525e+07, 4.5155e+07,
        5.3420e+07, 7.4413e+07, 3.2016e+07, 1.5222e+07, 1.0351e+08, 8.0454e+06,
        6.1438e+07, 1.8281e+08, 9.1395e+07, 4.9908e+07, 1.5454e+08, 6.1667e+08,
        6.6715e+07, 4.9781e+07, 3.2551e+08, 2.2851e+08, 4.1834e+07, 5.7174e+07,
        3.9504e+08, 1.0035e+08, 1.6615e+08, 1.4186e+08, 7.4687e+07, 2.4544e+08,
        1.3701e+08, 5.9197e+07, 2.5018e+09, 7.6142e+07, 5.6911e+07, 1.6802e+07,
        2.7410e+08, 1.4552e+08, 4.3532e+07, 3.0606e+07, 2.0748e+07, 7.0541e+07,
        1.5614e+08, 1.5419e+08, 3.3932e+07, 4.3994e+08, 2.3560e+07, 9.9615e+06,
        2.4187e+07, 5.2201e+07, 4.0335e+07, 4.2752e+07, 1.6798e+08, 2.1104e+07,
        2.1972e+08, 7.7895e+07, 4.9272e+08, 3.0272e+07, 1.1936e+08, 4.3952e+08,
        2.2165e+07, 4.6582e+07, 1.8975e+08, 6.3621e+07, 3.9029e+07, 2.0621e+08,
        7.6973e+07, 8.0714e+07, 3.1134e+07, 4.5572e+07, 3.7585e+08, 8.1677e+08,
        1.0847e+07, 2.0462e+08, 1.5599e+07, 1.0559e+08, 1.2661e+08, 2.7278e+07,
        1.7526e+07, 1.0874e+08, 4.5719e+07, 1.7344e+08, 1.3977e+08, 3.0614e+07,
        2.3139e+07, 4.0612e+08, 1.7718e+07, 2.4425e+07, 2.2857e+08, 7.4399e+07,
        1.3359e+07, 1.2291e+07, 7.8503e+07, 2.9265e+07, 4.4447e+07, 7.8968e+07,
        1.5501e+07, 7.5086e+07, 5.4685e+07, 1.4817e+08, 1.0552e+08, 4.1134e+08,
        1.2570e+07, 1.8554e+08, 7.8294e+07, 5.1007e+07, 2.9686e+08, 6.8279e+07,
        2.5234e+07, 1.0538e+08, 2.1541e+07, 2.1127e+08, 1.6827e+07, 4.9130e+07,
        5.8513e+07, 1.6096e+09])
Layer: encoder.6.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1.0701e+08, 1.0209e+08, 1.1281e+08, 5.5925e+07, 8.1846e+07, 1.1186e+08,
        8.1653e+07, 6.0020e+07, 8.1981e+07, 1.4718e+08, 7.1475e+07, 6.1522e+07,
        1.1543e+08, 1.2200e+08, 1.1640e+08, 5.7067e+07, 1.6655e+08, 1.2644e+08,
        9.6442e+07, 1.2275e+08, 5.4373e+07, 9.7846e+07, 7.8211e+07, 1.2844e+08,
        7.7183e+07, 1.0873e+08, 9.4086e+07, 8.6660e+07, 1.0425e+08, 1.2487e+08,
        1.0784e+08, 1.1963e+08, 8.0419e+07, 7.8241e+07, 1.9399e+08, 7.8629e+07,
        7.0418e+07, 8.0087e+07, 6.7403e+07, 6.6827e+07, 8.0919e+07, 7.3151e+07,
        1.6178e+08, 1.1836e+08, 6.2256e+07, 7.5286e+07, 1.1071e+08, 1.1815e+08,
        1.4036e+08, 6.4067e+07, 6.3585e+07, 1.0274e+08, 1.0681e+08, 1.1533e+08,
        1.0221e+08, 9.1006e+07, 1.1565e+08, 6.7065e+07, 1.0201e+08, 7.5049e+07,
        1.1121e+08, 8.8513e+07, 1.0831e+08, 7.9915e+07, 1.0323e+08, 1.7793e+08,
        1.1146e+08, 1.0050e+08, 1.3972e+08, 8.6308e+07, 1.1907e+08, 5.4647e+07,
        1.2569e+08, 8.9215e+07, 1.0415e+08, 9.9750e+07, 1.0016e+08, 7.5617e+07,
        8.6969e+07, 1.5218e+08, 7.8415e+07, 1.1577e+08, 1.5121e+08, 6.4353e+07,
        6.5108e+07, 8.9523e+07, 9.8720e+07, 1.5004e+08, 1.0328e+08, 8.5332e+07,
        4.9632e+07, 8.6810e+07, 1.2046e+08, 1.7029e+08, 1.0727e+08, 9.8462e+07,
        1.1634e+08, 9.5303e+07, 1.4122e+08, 8.1246e+07, 1.1173e+08, 1.4232e+08,
        9.7026e+07, 9.1737e+07, 9.1879e+07, 7.1846e+07, 8.1817e+07, 7.6064e+07,
        1.0023e+08, 1.2011e+08, 6.6366e+07, 1.0960e+08, 8.5523e+07, 1.1791e+08,
        1.0265e+08, 1.2369e+08, 1.0309e+08, 8.5713e+07, 5.6230e+07, 7.9285e+07,
        8.6282e+07, 1.0814e+08, 1.4624e+08, 1.4196e+08, 1.7093e+08, 1.9079e+08,
        6.2720e+07, 1.0169e+08, 6.0003e+07, 1.7605e+08, 9.4376e+07, 9.3023e+07,
        1.0069e+08, 8.7751e+07, 9.1541e+07, 1.0765e+08, 5.5577e+07, 5.7205e+07,
        1.2110e+08, 1.1074e+08, 9.5883e+07, 1.1530e+08, 9.0514e+07, 6.1169e+07,
        1.2660e+08, 9.3685e+07, 1.1254e+08, 5.5685e+07, 5.4558e+07, 1.2369e+08,
        1.0576e+08, 7.8938e+07, 1.0579e+08, 1.2691e+08, 1.0701e+08, 1.0132e+08,
        9.4964e+07, 8.1304e+07, 5.6591e+07, 1.4423e+08, 1.1173e+08, 8.0472e+07,
        1.2202e+08, 6.4357e+07, 1.2351e+08, 5.4153e+07, 1.1350e+08, 1.0509e+08,
        9.8938e+07, 6.7193e+07, 4.1388e+07, 1.6476e+08, 7.8419e+07, 7.4652e+07,
        7.5424e+07, 9.2448e+07, 1.1376e+08, 5.4252e+07, 7.5856e+07, 1.1123e+08,
        8.6444e+07, 9.6863e+07, 1.2823e+08, 1.3082e+08, 1.0261e+08, 8.9481e+07,
        9.3473e+07, 9.1814e+07, 1.1903e+08, 1.3945e+08, 1.2746e+08, 5.7821e+07,
        1.5706e+08, 7.7967e+07, 9.3275e+07, 1.0193e+08, 9.2881e+07, 7.5713e+07,
        6.3974e+07, 8.8559e+07, 1.0592e+08, 1.6896e+08, 1.0401e+08, 8.3693e+07,
        1.2793e+08, 8.8882e+07, 1.4450e+08, 8.3090e+07, 1.2731e+08, 6.9264e+07,
        1.0108e+08, 1.3349e+08, 1.2761e+08, 1.1951e+08, 7.4284e+07, 7.5777e+07,
        1.3993e+08, 8.9409e+07, 1.0042e+08, 1.3952e+08, 7.3225e+07, 1.7429e+08,
        9.5248e+07, 1.2318e+08, 1.1133e+08, 1.2108e+08, 1.2837e+08, 1.3441e+08,
        1.2515e+08, 6.0437e+07, 1.0923e+08, 7.0869e+07, 1.3307e+08, 1.1939e+08,
        1.4554e+08, 9.4259e+07, 1.1301e+08, 6.7980e+07, 5.8646e+07, 7.8889e+07,
        9.4019e+07, 7.8859e+07, 1.0399e+08, 9.3488e+07, 1.0764e+08, 1.2479e+08,
        1.1081e+08, 1.2064e+08, 6.4480e+07, 1.2234e+08, 1.2065e+08, 1.3998e+08,
        8.4188e+07, 1.3974e+08, 9.1092e+07, 9.0251e+07])
Layer: encoder.6.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2.0586e+08, 2.7860e+08, 2.5637e+08, 2.5589e+08, 2.1722e+08, 2.3401e+08,
        1.6379e+08, 1.8182e+08, 3.0988e+08, 2.4165e+08, 2.6313e+08, 2.9566e+08,
        1.9050e+08, 2.2985e+08, 2.3764e+08, 2.4536e+08, 1.5799e+08, 1.9927e+08,
        2.9693e+08, 2.1164e+08, 2.3163e+08, 2.1348e+08, 3.2271e+08, 2.3051e+08,
        1.5044e+08, 3.2699e+08, 2.4963e+08, 2.4453e+08, 1.9849e+08, 3.6015e+08,
        2.2233e+08, 3.5296e+08, 1.1431e+08, 3.1393e+08, 3.1868e+08, 1.3567e+08,
        2.9398e+08, 2.5085e+08, 2.6886e+08, 2.0813e+08, 1.4349e+08, 2.5448e+08,
        2.2927e+08, 1.7190e+08, 2.6180e+08, 2.2815e+08, 1.7326e+08, 1.7518e+08,
        1.7357e+08, 2.3598e+08, 1.9238e+08, 1.8125e+08, 1.6201e+08, 1.8450e+08,
        2.2785e+08, 2.9877e+08, 2.8925e+08, 2.4855e+08, 2.3524e+08, 4.2633e+08,
        1.3938e+08, 1.9609e+08, 2.5217e+08, 2.1640e+08, 1.7795e+08, 1.1581e+08,
        2.5703e+08, 3.1156e+08, 1.8411e+08, 1.7941e+08, 3.5225e+08, 2.4411e+08,
        2.2869e+08, 1.4914e+08, 1.0467e+08, 2.7357e+08, 1.3931e+08, 1.9701e+08,
        2.2399e+08, 3.5470e+08, 1.3295e+08, 2.4202e+08, 2.2733e+08, 2.3973e+08,
        2.6860e+08, 3.4024e+08, 2.0932e+08, 2.4586e+08, 1.5104e+08, 1.6157e+08,
        1.4022e+08, 3.1028e+08, 3.7370e+08, 2.7945e+08, 2.3504e+08, 1.9183e+08,
        2.9603e+08, 1.8050e+08, 2.1836e+08, 2.7014e+08, 2.9433e+08, 1.5240e+08,
        2.5118e+08, 1.4763e+08, 1.6924e+08, 1.1810e+08, 2.1883e+08, 2.5785e+08,
        2.1868e+08, 3.3054e+08, 3.3862e+08, 1.7289e+08, 2.4817e+08, 1.6788e+08,
        1.8408e+08, 3.0949e+08, 1.6721e+08, 2.4379e+08, 1.6611e+08, 2.2634e+08,
        1.5584e+08, 3.2199e+08, 1.2534e+08, 3.2414e+08, 2.9585e+08, 2.2460e+08,
        1.8299e+08, 2.3069e+08, 2.5042e+08, 2.1018e+08, 2.4495e+08, 2.6485e+08,
        2.1617e+08, 3.0351e+08, 1.9497e+08, 3.1856e+08, 2.6084e+08, 2.5741e+08,
        2.0226e+08, 2.4104e+08, 1.8708e+08, 2.4102e+08, 2.0741e+08, 1.3892e+08,
        4.3548e+08, 2.9746e+08, 1.9210e+08, 2.0645e+08, 2.8792e+08, 2.2480e+08,
        2.3742e+08, 2.3628e+08, 2.4581e+08, 2.4541e+08, 2.5446e+08, 2.1005e+08,
        2.1683e+08, 1.5096e+08, 2.1662e+08, 2.1348e+08, 2.0364e+08, 2.3503e+08,
        1.9773e+08, 2.0817e+08, 2.7223e+08, 1.3438e+08, 2.7000e+08, 1.6639e+08,
        2.7422e+08, 7.0090e+07, 1.5888e+08, 2.7893e+08, 3.0313e+08, 2.1149e+08,
        2.4106e+08, 1.6694e+08, 1.5668e+08, 2.6175e+08, 2.8970e+08, 2.5391e+08,
        2.3206e+08, 1.6805e+08, 1.8536e+08, 1.9408e+08, 1.5188e+08, 2.3196e+08,
        2.0269e+08, 2.5659e+08, 1.8338e+08, 3.8968e+08, 2.3272e+08, 2.6574e+08,
        1.6955e+08, 2.0867e+08, 2.7930e+08, 2.7043e+08, 2.3235e+08, 2.0386e+08,
        1.9642e+08, 2.0842e+08, 2.3533e+08, 3.0604e+08, 2.5009e+08, 2.5394e+08,
        2.4779e+08, 2.4778e+08, 3.4258e+08, 1.7008e+08, 1.9698e+08, 3.3095e+08,
        1.8761e+08, 2.4890e+08, 3.0390e+08, 2.4626e+08, 1.8497e+08, 1.9268e+08,
        3.0356e+08, 1.6784e+08, 1.8243e+08, 3.7050e+08, 1.9209e+08, 1.4583e+08,
        1.4872e+08, 2.1184e+08, 3.0496e+08, 2.9424e+08, 2.2552e+08, 2.8315e+08,
        1.9773e+08, 2.8896e+08, 3.6906e+08, 1.4826e+08, 4.1845e+08, 2.0542e+08,
        2.0622e+08, 2.3889e+08, 1.8743e+08, 2.1133e+08, 1.7111e+08, 2.0053e+08,
        1.7493e+08, 1.4398e+08, 2.7160e+08, 2.5336e+08, 2.7202e+08, 1.7531e+08,
        1.4564e+08, 2.9481e+08, 2.0123e+08, 1.0499e+08, 1.5346e+08, 2.6958e+08,
        2.7323e+08, 3.0724e+08, 2.3724e+08, 2.4171e+08])
Layer: encoder.6.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 884945.7500, 3830592.2500, 1030705.4375,  ...,  411285.1250,
        2434288.2500,  469725.8438])
Layer: encoder.6.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 977567.3750, 4459704.0000,  515113.9062,  ...,  873008.7500,
        2335080.2500,  527567.1250])
Layer: encoder.6.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([5910971.0000, 3947821.2500, 2789560.5000, 2729420.0000, 3787949.2500,
        4748142.0000, 4111940.2500, 2402948.5000, 5740617.5000, 2522063.7500,
        3389028.7500, 3492602.5000, 4519063.5000, 2904013.0000, 3230619.7500,
        4272862.5000, 3153100.2500, 5661753.5000, 3614715.5000, 2695315.0000,
        3177152.7500, 2509019.7500, 4747848.0000, 4846572.5000, 3558853.2500,
        3263341.7500, 5144761.0000, 2969855.5000, 4010559.7500, 4820790.5000,
        5010281.0000, 4014217.0000, 5324921.5000, 4333420.5000, 4045791.7500,
        4241314.0000, 4778815.0000, 4002371.5000, 3743771.7500, 6208431.5000,
        3301198.0000, 2952555.2500, 3695861.7500, 4787265.0000, 3894715.5000,
        4838982.5000, 3958992.5000, 4694001.0000, 4700085.5000, 3474739.7500,
        4549855.5000, 3804615.5000, 3554888.2500, 4095713.2500, 3690366.0000,
        3805772.2500, 4716701.5000, 3760494.5000, 3453153.7500, 3710083.7500,
        2524841.5000, 4689619.0000, 2903808.0000, 3517446.5000, 2505028.2500,
        3760107.0000, 3581288.0000, 5303282.0000, 4806658.0000, 4689680.0000,
        5647530.5000, 5567783.0000, 5456591.0000, 2566472.0000, 3456761.7500,
        5088296.5000, 2094238.8750, 3073187.2500, 2632980.7500, 4033806.0000,
        3213343.2500, 4438994.0000, 3570473.0000, 3841936.0000, 6166110.5000,
        3249802.5000, 2726296.7500, 3367291.5000, 3090930.2500, 2961905.5000,
        3772025.5000, 5312590.0000, 4392947.5000, 4305108.5000, 3311461.0000,
        3484457.0000, 5440994.0000, 7261083.0000, 6500989.5000, 6057318.0000,
        3627633.0000, 3526678.2500, 2447647.0000, 3905047.5000, 7105941.0000,
        3029620.7500, 4472456.0000, 3546385.0000, 2886245.2500, 2890810.7500,
        4035515.0000, 3608082.2500, 3473737.5000, 3920805.2500, 3846852.5000,
        2974925.0000, 3386531.7500, 4143659.7500, 4327358.5000, 4513013.5000,
        2814232.0000, 3734833.5000, 3829826.0000, 5290735.0000, 3473178.2500,
        2243851.2500, 5777370.0000, 4365347.5000, 3052139.7500, 3129511.5000,
        2976675.5000, 3357716.5000, 4186914.2500, 3618510.2500, 2934640.7500,
        4560487.5000, 4411662.0000, 4671241.5000, 5209693.5000, 2348458.2500,
        4296954.0000, 4391837.0000, 2289165.5000, 3443972.0000, 3808001.2500,
        6831312.0000, 2596274.5000, 3244419.0000, 3174957.5000, 3573378.5000,
        4301311.0000, 6577031.5000, 3739301.7500, 4197987.0000, 3504793.7500,
        3614303.0000, 3204904.2500, 3929749.2500, 3153907.5000, 3568239.0000,
        4177890.5000, 5298374.5000, 5671236.5000, 3733784.2500, 3398196.7500,
        3119126.5000, 5918168.5000, 3011097.0000, 5757521.0000, 3230368.0000,
        3411923.2500, 3830303.2500, 4846836.0000, 2629350.2500, 4955462.5000,
        6632033.5000, 3087776.0000, 3516561.0000, 3695746.5000, 3475114.5000,
        4372392.0000, 2557680.5000, 3440916.7500, 3063384.5000, 5278166.5000,
        3520327.5000, 3693140.0000, 2552419.5000, 2893260.7500, 3332660.2500,
        2311737.2500, 4672891.0000, 3904115.0000, 2935930.0000, 2528633.5000,
        3911262.0000, 3588033.0000, 3361803.7500, 3948451.5000, 5288839.0000,
        3744537.0000, 6903314.5000, 3298470.5000, 4235407.0000, 3484796.2500,
        4326060.0000, 3550096.0000, 4678305.5000, 3787942.2500, 3256633.0000,
        3706160.2500, 4176626.0000, 5479947.5000, 6210518.0000, 4045372.7500,
        5728984.5000, 3703204.2500, 4829027.5000, 3582646.0000, 4992751.0000,
        5608366.0000, 3557994.5000, 3798162.7500, 4515344.0000, 3093827.2500,
        3367338.0000, 3267863.0000, 4699727.0000, 4168806.7500, 3295622.5000,
        2651570.2500, 5128179.5000, 4133561.0000, 3987564.2500, 5240824.0000,
        2738344.2500, 3542912.2500, 3419894.5000, 3999975.0000, 3214557.0000,
        3971627.0000, 3771232.2500, 2857652.2500, 7480288.0000, 3870963.7500,
        3895784.0000, 4436936.0000, 3859017.2500, 5393949.0000, 3996355.7500,
        4968284.5000, 3146937.5000, 4811066.0000, 2977369.5000, 2989045.5000,
        3148100.7500])
Layer: encoder.6.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([16203267.0000, 11096201.0000, 16362881.0000,  8828334.0000,
        19817232.0000, 13882335.0000, 13244858.0000, 10280043.0000,
        13587982.0000, 13635650.0000,  9698434.0000, 12382398.0000,
        14525657.0000, 15031018.0000, 18020464.0000,  8947426.0000,
         9787712.0000, 10550373.0000,  6896470.0000, 14489220.0000,
         7729771.0000, 14523306.0000, 10766645.0000,  7900926.5000,
        10541484.0000, 13679535.0000, 17916712.0000, 15006890.0000,
        14410049.0000, 11900922.0000,  8073059.5000, 12724655.0000,
        14068320.0000, 19048494.0000,  7876500.0000,  9460576.0000,
        16622474.0000, 11234579.0000, 11545741.0000, 21230906.0000,
        14167359.0000, 12932101.0000, 11115373.0000, 12063949.0000,
         9999392.0000, 11111667.0000, 12237758.0000,  8200674.5000,
        10713189.0000, 10666952.0000, 14172807.0000, 10061254.0000,
        11819488.0000, 16064133.0000,  6602813.0000, 13941414.0000,
        12788173.0000, 13217607.0000, 17685702.0000, 14168615.0000,
        14297675.0000,  9741187.0000,  9454940.0000, 15090764.0000,
        12853350.0000, 17550322.0000,  7689840.0000,  9041402.0000,
        11949962.0000, 13453139.0000, 13812103.0000, 11598046.0000,
        15209941.0000,  7680350.5000,  9399700.0000, 15803188.0000,
        13660910.0000, 12301332.0000, 14823757.0000, 12923161.0000,
         8969536.0000, 19048318.0000, 16685980.0000,  9706419.0000,
        15421411.0000, 12068504.0000, 12731695.0000, 14636753.0000,
         7986111.5000, 11115726.0000, 14046513.0000, 13060323.0000,
        14482275.0000, 16468607.0000, 10606365.0000, 14391054.0000,
        16142455.0000, 16042363.0000,  7013740.0000, 15034760.0000,
         9633757.0000, 12785019.0000, 13017136.0000, 15465676.0000,
         9311373.0000, 13214309.0000, 16946642.0000, 14952466.0000,
        12399528.0000,  8672055.0000, 15968803.0000, 15708939.0000,
         6361752.5000, 10016134.0000, 10163351.0000, 14700249.0000,
         9405801.0000, 15376635.0000, 12902247.0000, 11369150.0000,
        13481125.0000, 11553868.0000, 16048456.0000, 11818271.0000,
         8067971.5000, 11532456.0000, 13941893.0000, 14776598.0000,
        10970279.0000, 10217345.0000, 12956027.0000, 11020297.0000,
        18829558.0000, 10447628.0000, 18585268.0000, 12997518.0000,
         9950261.0000, 16416199.0000, 11414882.0000, 13291564.0000,
         9157797.0000, 16049765.0000, 15633611.0000,  7960978.5000,
        14928794.0000, 13351551.0000,  9812744.0000, 14141378.0000,
         7780286.0000, 14290726.0000, 15974997.0000, 12121023.0000,
        14308395.0000, 14304342.0000,  9760413.0000, 14545684.0000,
        10900833.0000, 11436278.0000, 16964842.0000,  9101510.0000,
         8366054.5000, 14580861.0000,  8981382.0000,  9541432.0000,
         9975319.0000, 15681389.0000, 12806752.0000, 11566488.0000,
         7213043.0000, 13990307.0000, 11977462.0000, 13155454.0000,
         8105426.0000,  6599468.5000, 10928357.0000,  8891334.0000,
        15969395.0000,  9922227.0000, 18928236.0000,  8632703.0000,
        11860660.0000, 18908326.0000, 11341186.0000, 15376154.0000,
        11795188.0000,  8640117.0000, 12387458.0000, 13065162.0000,
        19655852.0000, 14070234.0000, 13120374.0000,  9777258.0000,
        14770169.0000, 15172372.0000, 15580786.0000, 14688028.0000,
        16734604.0000,  8410469.0000,  8668967.0000, 12309118.0000,
        15161727.0000, 10183447.0000, 14068321.0000, 15776473.0000,
        17811942.0000, 12219802.0000, 10136038.0000, 12634682.0000,
        16140502.0000,  9954480.0000, 11418980.0000, 12701315.0000,
        12419993.0000, 20359052.0000, 11615923.0000,  9566182.0000,
        16394868.0000, 11366197.0000, 13050468.0000,  9313496.0000,
        12241146.0000, 15423924.0000, 18956954.0000, 14523371.0000,
        16668962.0000, 20000122.0000, 14237791.0000, 10428387.0000,
        17475640.0000, 10699237.0000, 11438806.0000, 11943041.0000,
        11280100.0000, 11912207.0000, 13415600.0000, 13145564.0000,
        11205101.0000, 13806570.0000, 10051103.0000, 16589205.0000,
        11212434.0000, 11117452.0000, 15544592.0000, 10488720.0000,
        14139057.0000, 15765620.0000,  8564884.0000,  8615971.0000,
         9494305.0000, 16811520.0000, 12459061.0000, 14628778.0000,
        17741240.0000,  9607407.0000,  9975642.0000,  9599396.0000])
Layer: encoder.6.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 175584.4062,  378095.8750, 2324756.0000,  ...,  739780.0000,
         493360.7500,  506291.6875])
Layer: encoder.6.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2367378.2500, 1574241.6250, 1319817.6250, 1604653.5000,  761998.0000,
        1884860.5000, 1165912.3750, 1478073.0000, 1219083.0000, 2063511.8750,
        1655735.6250,  738552.1250, 1819758.8750, 2235978.7500, 1634320.3750,
        1331260.5000, 1393456.5000, 1358659.3750,  730471.6875, 2066957.5000,
        1584172.1250, 1309168.6250, 1316223.8750, 2127980.7500, 2272753.7500,
        1651286.1250,  995507.0000, 2046846.3750, 1888164.7500, 1437523.5000,
        1911028.3750, 2466765.0000, 1203419.8750, 3015499.0000, 1283302.1250,
         724776.8125, 2078826.5000,  932604.7500, 1806873.7500, 1890754.1250,
        2963947.0000,  930106.9375, 3050183.7500, 1092026.0000, 1358843.0000,
        1106211.5000, 1371871.1250, 1375983.7500, 2080195.0000, 2620478.7500,
        1124946.8750,  734703.6875,  951198.2500, 1779722.7500, 1062897.5000,
        3545727.7500,  825486.6250, 1303651.7500, 1155703.0000,  888821.0625,
        2551288.7500, 1759217.8750, 1643693.3750,  887199.2500, 2730777.2500,
         718859.2500, 1545142.0000, 1665416.5000, 1117851.7500,  971915.6250,
        1894961.8750, 2080394.2500,  897953.5000,  765323.5625, 2211951.5000,
        1115570.7500,  770447.0000, 3148933.5000, 1051449.7500, 2142514.2500,
        2585566.0000, 3517884.7500, 1353441.8750, 1759708.1250, 2526949.2500,
        1053290.2500, 1343532.7500,  873761.3750, 2449908.5000, 1923815.8750,
        1739555.1250, 1388890.8750,  788993.3750, 2464744.7500, 1115200.8750,
        2027293.0000, 1808781.3750, 1093875.0000, 1164417.5000,  734616.3125,
        3183043.2500, 1355004.7500, 1900964.3750, 1173447.5000, 2104381.7500,
         694466.1875, 1834113.1250,  710282.4375,  933106.4375, 2752035.5000,
        2134125.2500, 1977854.8750, 2016377.6250, 1150335.1250, 2085933.7500,
         991784.1875, 1960761.6250, 1616279.2500,  916711.1250, 1176715.2500,
        2304434.7500, 1800528.7500,  975029.6250, 1312822.7500, 2712598.7500,
        2564111.2500, 1726160.5000, 2495372.7500, 1957244.1250, 1087356.8750,
        1990834.0000, 2909463.2500, 1215437.6250, 1830345.6250, 1315459.6250,
         711313.4375,  628943.4375, 1975321.5000, 2132410.2500, 3486453.0000,
         899583.6250, 1406643.5000,  888293.5625, 1344908.2500,  799254.2500,
         904492.0625, 2234815.5000, 1385638.1250, 2590746.0000, 2333554.5000,
        1394229.5000, 1575700.8750, 4346351.5000, 3778578.7500,  998637.5000,
        1576036.3750, 1128151.3750,  864308.3125, 1180379.0000, 1089789.6250,
         876033.9375, 1521174.6250,  860231.0625, 1300583.2500, 1515912.3750,
         983195.8750, 1417888.7500, 1443380.8750, 2158692.2500,  564906.9375,
        2144169.7500, 3085851.7500, 1905614.3750, 1075250.3750, 1504376.3750,
        1523795.6250, 4215747.5000, 1147984.8750, 2025515.3750,  980551.2500,
        1539520.5000,  909521.0625, 1116782.6250, 1770163.6250, 1169659.5000,
        1493651.1250,  834028.3750, 1815765.0000, 1105196.5000, 3913403.7500,
        1317095.0000, 1034869.4375, 1072606.0000, 1232833.6250, 1603830.2500,
         787450.5000, 1925871.1250,  922891.3750,  870422.1250, 1525580.0000,
        2201103.7500, 2644469.2500, 1099916.7500,  950325.3125, 1452181.2500,
        1149044.3750,  700966.1875,  909172.8750, 2557385.7500, 1279651.3750,
        1203797.6250,  718181.2500,  701968.6250,  835657.6250,  826971.0625,
        1048312.0625, 3392516.0000, 1330792.1250, 1420554.1250, 1323948.1250,
        1161927.1250,  742339.0625,  681543.3125, 1466325.5000, 3415990.7500,
         974201.4375, 1160039.1250, 1725378.7500, 2304357.2500,  861371.5000,
        2403881.7500,  996152.0000, 1779177.6250, 1522872.5000, 1945983.5000,
         913122.1875,  949863.3750,  753138.8125, 2259278.7500, 1251669.1250,
        1112758.7500,  599683.5000,  831080.6875, 2284720.7500,  903100.8750,
        3027394.7500, 1049778.1250, 1725710.6250, 1735475.1250, 1496985.5000,
        1109579.5000, 1203042.0000, 1771072.1250,  866226.7500,  821664.6875,
         815395.0000])
Layer: encoder.6.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 5748678.5000,  7841209.5000,  5313146.5000,  4206416.5000,
         4591497.5000,  4480715.5000,  4598816.5000,  9327861.0000,
         6474205.0000, 10424621.0000,  7076143.5000,  4178401.5000,
         7739278.5000,  3397654.0000,  4825977.5000,  7513577.5000,
         4756618.5000,  3447790.7500,  5051371.0000,  6824551.0000,
         6878023.5000,  7284314.5000,  8098530.5000,  5605152.5000,
         6430972.0000,  4928090.5000,  8917059.0000,  7654391.5000,
         4221383.5000, 11398586.0000,  9211076.0000,  7286979.5000,
        12535675.0000,  5361509.0000,  3998107.7500,  2381664.5000,
         5207489.5000, 10331002.0000,  6426078.5000,  5826232.5000,
         9764837.0000,  5077259.5000,  9692341.0000,  5281762.0000,
         4410617.0000,  9760474.0000,  6726241.0000,  8635000.0000,
         3115919.5000,  3839756.2500,  3619050.5000,  3086412.7500,
         6008666.5000,  4704250.0000,  3544898.0000,  5044682.5000,
         7521407.0000,  3893891.2500,  3930301.5000,  3521609.5000,
         5128336.5000,  8886890.0000,  3018792.7500,  5943686.5000,
         6716132.0000,  4032256.7500,  4328481.0000,  3277702.2500,
         5943587.0000,  3063634.5000,  4125061.2500,  9338938.0000,
        12672177.0000,  4787013.5000,  6418498.5000,  8269660.0000,
         3600392.2500,  5194106.0000,  4792870.0000,  6075939.0000,
         4786785.5000,  3844752.7500,  6479951.5000,  7708087.0000,
         2191173.7500,  5406356.0000,  5448812.0000,  5689480.0000,
         4720088.5000, 14237976.0000,  6494715.5000,  7211645.0000,
         5435419.5000,  3389815.0000,  4880938.0000,  8553454.0000,
         8020585.0000,  2181185.5000,  4692763.5000,  5638514.5000,
         3210761.2500,  7500210.0000,  5492494.5000,  5083354.0000,
        12229800.0000,  8003488.0000,  3692385.7500,  5645057.0000,
         5556870.5000,  7252642.0000,  8314953.0000,  5593919.5000,
         2457384.5000,  2681661.7500,  8325133.5000,  3806281.5000,
         6607880.5000,  7930801.0000,  3560082.2500,  4453691.0000,
         2542984.7500,  3504596.2500,  7095618.5000, 11076080.0000,
         3287865.5000,  4223674.0000,  3273591.2500,  2662550.0000,
         2874376.7500,  6092839.0000,  3140654.7500,  6350521.5000,
         9373903.0000,  9475312.0000, 10255073.0000,  2545886.0000,
         4774504.0000,  3760846.7500,  2278983.2500,  3367822.2500,
         3134825.0000,  3949684.2500,  8330914.5000,  2787833.2500,
         5604180.0000, 13095837.0000,  5913358.5000,  2082496.6250,
        14155193.0000,  8877494.0000,  6526992.0000,  4388141.5000,
         3361550.7500,  3020948.7500,  9519273.0000,  4912932.5000,
         6322349.0000,  4784883.5000,  3095241.0000,  4382891.5000,
         3941274.2500,  3857578.2500,  4253564.0000,  3569618.0000,
         4540481.5000,  4294292.5000,  2927581.2500,  6508713.0000,
        10738905.0000,  3616155.7500, 10168471.0000,  3364845.2500,
         4985673.0000,  4493314.5000,  6997250.5000,  4202848.0000,
         7719045.0000,  5958087.5000,  2822130.2500,  8092202.0000,
         9241395.0000,  4847278.0000,  6070563.0000,  4155896.5000,
         6436832.0000,  3386283.2500,  6197447.0000,  4319487.5000,
         5125691.5000,  4989250.0000,  2729023.2500,  8397682.0000,
         3695326.5000,  3978150.0000, 10353535.0000,  2953483.0000,
         4804431.0000,  2724817.0000,  2800249.5000,  4459493.5000,
        12042863.0000,  9004154.0000, 10120342.0000,  3290473.0000,
         6679756.5000,  5151216.0000,  2583847.5000,  5596652.5000,
         8487334.0000,  3587787.5000,  3227625.0000,  8585686.0000,
         4277229.0000,  3308767.5000,  7069137.0000,  2549056.2500,
         6382468.5000,  6289697.5000,  2395474.5000,  8986418.0000,
         4644634.0000,  3433038.2500,  6355548.0000, 10440316.0000,
         4268642.0000,  4412671.5000,  7119609.0000,  9594298.0000,
         5852352.0000,  4264608.5000,  4194912.0000,  2682446.0000,
         4801578.5000,  2357469.5000,  3528907.0000,  7594161.0000,
         6952365.0000,  2561705.2500,  2575232.2500, 11618288.0000,
         7958789.5000,  3916613.5000,  3497109.7500,  4958883.0000,
         6198141.5000,  4828296.0000,  3355683.2500,  3913073.7500,
         4541325.0000,  8005979.0000,  4611368.5000,  4211409.0000,
        17380170.0000,  3742489.0000,  9880804.0000,  2923130.5000])
Layer: encoder.6.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([  98940.5156,   48285.0898, 2073565.6250,  ...,  129352.0859,
         156353.6406,   16507.5664])
Layer: encoder.6.3.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1548353.1250,  459707.4062,  237203.4375, 2074932.8750, 2144209.7500,
         549575.3125,  665150.8750, 1497910.5000,  467259.1562, 1701206.7500,
         825255.0000,  879144.1250, 1717030.6250, 2170592.0000, 1422733.6250,
         252407.1250, 1797844.6250, 1394322.8750,  831441.7500,  761520.4375,
         648370.8125, 1808247.0000, 1550293.5000,  244354.4844, 1465256.1250,
        2594145.2500,  399239.0938, 1151939.6250, 1022952.0000, 2176844.2500,
         532118.8750, 1868460.6250,  833659.0000, 1523826.8750, 1541530.2500,
         510442.2188,  544658.1875,  295283.2812, 1467960.1250,  670778.6250,
         660512.9375,  306813.5312,  400863.4688,  622758.2500,  653761.3750,
         548340.5000, 1174706.0000,  899325.6250, 1328383.6250,  345431.8438,
         461898.6250,  397437.7188, 1090833.7500,  842289.8125, 2103008.2500,
         321979.8750, 1104474.0000, 1169237.5000, 1002813.2500,  196933.9688,
         227252.4531, 1292927.0000, 1110610.2500, 2346450.7500,  601515.3125,
         663097.1250, 1195659.8750,  683781.5000,  578773.2500,  645610.0625,
         566793.6875,  957372.1875, 1400981.6250,  306640.1875,  740729.1875,
        1626850.6250,  288295.0312,  337055.0312,  685947.8750,  976524.1875,
         552635.8125,  640849.6875,  652509.6250, 1710115.5000, 2147556.7500,
         919902.3750,  428025.6250, 2077801.0000,  806495.5000, 1132917.6250,
        1402589.3750,  474224.8125, 2011865.1250,  717787.6875,  753848.2500,
        1207320.8750,  848984.3125, 1009462.3750, 1452572.2500, 1041342.1250,
        1278485.1250, 1959444.1250, 1354152.6250,  306367.5625, 2506624.2500,
        1632353.7500,  303059.8750, 2600261.2500,  627966.3750, 1252502.3750,
        1486820.6250,  300316.5938, 1815928.5000,  247964.1406, 1877918.3750,
        2005184.8750, 1400905.7500,  454893.8125,  433150.9375, 1641596.1250,
         854193.0000, 1092672.0000, 1950403.0000,  657114.1250, 2000439.8750,
        1123544.8750, 1061476.2500,  605258.1875, 2784860.0000, 1034392.5000,
         282220.2812,  423891.7812,  534458.2500,  744511.2500, 1258482.6250,
        2096396.8750,  349927.3438, 1032924.6250, 1175968.6250,  653174.3750,
        1538872.5000,  801623.9375, 1701721.2500, 2064429.3750,  643787.5000,
        1162206.3750, 1632801.1250, 1323963.8750,  620462.1875, 1379618.0000,
        1926951.8750, 1443589.7500,  286237.6562,  750810.0000,  404182.0625,
         521970.0000,  577985.6250,  834032.7500, 1338885.6250, 1451830.0000,
         441220.1875,  441029.5938, 1356441.5000,  718959.3125,  333290.6875,
         418947.7812,  284464.9688,  196786.6250,  488308.2500,  328445.1875,
         446877.1875, 2265101.2500, 2505112.0000,  989829.6875,  829872.9375,
        1204378.0000, 2160342.7500, 1305651.6250,  437732.7812,  685737.0625,
        1281737.3750, 1790580.5000,  307921.5000,  543037.8125,  551557.5625,
        1218153.0000,  267196.1250,  835659.0000,  937131.9375,  931434.4375,
        4105801.7500,  681512.0625,  307843.3438,  327809.0312, 1373288.6250,
        2283368.0000, 1407758.1250,  710148.0625,  709113.3125, 1932648.6250,
         750569.3125,  593096.6250,  865259.5000, 1036353.6250, 1051211.6250,
        2150331.5000,  606323.8750,  480795.4062,  766503.4375,  510472.3125,
        1708414.6250, 1780907.3750, 1363070.3750,  735680.3750,  599014.7500,
        2294674.0000,  436315.1250,  835043.4375, 1234142.1250,  328181.8438,
         326699.5312, 1181427.1250, 1299380.8750, 1785527.3750, 1040559.3125,
        1351928.7500,  274197.2500, 1571130.2500,  973863.9375,  711934.7500,
        1307135.2500, 1172730.2500, 1125514.1250,  260088.0938,  790964.8125,
         350918.0938, 1365269.7500, 1058195.5000,  310184.0312,  876803.3750,
        1031753.6250, 1498886.3750,  974186.8750, 1473333.8750, 1037337.4375,
        2554107.0000,  761487.2500,  822424.0000, 1196467.6250, 1057350.3750,
         528519.5625, 1111332.7500,  208371.4062,  622875.8125, 1457335.0000,
         943821.3750])
Layer: encoder.6.3.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 1202326.8750,  3415529.7500,  5026849.5000,  4128516.0000,
         3985970.7500,  9189440.0000,  2494274.2500,   954648.0000,
         4440599.0000,  5697887.0000, 10738398.0000,  3218351.7500,
         1465350.2500,  1205943.7500,   961250.1250,  1728140.6250,
         6071359.5000,  2553441.0000,  4518340.5000,  3843967.2500,
         2239357.0000,  7958264.5000,  6515185.0000,  3955611.2500,
         2287900.2500,  1382481.1250,  1624155.7500,  1346452.3750,
         8491951.0000,  6046743.0000,  6735388.5000,  1470009.7500,
         3392918.2500,  1856192.6250,  4914193.0000,  7421605.5000,
         3535251.5000,  7348007.5000,  4219730.5000,  2470890.2500,
          998387.7500,  2625522.0000,  4272798.0000,  6698441.0000,
         4180486.2500,  4178217.2500,  3405697.5000,  6388178.0000,
         3971031.0000,  4824979.0000,  5093963.0000, 11707437.0000,
         4707127.5000,  2921806.7500,  8333640.0000,  2568205.5000,
         2031796.3750,  6550541.0000,  6211227.5000,  3003750.5000,
         4171780.7500,  4519789.0000,   895134.8125,  2703696.2500,
         1913450.1250,  5273373.0000,   794948.0000,  2787791.0000,
         1243170.6250,  4582733.0000,  2186330.5000,  3491772.2500,
         4705730.5000,  3770828.7500,  1030196.8125,  1531089.3750,
         3006635.2500,  8852992.0000,  4618821.5000,  1300637.1250,
         1721978.1250,  2292504.2500,  4552069.5000,  7027166.0000,
         9527710.0000,  6445215.5000,  2505955.2500,  3025014.7500,
         6277647.5000,  3371350.7500,  1127171.2500,  1481289.7500,
        10581354.0000,  2484823.5000,  3184377.7500,  3128492.7500,
         2498441.5000,  2646609.0000,  2190694.0000,  1167592.5000,
         4097514.5000,  4301699.5000,  3513819.2500,  5304796.0000,
         5487082.0000,  7626793.0000,  3009406.5000,  2983748.2500,
        10936058.0000,  2290687.7500,  5953989.5000,  3818320.5000,
         7168828.0000,  2040231.2500,  6063933.5000,  4995227.0000,
         6083080.0000,  2733492.0000,  2308849.2500,  1305177.3750,
         3037187.0000,  3753384.2500,  2277548.2500,  1332380.8750,
         5988529.5000,  1432091.6250,  1784964.8750,  6457558.0000,
         4828749.0000,  6011543.5000,  1271837.6250,  5593458.0000,
         2064621.8750,  1876155.7500,  9525888.0000,  2657974.0000,
         3188608.2500,   922180.8125,  4115595.2500,  1345744.6250,
         2194141.0000,  1654745.7500,  3314675.7500,  6912834.0000,
         2514220.5000,  2325407.5000,  8107689.0000,  6922699.0000,
         2495308.0000,  4709445.5000,  5094191.5000,  6076419.5000,
         3033970.7500,  2550892.2500,  1281296.3750,  6105305.5000,
         3034668.2500,  5622543.5000,  2130526.5000,  4445037.0000,
         4023013.5000,  2712968.7500,  2030172.0000,  5016634.5000,
          874119.3750,  2164791.2500,  1338491.6250,  4199323.5000,
         3780909.7500,  4397251.0000,  1354398.7500,  9062383.0000,
         2183121.7500,  2021610.7500,  2101261.0000,  3127096.0000,
         3533531.2500,  2957353.2500,  7626907.5000,  1999851.6250,
         1286470.3750,  5000291.5000,  1440710.2500,  2605146.5000,
         7845003.5000,  1240156.1250,  7684385.5000,  3129781.2500,
         1749956.0000,  3798377.7500,  6199262.0000,  6303666.0000,
         5711147.0000,  3722130.2500,  5757665.0000,  3016792.0000,
         8518317.0000,  4158958.5000,  1360245.5000,  2717354.0000,
         5005386.0000,  1490570.2500,  1554955.6250,  5307424.5000,
         4133704.0000,  2665137.7500,  4172286.7500,  7519723.0000,
          866425.5000,  3853493.0000,  5411211.0000,  9397989.0000,
         4548174.5000,  3526676.2500,  5345147.0000,  1813358.5000,
         3439710.0000,  2657106.0000,  7278448.0000,  2832033.0000,
         1258490.8750,  2911245.7500,  4368830.0000,  4123798.7500,
         5854432.0000,  5705882.5000,  4435195.0000,  8059876.0000,
         2905324.7500,  4661513.5000,  1608209.5000,  1069771.1250,
         1242922.1250,  2785788.2500,  1539518.1250,  2513405.2500,
         1678559.5000,  6353201.0000,  5372641.0000,  3472516.7500,
         2921396.0000,  3871641.2500,  2500706.0000,  5821750.0000,
         4877341.0000,  2384148.2500,  6474634.0000,  1793790.7500,
         9186479.0000,  3135366.7500,  4665620.0000,  1985293.6250,
         2455649.0000,  2913946.0000,  3919246.7500,  5281678.0000])
Layer: encoder.6.3.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 2326.9312, 11686.0459, 19742.8242,  ...,  3678.8711, 38194.4570,
         8129.0015])
Layer: encoder.6.4.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 96467.0859,  86372.6406,  71354.8750,  97980.1953,  94502.9453,
         65827.5156, 121390.6562,  78933.6719,  79375.8594,  75078.8203,
         65920.9844, 107107.4375, 125714.9141,  65623.7734,  91065.1797,
         80816.3984,  80213.0234, 103099.6562,  82980.9688, 110587.9844,
         94712.5391,  99552.7734,  91426.2344,  90833.4688, 110716.3750,
         97984.0000,  78243.4609,  82872.0625,  99956.5625,  84296.4688,
        104892.9922,  83806.9453, 106123.1875,  85505.4219,  58546.9062,
         90963.2344,  76457.9688,  65150.7383,  66464.4453,  67358.7266,
        104797.8203,  70699.2500,  93049.3203, 103300.5078,  80740.8125,
         53909.3633,  90361.6406, 103624.7578, 113363.2422,  56380.4883,
        135075.0469,  99988.3281,  90625.8281,  80332.6016,  99039.9141,
        123122.1406,  58213.2852, 115763.8594,  76903.4219,  95464.0312,
         90725.4141,  76343.3438,  97809.7109,  86993.9531,  99309.6016,
        109273.1328, 102339.8828,  97511.7344,  71842.8594,  69703.4609,
         74786.0391,  85102.5156,  67626.7422, 126570.6875,  68109.4297,
         70402.3281, 107895.6016, 104181.6172,  99935.9609,  87138.8906,
         73332.6250,  84264.8906,  75125.7344,  86555.8438,  73404.3984,
        135398.1250,  59397.3125,  90100.6406,  96940.0547,  89159.5000,
        122110.4922, 100909.4766,  87098.9688,  82159.8125, 103079.8828,
        116631.2969,  85535.5078,  92173.0781, 100905.2266,  91642.1562,
         91446.7422,  85780.1797,  91261.3125,  97785.1641,  86675.1953,
        114049.1641,  89257.6875,  91653.4141,  70507.2344,  91827.4531,
         83690.4453,  81952.0781,  80686.1953,  87792.7891,  94863.6328,
         89463.5312,  72819.1094,  78183.7656,  86625.7734,  93768.7266,
         81424.6406, 120008.1719,  79175.0391,  83126.0781,  67690.5000,
         62610.5391,  81966.9141, 100588.2266, 113076.8438,  81245.3281,
         92906.7188, 104126.7344,  91355.8203,  92750.8672, 112494.4766,
         61949.3086,  88802.7109,  74093.3047, 103744.4375,  87962.0391,
        133610.7500,  91332.5625,  79162.0234,  88727.6016,  83591.6641,
        107653.8750,  84511.4609, 104878.3906,  86840.8281,  94508.0078,
         91267.3906, 118368.2812, 106729.8047, 102182.8125, 107113.9453,
         86095.2578,  94391.5156,  92080.9453,  95629.4141,  84281.3906,
        112530.9844,  79339.7891,  75388.6406,  68394.5000,  84602.5625,
        111203.8906, 134576.0469,  85568.3438,  99234.8906,  89831.9453,
        117313.5625,  74842.3125,  77646.0234, 103275.5234,  88656.1484,
        100521.2031, 112176.7422,  68586.3047, 109499.3906,  74878.8125,
        105510.8281,  82257.5234,  93953.8203,  96191.5234,  96420.3281,
         87992.2656,  74967.1328,  75675.9844,  86749.9297,  72266.2734,
         82993.2969,  85064.4844, 101150.7422,  84888.2031, 113781.5469,
        104427.4609,  73290.8438,  78799.3672,  83471.1953,  77325.3516,
         94412.8359,  72753.1172,  57492.8906,  84470.2266,  77165.1875,
         98812.4141, 102624.2578,  84463.4766,  98265.5781, 104221.6250,
         50783.7656,  89322.0156, 100598.1562,  80761.7734, 118607.2969,
        124307.5078,  94593.8750,  76232.2969,  65956.0781, 133562.7812,
         86002.0156,  95115.8984,  89536.0391,  94579.7344,  85270.3984,
        105813.9844,  70691.1484,  95063.1562, 132092.5156, 103710.3984,
        102311.7656,  66325.2812,  98731.4297,  64349.5195,  59595.5039,
         73447.4297,  62401.3516,  77446.9766,  88605.3594,  78812.2656,
         66995.9219,  86647.5391,  75039.4766,  82698.4219,  85019.3750,
        110457.7422, 102493.5938,  78386.8594,  87229.0156,  97148.4531,
         83844.6172,  65938.9141,  59372.7070, 115134.8359,  92885.0000,
         91502.1719])
Layer: encoder.6.4.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([411580.2500, 474490.5312, 453561.0312, 413043.2500, 426355.2500,
        550028.9375, 500631.5312, 530969.1250, 319639.1250, 564586.1250,
        506574.5938, 289843.1875, 347730.8750, 637611.5000, 413702.8438,
        487751.8438, 372906.9688, 391909.4062, 503542.5938, 507379.9375,
        627072.6875, 308109.2500, 363541.2500, 412962.1875, 386633.2812,
        480418.8125, 553763.2500, 500363.0312, 501405.5000, 341774.3438,
        375639.1875, 472354.9688, 316073.2500, 659328.6250, 441052.2188,
        395249.9375, 366541.8125, 570634.2500, 361842.7500, 514270.1250,
        383452.4688, 522949.0312, 410635.0625, 447482.6250, 431221.9375,
        442322.3750, 512897.0938, 362290.9375, 454661.1875, 354259.5938,
        423114.4375, 434355.0938, 363799.9375, 518368.5000, 481865.4688,
        327846.0312, 411974.2500, 365972.4062, 267461.4062, 350740.0625,
        479604.3125, 501460.1875, 550306.5000, 503257.5312, 575525.7500,
        487288.3750, 462042.8750, 378151.4375, 475099.8750, 399682.3750,
        369180.8750, 393203.6250, 387584.4062, 398772.0312, 523022.9062,
        363064.0625, 447810.4375, 430486.9375, 685638.2500, 492572.0000,
        452371.6562, 414869.1562, 400635.5625, 512987.9375, 454314.0625,
        329468.0312, 612019.3750, 441529.2500, 385660.1875, 481076.8438,
        405805.6562, 555892.0000, 419787.4688, 497460.7500, 433494.2812,
        380218.8125, 418889.2812, 418300.5938, 416483.5938, 352633.2188,
        493593.8438, 488547.2188, 439633.6562, 496185.3750, 409490.7188,
        423032.4062, 428492.0938, 528201.6875, 279326.4688, 634293.0000,
        497116.9375, 546242.2500, 467496.5938, 424320.7188, 483213.4375,
        552928.0000, 642310.0625, 450060.9375, 475697.1875, 419224.7188,
        451764.8125, 404853.3750, 496914.9062, 544458.4375, 510982.2188,
        580911.9375, 466336.2812, 391920.6250, 501745.4375, 493807.0312,
        409855.3438, 495226.1562, 599120.4375, 555232.8750, 434561.7812,
        521792.0625, 299804.2812, 548168.0625, 530200.0000, 392348.0625,
        451857.3750, 579355.3125, 514332.5625, 293933.1250, 414464.2500,
        437801.5312, 471839.0938, 431461.1562, 677300.1250, 551914.5000,
        386906.8125, 487217.0625, 362221.5000, 273433.0625, 370649.5000,
        438162.4688, 470364.7812, 409256.5000, 352099.4688, 438031.3750,
        579433.0000, 338107.4688, 402127.5625, 509478.3438, 619924.8125,
        504939.9062, 474191.3750, 472300.4375, 453071.9688, 527331.0000,
        577287.8750, 390512.5312, 364397.0000, 414219.2500, 364361.2812,
        357844.0312, 509424.4062, 381523.1875, 487487.2812, 490852.7500,
        406182.3438, 309025.1562, 519945.3438, 396762.4062, 455448.7188,
        504304.6562, 615337.0625, 525192.3125, 501401.8125, 359261.5938,
        679954.8125, 366921.7188, 372197.4375, 400920.9688, 518189.8750,
        470032.5938, 559320.6875, 436832.3125, 356724.8750, 328927.3438,
        448580.6875, 578693.7500, 455771.5625, 446801.4688, 376013.0000,
        463462.1250, 480657.0000, 401988.2500, 550960.6875, 485531.5000,
        372848.4375, 352012.8438, 470622.1250, 539352.5625, 446667.2188,
        498526.8438, 495100.0625, 381440.9062, 526962.7500, 347101.3750,
        523939.4688, 418257.8438, 491785.5938, 247623.8750, 318587.8125,
        416602.6250, 440644.2188, 388055.8125, 542511.8750, 556914.1875,
        540107.3125, 436857.1875, 603004.9375, 459580.1250, 423398.5312,
        546175.6875, 409291.2500, 469651.9375, 495825.9375, 353212.3125,
        395682.7812, 502991.0625, 495313.3750, 447150.5625, 351583.2500,
        476102.0312, 406088.2500, 535757.8125, 424610.0625, 310262.4688,
        444814.0000, 397986.4062, 435244.3125, 364843.7188, 435539.1875,
        498315.2188])
Layer: encoder.6.4.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1755.6240, 2486.7009, 6890.7046,  ..., 1625.6909, 4786.5947,
        3501.7144])
Layer: encoder.6.5.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([41446.6523, 61477.5469, 57509.0391, 54811.8281, 36966.8242, 40723.2031,
        27818.9473, 37186.7266, 44961.2617, 35837.4375, 59921.6758, 54791.7539,
        41163.3125, 54264.3438, 30547.9375, 44194.2070, 57524.0469, 36884.6875,
        39767.3984, 39258.5039, 47710.9961, 41230.1562, 49281.1875, 57344.3477,
        48335.8164, 41668.4570, 45498.9141, 38439.9180, 59050.5820, 59284.7695,
        41400.8164, 56209.2148, 49215.6797, 43381.0078, 51040.3828, 45119.7695,
        48917.0117, 39909.8477, 48241.8555, 42102.7422, 36586.8242, 36108.6758,
        37541.9336, 35732.3047, 42488.5000, 41868.1523, 34160.1562, 38738.2617,
        29609.2793, 36680.9688, 46681.7773, 33796.7969, 41927.7266, 46275.1172,
        58233.7227, 45974.3242, 57149.8281, 40710.5820, 33753.8711, 40977.0781,
        38439.9727, 40504.4727, 56140.5156, 49139.4102, 35744.6641, 52256.7812,
        60503.6445, 38458.9180, 37754.9180, 51094.3906, 60174.0234, 23973.2422,
        42191.5039, 53739.2148, 40014.2734, 41920.3281, 32506.7461, 58356.9102,
        28479.3281, 45775.4453, 38817.8125, 42473.8047, 58933.5273, 40918.2422,
        47010.9375, 34875.6875, 48580.5547, 51090.0664, 50554.3633, 53219.8086,
        42966.8242, 42945.2031, 44854.6914, 57341.3750, 38093.1719, 53073.9648,
        33222.6367, 45440.0977, 41667.5742, 38987.5391, 39404.6797, 44408.2812,
        33209.5430, 48024.6016, 61994.5234, 48163.5469, 51640.9727, 43919.1602,
        53333.3398, 37137.3164, 46570.1680, 52342.2422, 34725.6680, 53270.2852,
        46356.5977, 64701.3359, 44198.1289, 27403.9570, 38247.2266, 48292.1289,
        50318.2617, 51743.6211, 42636.0977, 62559.3750, 41176.3164, 58367.2695,
        50275.8398, 45051.4531, 56646.1602, 44802.2148, 65666.6719, 33519.7930,
        36008.0312, 56762.8633, 59317.9141, 37893.2773, 49526.4219, 49180.2969,
        33417.8516, 51620.0039, 45787.2461, 46731.7148, 68436.8203, 31518.0254,
        42464.8594, 53689.9375, 39419.9258, 37094.2852, 40019.9336, 63544.1523,
        41606.3320, 41283.5000, 41105.2383, 39141.2773, 56231.2812, 40538.3984,
        37569.7930, 44212.8242, 52541.1680, 50203.3203, 44536.4922, 52841.2422,
        63955.0039, 33457.4570, 51880.7930, 51121.1758, 46138.8789, 52902.7578,
        41202.2383, 36480.4062, 38364.7930, 37302.9062, 33247.1758, 54088.3203,
        55130.2852, 72018.1016, 50747.4219, 50262.4062, 58622.6836, 32372.9531,
        42630.5195, 44526.1758, 41190.0273, 47787.6328, 51039.4023, 34182.7812,
        44917.1250, 47473.1836, 58350.3594, 42010.1445, 51938.4414, 48824.7422,
        30967.2109, 57797.5742, 45353.8242, 45178.3750, 49780.6016, 55619.3242,
        47092.3906, 44908.3203, 54435.5234, 45813.1016, 47025.6992, 46067.7305,
        38497.1680, 48657.4531, 38235.8555, 37532.5117, 47457.8789, 42181.9727,
        40542.4570, 39357.6641, 34081.1875, 50932.8945, 71048.8828, 44793.6797,
        66588.3125, 56197.3789, 35628.4102, 42848.7695, 38992.5859, 37103.5000,
        50776.3516, 35013.2930, 43054.8242, 31022.4824, 43952.8828, 49773.9648,
        32324.7559, 51635.7734, 60803.3750, 40112.2422, 50243.0625, 37105.3633,
        46899.7656, 47886.8828, 46634.0391, 54495.6680, 38981.0508, 38244.0664,
        38941.8750, 42189.3867, 41581.9375, 45515.6211, 63715.2227, 47467.3438,
        65163.7500, 44203.2227, 33241.2188, 53845.2812, 72526.3594, 48281.2500,
        48651.5078, 35547.3242, 48312.7695, 45746.8594])
Layer: encoder.6.5.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([196632.6406, 299970.3750, 252623.4219, 152853.6875, 171212.6562,
        247016.2656, 230305.7656, 167920.2031, 256013.6094, 183670.9844,
        156634.7500, 235289.7031, 197999.0469, 210225.7188, 229143.2812,
        201452.2031, 211483.5312, 219723.6094, 181270.9062, 233296.5469,
        186566.1719, 188087.1562, 239854.3594, 335489.7812, 190658.6094,
        240208.2969, 165914.9219, 243244.6562, 195780.0000, 233844.2812,
        238685.4531, 237673.0469, 251330.0312, 141793.2969, 251931.6719,
        229040.7812, 223873.7969, 254546.6250, 183274.6875, 303589.9062,
        217083.7188, 257519.0312, 161455.6719, 291673.0312, 220784.0469,
        245366.0000, 278751.0000, 266492.3438, 189777.2500, 211040.4375,
        295055.0312, 296894.0625, 187026.1875, 155581.7969, 205127.1562,
        219984.9219, 273960.4375, 189972.5781, 244780.7656, 249810.0469,
        247957.8906, 161788.4062, 242145.8594, 253220.8906, 203594.9375,
        295832.5625, 209864.7031, 235946.8750, 193876.8281, 183789.4375,
        198606.3125, 218185.8906, 224566.8906, 173607.3438, 162735.8750,
        234171.0469, 228953.3906, 233786.7188, 223086.4375, 175765.4844,
        226892.8750, 250619.7656, 193285.9375, 238423.1875, 230007.5312,
        192897.0156, 169665.5938, 165158.4375, 184264.0469, 223781.6094,
        198795.0156, 202869.3125, 224671.9219, 257208.9844, 180555.2344,
        226496.0469, 204034.3906, 221091.7969, 243733.1250, 232469.8125,
        195660.0781, 150452.2031, 218947.6562, 244441.9844, 179001.5000,
        184116.3906, 124473.1641, 170538.5625, 336944.7812, 221976.5469,
        341324.9688, 225023.9062, 200067.8750, 190718.3281, 258455.0312,
        184636.1875, 317714.7188, 200991.8906, 244534.4844, 234561.8438,
        245476.4531, 191572.5312, 212601.6094, 234187.6875, 229129.2656,
        251072.6875, 255285.5000, 181243.6094, 203359.2344, 185608.2812,
        297800.5625, 228067.4062, 138989.5625, 223671.3906, 190545.4062,
        160424.0625, 209939.1875, 287561.5938, 209581.9688, 186182.9844,
        223257.5625, 186229.5156, 284124.9062, 186291.5781, 235828.1250,
        267080.6250, 255085.6875, 279958.9375, 194911.1562, 264220.7188,
        227269.4531, 229366.3125, 210419.2969, 121084.2500, 254293.9219,
        146849.2344, 252531.8594, 153458.2812, 208526.8750, 163016.4219,
        215934.8438, 269122.0312, 192463.4844, 229384.7188, 222511.9844,
        343554.9375, 283533.2188, 332879.6562, 288884.1250, 201919.2969,
        289419.7500, 230113.6406, 233000.4688, 234855.5781, 182272.9844,
        229386.4688, 230928.2812, 277297.5625, 233207.1719, 151542.0625,
        239350.5156, 210715.4531, 196555.7500, 208542.0000, 271468.5000,
        215078.3906, 198774.9375, 197904.4844, 217098.1719, 221245.2812,
        226053.8438, 177319.7812, 248650.0000, 213755.0312, 253505.8594,
        264679.0312, 223856.1875, 150411.8750, 206763.5625, 236830.7812,
        231374.1875, 189367.3594, 238667.8594, 249736.7812, 237277.3906,
        205537.6719, 170229.6875, 184882.8438, 174816.4375, 213353.0781,
        229748.9375, 224716.1094, 174302.0000, 275362.2188, 223360.1719,
        175595.2656, 267080.6250, 203656.6094, 162279.2188, 222454.9688,
        164778.2344, 191180.8750, 245583.1719, 263021.3125, 245558.2656,
        270230.3125, 249741.7656, 193754.0938, 134488.3125, 226769.4219,
        268226.9375, 338484.4688, 284027.1562, 207924.8438, 177096.3281,
        231869.6719, 221906.3906, 226579.3438, 130983.5312, 279941.1250,
        124040.5859, 204914.9688, 210397.3750, 193853.0781, 228145.3750,
        143222.4531, 229046.3438, 189278.1406, 188334.4844, 210587.7969,
        211980.0625, 201965.7031, 274629.7812, 273481.7812, 178948.6250,
        205988.1875])
Layer: encoder.6.5.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 779.0342,  244.6209, 6635.7617,  ...,  786.8663,  162.3167,
        1527.8496])
Layer: encoder.7.0.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([2412.2688, 2982.6072, 2725.4067, 2573.2383, 2335.8782, 2075.6467,
        2258.2703, 2355.3220, 2928.5886, 2879.9988, 2702.3293, 2801.5374,
        2112.0596, 3077.3745, 3077.8406, 2765.2812, 3082.5239, 2138.7214,
        2549.4690, 3580.6626, 2329.0298, 2910.4299, 2773.8596, 2603.4331,
        2976.4832, 2993.2249, 1793.3116, 3937.5283, 2940.6101, 2468.2412,
        2499.5525, 3077.9712, 2555.9915, 2510.7947, 3111.4414, 2380.7905,
        2884.5825, 2089.5244, 3127.7705, 2635.2974, 2885.7834, 2561.9312,
        2562.6775, 2543.6201, 2345.3167, 2799.4924, 3310.4590, 2453.5964,
        2556.8535, 3061.5146, 2289.5344, 2396.9331, 3194.7485, 3160.3652,
        3016.0156, 3376.1790, 2360.9509, 3303.8420, 3341.0952, 3197.1660,
        3041.5237, 2720.0405, 2863.7000, 2232.2295, 2261.0017, 2892.0869,
        2451.1567, 3615.0842, 2218.7866, 2673.5557, 2505.9409, 2457.5181,
        2655.5415, 2369.4915, 2629.9802, 3113.6738, 3608.0339, 2226.8210,
        2506.1567, 2248.7205, 3199.9119, 2996.6895, 2421.3833, 2830.2800,
        3423.5020, 2642.9775, 2521.5591, 2984.9761, 2252.9919, 2171.7493,
        3268.2812, 2655.9585, 2495.3784, 2356.0852, 3328.6987, 2498.3074,
        2649.4729, 2297.7061, 2442.0217, 2325.1736, 3002.8000, 3404.6145,
        2410.8660, 2758.1147, 2596.2485, 4017.0369, 2746.0786, 2629.2698,
        3181.0911, 2517.9202, 2522.1199, 2685.1106, 2528.9963, 3037.0442,
        2811.0925, 3073.1677, 3252.2986, 2771.9812, 2227.0642, 2836.9790,
        2462.1765, 3323.7334, 2343.2327, 2858.4705, 2660.6973, 2535.8076,
        1985.8994, 3118.4934, 3029.2898, 3829.5876, 4294.8193, 3316.4958,
        2754.7065, 2770.4663, 2992.9006, 3124.1516, 2679.8215, 2118.0508,
        2712.2820, 2568.1543, 2604.6406, 2384.4502, 3174.1506, 3719.2632,
        2938.0564, 2666.6270, 2808.4329, 2555.9846, 2453.2954, 3695.0591,
        3102.5325, 2990.4106, 2361.5559, 2098.3547, 3009.2581, 2691.0195,
        2909.7642, 2715.1592, 2434.8772, 2973.1604, 2407.4243, 2231.0576,
        3174.8357, 2454.0439, 2531.9451, 2317.1584, 2712.3076, 2031.8784,
        2845.3718, 2550.4753, 2775.2705, 2547.1067, 3380.5684, 3202.9492,
        4514.9346, 2403.1165, 2634.9612, 2845.5217, 3467.9324, 2628.3499,
        3324.8354, 2463.4009, 2488.5916, 3199.7119, 2832.9355, 2846.3164,
        3152.8967, 2715.1772, 2396.7336, 3330.3325, 2853.8052, 2278.3516,
        2997.1978, 2535.6143, 1974.2755, 3016.2874, 2553.5691, 3129.3665,
        3011.8477, 2986.2871, 2695.0806, 2687.4060, 2806.1785, 2664.0332,
        2752.0383, 2899.4690, 2684.0398, 2056.0496, 2458.8582, 2899.6597,
        2631.5840, 2500.4216, 2540.9517, 2563.4082, 2747.9292, 2677.6575,
        2323.0615, 2212.0215, 2830.0151, 2765.6475, 3206.2864, 2274.4924,
        3742.1001, 2596.3000, 2305.8562, 3523.6914, 2543.3684, 3470.2058,
        2056.1062, 3139.9841, 2654.3398, 2328.2664, 2984.0437, 2744.6201,
        2493.6079, 2911.2827, 2558.4004, 3370.0920, 3043.3528, 2116.1050,
        2426.1987, 2710.2400, 2735.5308, 3093.7373, 2490.0657, 3827.2644,
        3127.0249, 2677.8936, 2848.2458, 3263.7393, 2888.4773, 2813.5771,
        2561.4692, 2548.7778, 2620.0310, 2718.9136, 2726.7559, 2229.5684,
        2855.5244, 3031.2595, 2932.1255, 3362.2603, 2132.6018, 2800.1233,
        3699.4353, 2318.8284, 2639.0732, 2608.0867, 2620.4570, 2816.1362,
        3023.2529, 2250.9229, 3305.2520, 2062.0164, 2285.4993, 3115.4758,
        3071.9265, 2767.0681, 3749.0095, 3364.9487, 2806.5259, 2038.3827,
        3064.7561, 2314.2144, 2402.9836, 2312.2429, 2274.9958, 2655.8486,
        1900.3176, 3679.0679, 2884.5969, 2902.5054, 2486.0605, 2784.6597,
        2841.8540, 3165.7058, 2599.4172, 2680.2834, 2391.4124, 3082.5974,
        3009.5549, 3383.0857, 2369.5479, 2699.9092, 2403.2251, 2945.2937,
        3186.2524, 3458.2749, 2049.6953, 2554.5776, 2868.5508, 2847.6499,
        2577.9954, 2574.8916, 2210.3027, 3231.8293, 2709.7598, 2537.8247,
        2592.3442, 2353.7354, 2648.3396, 2847.3518, 3112.1372, 4074.7825,
        3365.4556, 2745.6956, 2947.7134, 3336.6733, 3029.3147, 2653.9976,
        2542.2617, 3019.9875, 2554.7466, 2800.5642, 2961.0901, 2958.7676,
        2612.4600, 2169.8635, 3415.7930, 2815.1143, 2514.2649, 2585.9546,
        3046.7000, 2254.5757, 2862.1448, 2543.2844, 3545.2581, 2630.2876,
        2917.8521, 2722.4336, 3108.7900, 2500.9202, 2908.3298, 2252.4080,
        3468.8577, 2936.2014, 2864.6145, 2374.2429, 2451.3469, 2256.4878,
        2707.8210, 3039.1011, 2691.1267, 2755.6294, 2523.9155, 2399.1121,
        1747.4058, 2903.4819, 2201.8330, 2206.3770, 3999.5625, 3533.9888,
        2486.2639, 2909.3237, 2273.3772, 2745.7114, 2797.1904, 2793.1873,
        2499.3140, 2611.2917, 3278.0911, 3126.4355, 2957.4861, 3931.8496,
        2493.9441, 2949.5181, 2778.6235, 2613.0828, 2641.6123, 2735.7661,
        2115.3096, 2748.6958, 2621.1641, 2008.8057, 2242.7402, 2487.6338,
        2413.4067, 3094.2896, 2439.9111, 2560.8047, 3225.2913, 2721.0752,
        3124.5940, 3368.7703, 2980.8306, 2977.2585, 2012.2321, 2909.9346,
        2504.8860, 2514.8538, 2965.3447, 2080.9927, 2093.3506, 3248.6306,
        2772.8884, 2688.4075, 3139.7505, 2706.7993, 2606.5735, 3345.4106,
        2872.2275, 2466.0964, 2607.8689, 2419.7776, 2406.3125, 2214.7026,
        3027.8254, 2528.1450, 2918.4155, 3090.0247, 2419.7183, 2547.0764,
        3221.7798, 2935.0249, 2770.6194, 3856.8130, 3421.6047, 2864.5110,
        2998.2158, 3279.1157, 2091.2512, 3033.2915, 2730.9553, 2793.1809,
        2675.6816, 2504.6597, 3696.9746, 3249.0588, 3802.2175, 3484.2949,
        3251.6628, 2271.6013, 2984.6235, 2607.8369, 2585.7512, 2878.5933,
        3042.0583, 2719.4167, 2337.1350, 2435.2241, 3434.4663, 2702.6267,
        3079.3611, 2042.9071, 2995.4597, 2353.2878, 2574.8059, 2751.7927,
        2294.8245, 3178.2678, 2476.8335, 2813.1296, 2211.9604, 3393.1724,
        2450.0847, 2398.4312, 2797.9224, 2319.2566, 2479.4573, 3405.0950,
        2937.3352, 2925.8193, 3047.6843, 2615.0459, 3501.4800, 2625.0759,
        3208.3508, 2682.9937, 2500.4153, 2309.6262, 2890.7197, 3352.6304,
        2842.2988, 3091.1963, 2357.9180, 2345.5847, 2597.9104, 2500.6670,
        2053.1956, 2811.4673, 3180.8572, 4025.6702, 2542.5146, 3102.0491,
        2157.1831, 3157.7544, 3417.0227, 3144.9504, 2089.3074, 2412.5901,
        3057.0833, 2403.5806])
Layer: encoder.7.0.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([28670.6445, 28550.8418, 26857.3398, 22603.2734, 28003.2051, 25230.8867,
        25967.6211, 22236.7617, 33481.8164, 26159.4277, 24987.8535, 28825.8418,
        27143.9375, 23108.6230, 26951.3691, 27094.6035, 26370.7246, 26162.8711,
        24836.1953, 30964.3145, 23769.1875, 39971.9688, 23754.3613, 27968.1348,
        24548.8535, 27687.0039, 25654.8926, 21851.1641, 21397.7559, 32651.9863,
        34507.8008, 22206.5176, 20635.6875, 28111.3965, 31086.3242, 36863.4883,
        20932.8926, 25904.0840, 25569.5195, 29960.4531, 26473.1621, 31456.3809,
        28719.9180, 27803.2168, 22717.7520, 23560.1816, 33001.0078, 24126.8242,
        27475.5527, 31708.3848, 31259.7676, 23088.3691, 28777.1953, 25600.1133,
        25086.3809, 27964.5000, 27289.9004, 21486.8203, 29475.6133, 25407.2324,
        27392.6543, 31698.9199, 29074.1523, 22140.8652, 30396.1523, 23809.0020,
        25203.2207, 27249.2285, 31172.6836, 30481.7090, 19682.2051, 32285.8613,
        27983.6797, 25386.2559, 22987.0059, 24466.2617, 23607.8008, 27575.3652,
        30526.2988, 27696.9727, 25350.5176, 24805.5820, 20384.4609, 31955.2441,
        26769.7324, 26879.9980, 31544.6426, 24651.8633, 23001.8535, 24022.1992,
        22384.2715, 31619.2129, 26976.6797, 28089.1328, 22322.7246, 22728.0664,
        29546.8887, 22478.9355, 26358.5684, 23803.3320, 23635.5254, 30591.6719,
        24156.0059, 28056.3125, 33960.2930, 31239.6582, 24030.7832, 26861.8457,
        23831.5586, 23731.5801, 26525.3945, 33166.2930, 27640.0566, 21554.0605,
        23650.0625, 30662.8418, 26794.3105, 27426.2773, 27874.3594, 23265.9414,
        32622.7266, 21788.3477, 24559.5488, 25727.3945, 30176.1328, 20623.7500,
        30002.0312, 23893.0137, 27019.8379, 25108.1094, 21407.0918, 22562.7441,
        24455.3809, 25689.1934, 20291.6523, 33424.9727, 30691.9453, 30647.9160,
        29955.9883, 23561.5645, 24232.1230, 25415.6074, 18534.9199, 30266.3320,
        36274.6719, 30326.5371, 22702.4141, 35080.3867, 30160.7344, 21721.5312,
        20604.3613, 27881.4648, 35334.9961, 18407.8516, 24784.6230, 24053.2852,
        25597.0195, 24116.1973, 29499.0996, 23927.6523, 24223.7676, 21184.7754,
        24142.6367, 25674.6113, 32450.0352, 23439.2207, 28278.4062, 36358.0234,
        24310.9609, 27250.6973, 20429.3301, 24913.2773, 27226.6250, 32262.3145,
        24644.9570, 29370.3164, 24654.1895, 25437.8848, 33541.5586, 37583.3438,
        26465.3926, 29648.3867, 33839.5156, 31347.0684, 26862.9941, 21397.1641,
        29831.1504, 22416.0664, 32415.8496, 33764.7344, 32799.4453, 36875.3008,
        25886.3477, 30818.5996, 18125.1309, 28314.9980, 30335.9238, 29585.1699,
        27098.7422, 27875.0957, 23808.1621, 25901.4238, 27874.2695, 30143.8477,
        25928.4590, 26758.4395, 24023.6602, 27522.8066, 27529.8789, 23784.2246,
        23088.4570, 26924.6211, 24180.5391, 24376.9316, 26141.4102, 24631.7832,
        27381.0293, 39643.1914, 26804.1660, 29948.3320, 28670.8418, 22289.8730,
        34466.0977, 33639.6992, 27504.3027, 29502.1719, 27398.8477, 27422.7617,
        27035.5703, 20958.7852, 24765.1465, 23593.3984, 29745.7695, 23805.5176,
        23159.1445, 29186.2070, 22622.3828, 33540.0234, 31361.8848, 21449.6934,
        27866.7871, 28501.7910, 26334.5547, 21423.7363, 25567.4668, 25663.4980,
        28068.0176, 25582.1406, 26803.2969, 25941.5703, 35731.4297, 25056.9316,
        24483.3125, 27720.8340, 30529.8789, 23540.5762, 24419.3008, 25834.1367,
        32517.1328, 22843.6133, 33241.5625, 24523.2305, 24582.4512, 21830.2324,
        28677.8027, 28745.5781, 22650.0293, 24416.5938, 25165.3340, 24082.6699,
        25566.7031, 25594.1406, 25595.5039, 28952.5938, 26772.7930, 31324.0020,
        25218.5293, 24830.1875, 24016.3770, 36181.3164, 20452.3750, 21055.4824,
        23170.7695, 26994.6074, 25524.5137, 30015.5996, 33580.1094, 21296.3633,
        23686.2910, 21227.6211, 27474.1699, 24270.3086, 29054.7344, 30737.1426,
        25750.3281, 28443.0586, 22831.9316, 28880.7383, 31924.4238, 22253.4160,
        23800.7441, 40152.2031, 24929.9922, 25329.3672, 24654.9824, 30636.3125,
        25154.2324, 22347.7070, 27684.9961, 27613.3398, 27976.5254, 24904.5117,
        29147.4551, 32333.7324, 31169.0723, 28988.4414, 29302.6484, 22921.6445,
        35996.2461, 26689.9082, 28158.8359, 23263.4609, 27222.3848, 19842.8770,
        26754.6992, 21979.4707, 26994.0547, 28249.8066, 26293.9355, 31201.8516,
        21055.6504, 24621.7344, 25206.5371, 24796.1797, 26951.0898, 21398.5566,
        26286.0840, 26841.5469, 21591.7480, 29387.4688, 20971.4004, 29297.5176,
        24381.4414, 33481.8398, 26014.1133, 31072.2285, 26816.1934, 23622.9160,
        28075.3418, 30010.4141, 27022.3496, 24411.3672, 23521.7812, 31264.9316,
        34785.7109, 26061.4141, 30366.4336, 27248.9434, 27215.9766, 28431.4688,
        20915.8516, 19851.6270, 23045.1660, 30666.8281, 23595.2266, 31604.1641,
        30549.0117, 35064.4258, 23705.9590, 25752.9473, 25534.0371, 31462.1719,
        25072.8809, 29338.2734, 23754.7949, 27316.4355, 23906.3516, 26689.6875,
        25762.1582, 29282.1895, 19130.2715, 27284.7148, 38371.8945, 28841.1660,
        33327.0781, 26605.8770, 21307.8496, 27678.9980, 30494.3379, 32071.3340,
        25895.4746, 38417.1367, 20989.2422, 26406.9141, 33148.2461, 30698.4121,
        19656.5742, 23038.8281, 26139.3086, 19606.9844, 32969.9766, 29875.2578,
        32575.2910, 35590.9336, 26037.1309, 25330.3301, 33963.2734, 31456.8398,
        33453.2773, 21228.0137, 30173.0977, 22012.4355, 33664.2617, 26161.6035,
        21349.4863, 21302.8047, 22497.6758, 27873.1270, 27056.4844, 25280.4023,
        26487.2676, 21237.9805, 24855.7637, 36267.5078, 22285.3906, 28468.4043,
        22053.1562, 31857.8848, 26258.1250, 19982.3652, 25426.8906, 28483.2676,
        34682.4609, 23343.7949, 22852.1152, 20176.6055, 27225.7207, 21571.0137,
        29480.0000, 28712.6855, 24787.2812, 31424.3535, 23212.0703, 26880.9629,
        27811.7109, 23101.1855, 30699.8359, 27621.5586, 30891.4570, 30547.2988,
        21035.2656, 25243.1367, 20564.3438, 24468.8633, 26365.3535, 24749.5957,
        21261.3320, 30296.5371, 30996.3418, 25932.8359, 32026.6855, 25948.4336,
        22190.3262, 27843.4668, 28736.5703, 25935.6777, 27648.4395, 25837.5664,
        23473.9141, 21141.4453, 30010.3906, 27489.7109, 30480.5000, 18722.7070,
        27916.2441, 29953.9805, 22038.9121, 26337.4844, 28451.8574, 26360.1875,
        27801.1836, 24154.0215, 21439.7051, 33663.4414, 22108.6309, 28167.5703,
        26712.6133, 25873.7617, 26875.7109, 29525.9922, 25415.7188, 30468.7285,
        31471.7695, 25561.0645, 25462.7988, 25793.1191, 36491.4805, 19934.6113,
        23222.2246, 28336.5254, 24953.5586, 27306.2422, 23438.1973, 27675.9883,
        26269.8184, 23787.3281, 20914.9160, 35317.8477, 24533.0645, 25327.2969,
        22780.9668, 22596.3672])
Layer: encoder.7.0.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1580.8918,   38.1548,  339.3494,  ...,  517.3232, 4345.1514,
        2871.8552])
Layer: encoder.7.0.downsample.0
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([1671.3712,  215.7866,  459.6297,  ...,  871.8604, 4318.5610,
        2734.7278])
Layer: encoder.7.1.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 654.7888,  709.7891,  696.6465,  772.2133,  984.1491,  743.0489,
         985.4356,  789.2560,  800.3950, 1022.9559,  742.2805,  659.2640,
         772.6758, 1148.9055,  887.2322,  730.5799,  608.4373,  702.7185,
         833.6788,  785.1878,  925.1104,  622.5391,  908.7003,  764.2008,
         879.3868,  634.7474,  860.7819,  736.5886,  924.2158,  748.8348,
         898.6395,  732.5013,  686.7525,  708.4800, 1020.9601,  958.1752,
        1010.1428,  795.7204,  652.3831,  872.5542,  896.0934,  687.3635,
         785.9742,  933.2659,  694.1833,  678.7566, 1057.1063,  580.4835,
         710.1255,  660.8940,  799.1406,  737.4241,  882.5859,  746.1190,
         829.1805,  673.4861,  653.4316,  839.6575,  686.2794,  646.7151,
         830.8532,  739.6487,  876.0396,  876.8488,  870.7490,  687.6634,
         863.6849,  831.6339,  828.3506,  806.6798, 1033.6125,  852.4885,
         775.9471,  699.7735,  894.4395,  778.0651,  688.4913, 1164.0516,
         801.0403,  789.1684,  756.3104,  687.4252,  727.1266,  690.4801,
         613.3808,  743.1140,  658.4633,  805.1036,  930.4682,  897.1339,
         939.4323,  990.8623,  633.6772, 1066.6776,  817.5281,  762.5087,
         892.2791,  843.8680,  730.9269,  962.3195,  747.7480,  610.1307,
         936.8645,  786.5699, 1021.9957,  711.8329,  727.0657,  811.7071,
         816.5897,  874.1467,  640.4518,  771.5114,  849.3839,  641.5148,
         760.6292,  866.5835,  703.3688,  816.4354,  699.3733,  687.1486,
         751.1875,  822.2951,  597.7205,  851.1977,  873.1088,  854.0242,
         811.3345,  708.9979,  888.2280,  756.6717,  724.0403,  707.1157,
         779.9386,  700.6355,  783.8795,  773.0317,  657.9716,  761.2477,
         894.7802,  811.8798,  807.7452,  827.1331,  942.7203,  780.8818,
         988.5930,  723.4240,  855.3718,  942.6345,  800.3116,  789.0945,
         782.1293,  740.3737,  791.9059,  925.7014, 1137.0125,  711.9724,
         806.1885,  855.4263,  620.4414,  846.5217, 1027.4344,  702.9057,
         941.0115,  747.4340,  657.4004,  672.2005,  798.2604,  731.3759,
         711.4866,  823.5773,  698.8586,  804.1694,  943.2944,  727.6408,
         791.4396,  718.6116,  662.5893,  872.6262,  740.4261,  909.6734,
         654.7440,  922.7359,  814.1803,  805.8527,  645.3071,  783.5131,
         897.7059,  661.8694,  839.3419,  745.5388,  592.1904,  785.2782,
         718.9750,  817.3834,  867.0526,  829.7178,  966.7199,  942.1161,
         908.1846,  778.2379,  745.9017, 1063.6626,  720.6656,  659.0115,
         894.4656, 1058.3093,  647.3897,  828.2300,  689.1740,  988.9871,
         974.8770,  710.8588,  887.1194,  622.9044,  604.4883,  709.2726,
         866.7498, 1012.5962,  861.3377,  661.8801,  847.8498,  665.0169,
         789.7172,  813.6437,  694.7319,  817.4265,  848.5251,  731.5493,
         768.9656, 1013.8966,  808.3875,  697.2477,  682.0961,  835.4204,
         891.8701,  717.2253,  654.8083,  816.0811,  757.2310,  657.0496,
        1029.3595,  760.9573,  768.8544,  859.3762,  951.7803,  822.3580,
         803.5132,  840.5530,  641.2918,  891.4287,  595.2934,  784.2921,
         859.6028,  799.3322,  663.6092,  694.2419, 1003.2259,  833.7757,
         719.4291,  868.4594,  762.0871,  728.5571,  777.6138,  796.9485,
         923.0938,  837.0325,  812.1204,  741.7149,  883.5204,  763.3338,
         975.2917,  647.0874, 1003.9248,  616.5371,  677.2806,  911.4493,
         597.6194,  939.9317,  959.9839,  739.1246,  602.7975,  830.2416,
         819.6608,  911.0496,  772.3857,  759.3742,  809.9503,  873.6238,
         768.5437,  914.0576,  846.4790,  728.1504, 1021.5981,  817.7071,
         678.7675,  563.7487,  586.0085,  726.3187,  565.0684,  747.1887,
         800.6998,  803.0408,  641.7223,  793.9083,  767.2584,  663.3947,
         819.2346,  792.9889,  827.1749,  858.1743,  984.1695,  767.2363,
         586.6695, 1069.0627,  669.3231,  831.4750,  991.6794,  851.1953,
         742.5958,  695.2434,  665.9429,  694.8290,  874.1021,  756.1707,
         721.9352,  804.7925,  738.8157,  701.6061,  851.3699,  849.6547,
         901.4221,  689.8916,  971.4572,  694.5812,  976.4111,  821.9651,
         751.5314,  677.9268, 1021.1559,  940.7708,  758.3013,  673.0658,
         668.0149,  764.1747,  760.5369,  599.4933,  962.3206,  977.2585,
         849.6386,  675.0144,  849.6859,  766.4279,  868.3929,  923.6017,
         639.4025,  705.0637,  845.8110,  784.5675,  761.7232,  795.0772,
        1141.6793,  757.2902,  781.7358,  896.7911,  753.4776,  842.6992,
         810.7947,  968.0058,  678.1819,  695.1971,  683.2987,  881.1259,
         778.7773,  885.7797,  825.6478,  796.1633,  722.8439,  748.5179,
        1032.6432,  772.7977,  759.6995,  843.2975,  739.6872,  865.6202,
         714.6578,  576.3629, 1005.1528,  870.6577,  716.3337,  654.4388,
         869.4189,  772.4668,  748.4773,  750.0306,  816.8486,  861.8564,
         689.6317,  983.0268,  938.4926,  735.0592,  895.5587,  853.5328,
         759.2623,  743.9762,  687.2276,  854.4039,  793.3780,  868.1558,
         663.5321,  847.2267,  913.2405,  820.2076,  764.7930,  722.1608,
         679.3187,  633.5652,  829.2133,  803.9199,  848.7919,  716.8329,
         832.7600,  925.3401, 1080.2389,  895.2589,  881.3404,  714.7153,
         902.4052, 1076.3029,  712.7163,  899.1369,  890.8602,  744.5876,
         823.3185,  936.4110,  743.4135,  734.2289, 1031.5441,  767.3370,
         788.5577,  929.7546,  920.7258,  809.3647,  875.9999,  759.4853,
         734.0679,  808.1406,  811.6782, 1178.4039,  688.2614,  773.7936,
         684.4534, 1036.2531,  598.7689,  711.4009,  848.9926,  904.1951,
         785.9114,  882.2393,  703.7689,  768.4096,  871.1633,  883.8629,
         856.9757, 1033.7972,  696.0616,  686.4715,  693.6495,  849.6095,
         737.9991,  698.5978,  906.7686,  667.1627,  698.5087,  691.5029,
         744.7659,  656.9395,  880.2389,  759.1658,  734.7352,  913.8495,
         849.2803,  767.1097,  822.6584,  781.1590,  878.9734,  999.2285,
         779.4414,  722.0709,  644.7255,  846.5083,  944.3452, 1105.3416,
         883.4249,  631.1425,  838.8819,  638.0312,  859.9938,  777.8619,
         830.4363,  836.3375,  751.8737,  825.3623,  968.7468,  804.5284,
         751.3894,  739.1783,  812.9669,  693.3649,  660.8791,  657.0390,
         846.8680,  984.8362])
Layer: encoder.7.1.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([ 8303.2930,  9798.2529,  6632.9712,  7658.0928,  6634.9756,  8085.5264,
         5374.0405,  7863.6772,  7040.2632,  7553.4268,  8863.8438,  5745.4551,
         6484.5059,  6634.2578,  8313.2314,  8050.7759,  9394.8154,  5664.1626,
         6075.5430,  7236.4570,  5441.6631,  9584.1182,  6651.6206,  7429.2451,
         7939.4585,  7148.6104,  7976.9434,  6654.0767,  7084.1592,  6713.1841,
         6398.5181,  7063.4370,  7648.8745,  6967.7505,  5513.1602,  6210.1338,
         6612.0825,  8420.0420,  6421.0161,  7965.0688,  7782.9087,  6761.9263,
         7637.0601,  7526.9971,  6933.7534,  7356.7002,  6148.4019,  7454.8027,
         5923.2061, 10978.8438,  6798.2734,  6612.6016,  6193.0317,  7508.3755,
         6890.5186,  6208.2612,  7245.8408,  6755.5581,  5675.7798,  7599.2319,
         6811.1094,  6276.2300,  6019.3701,  7498.4351,  7878.3667,  7787.9497,
         7432.1895,  7783.8169,  7838.6284,  6803.0273,  6949.5029,  8149.2451,
         6995.6553,  7653.4316,  6699.2759,  7512.0483,  8081.3809,  6271.7485,
         7257.5386,  6688.5166,  7119.7524,  7848.2222,  9702.4785,  8704.0947,
         7520.4355,  6566.7866,  5875.8340,  6509.1123,  7994.6240,  7054.8638,
         7737.7266,  8571.5244,  6725.2812,  7596.3682,  7127.8794,  7013.4756,
         7132.9893,  7174.1431,  8547.8135,  6742.0483,  6412.2168,  7417.4917,
         7233.8462,  7268.9434,  6407.5757,  8137.5015,  7488.1157, 10390.2021,
         8070.8779,  7061.1147,  7443.8853,  9430.8486,  6446.1221,  6682.5854,
         6699.0205,  6846.2100,  6126.6479,  7127.2646,  5900.9775,  6912.1572,
         6663.2754,  6258.3687,  5440.6338,  6665.6860,  8235.1143,  7734.3501,
         6493.9551,  5396.2598,  7225.6890,  6565.1729,  8845.1602,  6277.4312,
         8822.4014,  6262.0381,  8765.6982,  8826.6992,  8188.2549,  5679.2505,
         7995.0923,  5745.3945,  7205.2217,  7811.5283,  7979.1870,  6603.3931,
         6899.8408,  7995.3379,  6352.2769,  6084.8691,  6734.1313,  7436.2539,
         6704.3877,  7191.3213,  6781.0400,  6968.6250,  6924.5752,  8634.3555,
         7112.8760,  7228.3735,  7905.9116,  6388.8408,  7062.9609,  6069.2046,
         8178.6392,  6566.8350,  8324.0371,  5821.3198,  8613.6309,  9546.2256,
         6915.1802,  7280.6494,  6949.3735,  8985.0654,  7550.2778,  8500.4424,
         7642.8032,  7287.0781,  8446.2578,  7774.5557,  6586.0361,  7947.7407,
         7590.5918,  6821.8574,  6525.0718,  7690.5913,  7645.3789,  7011.3599,
         7859.1514,  6675.8979,  7169.8682,  6573.1182,  7574.3481,  6221.8130,
         6858.8687,  5440.9414,  7011.8887,  6578.3525,  6739.4355,  6464.7212,
         6172.5322,  5802.3540,  6873.8291,  7404.9082,  8995.1074,  8075.8262,
         6345.0186,  6978.9512,  7266.8579,  8443.0137,  6993.9565,  5310.8608,
         7162.4106,  6289.4849,  7947.8516,  7014.5137,  7131.4595,  8397.5898,
         6663.2568,  5003.8169,  6921.5957,  5977.2095,  6827.3716,  8753.2939,
         7287.4561,  6839.1821,  8991.3809,  6469.0571,  7046.7241,  7056.1763,
         8605.2773,  7477.7642,  7418.3711,  7638.2427,  6920.8369,  7958.3696,
         6714.2891,  6426.6128,  7798.0308,  7340.0962,  6455.9849,  8504.4932,
         6647.8604,  5815.8608,  6770.9106,  6887.2197,  4948.1069,  7186.3579,
         7481.8228,  7428.3037,  7689.3818,  6899.5479,  7021.3857,  6928.6685,
         6406.0103,  6362.0039,  6658.4023,  9285.5322,  7967.1943,  6405.0928,
         8094.5938,  6396.5850,  6735.0371,  9201.3027,  7537.7915,  7610.7085,
         6418.6929,  6794.9414,  7418.8062,  8798.8066,  7125.8174,  7089.4634,
         7205.9214,  6295.3599,  7558.2832,  5839.3462,  7792.1113,  7902.6841,
         7725.1860,  7028.9482,  5094.3228,  6870.8711,  7138.1396,  6899.7993,
         7191.9624,  6546.9355,  8370.4365,  7342.7891,  7983.3115,  6329.4932,
         7177.2139,  6458.4570,  8585.6914,  6481.0273,  7791.8467,  6879.7827,
         6133.2842,  8653.1953,  5731.5942,  7634.0444,  7381.2188,  6502.8535,
         7209.6050,  5810.7290,  6386.3911,  9837.3271,  6699.5669,  7063.9888,
         5986.9746,  6572.4702,  6755.8882,  6821.2949,  7581.4619,  6618.4150,
         6886.9307,  7468.0488,  6616.5957,  7009.4097,  8207.0811,  7286.0566,
         7211.4893,  7519.5068,  7343.2437,  6111.9756,  8152.1289,  7111.3867,
         6827.8037,  7085.3120,  7216.6519,  7341.6465,  7926.6689,  6250.2368,
         7117.8306,  7788.6826,  7352.8149,  8150.7783,  7653.9160,  5700.4326,
         6249.7061,  7591.8979,  7625.2354,  5849.1509,  8682.5498,  4983.9673,
         7582.1899,  8331.5566,  6612.6553,  6022.2847,  5531.1035,  6558.6831,
         6055.5083,  5324.6733,  7693.0942,  8701.0449,  5924.5664,  6552.7510,
         5798.6138,  7023.6099,  6136.5420,  8789.3066,  7733.6484,  7385.3555,
         6963.6587,  6460.5845,  6800.5488,  9957.4883,  6738.9033,  5880.4189,
         5855.4390,  6705.0254,  7171.2783,  6853.0967,  8948.6787,  6238.5869,
         7178.4155,  6663.4019,  7948.6807,  9520.1650,  5923.1431,  6422.9585,
         8180.5728,  7788.2979,  6952.0283,  6807.8955,  6559.0938,  6828.5269,
         7491.3442,  6319.7383,  7253.5586,  6542.2915,  6413.8496,  7822.5352,
         7427.1416,  9780.3779,  6427.3184,  5689.5811,  7312.6978,  7999.1968,
         7574.3628,  7225.5059,  6041.7881,  6543.5117,  5960.9404,  6715.4355,
         7608.3052,  6205.4980,  7822.2192,  7403.4482,  7138.9902,  8002.9028,
         7353.8032,  8299.2578,  7439.9214,  6616.6426,  8458.6826,  5519.5352,
         6573.8071,  5887.3013,  7239.0264,  8806.8262,  7192.5342,  9929.7822,
         7860.8174,  5769.7275,  7269.1104,  7028.3916,  7257.3540,  8025.3081,
         8974.5439,  7276.3433,  8776.2617,  6821.4497,  7948.9229,  7478.5908,
         6475.1904,  5876.6675,  6033.0879,  6409.0386,  6113.7163,  6516.7588,
         8686.0674,  7255.9609,  6857.4561,  7083.2803,  7613.7510,  6030.5005,
         7275.2441,  8226.6611,  8165.3506,  6426.4043,  5931.9121,  6813.2842,
         5517.9214,  7164.3530,  7032.4238,  7792.1187,  7329.2676,  8364.7207,
         5851.3555,  6942.6304,  7477.0483,  8491.1719,  7100.6123,  6639.0610,
         7014.0796,  6751.8018,  6446.3765,  6148.0566,  7287.0732,  6863.4414,
         7321.0532,  7524.5303,  7883.9707,  6596.3804,  6971.5254,  5614.3521,
         7220.5278,  7338.2402,  7700.9551,  6734.6694,  7136.0293,  5636.7119,
         7268.3203,  7353.1533,  7041.7539,  6551.0874,  5394.6211,  7979.9385,
         8574.4346,  7589.6255,  8118.3916,  7707.5205,  7864.2524,  7304.1382,
         6595.0908,  6859.3086,  7292.3560,  7792.9116,  6729.2573,  6320.5557,
         8194.4941,  5384.0562,  6614.0459,  5586.3643,  6979.0815,  6759.0176,
         9238.4697,  7740.9907,  8185.8394,  7135.1143,  6651.9424,  6352.1060,
         6983.1592,  7449.4429])
Layer: encoder.7.1.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([135.0041,  39.4600, 903.7475,  ..., 243.5495, 817.6992, 216.9193])
Layer: encoder.7.2.conv1
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([517.0196, 574.6078, 434.7454, 449.6288, 449.6983, 475.9615, 499.2723,
        420.9833, 412.9988, 569.4041, 618.7405, 452.4937, 564.8644, 363.3859,
        505.8278, 439.6046, 635.2363, 474.8245, 401.8936, 466.1898, 468.5129,
        703.0812, 467.7445, 368.5706, 593.1123, 432.9322, 529.4144, 374.1097,
        571.4586, 667.8574, 492.7699, 797.1534, 373.4934, 394.0449, 732.0703,
        549.3548, 473.5643, 603.1478, 483.5438, 526.4558, 631.8069, 672.1957,
        538.3978, 529.3529, 371.9464, 572.6600, 406.5458, 437.3257, 445.6121,
        421.8132, 459.5922, 670.5169, 398.5575, 593.5529, 413.8857, 448.3973,
        474.8805, 646.4853, 523.8859, 491.4464, 515.7225, 528.5331, 503.4590,
        564.6191, 438.3401, 401.8219, 760.7202, 518.2338, 604.2936, 551.4013,
        445.6310, 530.5416, 494.1294, 479.2367, 408.6164, 523.1550, 492.6043,
        471.7843, 512.8718, 570.7885, 637.6464, 480.9111, 634.4958, 443.2925,
        502.4947, 511.1362, 344.6089, 622.0458, 599.1832, 481.5622, 561.4981,
        559.7311, 694.8909, 637.5273, 614.7432, 513.1452, 661.9092, 457.4409,
        587.9363, 542.5123, 441.8748, 593.6800, 596.3421, 572.2839, 664.0269,
        587.5909, 432.6987, 869.1990, 370.9902, 443.0639, 470.9972, 446.7634,
        400.7274, 462.8200, 389.3669, 537.0632, 446.9926, 517.3048, 764.8510,
        439.5689, 454.5711, 460.7627, 455.6515, 509.5019, 585.0270, 556.3514,
        489.9210, 528.4073, 729.4741, 556.5410, 627.8107, 484.1933, 519.5486,
        488.7104, 603.6431, 436.6825, 775.5233, 501.4777, 405.9679, 365.0578,
        473.2585, 528.7433, 493.2076, 587.3469, 677.6700, 447.1451, 524.9644,
        444.5976, 547.9251, 579.6349, 495.4400, 402.2363, 430.0212, 568.4070,
        421.6783, 490.5988, 472.2950, 374.4820, 370.1485, 434.5483, 490.2446,
        450.5284, 547.0853, 485.3339, 554.8896, 483.4854, 553.9723, 549.3794,
        455.7390, 478.0518, 579.8046, 442.7378, 509.3669, 347.8401, 585.9028,
        496.1047, 501.3137, 388.7122, 519.1686, 542.9736, 468.2848, 472.8250,
        437.7927, 620.8730, 415.4257, 539.1672, 510.3907, 682.4512, 588.4437,
        427.8831, 512.6342, 473.0591, 363.6625, 495.3376, 492.3062, 534.1789,
        639.9799, 659.2691, 455.6019, 538.5375, 477.0858, 677.2596, 452.0764,
        609.7486, 427.7774, 413.2500, 474.6724, 574.9941, 535.1862, 413.3383,
        418.2045, 514.1141, 448.5803, 326.1842, 446.4486, 603.2291, 468.9467,
        506.6318, 427.4485, 656.2557, 409.8044, 482.0660, 535.2059, 521.2321,
        369.2427, 703.4440, 626.7303, 539.6826, 482.0424, 410.8064, 566.4809,
        586.9618, 455.8439, 376.4859, 576.8265, 560.7842, 514.1733, 394.4856,
        618.8558, 682.6786, 458.0909, 604.6904, 423.3998, 690.2759, 406.2720,
        404.9139, 629.3866, 506.3304, 474.4955, 416.9066, 598.7910, 413.4350,
        447.9076, 604.6181, 647.2690, 461.3837, 495.4391, 491.8282, 789.6027,
        577.0894, 741.6125, 537.6205, 476.7539, 485.8923, 600.6519, 437.4346,
        591.2346, 464.9053, 414.9432, 427.4420, 463.7260, 620.3290, 683.7547,
        433.1991, 605.6666, 486.8260, 572.0987, 520.1641, 454.2058, 539.1606,
        669.5403, 428.3289, 370.2997, 640.9166, 442.7247, 567.6434, 457.4540,
        437.6168, 565.5991, 539.3723, 704.9478, 525.5190, 533.8307, 516.1196,
        394.1699, 719.6266, 768.1663, 648.6714, 646.6709, 416.6604, 500.4030,
        438.5179, 351.6154, 519.7204, 597.0422, 398.9331, 574.0895, 669.3866,
        536.5813, 502.7502, 497.7947, 422.2437, 575.9855, 593.6157, 546.2281,
        459.0525, 465.7087, 385.0039, 419.3967, 347.2585, 438.7312, 718.9382,
        594.9360, 566.5332, 671.1248, 514.8922, 511.4791, 511.1623, 422.6781,
        455.1694, 618.3001, 477.6367, 573.2087, 454.9485, 443.2445, 578.1558,
        534.7541, 473.7773, 573.0412, 457.0718, 479.8201, 580.4922, 521.0602,
        666.7676, 613.3146, 471.1671, 598.7750, 391.2695, 447.3717, 557.7200,
        542.6378, 530.2051, 449.4284, 433.5450, 484.8777, 444.1214, 523.4462,
        493.0248, 471.6194, 602.8603, 484.5511, 462.9270, 631.2697, 652.8135,
        418.5154, 402.4164, 393.1292, 459.0857, 419.4462, 487.9996, 439.4257,
        436.8305, 366.1512, 405.0908, 640.7106, 464.4081, 432.6537, 536.1708,
        398.6646, 579.7482, 503.2380, 498.3734, 481.6685, 384.6701, 507.1442,
        561.5567, 409.6924, 474.7889, 557.5059, 543.9504, 411.7990, 529.1730,
        623.9863, 653.3872, 581.7817, 365.0397, 434.6860, 617.4414, 459.6116,
        541.5576, 406.8450, 732.3764, 412.8449, 544.4699, 624.0209, 473.5917,
        389.2647, 370.8669, 573.4161, 419.0122, 461.2615, 654.3153, 486.5304,
        511.2411, 652.1184, 498.1899, 608.8921, 765.9489, 490.6934, 440.8570,
        536.0398, 589.8998, 504.2278, 413.0342, 701.5273, 586.1854, 549.3380,
        510.8029, 651.4033, 409.9651, 541.6702, 458.9873, 564.7131, 403.5547,
        617.5595, 413.0829, 488.7978, 469.6125, 513.9399, 493.6297, 515.9843,
        566.2495, 512.9068, 417.2429, 396.7081, 413.9098, 653.9396, 518.2914,
        537.8093, 696.5264, 494.8493, 487.3376, 420.0092, 578.1200, 587.5648,
        643.5613, 530.4090, 404.0332, 610.2410, 765.0695, 561.5786, 419.6389,
        580.0266, 432.0693, 532.1546, 517.0308, 499.2654, 640.7905, 349.6015,
        425.5093, 366.8189, 525.0812, 651.6769, 966.1644, 582.5325, 435.8394,
        524.2519, 614.9797, 770.2573, 562.4438, 579.1965, 609.1951, 634.9751,
        550.2770, 455.5549, 442.7785, 524.0029, 549.0779, 792.6688, 527.5100,
        522.2530, 480.1059, 492.2946, 432.4316, 496.5067, 572.7248, 449.4189,
        445.3242, 303.8669, 721.1024, 601.1169, 427.7734, 372.6724, 482.9659,
        556.0187, 539.3764, 475.9171, 591.6575, 552.7900, 602.8801, 399.9532,
        557.7056])
Layer: encoder.7.2.conv2
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([7090.9268, 4665.1479, 7133.1821, 5845.6440, 4166.2632, 5053.9907,
        5212.0225, 5996.0332, 7048.4541, 4994.7461, 5480.5107, 8158.9292,
        5408.6558, 5087.4717, 5328.0361, 5337.7700, 5260.8047, 4770.2246,
        6681.5747, 5502.9087, 7187.7749, 5164.2456, 5191.7778, 5225.2065,
        4991.0352, 4652.5332, 4741.6797, 5718.7705, 5560.8433, 4977.4404,
        7275.4360, 5025.2012, 4689.5894, 6093.3032, 5831.8560, 6088.0029,
        5352.8789, 5037.3091, 6758.4092, 4454.8125, 5643.4819, 5952.6313,
        7958.8652, 4762.3081, 5891.9678, 7286.6704, 5234.6509, 5211.2207,
        4564.8335, 4691.1221, 6033.4307, 5197.1025, 5412.9922, 4770.3965,
        3775.8088, 4617.0830, 5211.7227, 6208.0215, 4914.7031, 5123.9741,
        6630.6963, 4275.2720, 4334.2520, 5462.5171, 5713.7144, 4691.1445,
        5872.5508, 6665.2573, 5238.8687, 3880.7080, 6852.2319, 6896.7422,
        3685.3923, 4963.2485, 5551.0479, 6303.0000, 6086.5669, 4872.9688,
        5361.7598, 6105.0483, 6964.0610, 3924.0757, 6126.7935, 4846.8682,
        4494.7930, 5644.6333, 5625.4224, 5138.5425, 5976.3057, 6549.5771,
        6016.4014, 6427.2988, 5233.5020, 5547.4331, 4913.1768, 4617.1484,
        6133.8438, 7187.9175, 5224.7637, 5132.2432, 7574.2979, 5311.1631,
        4899.5786, 5270.6343, 4704.2217, 6235.4722, 6134.5527, 4600.6494,
        5222.0142, 4354.1089, 6025.0815, 6115.1001, 4378.5957, 6008.9512,
        5421.0142, 7599.5708, 6612.5293, 4992.1616, 4726.6934, 5044.3193,
        5734.6074, 5858.5981, 5863.5796, 5092.7739, 5636.3311, 4220.5366,
        4280.5459, 6410.5024, 4816.5664, 5499.1724, 7228.9683, 4059.5549,
        5583.8105, 5999.4658, 6708.0078, 4532.9932, 6821.9307, 6618.1260,
        5521.2021, 6713.7153, 5217.9805, 7042.7275, 5304.3906, 4835.5791,
        6609.9766, 4742.8306, 4768.5156, 7528.1289, 5764.0273, 4830.3096,
        6766.6680, 5176.6460, 6010.6406, 6335.8301, 7710.8364, 4134.0713,
        6448.4761, 4962.3613, 6056.5127, 5231.3262, 5441.9282, 5728.6948,
        4579.8711, 5564.6772, 5525.0835, 6260.6113, 5598.1631, 6033.4277,
        5951.7603, 5935.7305, 5642.4878, 5364.6011, 5975.9355, 7004.8926,
        4579.6270, 5554.6172, 6385.7231, 4806.6558, 5126.9238, 5410.8472,
        5343.3486, 5745.8096, 5323.7856, 5353.3428, 4396.1929, 4900.1831,
        4842.0698, 6341.3867, 4302.0933, 7232.9116, 6520.9497, 6051.9561,
        5672.8252, 8131.9512, 5329.0938, 5671.4961, 4695.2632, 6249.7827,
        4645.5078, 4862.0781, 6448.4082, 5052.2188, 4255.9771, 6705.1387,
        6245.1182, 5038.5898, 5842.0928, 7165.7407, 6138.0581, 6527.4224,
        6331.8188, 4746.5991, 4289.6396, 6247.7417, 4467.7144, 5003.2949,
        4550.8560, 5322.1382, 3760.3450, 8220.1738, 6276.4438, 3985.4507,
        6133.1387, 4853.9395, 5016.2266, 5158.6245, 4597.7339, 4953.8833,
        6288.0654, 6829.2051, 4746.6523, 6187.0112, 5460.6104, 6206.9966,
        5121.4595, 5165.0435, 4846.1143, 5452.9243, 5511.8242, 5527.0664,
        5482.4609, 6797.3643, 6891.9688, 7059.7173, 5765.0645, 5103.9663,
        5052.5845, 5338.1182, 4477.4443, 7031.6733, 4738.4619, 5474.7798,
        5612.6406, 5122.4004, 5808.4888, 4922.3438, 4731.7417, 4718.7598,
        4102.7065, 4285.6235, 4893.5088, 5656.3149, 6065.8970, 4951.6548,
        5849.3228, 5029.2505, 4960.7808, 5401.3442, 4638.2837, 5515.9868,
        5211.6743, 5244.6606, 5585.9678, 5821.3599, 6412.2373, 6638.7930,
        4581.9780, 6077.2549, 4326.0483, 4528.3682, 5733.3843, 6614.0859,
        4455.6777, 4685.6899, 7212.8960, 5087.7476, 4726.3613, 7316.4160,
        8503.8906, 5637.5024, 6188.7510, 4985.3438, 6270.0640, 5731.7920,
        5710.5049, 4901.6807, 4503.7012, 4292.1079, 7502.7578, 6186.8809,
        7126.8101, 4926.7168, 5052.0918, 5087.1426, 5099.2495, 7064.5068,
        4790.2827, 5022.3052, 5655.4722, 5733.4287, 4958.7417, 4053.9277,
        4765.1294, 5465.1479, 4870.0073, 5237.3335, 5597.8516, 5434.9849,
        6728.4868, 6675.9468, 5242.1440, 5878.5942, 4999.6553, 7718.2827,
        4570.6050, 5268.2539, 5935.5527, 6855.9482, 4908.5781, 7694.7490,
        6742.8481, 4990.8315, 5215.1934, 4587.6929, 5128.0283, 5177.3848,
        6994.6660, 5167.9150, 5746.3799, 5357.9834, 5604.0508, 5504.1826,
        7248.1626, 6996.0229, 5589.1553, 5153.2632, 5807.4985, 7072.8403,
        5267.5142, 6257.9492, 4553.1772, 4466.8594, 4982.6133, 5490.6958,
        4267.2900, 7167.2842, 3991.5830, 6106.2808, 5449.2637, 5266.3604,
        5346.8770, 5946.2129, 4025.9382, 4707.7808, 5627.4443, 5909.5327,
        5997.1196, 5992.7271, 7278.4233, 5523.1216, 6573.4102, 4340.2314,
        7273.0254, 5567.5098, 5581.6235, 6854.4512, 5770.3521, 5760.2788,
        6247.9058, 4158.3613, 5470.8726, 5296.4165, 5994.6011, 5681.7417,
        3524.9783, 5116.1343, 6075.2280, 5435.8276, 5449.6309, 4231.4526,
        5414.3418, 6545.2202, 5871.6343, 7640.5308, 5373.8477, 4761.6079,
        5971.9780, 5758.6387, 5426.7207, 5074.3579, 6516.2559, 5257.8628,
        6577.0835, 6073.0620, 4378.0796, 6382.4204, 3402.5425, 5476.2056,
        7272.9062, 5875.9458, 5241.1040, 5284.1362, 6076.7617, 4767.1675,
        4906.0415, 5305.8467, 4490.0083, 4332.9751, 3736.9888, 5066.1714,
        4651.3174, 5790.4302, 4875.0430, 3907.7195, 7860.9355, 4276.3135,
        5762.0747, 4759.6006, 6583.0889, 6449.2461, 5856.5039, 6380.1709,
        6062.4365, 4542.8145, 6223.5659, 4247.1196, 7101.2378, 6435.2329,
        5573.0181, 6184.6738, 5222.9814, 5566.4395, 7277.0137, 8609.2227,
        7068.3164, 5431.6948, 7712.9956, 4537.2065, 6326.4170, 7847.1187,
        6929.4658, 5628.3247, 6251.3721, 5209.0073, 7551.0854, 4899.9712,
        6617.2637, 4272.1069, 4779.7363, 5292.1875, 4255.1826, 7565.5591,
        4968.5552, 5737.6030, 5632.4824, 7034.4741, 6224.6167, 6325.8750,
        7576.7988, 5463.7383, 6929.0801, 5724.7783, 5641.6738, 5243.1548,
        5886.2769, 4874.4316, 5804.9478, 6164.1562, 5326.6069, 5696.6636,
        4564.5107, 5645.5728, 4258.6670, 5972.0156, 5277.1523, 4635.7271,
        7959.9927, 4750.5640, 5187.8970, 4984.1787, 4420.7544, 6072.6479,
        6028.6812, 4734.9463, 7906.6533, 4833.1255, 4933.9561, 5834.6235,
        5077.4370, 4657.7300, 4813.7637, 5406.7812, 5429.7808, 6143.6152,
        7710.4287, 4279.2842, 6087.4512, 5271.9277, 6547.6606, 4143.8027,
        6188.8491, 5257.7305])
Layer: encoder.7.2.conv3
Type of relevance_map: <class 'torch.Tensor'>
Content of relevance_map: tensor([188.5481,  15.8750, 505.7357,  ..., 306.7366, 856.7117, 139.5302])
[DEBUG] Global concept maps computed with 53 layers.
[INFO] Using device: cuda
Layer: conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.4.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.4.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.4.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.4.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.4.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.4.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.4.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.5.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.5.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1.], device='cuda:0')}}
Layer: encoder.5.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0.], device='cuda:0')}}
Layer: encoder.5.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0.], device='cuda:0')}}
Layer: encoder.5.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.5.3.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 0.], device='cuda:0')}}
Layer: encoder.5.3.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0')}}
Layer: encoder.5.3.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.6.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.6.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0')}}
Layer: encoder.6.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.6.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')}}
Layer: encoder.6.3.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.3.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.3.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.4.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.6.4.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.4.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.6.5.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0')}}
Layer: encoder.7.0.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')}}
Layer: encoder.7.0.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0')}}
Layer: encoder.7.0.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.0.downsample.0
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.1.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.7.1.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.7.1.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}}
Layer: encoder.7.2.conv1
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0')}}
Layer: encoder.7.2.conv2
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0')}}
Layer: encoder.7.2.conv3
Type of relevance_map: <class 'dict'>
Content of relevance_map: {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}}
[DEBUG] Global pruning mask: OrderedDict([('conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0')}}), ('encoder.4.0.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0')}}), ('encoder.4.0.conv2', {'Conv2d': {'weight': tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0')}}), ('encoder.4.0.conv3', {'Conv2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.0.downsample.0', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,
        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.1.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0')}}), ('encoder.4.1.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.1.conv3', {'Conv2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.4.2.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,
        0., 1., 1., 0., 1., 1., 0., 0., 1., 1.], device='cuda:0')}}), ('encoder.4.2.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.4.2.conv3', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 0.], device='cuda:0')}}), ('encoder.5.0.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1.], device='cuda:0')}}), ('encoder.5.0.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,
        1., 1.], device='cuda:0')}}), ('encoder.5.0.conv3', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0')}}), ('encoder.5.0.downsample.0', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.1.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1.], device='cuda:0')}}), ('encoder.5.1.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1.], device='cuda:0')}}), ('encoder.5.1.conv3', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.2.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0.], device='cuda:0')}}), ('encoder.5.2.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0.], device='cuda:0')}}), ('encoder.5.2.conv3', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.5.3.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 0.], device='cuda:0')}}), ('encoder.5.3.conv2', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 1.], device='cuda:0')}}), ('encoder.5.3.conv3', {'Conv2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,
        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,
        0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.0.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.0.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.0.conv3', {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 0.], device='cuda:0')}}), ('encoder.6.0.downsample.0', {'Conv2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 0.,  ..., 0., 1., 0.], device='cuda:0')}}), ('encoder.6.1.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.1.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,
        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.1.conv3', {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.2.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0.], device='cuda:0')}}), ('encoder.6.2.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0.], device='cuda:0')}}), ('encoder.6.2.conv3', {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:0')}}), ('encoder.6.3.conv1', {'Conv2d': {'weight': tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.3.conv2', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.3.conv3', {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.4.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 1.], device='cuda:0')}}), ('encoder.6.4.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.4.conv3', {'Conv2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 1., 1.,  ..., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.5.conv1', {'Conv2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1.], device='cuda:0')}}), ('encoder.6.5.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.,
        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 1., 0., 1.], device='cuda:0')}}), ('encoder.6.5.conv3', {'Conv2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0'), 'bias': tensor([0., 0., 1.,  ..., 0., 0., 1.], device='cuda:0')}}), ('encoder.7.0.conv1', {'Conv2d': {'weight': tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0'), 'bias': tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,
        1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,
        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,
        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')}}), ('encoder.7.0.conv2', {'Conv2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0'), 'bias': tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,
        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,
        0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,
        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,
        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,
        1., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0')}}), ('encoder.7.0.conv3', {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.0.downsample.0', {'Conv2d': {'weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.1.conv1', {'Conv2d': {'weight': tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,
        1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,
        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,
        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0')}}), ('encoder.7.1.conv2', {'Conv2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,
        0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,
        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,
        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,
        0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0')}}), ('encoder.7.1.conv3', {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}}), ('encoder.7.2.conv1', {'Conv2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0'), 'bias': tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,
        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
        0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,
        1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,
        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,
        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
        0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1.], device='cuda:0')}}), ('encoder.7.2.conv2', {'Conv2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,
        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,
        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,
        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,
        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.,
        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,
        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,
        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,
        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,
        0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,
        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
        1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,
        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,
        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,
        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,
        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,
        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,
        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,
        1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0')}}), ('encoder.7.2.conv3', {'Conv2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}, 'BatchNorm2d': {'weight': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0'), 'bias': tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:0')}})])
Full profiling results saved to /home/paul/projects/CV4RS-main/pruning_callgraph.txt
=== Round 2/3 ===
Applying pruning mask for Round 2...
[DEBUG] Validating mask for layer: conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 10, 7, 7])
[INFO] Successfully applied mask to weight in layer: conv1
[DEBUG] Layer conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 10, 7, 7])
[INFO] Successfully applied mask to weight in layer: conv1
[DEBUG] Layer conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: conv1
[DEBUG] Validating mask for layer: encoder.4.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv1
[DEBUG] Layer encoder.4.0.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv1
[DEBUG] Layer encoder.4.0.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv1
[DEBUG] Validating mask for layer: encoder.4.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv2
[DEBUG] Layer encoder.4.0.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv2
[DEBUG] Layer encoder.4.0.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv2
[DEBUG] Validating mask for layer: encoder.4.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv3
[DEBUG] Layer encoder.4.0.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.conv3
[DEBUG] Layer encoder.4.0.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.conv3
[DEBUG] Validating mask for layer: encoder.4.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.downsample.0
[DEBUG] Layer encoder.4.0.downsample.0 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.0.downsample.0
[DEBUG] Layer encoder.4.0.downsample.0 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.0.downsample.0
[DEBUG] Validating mask for layer: encoder.4.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv1
[DEBUG] Layer encoder.4.1.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv1
[DEBUG] Layer encoder.4.1.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv1
[DEBUG] Validating mask for layer: encoder.4.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv2
[DEBUG] Layer encoder.4.1.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv2
[DEBUG] Layer encoder.4.1.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv2
[DEBUG] Validating mask for layer: encoder.4.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv3
[DEBUG] Layer encoder.4.1.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.1.conv3
[DEBUG] Layer encoder.4.1.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.1.conv3
[DEBUG] Validating mask for layer: encoder.4.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv1
[DEBUG] Layer encoder.4.2.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv1
[DEBUG] Layer encoder.4.2.conv1 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv1
[DEBUG] Validating mask for layer: encoder.4.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv2
[DEBUG] Layer encoder.4.2.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([64, 64, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv2
[DEBUG] Layer encoder.4.2.conv2 has bias with shape torch.Size([64])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv2
[DEBUG] Validating mask for layer: encoder.4.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.4.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv3
[DEBUG] Layer encoder.4.2.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 64, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.4.2.conv3
[DEBUG] Layer encoder.4.2.conv3 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.4.2.conv3
[DEBUG] Validating mask for layer: encoder.5.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv1
[DEBUG] Layer encoder.5.0.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv1
[DEBUG] Layer encoder.5.0.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv1
[DEBUG] Validating mask for layer: encoder.5.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv2
[DEBUG] Layer encoder.5.0.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv2
[DEBUG] Layer encoder.5.0.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv2
[DEBUG] Validating mask for layer: encoder.5.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv3
[DEBUG] Layer encoder.5.0.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.conv3
[DEBUG] Layer encoder.5.0.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.conv3
[DEBUG] Validating mask for layer: encoder.5.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.downsample.0
[DEBUG] Layer encoder.5.0.downsample.0 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.0.downsample.0
[DEBUG] Layer encoder.5.0.downsample.0 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.0.downsample.0
[DEBUG] Validating mask for layer: encoder.5.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv1
[DEBUG] Layer encoder.5.1.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv1
[DEBUG] Layer encoder.5.1.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv1
[DEBUG] Validating mask for layer: encoder.5.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv2
[DEBUG] Layer encoder.5.1.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv2
[DEBUG] Layer encoder.5.1.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv2
[DEBUG] Validating mask for layer: encoder.5.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv3
[DEBUG] Layer encoder.5.1.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.1.conv3
[DEBUG] Layer encoder.5.1.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.1.conv3
[DEBUG] Validating mask for layer: encoder.5.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv1
[DEBUG] Layer encoder.5.2.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv1
[DEBUG] Layer encoder.5.2.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv1
[DEBUG] Validating mask for layer: encoder.5.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv2
[DEBUG] Layer encoder.5.2.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv2
[DEBUG] Layer encoder.5.2.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv2
[DEBUG] Validating mask for layer: encoder.5.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv3
[DEBUG] Layer encoder.5.2.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.2.conv3
[DEBUG] Layer encoder.5.2.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.2.conv3
[DEBUG] Validating mask for layer: encoder.5.3.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv1
[DEBUG] Layer encoder.5.3.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv1
[DEBUG] Layer encoder.5.3.conv1 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv1
[DEBUG] Validating mask for layer: encoder.5.3.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv2
[DEBUG] Layer encoder.5.3.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([128, 128, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv2
[DEBUG] Layer encoder.5.3.conv2 has bias with shape torch.Size([128])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv2
[DEBUG] Validating mask for layer: encoder.5.3.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.5.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv3
[DEBUG] Layer encoder.5.3.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 128, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.5.3.conv3
[DEBUG] Layer encoder.5.3.conv3 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.5.3.conv3
[DEBUG] Validating mask for layer: encoder.6.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv1
[DEBUG] Layer encoder.6.0.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv1
[DEBUG] Layer encoder.6.0.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv1
[DEBUG] Validating mask for layer: encoder.6.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv2
[DEBUG] Layer encoder.6.0.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv2
[DEBUG] Layer encoder.6.0.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv2
[DEBUG] Validating mask for layer: encoder.6.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv3
[DEBUG] Layer encoder.6.0.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.conv3
[DEBUG] Layer encoder.6.0.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.conv3
[DEBUG] Validating mask for layer: encoder.6.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.downsample.0
[DEBUG] Layer encoder.6.0.downsample.0 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.0.downsample.0
[DEBUG] Layer encoder.6.0.downsample.0 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.0.downsample.0
[DEBUG] Validating mask for layer: encoder.6.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv1
[DEBUG] Layer encoder.6.1.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv1
[DEBUG] Layer encoder.6.1.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv1
[DEBUG] Validating mask for layer: encoder.6.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv2
[DEBUG] Layer encoder.6.1.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv2
[DEBUG] Layer encoder.6.1.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv2
[DEBUG] Validating mask for layer: encoder.6.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv3
[DEBUG] Layer encoder.6.1.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.1.conv3
[DEBUG] Layer encoder.6.1.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.1.conv3
[DEBUG] Validating mask for layer: encoder.6.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv1
[DEBUG] Layer encoder.6.2.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv1
[DEBUG] Layer encoder.6.2.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv1
[DEBUG] Validating mask for layer: encoder.6.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv2
[DEBUG] Layer encoder.6.2.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv2
[DEBUG] Layer encoder.6.2.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv2
[DEBUG] Validating mask for layer: encoder.6.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv3
[DEBUG] Layer encoder.6.2.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.2.conv3
[DEBUG] Layer encoder.6.2.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.2.conv3
[DEBUG] Validating mask for layer: encoder.6.3.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv1
[DEBUG] Layer encoder.6.3.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv1
[DEBUG] Layer encoder.6.3.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv1
[DEBUG] Validating mask for layer: encoder.6.3.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv2
[DEBUG] Layer encoder.6.3.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv2
[DEBUG] Layer encoder.6.3.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv2
[DEBUG] Validating mask for layer: encoder.6.3.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv3
[DEBUG] Layer encoder.6.3.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.3.conv3
[DEBUG] Layer encoder.6.3.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.3.conv3
[DEBUG] Validating mask for layer: encoder.6.4.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv1
[DEBUG] Layer encoder.6.4.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv1
[DEBUG] Layer encoder.6.4.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv1
[DEBUG] Validating mask for layer: encoder.6.4.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv2
[DEBUG] Layer encoder.6.4.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv2
[DEBUG] Layer encoder.6.4.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv2
[DEBUG] Validating mask for layer: encoder.6.4.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.4.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv3
[DEBUG] Layer encoder.6.4.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.4.conv3
[DEBUG] Layer encoder.6.4.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.4.conv3
[DEBUG] Validating mask for layer: encoder.6.5.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv1
[DEBUG] Layer encoder.6.5.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv1
[DEBUG] Layer encoder.6.5.conv1 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv1
[DEBUG] Validating mask for layer: encoder.6.5.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv2
[DEBUG] Layer encoder.6.5.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([256, 256, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv2
[DEBUG] Layer encoder.6.5.conv2 has bias with shape torch.Size([256])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv2
[DEBUG] Validating mask for layer: encoder.6.5.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.6.5.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv3
[DEBUG] Layer encoder.6.5.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([1024, 256, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.6.5.conv3
[DEBUG] Layer encoder.6.5.conv3 has bias with shape torch.Size([1024])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.6.5.conv3
[DEBUG] Validating mask for layer: encoder.7.0.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv1
[DEBUG] Layer encoder.7.0.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv1
[DEBUG] Layer encoder.7.0.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv1
[DEBUG] Validating mask for layer: encoder.7.0.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv2
[DEBUG] Layer encoder.7.0.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv2
[DEBUG] Layer encoder.7.0.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv2
[DEBUG] Validating mask for layer: encoder.7.0.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv3
[DEBUG] Layer encoder.7.0.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.conv3
[DEBUG] Layer encoder.7.0.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.conv3
[DEBUG] Validating mask for layer: encoder.7.0.downsample.0
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.downsample.0
[DEBUG] Layer encoder.7.0.downsample.0 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.downsample.0
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 1024, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.0.downsample.0
[DEBUG] Layer encoder.7.0.downsample.0 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.0.downsample.0
[DEBUG] Validating mask for layer: encoder.7.1.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv1
[DEBUG] Layer encoder.7.1.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv1
[DEBUG] Layer encoder.7.1.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv1
[DEBUG] Validating mask for layer: encoder.7.1.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv2
[DEBUG] Layer encoder.7.1.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv2
[DEBUG] Layer encoder.7.1.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv2
[DEBUG] Validating mask for layer: encoder.7.1.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv3
[DEBUG] Layer encoder.7.1.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.1.conv3
[DEBUG] Layer encoder.7.1.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.1.conv3
[DEBUG] Validating mask for layer: encoder.7.2.conv1
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv1
[DEBUG] Layer encoder.7.2.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv1
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 2048, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv1
[DEBUG] Layer encoder.7.2.conv1 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv1
[DEBUG] Validating mask for layer: encoder.7.2.conv2
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv2
[DEBUG] Layer encoder.7.2.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv2
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([512, 512, 3, 3])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv2
[DEBUG] Layer encoder.7.2.conv2 has bias with shape torch.Size([512])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv2
[DEBUG] Validating mask for layer: encoder.7.2.conv3
[WARNING] Mask for Conv2d is not a Tensor: <class 'dict'>
[WARNING] Mask for BatchNorm2d is not a Tensor: <class 'dict'>
[INFO] Applying pruning mask to layer: encoder.7.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv3
[DEBUG] Layer encoder.7.2.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv3
[INFO] Reshaping 1D mask to match 4D weight dimensions.
[DEBUG] Final adjusted mask shape: torch.Size([2048, 512, 1, 1])
[INFO] Successfully applied mask to weight in layer: encoder.7.2.conv3
[DEBUG] Layer encoder.7.2.conv3 has bias with shape torch.Size([2048])
[INFO] Adjusting bias mask to match bias dimensions.
[INFO] Successfully applied mask to bias in layer: encoder.7.2.conv3
Training and communication for Round 2...
Epoch 1/2
----------
Epoch 2/2
----------
Epoch 1/2
----------
Epoch 2/2
----------
Epoch 1/2
----------
Epoch 2/2
----------
Skipping missing parameter: conv1.bias
Skipping missing parameter: encoder.0.bias
Skipping missing parameter: encoder.4.0.conv1.bias
Skipping missing parameter: encoder.4.0.conv2.bias
Skipping missing parameter: encoder.4.0.conv3.bias
Skipping missing parameter: encoder.4.0.downsample.0.bias
Skipping missing parameter: encoder.4.1.conv1.bias
Skipping missing parameter: encoder.4.1.conv2.bias
Skipping missing parameter: encoder.4.1.conv3.bias
Skipping missing parameter: encoder.4.2.conv1.bias
Skipping missing parameter: encoder.4.2.conv2.bias
Skipping missing parameter: encoder.4.2.conv3.bias
Skipping missing parameter: encoder.5.0.conv1.bias
Skipping missing parameter: encoder.5.0.conv2.bias
Skipping missing parameter: encoder.5.0.conv3.bias
Skipping missing parameter: encoder.5.0.downsample.0.bias
Skipping missing parameter: encoder.5.1.conv1.bias
Skipping missing parameter: encoder.5.1.conv2.bias
Skipping missing parameter: encoder.5.1.conv3.bias
Skipping missing parameter: encoder.5.2.conv1.bias
Skipping missing parameter: encoder.5.2.conv2.bias
Skipping missing parameter: encoder.5.2.conv3.bias
Skipping missing parameter: encoder.5.3.conv1.bias
Skipping missing parameter: encoder.5.3.conv2.bias
Skipping missing parameter: encoder.5.3.conv3.bias
Skipping missing parameter: encoder.6.0.conv1.bias
Skipping missing parameter: encoder.6.0.conv2.bias
Skipping missing parameter: encoder.6.0.conv3.bias
Skipping missing parameter: encoder.6.0.downsample.0.bias
Skipping missing parameter: encoder.6.1.conv1.bias
Skipping missing parameter: encoder.6.1.conv2.bias
Skipping missing parameter: encoder.6.1.conv3.bias
Skipping missing parameter: encoder.6.2.conv1.bias
Skipping missing parameter: encoder.6.2.conv2.bias
Skipping missing parameter: encoder.6.2.conv3.bias
Skipping missing parameter: encoder.6.3.conv1.bias
Skipping missing parameter: encoder.6.3.conv2.bias
Skipping missing parameter: encoder.6.3.conv3.bias
Skipping missing parameter: encoder.6.4.conv1.bias
Skipping missing parameter: encoder.6.4.conv2.bias
Skipping missing parameter: encoder.6.4.conv3.bias
Skipping missing parameter: encoder.6.5.conv1.bias
Skipping missing parameter: encoder.6.5.conv2.bias
Skipping missing parameter: encoder.6.5.conv3.bias
Skipping missing parameter: encoder.7.0.conv1.bias
Skipping missing parameter: encoder.7.0.conv2.bias
Skipping missing parameter: encoder.7.0.conv3.bias
Skipping missing parameter: encoder.7.0.downsample.0.bias
Skipping missing parameter: encoder.7.1.conv1.bias
Skipping missing parameter: encoder.7.1.conv2.bias
Skipping missing parameter: encoder.7.1.conv3.bias
Skipping missing parameter: encoder.7.2.conv1.bias
Skipping missing parameter: encoder.7.2.conv2.bias
Skipping missing parameter: encoder.7.2.conv3.bias
[INFO] Starting validation for Round 2...
True labels sample: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]
Predicted labels sample: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
Predicted probabilities sample: [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]
 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]
 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]
 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]
 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
  nan]]
NaN detected in predicted probabilities array.
[[nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 ...
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]]

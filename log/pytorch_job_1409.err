/faststorage/paul/mamba/envs/pytorch_env/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
/faststorage/paul/mamba/envs/pytorch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/faststorage/paul/mamba/envs/pytorch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
training:   0%|          | 0/58 [00:00<?, ?it/s]training:   2%|▏         | 1/58 [00:04<04:39,  4.90s/it]training:   3%|▎         | 2/58 [00:05<02:00,  2.15s/it]training:   5%|▌         | 3/58 [00:05<01:10,  1.29s/it]training:   7%|▋         | 4/58 [00:05<00:47,  1.14it/s]training:   9%|▊         | 5/58 [00:05<00:34,  1.53it/s]training:  10%|█         | 6/58 [00:06<00:27,  1.92it/s]training:  12%|█▏        | 7/58 [00:06<00:22,  2.31it/s]training:  14%|█▍        | 8/58 [00:06<00:18,  2.66it/s]training:  16%|█▌        | 9/58 [00:06<00:16,  2.96it/s]training:  17%|█▋        | 10/58 [00:07<00:14,  3.23it/s]training:  19%|█▉        | 11/58 [00:07<00:13,  3.39it/s]training:  21%|██        | 12/58 [00:07<00:13,  3.51it/s]training:  22%|██▏       | 13/58 [00:07<00:12,  3.67it/s]training:  24%|██▍       | 14/58 [00:08<00:11,  3.69it/s]training:  26%|██▌       | 15/58 [00:08<00:11,  3.76it/s]training:  28%|██▊       | 16/58 [00:08<00:11,  3.81it/s]training:  29%|██▉       | 17/58 [00:08<00:10,  3.84it/s]training:  31%|███       | 18/58 [00:09<00:10,  3.89it/s]training:  33%|███▎      | 19/58 [00:09<00:10,  3.88it/s]training:  34%|███▍      | 20/58 [00:09<00:09,  3.96it/s]training:  36%|███▌      | 21/58 [00:09<00:09,  3.95it/s]training:  38%|███▊      | 22/58 [00:10<00:09,  3.89it/s]training:  40%|███▉      | 23/58 [00:10<00:08,  3.93it/s]training:  41%|████▏     | 24/58 [00:10<00:08,  3.95it/s]training:  43%|████▎     | 25/58 [00:11<00:08,  3.89it/s]training:  45%|████▍     | 26/58 [00:11<00:08,  3.90it/s]training:  47%|████▋     | 27/58 [00:11<00:07,  3.91it/s]training:  48%|████▊     | 28/58 [00:11<00:07,  3.93it/s]training:  50%|█████     | 29/58 [00:12<00:07,  3.91it/s]training:  52%|█████▏    | 30/58 [00:12<00:07,  3.92it/s]training:  53%|█████▎    | 31/58 [00:12<00:06,  3.92it/s]training:  55%|█████▌    | 32/58 [00:12<00:06,  3.92it/s]training:  57%|█████▋    | 33/58 [00:13<00:06,  3.92it/s]training:  59%|█████▊    | 34/58 [00:13<00:06,  3.94it/s]training:  60%|██████    | 35/58 [00:13<00:05,  3.97it/s]training:  62%|██████▏   | 36/58 [00:13<00:05,  3.89it/s]training:  64%|██████▍   | 37/58 [00:14<00:05,  3.91it/s]training:  66%|██████▌   | 38/58 [00:14<00:05,  3.97it/s]training:  67%|██████▋   | 39/58 [00:14<00:04,  3.91it/s]training:  69%|██████▉   | 40/58 [00:14<00:04,  3.90it/s]training:  71%|███████   | 41/58 [00:15<00:04,  3.92it/s]training:  72%|███████▏  | 42/58 [00:15<00:04,  3.93it/s]training:  74%|███████▍  | 43/58 [00:15<00:03,  3.92it/s]training:  76%|███████▌  | 44/58 [00:15<00:03,  3.93it/s]training:  78%|███████▊  | 45/58 [00:16<00:03,  3.92it/s]training:  79%|███████▉  | 46/58 [00:16<00:03,  3.94it/s]training:  81%|████████  | 47/58 [00:16<00:02,  3.93it/s]training:  83%|████████▎ | 48/58 [00:16<00:02,  3.93it/s]training:  84%|████████▍ | 49/58 [00:17<00:02,  3.88it/s]training:  86%|████████▌ | 50/58 [00:17<00:02,  3.94it/s]training:  88%|████████▊ | 51/58 [00:17<00:01,  3.93it/s]training:  90%|████████▉ | 52/58 [00:17<00:01,  3.92it/s]training:  91%|█████████▏| 53/58 [00:18<00:01,  3.94it/s]training:  93%|█████████▎| 54/58 [00:18<00:01,  3.93it/s]training:  95%|█████████▍| 55/58 [00:18<00:00,  3.94it/s]training:  97%|█████████▋| 56/58 [00:18<00:00,  3.92it/s]training:  98%|█████████▊| 57/58 [00:19<00:00,  3.90it/s]training: 100%|██████████| 58/58 [00:19<00:00,  3.84it/s]training: 100%|██████████| 58/58 [00:19<00:00,  2.95it/s]
test:   0%|          | 0/123 [00:00<?, ?it/s]test:   0%|          | 0/123 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/paul/projects/CV4RS-main/train.py", line 47, in <module>
    train()
  File "/home/paul/projects/CV4RS-main/train.py", line 39, in train
    global_model, global_results = global_client.train(
  File "/home/paul/projects/CV4RS-main/utils/clients.py", line 548, in train
    report = self.validation_round()
  File "/home/paul/projects/CV4RS-main/utils/clients.py", line 622, in validation_round
    logits = forward_debug(self.model, data)
  File "/home/paul/projects/CV4RS-main/utils/pytorch_utils.py", line 131, in forward_debug
    x = module(x)
  File "/faststorage/paul/mamba/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/faststorage/paul/mamba/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/faststorage/paul/mamba/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/faststorage/paul/mamba/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
RuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [128, 19]
